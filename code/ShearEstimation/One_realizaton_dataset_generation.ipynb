{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0253a3e6-82bc-4437-a09a-5d6d19984a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import h5py\n",
    "import galsim\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d09a2b5b-1afb-421a-b863-5745350570e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc_rayleigh(sigma, max_val):\n",
    "    assert max_val > sigma\n",
    "    tmp = max_val+1.0\n",
    "    while tmp > max_val:\n",
    "        tmp = np.random.rayleigh(sigma)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f54bfa1-9135-4bbd-9b9c-3f277b025658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11181068014837506\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "test = trunc_rayleigh(.2, .6)\n",
    "print (test)\n",
    "print(type(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "000ba012-3c79-48ab-90fc-d89fcbc7e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc_gaussian(mean, std, min_val):\n",
    "    tmp = min_val+1.0\n",
    "    while tmp < min_val:\n",
    "        tmp = np.random.normal(mean, std_dev)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96336d20-893d-4a2e-abf5-17c15c8edb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psf(x,y):\n",
    "    \n",
    "    psf_sigma = 2.0 + 0.25 * ((x+y)-1)\n",
    "    psf_g1 = 0.25 * 2. * (x-0.5)\n",
    "    psf_g2 = 0.25 * y\n",
    "    \n",
    "    psf_gauss = galsim.Gaussian(sigma=psf_sigma)\n",
    "    psf = psf_gauss.shear(g1=psf_g1, g2=psf_g2)\n",
    "    \n",
    "    return psf, psf_sigma, psf_g1, psf_g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d42f55-f1ed-43f2-b93b-655a682471d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gal_angle():\n",
    "    \n",
    "    theta = 2.0 * np.pi * np.random.uniform(0.0, 1)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b2ffc73-92d1-491a-b047-346e77811fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.576883551722925\n"
     ]
    }
   ],
   "source": [
    "print (get_gal_angle())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a1bb30a-4f69-4603-aba3-976ea8333166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gal_ellipticity(theta):\n",
    "    ellip = trunc_rayleigh(.2, .6)\n",
    "    e1 = ellip * np.cos(2 * theta)\n",
    "    e2 = ellip * np.sin(2* theta)\n",
    "    return e1, e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "666c7388-705f-4b2b-95f9-77ad6cfe57bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.24900957446340594 0.37468872082974086\n",
      "<class 'numpy.float64'> <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "e1, e2 = get_gal_ellipticity(get_gal_angle())\n",
    "print (e1, e2)\n",
    "print (type(e1), type(e2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "795c033f-fb5b-46a0-aaaf-f77557ed9de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shear(shear_range):\n",
    "    shear = np.random.uniform(shear_range[0], shear_range[1])\n",
    "    return shear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "106a0801-906e-4248-8925-5ff9db8299c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flux(S_range, R):\n",
    "    S = np.random.uniform(S_range[0], S_range[1])\n",
    "    F = S * np.pi * (R/.263)**2\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b88d4dc-d6a7-4307-b992-72ac7ff3f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gal(R_range, sersic_n_range, S_range):\n",
    "    R = np.random.uniform(R_range[0], R_range[1])\n",
    "    n = np.random.uniform(sersic_n_range[0], sersic_n_range[1])\n",
    "    F = get_flux(S_range, R)\n",
    "    gal = galsim.Sersic(n = n, half_light_radius = R, flux = F)\n",
    "    return gal, R, n, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aea092b-3d8a-4ab7-9930-2b81d9963cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spiral(R_range, sersic_bulge, sersic_disk_range, S_range):\n",
    "    \n",
    "    frac_disk = np.random.uniform()\n",
    "    \n",
    "    R_disk = np.random.uniform(R_range[0], R_range[1])\n",
    "    S_disk_range = tuple(element * frac_disk for element in S_range)\n",
    "    S_disk = np.random.uniform(S_disk_range[0], S_disk_range[1])\n",
    "    F_disk = S_disk * np.pi * (R_disk/.263)**2\n",
    "    n_d = np.random.uniform(sersic_disk_range[0], sersic_disk_range[1])\n",
    "    \n",
    "    frac_bulge = 1-frac_disk\n",
    "    \n",
    "    R_bulge = np.random.uniform(.4, .6) * R_disk\n",
    "    F_bulge = F_disk/frac_disk * frac_bulge\n",
    "\n",
    "    bulge = galsim.Sersic(n = sersic_bulge, half_light_radius = R_bulge, flux = F_bulge)\n",
    "    disk = galsim.Sersic(n = n_d, half_light_radius = R_disk, flux = F_disk)\n",
    "    \n",
    "    gal = disk + bulge\n",
    "    \n",
    "    return gal, R_bulge, R_disk, n_d, F_bulge+F_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeb545aa-744b-4f99-800e-ea3d5d0cd591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snr():\n",
    "    snr = np.random.normal(60, 30)\n",
    "    snr_value = max(snr, 0.1)\n",
    "    return snr_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c8f7f6a-b777-457d-93a3-adb4640e4c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.129092391648335\n"
     ]
    }
   ],
   "source": [
    "print (get_snr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "342e5cbd-6e10-4293-8a83-32ec5beb2b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 25\n",
    "ny = 25\n",
    "stamp_xsize = 127 # pixel\n",
    "stamp_ysize = 127 # pixel\n",
    "pixel_scale = .263 # arcsec / pixel\n",
    "\n",
    "\n",
    "noise_sigma = 1.\n",
    "\n",
    "shift_radius = .263 # arcsec\n",
    "shift_radius_sq = shift_radius ** 2\n",
    "\n",
    "shear_range = (-0.1, 0.1) # uniform distribution\n",
    "\n",
    "sersic_bulge = 4.\n",
    "sersic_disk_range = (1., 1.5)\n",
    "\n",
    "sersic_n_range = (1.0, 6.0) #uniform distribution\n",
    "\n",
    "# half-light radius\n",
    "R_range = (.526, 2.104) # arcsec, half-light radius, uniform distribution\n",
    "\n",
    "R_disk_range = (.526, 2.104) # arcsec\n",
    "\n",
    "S_range = (1., 15.) # pix^-2, uniform distribution\n",
    "\n",
    "seed_1 = 98237\n",
    "rng_1 = galsim.BaseDeviate(seed_1)\n",
    "random_seed = rng_1.raw() # used for gal simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0e29ab6-ccf9-431f-bd1c-64396c92f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fit_files_directory = os.path.join('/data3/shear_simulated_galaxy', 'fits_files_TEST_noise_free')\n",
    "if not os.path.isdir(fit_files_directory):\n",
    "    os.mkdir(fit_files_directory)\n",
    "    \n",
    "galaxy_path = os.path.join('/data3/shear_simulated_galaxy/fits_files_TEST_noise_free', 'galaxy_images')\n",
    "if not os.path.isdir(galaxy_path):\n",
    "    os.mkdir(galaxy_path)\n",
    "psf_path = os.path.join('/data3/shear_simulated_galaxy/fits_files_TEST_noise_free', 'psf_images')\n",
    "if not os.path.isdir(psf_path):\n",
    "    os.mkdir(psf_path)\n",
    "    \n",
    "hdf5_path = '/data3/shear_simulated_galaxy/NonUniformPsf_image127x127_with_Metadata_TEST_noise_free.hdf5'\n",
    "hf = h5py.File(hdf5_path, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cf6a976-385d-4d35-b3e8-879f687e278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = []\n",
    "batch_size = 5000\n",
    "csv_file_path = os.path.join('/data3/shear_simulated_galaxy', 'Metadata_TEST_noise_free.csv')\n",
    "\n",
    "image_id_counter = 0\n",
    "    \n",
    "gal_image = galsim.ImageF(stamp_xsize * nx, stamp_ysize * ny, scale = pixel_scale)\n",
    "psf_image = galsim.ImageF(stamp_xsize * nx, stamp_ysize * ny, scale = pixel_scale)\n",
    "#image = galsim.ImageF(stamp_xsize * nx, stamp_ysize * ny, scale = pixel_scale)\n",
    "\n",
    "for iy in range(ny):\n",
    "    for ix in range(nx):\n",
    "\n",
    "        rng = galsim.BaseDeviate(random_seed+ix)\n",
    "        snr = get_snr()\n",
    "        \n",
    "        isSpiral = False\n",
    "\n",
    "        #rng_s = galsim.BaseDeviate(seed_1+k+1)\n",
    "        #rng_s1 = galsim.BaseDeviate(seed_3+k+1)\n",
    "        #ud = galsim.UniformDeviate(random_seed+k+1)\n",
    "\n",
    "\n",
    "        # create galaxy in this subimage\n",
    "        \n",
    "        if (np.random.uniform() <= 0.5):\n",
    "            gal, R, n, F = get_gal(R_range, sersic_n_range, S_range)\n",
    "        else:\n",
    "            gal, R_bulge, R_disk, n, F = get_spiral(R_range, sersic_bulge, sersic_disk_range, S_range)\n",
    "            isSpiral = True\n",
    "            \n",
    "            #get_gal(R_range, sersic_n_range, pixel_scale, S_range)\n",
    "        \n",
    "        # add ellipticity to galaxy\n",
    "        theta = get_gal_angle()\n",
    "        e1, e2 = get_gal_ellipticity(theta)\n",
    "        gal = gal.shear(g1=e1, g2=e2)\n",
    "\n",
    "        # shear the galaxy\n",
    "        g1 = get_shear(shear_range)\n",
    "        g2 = get_shear(shear_range)\n",
    "        shear_gal = gal.lens(g1 = g1, g2 = g2, mu = 1.)\n",
    "        \n",
    "        # shift galaxy\n",
    "        rsq = 2 * shift_radius_sq\n",
    "        while (rsq > shift_radius_sq):\n",
    "            dx = (2*np.random.random()-1) * shift_radius/2\n",
    "            dy = (2*np.random.random()-1) * shift_radius/2\n",
    "            rsq = dx**2 + dy**2\n",
    "\n",
    "        this_gal = shear_gal.shift(dx,dy) \n",
    "\n",
    "        # create psf\n",
    "        psf_x = np.random.uniform(0.0, 1.0)\n",
    "        psf_y = np.random.uniform(0.0, 1.0)\n",
    "        this_psf, psf_sigma, psf_e1, psf_e2 = get_psf(psf_x, psf_y)\n",
    "\n",
    "        # convolve psf with gal\n",
    "        final_gal = galsim.Convolve([this_psf, this_gal])\n",
    "        \n",
    "        # +1  and -1 to create one pixel border between stamps\n",
    "        # create subimage\n",
    "        b = galsim.BoundsI(ix * stamp_xsize + 1,(ix+1) * stamp_xsize -1,\n",
    "                            iy * stamp_ysize + 1, (iy+1) * stamp_ysize -1)\n",
    "        sub_gal_image = gal_image[b]\n",
    "        sub_psf_image = psf_image[b]\n",
    "        subim = final_gal.drawImage(sub_gal_image)\n",
    "        \n",
    "        #sub_image = image[b]\n",
    "        #im = shear_gal.drawImage(sub_image)\n",
    "\n",
    "        # add noise\n",
    "        #noise = galsim.CCDNoise(rng, sky_level=0., gain = -1.0, read_noise=1.0)\n",
    "        #subim.addNoise(noise)\n",
    "\n",
    "        subpsf_im = this_psf.drawImage(sub_psf_image)\n",
    "\n",
    "        # generate object_id\n",
    "        object_id = int(f\"{ix}{iy}\") #keep track of different realizations of the same galaxy, galaxy_id\n",
    "        object_id_g = image_id_counter # actual object id\n",
    "        object_id_p = image_id_counter\n",
    "        #object_id_p = int(str(object_id_g)+\"0\") #psf id, have an additional 0 at the end of galaxy id\n",
    "\n",
    "        image_id_counter +=1\n",
    "\n",
    "\n",
    "        if snr>10:\n",
    "            # write images to fits files\n",
    "            psf_name = str(object_id_p) + '.fits'\n",
    "            psf_file_name = os.path.join(psf_path, psf_name)\n",
    "\n",
    "            gal_name = str(object_id_g) + '.fits'\n",
    "            gal_file_name = os.path.join(galaxy_path, gal_name)\n",
    "            \n",
    "            subpsf_im.write(psf_file_name)\n",
    "            subim.write(gal_file_name)\n",
    "\n",
    "            #'galaxy_id': object_id,\n",
    "\n",
    "            if isSpiral == True:\n",
    "                metadata.append({\n",
    "                    'object_id': object_id_g,\n",
    "                    'e1': e1,\n",
    "                    'e2': e2,\n",
    "                    'g1': g1,\n",
    "                    'g2': g2,\n",
    "                    'psf_e1': psf_e1,\n",
    "                    'psf_e2': psf_e2,\n",
    "                    'psf_sigma': psf_sigma,\n",
    "                    'sersic_n': 0.,\n",
    "                    'sersic_bulge_n': 4.,\n",
    "                    'sersic_disk_n': n,\n",
    "                    'half_light_radius': 0.,\n",
    "                    'half_light_radius(bulge)': R_bulge,\n",
    "                    'half_light_radius(disk)': R_disk,\n",
    "                    'flux': F,\n",
    "                    'shift_radius_dx': dx,\n",
    "                    'shift_radius_dy': dy,\n",
    "                    #'snr': snr\n",
    "                })\n",
    "                isSpiral = False\n",
    "            else:\n",
    "                metadata.append({               \n",
    "                    'object_id': object_id_g,\n",
    "                    'e1': e1,\n",
    "                    'e2': e2,\n",
    "                    'g1': g1,\n",
    "                    'g2': g2,\n",
    "                    'psf_e1': psf_e1,\n",
    "                    'psf_e2': psf_e2,\n",
    "                    'psf_sigma': psf_sigma,\n",
    "                    'sersic_n': n,\n",
    "                    'sersic_bulge_n': 0.,\n",
    "                    'sersic_disk_n': 0.,\n",
    "                    'half_light_radius': R,\n",
    "                    'half_light_radius(bulge)': 0.,\n",
    "                    'half_light_radius(disk)': 0.,\n",
    "                    'flux': F,\n",
    "                    'shift_radius_dx': dx,\n",
    "                    'shift_radius_dy': dy,\n",
    "                    #'snr': snr\n",
    "                })\n",
    "\n",
    "            if len(metadata) >= batch_size or (ix==nx-1 and iy==ny-1):\n",
    "                metadata_df = pd.DataFrame(metadata)\n",
    "                metadata_df.to_csv(csv_file_path, mode='a', header=False, index=False)\n",
    "                metadata=[]\n",
    "                metadata_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9943a7e-9eac-4dd3-a000-4f17f7256893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '-0.10804144009563121', '-0.5249494413649045', '0.015583199691669838', '-0.06941239647790914', '0.2117934048370203', '0.20042974674013736', '2.1813264491586475', '0.0', '4.0', '1.2187613152368861', '0.0', '0.9561269268314272', '1.8032807176415349', '1108.231394520936', '-0.07077429628152049', '0.06394819343738009']\n",
      "File likely does not have headers\n"
     ]
    }
   ],
   "source": [
    "csv_file = '/data3/shear_simulated_galaxy/Metadata_TEST_noise_free.csv'\n",
    "import re\n",
    "with open(csv_file, 'r', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    first_row = next(reader)  # Read the first row\n",
    "    print(first_row)\n",
    "    \n",
    "    header_detected = False\n",
    "    for value in first_row:\n",
    "        if re.match(r'^[A-Za-z]', value):  # Check if the value starts with an alphabetic character\n",
    "            header_detected = True\n",
    "            break\n",
    "\n",
    "    if header_detected:\n",
    "        print(\"File likely has headers\")\n",
    "    else:\n",
    "        print(\"File likely does not have headers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fe80a2c-dbfe-45b2-8502-eb23ade670b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file names\n",
    "input_csv_file = '/data3/shear_simulated_galaxy/Metadata_TEST_noise_free.csv'\n",
    "output_csv_file = os.path.join('/data3/shear_simulated_galaxy', 'metadata_TEST_noise_free.csv')\n",
    "\n",
    "# Define your header row\n",
    "header = ['object_id',\n",
    "          'e1',\n",
    "          'e2',\n",
    "          'g1',\n",
    "          'g2',\n",
    "          'psf_e1',\n",
    "          'psf_e2',\n",
    "          'psf_sigma',\n",
    "          'sersic_n',\n",
    "          'sersic_bulge_n',\n",
    "          'sersic_disk_n',\n",
    "          'half_light_radius',\n",
    "          'half_light_radius(bulge)',\n",
    "          'half_light_radius(disk)',\n",
    "          'flux',\n",
    "          'shift_radius_dx',\n",
    "          'shift_radius_dy']\n",
    "          #'snr']\n",
    "\n",
    "with open(input_csv_file, 'r', newline='') as infile, \\\n",
    "     open(output_csv_file, 'w', newline='') as outfile:\n",
    "    \n",
    "    # Create a CSV reader for the existing file and a CSV writer for the new file\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    # Write the header row to the new file\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    # Copy the existing data from the old file to the new file\n",
    "    for row in reader:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11ea0da5-8110-4109-8054-a5320928dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hdf5_from_raw_images():\n",
    "    \n",
    "    #WORKING TO PRODUCE FINAL FULL DATASET:\n",
    "\n",
    "    #for raw:\n",
    "\n",
    "    #get number of galaxies in the image directory and sort them\n",
    "    #object id is the filename of the galaxy images\n",
    "    #galaxy id keeps track of the same galaxy\n",
    "\n",
    "    image_name_list = sorted(os.listdir(\"/data3/shear_simulated_galaxy/fits_files_TEST_noise_free/galaxy_images\"))\n",
    "    psf_name_list = sorted(os.listdir(\"/data3/shear_simulated_galaxy/fits_files_TEST_noise_free/psf_images\"))\n",
    "    #gal_name_list = sorted(os.listdir(\"/data3/shear_simulated_galaxy/fits_files_TEST_noise_free/just_gal_images\"))\n",
    "    \n",
    "    # check if galaxy and psf list have equal number of images\n",
    "    if len(image_name_list)!=len(psf_name_list):\n",
    "        return \"not every galaxy has coresponding psf\"\n",
    "\n",
    "    #load metadata\n",
    "    sheardata = pd.read_csv('/data3/shear_simulated_galaxy/metadata_TEST_noise_free.csv')\n",
    "    sheardata.describe()\n",
    "\n",
    "    b = np.argsort(sheardata['object_id'])\n",
    "    sorted_sheardata = sheardata.iloc[b][:]   \n",
    "    sheardata = sorted_sheardata\n",
    "    \n",
    "    \"\"\"\n",
    "    column_to_drop = 'snr'\n",
    "\n",
    "    # Check if the column exists before dropping\n",
    "    if column_to_drop in sheardata.columns:\n",
    "        sheardata.drop(column_to_drop, axis=1, inplace=True)\n",
    "        print(f\"Column '{column_to_drop}' has been dropped.\")\n",
    "    else:\n",
    "        print(f\"Column '{column_to_drop}' not found in DataFrame.\")\n",
    "    \"\"\"\n",
    "\n",
    "    #name the file you want to create\n",
    "    hf= h5py.File('/data3/shear_simulated_galaxy/NonUniformPsf_image127x127_with_Metadata_TEST_noise_free.hdf5', 'a')\n",
    "\n",
    "    # create metadata's corresponding dataset in hdf5 file\n",
    "    for (columnName, columnData) in sheardata.iteritems():\n",
    "        print(columnName)\n",
    "        hf.create_dataset(columnName,data=sheardata[columnName])\n",
    "\n",
    "        \n",
    "    for i in range(len(image_name_list)):     \n",
    "\n",
    "        #object_id = image_name_list[i][0:17] # slice the object_id\n",
    "        galaxy_image = []\n",
    "        #just_galaxy_image = []\n",
    "        psf_image = []\n",
    "        \n",
    "        try:\n",
    "            g_image = fits.open(\"/data3/shear_simulated_galaxy/fits_files_TEST_noise_free/galaxy_images/\"+image_name_list[i])\n",
    "            g_image_data = g_image[0].data\n",
    "            \n",
    "            #image = fits.open(\"/data3/shear_simulated_galaxy/fits_files_TEST_noise_free/just_gal_images/\"+image_name_list[i])\n",
    "            #image_data = image[0].data\n",
    "\n",
    "            p_image = fits.open(\"/data3/shear_simulated_galaxy/fits_files_TEST_noise_free/psf_images/\"+psf_name_list[i])\n",
    "            p_image_data = p_image[0].data\n",
    "        except fits.verify.VerifyError:\n",
    "            print(f\"Corrupt FITS file: {image_name_list[i]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing FITS file: {image_name_list[i]} - Error: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "        g_pad1 = int((127-len(g_image_data))/2)\n",
    "        g_pad2 = 127-len(g_image_data)-g_pad1\n",
    "        g_pad3 = int((127-len(g_image_data[0]))/2)\n",
    "        g_pad4 = 127-len(g_image_data[0])-g_pad3\n",
    "\n",
    "        g_im = np.pad(g_image_data,((g_pad1,g_pad2),(g_pad3,g_pad4)),\"constant\",constant_values = ((0,0),(0,0)))\n",
    "\n",
    "        galaxy_image.append(g_im)\n",
    "\n",
    "        #galaxy_image_reshape = np.reshape(np.array(galaxy_image),[1,1,127,127])\n",
    "        \"\"\"\n",
    "        i_pad1 = int((127-len(image_data))/2)\n",
    "        i_pad2 = 127-len(image_data)-i_pad1\n",
    "        i_pad3 = int((127-len(image_data[0]))/2)\n",
    "        i_pad4 = 127-len(image_data[0])-i_pad3\n",
    "\n",
    "        im = np.pad(g_image_data,((g_pad1,g_pad2),(g_pad3,g_pad4)),\"constant\",constant_values = ((0,0),(0,0)))\n",
    "\n",
    "        just_galaxy_image.append(im)\n",
    "        \"\"\"\n",
    "        \n",
    "        p_pad1 = int((127-len(p_image_data))/2)\n",
    "        p_pad2 = 127-len(p_image_data)-p_pad1\n",
    "        p_pad3 = int((127-len(p_image_data[0]))/2)\n",
    "        p_pad4 = 127-len(p_image_data[0])-p_pad3\n",
    "\n",
    "\n",
    "        p_im = np.pad(p_image_data,((p_pad1,p_pad2),(p_pad3,p_pad4)),\"constant\",constant_values = ((0,0),(0,0)))\n",
    "\n",
    "        psf_image.append(p_im)\n",
    "\n",
    "        #psf_image_reshape = np.reshape(np.array(psf_image),[1,1,127,127])\n",
    "        \n",
    "\n",
    "        if i == 0:\n",
    "            hf.create_dataset(\"galaxy_image\",data = galaxy_image,chunks = True,maxshape = (None,127,127))\n",
    "            #hf.create_dataset(\"just_galaxy_image\",data = just_galaxy_image,chunks = True,maxshape = (None,127,127))\n",
    "            hf.create_dataset(\"psf_image\",data = psf_image,chunks = True,maxshape = (None,127,127))\n",
    "\n",
    "        else:\n",
    "            hf['galaxy_image'].resize((hf['galaxy_image'].shape[0]+1), axis=0)\n",
    "            hf['galaxy_image'][hf[\"galaxy_image\"].shape[0]-1,:,:] = galaxy_image\n",
    "            \n",
    "            hf['just_galaxy_image'].resize((hf['just_galaxy_image'].shape[0]+1), axis=0)\n",
    "            hf['just_galaxy_image'][hf[\"just_galaxy_image\"].shape[0]-1,:,:] = galaxy_image\n",
    "            \n",
    "            hf['psf_image'].resize((hf['psf_image'].shape[0]+1), axis=0)\n",
    "            hf['psf_image'][hf[\"psf_image\"].shape[0]-1,:,:] = psf_image\n",
    "\n",
    "            \n",
    "        g_image.close()\n",
    "        p_image.close()\n",
    "\n",
    "\n",
    "    hf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4704849e-c359-48ea-8e3c-3db18d25116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1572471/2182091141.py:41: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for (columnName, columnData) in sheardata.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object_id\n",
      "e1\n",
      "e2\n",
      "g1\n",
      "g2\n",
      "psf_e1\n",
      "psf_e2\n",
      "psf_sigma\n",
      "sersic_n\n",
      "sersic_bulge_n\n",
      "sersic_disk_n\n",
      "half_light_radius\n",
      "half_light_radius(bulge)\n",
      "half_light_radius(disk)\n",
      "flux\n",
      "shift_radius_dx\n",
      "shift_radius_dy\n"
     ]
    }
   ],
   "source": [
    "make_hdf5_from_raw_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d08419a5-1fe9-4d05-a64d-3a47f1ae34ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1\n",
      "<HDF5 dataset \"e1\": shape (600,), type \"<f8\">\n",
      "-----------\n",
      "e2\n",
      "<HDF5 dataset \"e2\": shape (600,), type \"<f8\">\n",
      "-----------\n",
      "flux\n",
      "<HDF5 dataset \"flux\": shape (600,), type \"<f8\">\n",
      "-----------\n",
      "g1\n",
      "<HDF5 dataset \"g1\": shape (600,), type \"<f8\">\n",
      "-----------\n",
      "g2\n",
      "<HDF5 dataset \"g2\": shape (600,), type \"<f8\">\n",
      "-----------\n",
      "galaxy_image\n",
      "<HDF5 dataset \"galaxy_image\": shape (600, 127, 127), type \">f4\">\n",
      "-----------\n",
      "half_light_radius\n",
      "<HDF5 dataset \"half_light_radius\": shape (600,), type \"<f8\">\n",
      "-----------\n",
      "half_light_radius(bulge)\n",
      "<HDF5 dataset \"half_light_radius(bulge)\": shape (600,), type \"<f8\">\n",
      "-----------\n",
      "half_light_radius(disk)\n",
      "<HDF5 dataset \"half_light_radius(disk)\": shape (600,), type \"<f8\">\n",
      "-----------\n",
      "object_id\n",
      "<HDF5 dataset \"object_id\": shape (600,), type \"<i8\">\n",
      "-----------\n",
      "psf_e1\n",
      "<HDF5 dataset \"psf_e1\": shape (600,), type \"<f8\">\n",
      "-----------\n",
      "psf_e2\n",
      "<HDF5 dataset \"psf_e2\": shape (600,), type \"<f8\">\n",
      "-----------\n",
      "psf_image\n",
      "<HDF5 dataset \"psf_image\": shape (600, 127, 127), type \">f4\">\n",
      "-----------\n",
      "psf_sigma\n",
      "<HDF5 dataset \"psf_sigma\": shape (600,), type \"<f8\">\n",
      "-----------\n",
      "sersic_bulge_n\n",
      "<HDF5 dataset \"sersic_bulge_n\": shape (600,), type \"<f8\">\n",
      "-----------\n",
      "sersic_disk_n\n",
      "<HDF5 dataset \"sersic_disk_n\": shape (600,), type \"<f8\">\n",
      "-----------\n",
      "sersic_n\n",
      "<HDF5 dataset \"sersic_n\": shape (600,), type \"<f8\">\n",
      "-----------\n",
      "shift_radius_dx\n",
      "<HDF5 dataset \"shift_radius_dx\": shape (600,), type \"<f8\">\n",
      "-----------\n",
      "shift_radius_dy\n",
      "<HDF5 dataset \"shift_radius_dy\": shape (600,), type \"<f8\">\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "hf = h5py.File('/data3/shear_simulated_galaxy/NonUniformPsf_image127x127_with_Metadata_TEST_noise_free.hdf5', 'r')\n",
    "all_items = hf.items()\n",
    "\n",
    "# Print the items\n",
    "for name, item in all_items:\n",
    "    print(name)\n",
    "    print(item)  # This will print the metadata about the group or dataset\n",
    "    print(\"-----------\")\n",
    "    \n",
    "gal_image\n",
    "\n",
    "# Close the HDF5 file\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6e672-c293-4709-9229-9060499cee1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envname",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

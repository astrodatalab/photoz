{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eda2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import keras\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Input, Concatenate\n",
    "\n",
    "from photoz_utils import *\n",
    "from DataMaker import *\n",
    "\n",
    "GB_LIMIT = 5\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d65a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(GB_LIMIT*1000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29196bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_modes = {\"train\", \"test\"}\n",
    "class HDF5DataGenerator(Sequence):\n",
    "    \"\"\"Just a simple custom Keras HDF5 ImageDataGenerator.\n",
    "    \n",
    "    Custom Keras ImageDataGenerator that generates\n",
    "    batches of tensor images (or data points) from HDF5 files with (optional) real-time\n",
    "    data augmentation.\n",
    "     \n",
    "    Arguments\n",
    "    ---------\n",
    "    src : str\n",
    "        Path of the hdf5 source file.\n",
    "    label_key : str\n",
    "        Key of the h5 file labels dataset.\n",
    "        Default is \"labels\".\n",
    "    classes_key : str\n",
    "        Key of the h5 file dataset containing\n",
    "        the raw classes.\n",
    "        Default is None.\n",
    "    batch_size : int\n",
    "        Size of each batch, must be a power of two.\n",
    "        (16, 32, 64, 128, 256, ...)\n",
    "        Default is 32.\n",
    "    shuffle : bool\n",
    "        Shuffle images at the end of each epoch.\n",
    "        Default is True.\n",
    "    scaler : \"std\", \"norm\" or False\n",
    "        \"std\" mode means standardization to range [-1, 1]\n",
    "        with 0 mean and unit variance.\n",
    "        \"norm\" mode means normalization to range [0, 1].\n",
    "        Default is \"std\".\n",
    "    num_classes : None or int\n",
    "        Specifies the total number of classes\n",
    "        for labels encoding.\n",
    "        Default is None.\n",
    "    labels_encoding : \"hot\", \"smooth\" or False\n",
    "        \"hot\" mode means classic one hot encoding.\n",
    "        \"smooth\" mode means smooth hot encoding.\n",
    "        Default is \"hot\".\n",
    "    smooth_factor : int or float\n",
    "        smooth factor used by smooth\n",
    "        labels encoding.\n",
    "        Default is 0.1.\n",
    "    augmenter : albumentations Compose([]) Pipeline or False\n",
    "        An albumentations transformations pipeline\n",
    "        to apply to each sample.\n",
    "        Default is False.\n",
    "    mode : str \"train\" or \"test\"\n",
    "        Model generator type. \"train\" is used for\n",
    "        fit_generator() and evaluate_generator.\n",
    "        \"test\" is used for predict_generator().\n",
    "        Default is \"train\".\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Turn off scaler (scaler=False) if using the\n",
    "    ToFloat(max_value=255) transformation from\n",
    "    albumentations.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    Example of usage:\n",
    "    ```python\n",
    "    my_augmenter = Compose([\n",
    "        HorizontalFlip(p=0.5),\n",
    "        RandomContrast(limit=0.2, p=0.5),\n",
    "        RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
    "        RandomBrightness(limit=0.2, p=0.5),\n",
    "        Resize(227, 227, cv2.INTER_AREA)\n",
    "    ])\n",
    "\n",
    "    # Create the generator.\n",
    "    train_gen = HDF5ImageGenerator(\n",
    "        'path/to/my/file.h5',\n",
    "         augmenter=my_augmenter)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        src,\n",
    "        label_key=\"labels\",\n",
    "        classes_key=None,\n",
    "        batch_size=200,\n",
    "        shuffle=True,\n",
    "        scaler=True,\n",
    "        num_classes=None,\n",
    "        labels_encoding=\"hot\",\n",
    "        smooth_factor=0.1,\n",
    "        augmenter=False,\n",
    "        mode=\"train\",\n",
    "    ):\n",
    "\n",
    "        if mode not in available_modes:\n",
    "            raise ValueError('`mode` should be `train` '\n",
    "                             '(fit_generator() and evaluate_generator()) or '\n",
    "                             '`test` (predict_generator(). '\n",
    "                             'Received: %s' % mode)\n",
    "        self.mode = mode\n",
    "\n",
    "        if labels_encoding not in available_labels_encoding:\n",
    "            raise ValueError('`labels_encoding` should be `hot` '\n",
    "                             '(classic binary matrix) or '\n",
    "                             '`smooth` (smooth encoding) or '\n",
    "                             'False (no labels encoding). '\n",
    "                             'Received: %s' % labels_encoding)\n",
    "        self.labels_encoding = labels_encoding\n",
    "\n",
    "        if (self.labels_encoding == \"smooth\") and not (0 < smooth_factor <= 1):\n",
    "            raise ValueError('`smooth` labels encoding '\n",
    "                             'must use a `smooth_factor` '\n",
    "                             '< 0 smooth_factor <= 1')\n",
    "\n",
    "        if augmenter and not isinstance(augmenter, Compose):\n",
    "            raise ValueError('`augmenter` argument '\n",
    "                             'must be an instance of albumentations '\n",
    "                             '`Compose` class. '\n",
    "                             'Received type: %s' % type(augmenter))\n",
    "        self.augmenter = augmenter\n",
    "\n",
    "        self.src: str = src\n",
    "        self.label_key: str = label_key\n",
    "        self.classes_key: str = classes_key\n",
    "        self.batch_size: int = batch_size\n",
    "        self.shuffle: bool = shuffle\n",
    "        self.scaler: bool = scaler\n",
    "        self.num_classes: int = num_classes\n",
    "        self.smooth_factor: float = smooth_factor\n",
    "\n",
    "        self._indices = np.arange(self.__get_dataset_shape(self.label_key, 0))\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Representation of the class.\"\"\"\n",
    "        return f\"{self.__class__.__name__}({self.__dict__!r})\"\n",
    "\n",
    "    def __get_dataset_shape(self, dataset: str, index: int) -> Tuple[int, ...]:\n",
    "        \"\"\"Get an h5py dataset shape.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        dataset : str\n",
    "            The dataset key.\n",
    "        index : int\n",
    "            The dataset index.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ints\n",
    "            A tuple of array dimensions.\n",
    "        \"\"\"\n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            return file[dataset].shape[index]\n",
    "\n",
    "    def __get_dataset_items(\n",
    "        self,\n",
    "        indices: np.ndarray,\n",
    "        dataset: Optional[str] = None\n",
    "    ) -> Union[np.ndarray, Tuple[np.ndarray]]:\n",
    "        \"\"\"Get an HDF5 dataset items.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        indices : ndarray, \n",
    "            The list of current batch indices.\n",
    "        dataset : (optional) str\n",
    "            The dataset key. If None, returns\n",
    "            a batch of (image tensors, labels).\n",
    "            Defaults to None.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray or a tuple of ndarrays\n",
    "            A batch of samples.\n",
    "        \"\"\"\n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            if dataset is not None:\n",
    "                return np.asarray(file[dataset][indices]).astype('float32')\n",
    "            else:\n",
    "                return np.asarray(file[self.label_key][indices]).astype('float32')\n",
    "    \n",
    "    @property\n",
    "    def num_items(self) -> int:\n",
    "        \"\"\"Grab the total number of examples\n",
    "         from the dataset.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The total number of examples.\n",
    "        \"\"\"\n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            return file[self.label_key].shape[0]\n",
    "    \n",
    "    @property \n",
    "    def classes(self) -> list:\n",
    "        \"\"\"Grab \"human\" classes from the dataset.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of the raw classes.\n",
    "        \"\"\"\n",
    "        if self.classes_key is None:\n",
    "            raise ValueError('Canceled. parameter `classes_key` '\n",
    "                             'is set to None.')\n",
    "        \n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            return file[self.classes_key][:]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The number of batches per epochs.\n",
    "        \"\"\"\n",
    "        return int(\n",
    "            np.ceil(\n",
    "                self.__get_dataset_shape(self.label_key, 0) /\n",
    "                float(self.batch_size)))\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_labels_smoothing(batch_y: np.ndarray,\n",
    "                               factor: float) -> np.ndarray:\n",
    "        \"\"\"Applies labels smoothing to the original\n",
    "         labels binary matrix.\n",
    "         \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_y : np.ndarray\n",
    "            Current batch integer labels.\n",
    "        factor : float\n",
    "            Smoothing factor.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A binary class matrix.\n",
    "        \"\"\"\n",
    "        batch_y *= 1 - factor\n",
    "        batch_y += factor / batch_y.shape[1]\n",
    "\n",
    "        return batch_y\n",
    "\n",
    "    def apply_labels_encoding(\n",
    "            self,\n",
    "            batch_y: np.ndarray,\n",
    "            smooth_factor: Optional[float] = None) -> np.ndarray:\n",
    "        \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "         See Keras to_categorical utils function.\n",
    "         \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_y : np.ndarray\n",
    "            Current batch integer labels.\n",
    "        smooth_factor : (optional) Float\n",
    "            Smooth factor.\n",
    "            Defaults to None.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A binary class matrix.\n",
    "        \"\"\"\n",
    "        batch_y = to_categorical(batch_y, num_classes=self.num_classes)\n",
    "\n",
    "        if smooth_factor is not None:\n",
    "            batch_y = self.apply_labels_smoothing(batch_y,\n",
    "                                                  factor=smooth_factor)\n",
    "\n",
    "        return batch_y\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_normalization(batch_X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalize the pixel intensities. \n",
    "        \n",
    "        Normalize the pixel intensities to the range [0, 1].\n",
    "         \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_X : np.ndarray\n",
    "            Batch of image tensors to be normalized.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A batch of normalized image tensors.\n",
    "        \"\"\"\n",
    "        return batch_X.astype(\"float32\") / 4.0\n",
    "\n",
    "    def __next_batch(self,\n",
    "                     indices: np.ndarray) -> Tuple[np.ndarray]:\n",
    "        \"\"\"Generates a batch of train/val data for the given indices.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        index : int\n",
    "            The index for the batch.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ndarrays\n",
    "            A tuple containing a batch of image tensors\n",
    "            and their associated labels.\n",
    "        \"\"\"\n",
    "        # Grab samples (tensors, labels) HDF5 source file.\n",
    "        (batch_y) = np.asarray(self.__get_dataset_items(indices))\n",
    "\n",
    "\n",
    "        # Shall we apply labels encoding?\n",
    "        if self.labels_encoding:\n",
    "            batch_y = self.apply_labels_encoding(\n",
    "                batch_y,\n",
    "                smooth_factor=self.smooth_factor\n",
    "                if self.labels_encoding == \"smooth\" else None,\n",
    "            )\n",
    "\n",
    "        return (batch_y)\n",
    "\n",
    "    def __getitem__(\n",
    "            self,\n",
    "            index: int) -> Union[np.ndarray, Tuple[np.ndarray]]:\n",
    "        \"\"\"Generates a batch of data for the given index.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        index : int\n",
    "            The index for the current batch.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ndarrays or ndarray\n",
    "            A tuple containing a batch of image tensors\n",
    "            and their associated labels (train) or\n",
    "            a tuple of image tensors (predict).\n",
    "        \"\"\"\n",
    "        # Indices for the current batch.\n",
    "        indices = np.sort(self._indices[index * self.batch_size:(index + 1) *\n",
    "                                        self.batch_size])\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            return self.__next_batch(indices)\n",
    "        else:\n",
    "            return self.__next_batch_test(indices)\n",
    "\n",
    "    def __shuffle_indices(self):\n",
    "        \"\"\"If the shuffle parameter is set to True,\n",
    "         dataset will be shuffled (in-place).\n",
    "         (not available in test 'mode').\n",
    "        \"\"\"\n",
    "        if (self.mode == \"train\") and self.shuffle:\n",
    "            np.random.shuffle(self._indices)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Triggered once at the very beginning as well as \n",
    "         at the end of each epoch.\n",
    "        \"\"\"\n",
    "        self.__shuffle_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9280fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_images = {'label_key': 'image',\n",
    "    'scaler': True,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': True}\n",
    "\n",
    "args_specz = {'label_key': 'specz_redshift',\n",
    "    'scaler': True,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': True}\n",
    "\n",
    "TRAIN_PATH = '/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_training.hdf5'\n",
    "VAL_PATH = '/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_validation.hdf5'\n",
    "TEST_PATH = '/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_testing.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8863bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_g = {'label_key': 'g_cmodel_mag',\n",
    "    'scaler': True,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': True}\n",
    "\n",
    "args_r = {'label_key': 'r_cmodel_mag',\n",
    "    'scaler': True,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': True}\n",
    "\n",
    "args_i = {'label_key': 'i_cmodel_mag',\n",
    "    'scaler': True,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': True}\n",
    "\n",
    "args_z = {'label_key': 'z_cmodel_mag',\n",
    "    'scaler': True,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': True}\n",
    "\n",
    "args_y = {'label_key': 'y_cmodel_mag',\n",
    "    'scaler': True,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db3d73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = HDF5DataGenerator(src=TRAIN_PATH, **args_images)\n",
    "train_specz = HDF5DataGenerator(src=TRAIN_PATH, **args_specz)\n",
    "train_g = HDF5DataGenerator(src=TRAIN_PATH, **args_g)\n",
    "train_r = HDF5DataGenerator(src=TRAIN_PATH, **args_r)\n",
    "train_i = HDF5DataGenerator(src=TRAIN_PATH, **args_i)\n",
    "train_z = HDF5DataGenerator(src=TRAIN_PATH, **args_z)\n",
    "train_y = HDF5DataGenerator(src=TRAIN_PATH, **args_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c062de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f15765f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_specz.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce9f5522",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxiesMLDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, image_gen, label_gen, mag_gens=[]):\n",
    "        self.image_gen: HDF5DataGenerator = image_gen\n",
    "        self.label_gen: HDF5DataGenerator = label_gen\n",
    "        self.mag_gens: list[HDF5DataGenerator] = mag_gens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_gen)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        mags = []\n",
    "        for i in range(len(self.mag_gens)):\n",
    "            mags.append(self.mag_gens[i].__getitem__(index))\n",
    "        mags = np.column_stack(mags)\n",
    "        images = self.image_gen[index]\n",
    "        labels = self.label_gen[index]\n",
    "        return [images, mags], labels\n",
    "    def on_epoch_end(self):\n",
    "        self.image_gen.on_epoch_end()\n",
    "        self.image_gen.on_epoch_end()\n",
    "        for gen in range(len(mag_gens)):\n",
    "            gen.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d262cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mags = [train_g, train_r, train_i, train_z, train_y]\n",
    "test = GalaxiesMLDataGenerator(train_images, train_specz, train_mags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6be4fd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.03292560577392578 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "test.__getitem__(0)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "660c00fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoinedMags(tf.keras.utils.Sequence):\n",
    "    def __init__(self, input_gen1, input_gen2, input_gen3,input_gen4,input_gen5):\n",
    "        self.gen1 = input_gen1\n",
    "        self.gen2 = input_gen2\n",
    "        self.gen3 = input_gen3\n",
    "        self.gen4 = input_gen4        \n",
    "        self.gen5 = input_gen5\n",
    "\n",
    "        #assert len(input_gen1) == len(input_gen2) == len(target_gen)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gen1)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x1 = self.gen1[i]\n",
    "        x2 = self.gen2[i]\n",
    "        x3 = self.gen3[i]\n",
    "        x4 = self.gen4[i]\n",
    "        x5 = self.gen5[i]\n",
    "        \n",
    "        return np.column_stack([x1, x2, x3, x4, x5])\n",
    "    def on_epoch_end(self):\n",
    "        self.gen1.on_epoch_end()\n",
    "        self.gen2.on_epoch_end()\n",
    "        self.gen3.on_epoch_end()\n",
    "        self.gen4.on_epoch_end()\n",
    "        self.gen5.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3610ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoinedGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, input_gen1, input_gen2, target_gen):\n",
    "        self.gen1 = input_gen1\n",
    "        self.gen2 = input_gen2\n",
    "        self.gen3 = target_gen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gen1)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x1 = self.gen1[i]\n",
    "        x2 = self.gen2[i]\n",
    "        y = self.gen3[i]\n",
    "        \n",
    "        return [x1, x2], y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.gen1.on_epoch_end()\n",
    "        self.gen2.on_epoch_end()\n",
    "        self.gen3.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82d21ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mags2 = JoinedMags(train_g, train_r, train_i, train_z, train_y)\n",
    "joint_gen = JoinedGen(train_images, train_mags2, train_specz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d5e44d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.03117966651916504 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "joint_gen.__getitem__(0)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40cd700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mags are different in each gen. in test, there are 5 arrays with each having 256 mags of the same band.\n",
    "#in joint_gen, there are 256 arrays with each having 5 mags of different bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53d3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
7, 18.706116,\n",
       "       17.72638 , 19.173449, 18.79076 , 18.917906, 17.966906, 16.278381,\n",
       "       18.379158, 17.945133, 18.66616 , 17.472141, 18.917723, 18.907227,\n",
       "       19.272688, 19.01975 , 15.874249, 16.511864, 15.570441, 19.144005,\n",
       "       16.030416, 15.226381, 19.46322 , 15.950298, 18.470943, 17.021091,\n",
       "       21.439095, 20.091217, 16.411922, 18.861046, 18.672426, 21.30789 ,\n",
       "       20.646671, 16.86082 , 17.583057, 17.849754, 18.691372, 19.941948,\n",
       "       17.265753, 19.854164, 16.004375, 20.779236, 17.040428, 16.778423,\n",
       "       18.85165 , 19.003773, 17.628056, 19.388725, 17.39193 , 18.616564,\n",
       "       18.176159, 18.978107, 18.888443, 21.396345, 18.781359, 19.304176,\n",
       "       18.29662 , 19.737099, 20.60617 , 19.799183, 17.49388 , 17.340836,\n",
       "       18.685162, 16.109833, 21.60137 , 19.50654 , 20.904207, 21.409355,\n",
       "       18.263332, 20.550203, 17.065817, 21.229172, 17.894503, 21.751507,\n",
       "       18.913887, 19.642492, 19.10638 , 18.568703, 18.652702, 18.21856 ,\n",
       "       17.915382, 18.845959, 18.334557, 18.376778, 17.901066, 19.032661,\n",
       "       17.520441, 17.715023, 18.581396, 19.260895, 21.116474, 17.800194,\n",
       "       18.354813, 19.002275, 17.983835, 17.230627, 21.148087, 19.055128,\n",
       "       19.682081, 18.568108, 18.86867 , 18.06604 , 19.224312, 19.195965,\n",
       "       18.870174, 17.765606, 18.990986, 17.696674, 17.908663, 21.518093,\n",
       "       19.837212, 17.441563, 20.51305 , 16.896133, 19.302341, 16.169388,\n",
       "       18.309996, 16.30292 , 17.672827, 18.232985, 19.340225, 20.932987,\n",
       "       17.472992, 19.241383, 18.974915, 19.374891, 18.349895, 20.928734,\n",
       "       19.17106 , 19.403183, 20.411459, 19.147226, 16.118748, 18.730778,\n",
       "       18.722115, 19.063938, 17.076347, 18.001627, 18.347715, 18.757587,\n",
       "       18.047031, 18.737757, 18.105614, 18.426105, 17.658197, 18.208725,\n",
       "       19.618563, 20.098478, 18.693588, 18.047981, 17.834726, 19.141499,\n",
       "       18.887707, 19.026491, 19.324722, 19.223585, 18.8987  , 21.334465,\n",
       "       18.429993, 18.14298 , 21.142975, 18.979048, 18.141659, 19.103952,\n",
       "       17.817581, 18.720984, 19.018902, 18.246391, 19.668419, 18.683216,\n",
       "       17.894417, 17.565197, 18.13061 , 18.106504, 21.266924, 18.501577,\n",
       "       18.883709, 18.789558, 19.079948, 18.108715, 18.707653, 19.150688,\n",
       "       18.106285, 19.206259, 20.314564, 20.891066, 18.752201, 20.647526,\n",
       "       19.334084, 18.2101  , 18.872908, 18.428646, 18.33851 , 19.213812,\n",
       "       17.297016, 17.93932 , 16.991505, 19.281467, 18.573853, 19.63879 ,\n",
       "       18.656044, 21.816006, 18.998775, 18.285059, 19.455246, 17.653736,\n",
       "       18.997494, 18.57093 , 18.458351, 17.964659, 21.53085 , 18.790295,\n",
       "       18.296837, 18.530472, 18.748528, 19.242725, 21.140236, 20.901083,\n",
       "       20.595787, 21.089058, 19.054306, 17.73578 , 18.850004, 17.203754,\n",
       "       20.2881  , 19.513721, 19.282696, 18.828648, 18.509022, 19.321049,\n",
       "       16.279478, 20.066103, 18.179642, 18.890217, 18.538347, 20.227589,\n",
       "       19.012579, 17.32281 , 17.644451, 19.45913 , 19.776442, 20.95152 ,\n",
       "       17.485506, 17.740322, 21.28284 , 16.81932 ], dtype=float32)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.__getitem__(0)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "393990c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the same way Evan did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "660c00fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoinedMags(tf.keras.utils.Sequence):\n",
    "    def __init__(self, input_gen1, input_gen2, input_gen3,input_gen4,input_gen5):\n",
    "        self.gen1 = input_gen1\n",
    "        self.gen2 = input_gen2\n",
    "        self.gen3 = input_gen3\n",
    "        self.gen4 = input_gen4        \n",
    "        self.gen5 = input_gen5\n",
    "\n",
    "        #assert len(input_gen1) == len(input_gen2) == len(target_gen)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gen1)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x1 = self.gen1[i]\n",
    "        x2 = self.gen2[i]\n",
    "        x3 = self.gen3[i]\n",
    "        x4 = self.gen4[i]\n",
    "        x5 = self.gen5[i]\n",
    "\n",
    "        return np.column_stack([x1, x2, x3, x4, x5])\n",
    "    def on_epoch_end(self):\n",
    "        self.gen1.on_epoch_end()\n",
    "        self.gen2.on_epoch_end()\n",
    "        self.gen3.on_epoch_end()\n",
    "        self.gen4.on_epoch_end()\n",
    "        self.gen5.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3610ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoinedGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, input_gen1, input_gen2, target_gen):\n",
    "        self.gen1 = input_gen1\n",
    "        self.gen2 = input_gen2\n",
    "        self.gen3 = target_gen\n",
    "\n",
    "        #assert len(input_gen1) == len(input_gen2) == len(target_gen)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gen1)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x1 = self.gen1[i]\n",
    "        x2 = self.gen2[i]\n",
    "        y = self.gen3[i]\n",
    "\n",
    "        return [x1, x2], y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.gen1.on_epoch_end()\n",
    "        self.gen2.on_epoch_end()\n",
    "        self.gen3.on_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82d21ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mags2 = JoinedMags(train_g, train_r, train_i, train_z, train_y)\n",
    "joint_gen = JoinedGen(train_images, train_mags2, train_specz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d5e44d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20.162785, 20.30324 , 20.003777, 19.59278 , 19.839014],\n",
       "       [21.448307, 21.5829  , 21.402744, 20.637022, 20.885056],\n",
       "       [22.126463, 20.349356, 19.516052, 19.154455, 18.874588],\n",
       "       ...,\n",
       "       [20.402996, 18.878391, 18.246067, 17.909672, 17.740322],\n",
       "       [22.63111 , 22.008833, 21.642885, 21.354769, 21.28284 ],\n",
       "       [19.446146, 17.942152, 17.334478, 17.024094, 16.81932 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_gen.__getitem__(0)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mags are different in each gen. in test, there are 5 arrays with each having 256 mags of the same band.\n",
    "#in joint_gen, there are 256 arrays with each having 5 mags of different bands"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

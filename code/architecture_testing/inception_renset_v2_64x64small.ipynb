{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd5cea9",
   "metadata": {},
   "source": [
    "# This notebook uses the Inception-ResNet v2 architecture. The stem has been modified to accommodate for 64x64 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da1d79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 11:23:03.791862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-01 11:23:04.351039: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-01 11:23:04.351090: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-01 11:23:04.351095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import keras\n",
    "import os\n",
    "import tensorboard\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Input, concatenate, add, Activation, BatchNormalization, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from photoz_utils import *\n",
    "from DataMakerPlus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c6416a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "GB_LIMIT = 17\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(GB_LIMIT*1000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dece0a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (5, 64, 64)\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 0.0001\n",
    "Z_MAX = 4\n",
    "hparams = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'z_max': Z_MAX\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a546612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = f'/data/HSC/HSC_v6/step3A/64x64_training_small.hdf5'\n",
    "VAL_PATH = f'/data/HSC/HSC_v6/step3A/64x64_validation_small.hdf5'\n",
    "TEST_PATH = f'/data/HSC/HSC_v6/step3A/64x64_testing_small.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e5e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_args = {\n",
    "    'image_key': 'image',\n",
    "    'numerical_keys': None,\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': True,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': hparams['batch_size'],\n",
    "    'shuffle': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8e667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = HDF5DataGenerator(TRAIN_PATH, mode='train', **gen_args)\n",
    "val_gen = HDF5DataGenerator(VAL_PATH, mode='train', **gen_args)\n",
    "test_gen = HDF5DataGenerator(TEST_PATH, mode='test', **gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b1e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def calculate_loss(z_photo, z_spec):\n",
    "    \"\"\"\n",
    "    HSC METRIC. Returns an array. Loss is accuracy metric defined by HSC, meant\n",
    "    to capture the effects of bias, scatter, and outlier all in one. This has\n",
    "    uses for both point and density estimation.\n",
    "    z_photo: array\n",
    "        Photometric or predicted redshifts.\n",
    "    z_spec: array\n",
    "        Spectroscopic or actual redshifts.\n",
    "    \"\"\"\n",
    "    dz = delz(z_photo, z_spec)\n",
    "    gamma = 0.15\n",
    "    denominator = 1.0 + K.square(dz/gamma)\n",
    "    loss = 1 - 1.0 / denominator\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf11cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1,1)):\n",
    "    out = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, data_format='channels_first')(x)\n",
    "    out = BatchNormalization(axis=1, scale=False)(out)\n",
    "    out = Activation('relu')(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0e5ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_block_a(x):\n",
    "    original_in = x\n",
    "\n",
    "    branch1 = conv2d_bn(x, 32, 1, 1)\n",
    "\n",
    "    branch2 = conv2d_bn(x, 32, 1, 1)\n",
    "    branch2 = conv2d_bn(branch2, 32, 3, 3)\n",
    "\n",
    "    branch3 = conv2d_bn(x, 32, 1, 1)\n",
    "    branch3 = conv2d_bn(branch3, 48, 3, 3)\n",
    "    branch3 = conv2d_bn(branch3, 64, 3, 3)\n",
    "\n",
    "    inc_block_out = concatenate([branch1, branch2, branch3], axis=1)\n",
    "    inc_block_out = Conv2D(384, (1,1), strides=(1,1), padding='same', data_format='channels_first')(inc_block_out)\n",
    "    inc_block_out = Lambda(lambda x: x * 0.1)(inc_block_out)\n",
    "    out = add([original_in, inc_block_out])\n",
    "    out = Activation('relu')(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eac7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_block_a(x):\n",
    "    branch1 = conv2d_bn(x, 384, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch2 = conv2d_bn(x, 256, 1, 1)\n",
    "    branch2 = conv2d_bn(branch2, 256, 3, 3)\n",
    "    branch2 = conv2d_bn(branch2, 384, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch3 = MaxPooling2D((3,3), strides=(2,2), padding='valid', data_format='channels_first')(x)\n",
    "\n",
    "    out = concatenate([branch1, branch2, branch3], axis=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50a430e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_block_b(x):\n",
    "    original_in = x\n",
    "\n",
    "    branch1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch2 = conv2d_bn(x, 128, 1, 1)\n",
    "    branch2 = conv2d_bn(branch2, 160, 1, 7)\n",
    "    branch2 = conv2d_bn(branch2, 192, 7, 1)\n",
    "\n",
    "    inc_block_out = concatenate([branch1, branch2], axis=1)\n",
    "    inc_block_out = Conv2D(1152, (1,1), strides=(1,1), padding='same', data_format='channels_first')(inc_block_out)\n",
    "    inc_block_out = Lambda(lambda x: x * 0.1)(inc_block_out)\n",
    "    out = add([original_in, inc_block_out])\n",
    "    out = Activation('relu')(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2b4a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_block_b(x):\n",
    "    branch1 = conv2d_bn(x, 256, 1, 1)\n",
    "    branch1 = conv2d_bn(branch1, 384, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch2 = conv2d_bn(x, 256, 1, 1)\n",
    "    branch2 = conv2d_bn(branch2, 288, 3, 3)\n",
    "    branch2 = conv2d_bn(branch2, 320, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch3 = MaxPooling2D((3,3), strides=(2,2), padding='valid', data_format='channels_first')(x)\n",
    "\n",
    "    branch4 = conv2d_bn(x, 256, 1, 1)\n",
    "    branch4 = conv2d_bn(branch4, 288, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    out = concatenate([branch1, branch2, branch3, branch4], axis=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19668269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_block_c(x):\n",
    "    original_in = x\n",
    "\n",
    "    branch1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch2 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch2 = conv2d_bn(branch2, 224, 1, 3)\n",
    "    branch2 = conv2d_bn(branch2, 256, 3, 1)\n",
    "\n",
    "    inc_block_out = concatenate([branch1, branch2], axis=1)\n",
    "    inc_block_out = Conv2D(2144, (1,1), strides=(1,1), padding='same', data_format='channels_first')(inc_block_out)\n",
    "    inc_block_out = Lambda(lambda x: x * 0.1)(inc_block_out)\n",
    "    out = add([original_in, inc_block_out])\n",
    "    out = Activation('relu')(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3383ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(x):\n",
    "    out = conv2d_bn(x, 32, 3, 3)\n",
    "    out = conv2d_bn(out, 32, 3, 3)\n",
    "    out = conv2d_bn(out, 64, 3, 3)\n",
    "\n",
    "    branch1 = MaxPooling2D((3, 3), strides=(2,2), padding='same', data_format='channels_first')(out)\n",
    "    branch2 = conv2d_bn(out, 96, 3, 3, strides=(2,2))\n",
    "    out = concatenate([branch1, branch2], axis=1)\n",
    "\n",
    "    branch1 = conv2d_bn(out, 64, 1, 1)\n",
    "    branch1 = conv2d_bn(branch1, 96, 3, 3)\n",
    "    branch2 = conv2d_bn(out, 64, 1, 1)\n",
    "    branch2 = conv2d_bn(branch2, 64, 7, 1)\n",
    "    branch2 = conv2d_bn(branch2, 64, 1, 7)\n",
    "    branch2 = conv2d_bn(branch2, 96, 3, 3)\n",
    "    out = concatenate([branch1, branch2], axis=1)\n",
    "\n",
    "    out = conv2d_bn(out, 384, 3, 3)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0f962e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape=IMAGE_SHAPE)\n",
    "x = stem(input_)\n",
    "\n",
    "x = inc_block_a(x)\n",
    "x = inc_block_a(x)\n",
    "x = reduction_block_a(x)\n",
    "x = inc_block_b(x)\n",
    "x = inc_block_b(x)\n",
    "x = inc_block_b(x)\n",
    "x = inc_block_b(x)\n",
    "x = reduction_block_b(x)\n",
    "x = inc_block_c(x)\n",
    "x = inc_block_c(x)\n",
    "x = GlobalAveragePooling2D(data_format='channels_first')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1)(x)\n",
    "\n",
    "model = Model(input_, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a32f9746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 64, 64)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 64, 64)   1472        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 64, 64)  96          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 32, 64, 64)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 64, 64)   9248        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 64, 64)  96          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 64, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 64, 64)   18496       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 64, 64, 64)  192         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 64, 64, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 96, 32, 32)   55392       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 96, 32, 32)  288         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 32, 32)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 96, 32, 32)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 160, 32, 32)  0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 64, 32, 32)   10304       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 64, 32, 32)  192         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 64, 32, 32)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 64, 32, 32)   28736       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 64, 32, 32)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 64, 32, 32)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 32, 32)   10304       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 64, 32, 32)   28736       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 32, 32)  192         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 64, 32, 32)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 64, 32, 32)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 64, 32, 32)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 96, 32, 32)   55392       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 96, 32, 32)   55392       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 96, 32, 32)  288         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 96, 32, 32)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 96, 32, 32)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 96, 32, 32)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 192, 32, 32)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 384, 32, 32)  663936      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 384, 32, 32)  1152       ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 384, 32, 32)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 32, 32, 32)   12320       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 32, 32, 32)  96          ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 32, 32)   12320       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 48, 32, 32)   13872       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 32, 32, 32)  96          ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 48, 32, 32)  144         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 48, 32, 32)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 32)   12320       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 32, 32)   9248        ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 64, 32, 32)   27712       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 32, 32, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 32, 32)  96          ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 64, 32, 32)  192         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 64, 32, 32)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 32, 32)  0           ['activation_11[0][0]',          \n",
      "                                                                  'activation_13[0][0]',          \n",
      "                                                                  'activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 384, 32, 32)  49536       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 384, 32, 32)  0           ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 384, 32, 32)  0           ['activation_10[0][0]',          \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 384, 32, 32)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 32, 32, 32)   12320       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 32, 32, 32)  96          ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 32, 32, 32)   12320       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 48, 32, 32)   13872       ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 32, 32, 32)  96          ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 48, 32, 32)  144         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 48, 32, 32)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 32, 32, 32)   12320       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 32, 32, 32)   9248        ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 64, 32, 32)   27712       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 32, 32, 32)  96          ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 32, 32, 32)  96          ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 64, 32, 32)  192         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 64, 32, 32)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128, 32, 32)  0           ['activation_18[0][0]',          \n",
      "                                                                  'activation_20[0][0]',          \n",
      "                                                                  'activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 384, 32, 32)  49536       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 384, 32, 32)  0           ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 384, 32, 32)  0           ['activation_17[0][0]',          \n",
      "                                                                  'lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 384, 32, 32)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 256, 32, 32)  98560       ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 256, 32, 32)  768        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 256, 32, 32)  0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 256, 32, 32)  590080      ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 256, 32, 32)  768        ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 256, 32, 32)  0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 384, 15, 15)  1327488     ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 384, 15, 15)  885120      ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 384, 15, 15)  1152       ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 384, 15, 15)  1152       ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 384, 15, 15)  0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 384, 15, 15)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 384, 15, 15)  0          ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 1152, 15, 15  0           ['activation_25[0][0]',          \n",
      "                                )                                 'activation_28[0][0]',          \n",
      "                                                                  'max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 128, 15, 15)  147584      ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 128, 15, 15)  384        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 128, 15, 15)  0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 160, 15, 15)  143520      ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 160, 15, 15)  480        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 160, 15, 15)  0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 192, 15, 15)  221376      ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 192, 15, 15)  215232      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 192, 15, 15)  576        ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 192, 15, 15)  576        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 384, 15, 15)  0           ['activation_29[0][0]',          \n",
      "                                                                  'activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 1152, 15, 15  443520      ['concatenate_5[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 1152, 15, 15  0           ['conv2d_33[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 1152, 15, 15  0           ['concatenate_4[0][0]',          \n",
      "                                )                                 'lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 1152, 15, 15  0           ['add_2[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 128, 15, 15)  147584      ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 128, 15, 15)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 128, 15, 15)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 160, 15, 15)  143520      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 160, 15, 15)  480        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 160, 15, 15)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 192, 15, 15)  221376      ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 192, 15, 15)  215232      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 192, 15, 15)  576        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 192, 15, 15)  576        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 384, 15, 15)  0           ['activation_34[0][0]',          \n",
      "                                                                  'activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 1152, 15, 15  443520      ['concatenate_6[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 1152, 15, 15  0           ['conv2d_38[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 1152, 15, 15  0           ['activation_33[0][0]',          \n",
      "                                )                                 'lambda_3[0][0]']               \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 1152, 15, 15  0           ['add_3[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 128, 15, 15)  147584      ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 128, 15, 15)  384        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 128, 15, 15)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 160, 15, 15)  143520      ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 160, 15, 15)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 160, 15, 15)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 192, 15, 15)  221376      ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 192, 15, 15)  215232      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 192, 15, 15)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 192, 15, 15)  576        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 384, 15, 15)  0           ['activation_39[0][0]',          \n",
      "                                                                  'activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 1152, 15, 15  443520      ['concatenate_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 1152, 15, 15  0           ['conv2d_43[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 1152, 15, 15  0           ['activation_38[0][0]',          \n",
      "                                )                                 'lambda_4[0][0]']               \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 1152, 15, 15  0           ['add_4[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 128, 15, 15)  147584      ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 128, 15, 15)  384        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 128, 15, 15)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 160, 15, 15)  143520      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 160, 15, 15)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 160, 15, 15)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 192, 15, 15)  221376      ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 192, 15, 15)  215232      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 192, 15, 15)  576        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 192, 15, 15)  576        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 384, 15, 15)  0           ['activation_44[0][0]',          \n",
      "                                                                  'activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 1152, 15, 15  443520      ['concatenate_8[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)              (None, 1152, 15, 15  0           ['conv2d_48[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 1152, 15, 15  0           ['activation_43[0][0]',          \n",
      "                                )                                 'lambda_5[0][0]']               \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 1152, 15, 15  0           ['add_5[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 256, 15, 15)  295168      ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 256, 15, 15)  768        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 256, 15, 15)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 256, 15, 15)  295168      ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 288, 15, 15)  663840      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 256, 15, 15)  295168      ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 256, 15, 15)  768        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 288, 15, 15)  864        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 256, 15, 15)  768        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 256, 15, 15)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 288, 15, 15)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 256, 15, 15)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 384, 7, 7)    885120      ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 320, 7, 7)    829760      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 288, 7, 7)    663840      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 384, 7, 7)   1152        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 320, 7, 7)   960         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 288, 7, 7)   864         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 384, 7, 7)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 320, 7, 7)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 1152, 7, 7)  0           ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 288, 7, 7)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 2144, 7, 7)   0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]',        \n",
      "                                                                  'activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 192, 7, 7)    411840      ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 192, 7, 7)   576         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 192, 7, 7)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 224, 7, 7)    129248      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 224, 7, 7)   672         ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 224, 7, 7)    0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 192, 7, 7)    411840      ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 256, 7, 7)    172288      ['activation_58[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 192, 7, 7)   576         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 256, 7, 7)   768         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 192, 7, 7)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 256, 7, 7)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 448, 7, 7)    0           ['activation_56[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 2144, 7, 7)   962656      ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, 2144, 7, 7)   0           ['conv2d_60[0][0]']              \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 2144, 7, 7)   0           ['concatenate_9[0][0]',          \n",
      "                                                                  'lambda_6[0][0]']               \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 2144, 7, 7)   0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 192, 7, 7)    411840      ['activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 192, 7, 7)   576         ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 192, 7, 7)    0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 224, 7, 7)    129248      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 224, 7, 7)   672         ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 224, 7, 7)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 192, 7, 7)    411840      ['activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 256, 7, 7)    172288      ['activation_63[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 192, 7, 7)   576         ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 256, 7, 7)   768         ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 192, 7, 7)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 256, 7, 7)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 448, 7, 7)    0           ['activation_61[0][0]',          \n",
      "                                                                  'activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 2144, 7, 7)   962656      ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)              (None, 2144, 7, 7)   0           ['conv2d_65[0][0]']              \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 2144, 7, 7)   0           ['activation_60[0][0]',          \n",
      "                                                                  'lambda_7[0][0]']               \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 2144, 7, 7)   0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2144)        0           ['activation_65[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2144)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            2145        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,932,033\n",
      "Trainable params: 16,913,473\n",
      "Non-trainable params: 18,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e5173bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=hparams['learning_rate']), loss='mse', metrics='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e468ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'inception_resnet_2_64x64_small_v1'\n",
    "\n",
    "checkpoint_filepath = f'/data2/models/{model_name}/checkpoints/cp.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
    "log_dir = os.path.join('/data2/logs/', model_name)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_freq='epoch',\n",
    "    save_best_only=True,\n",
    "    verbose=True)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "hparam_callback = hp.KerasCallback(log_dir, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb6ef640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.4189 - mse: 1.4189\n",
      "Epoch 1: loss improved from inf to 1.41890, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 91s 1s/step - loss: 1.4189 - mse: 1.4189 - val_loss: 0.5757 - val_mse: 0.5757\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.5413 - mse: 0.5413\n",
      "Epoch 2: loss improved from 1.41890 to 0.54126, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.5413 - mse: 0.5413 - val_loss: 0.5381 - val_mse: 0.5381\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.5470 - mse: 0.5470\n",
      "Epoch 3: loss did not improve from 0.54126\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.5470 - mse: 0.5470 - val_loss: 0.5393 - val_mse: 0.5393\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.4470 - mse: 0.4470\n",
      "Epoch 4: loss improved from 0.54126 to 0.44696, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 42s 1s/step - loss: 0.4470 - mse: 0.4470 - val_loss: 0.3729 - val_mse: 0.3729\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.4009 - mse: 0.4009\n",
      "Epoch 5: loss improved from 0.44696 to 0.40091, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 40s 1s/step - loss: 0.4009 - mse: 0.4009 - val_loss: 0.3339 - val_mse: 0.3339\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.4265 - mse: 0.4265\n",
      "Epoch 6: loss did not improve from 0.40091\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.4265 - mse: 0.4265 - val_loss: 0.3491 - val_mse: 0.3491\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3650 - mse: 0.3650\n",
      "Epoch 7: loss improved from 0.40091 to 0.36498, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.3650 - mse: 0.3650 - val_loss: 0.3303 - val_mse: 0.3303\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3484 - mse: 0.3484\n",
      "Epoch 8: loss improved from 0.36498 to 0.34837, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.3484 - mse: 0.3484 - val_loss: 0.3385 - val_mse: 0.3385\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3138 - mse: 0.3138\n",
      "Epoch 9: loss improved from 0.34837 to 0.31382, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.3138 - mse: 0.3138 - val_loss: 0.3196 - val_mse: 0.3196\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2964 - mse: 0.2964\n",
      "Epoch 10: loss improved from 0.31382 to 0.29642, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.2964 - mse: 0.2964 - val_loss: 0.2996 - val_mse: 0.2996\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2659 - mse: 0.2659\n",
      "Epoch 11: loss improved from 0.29642 to 0.26586, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.2659 - mse: 0.2659 - val_loss: 0.2876 - val_mse: 0.2876\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2656 - mse: 0.2656\n",
      "Epoch 12: loss improved from 0.26586 to 0.26562, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.2656 - mse: 0.2656 - val_loss: 0.2460 - val_mse: 0.2460\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2928 - mse: 0.2928\n",
      "Epoch 13: loss did not improve from 0.26562\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.2928 - mse: 0.2928 - val_loss: 0.2425 - val_mse: 0.2425\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2560 - mse: 0.2560\n",
      "Epoch 14: loss improved from 0.26562 to 0.25597, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.2560 - mse: 0.2560 - val_loss: 0.2306 - val_mse: 0.2306\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2329 - mse: 0.2329\n",
      "Epoch 15: loss improved from 0.25597 to 0.23288, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 43s 1s/step - loss: 0.2329 - mse: 0.2329 - val_loss: 0.1888 - val_mse: 0.1888\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2375 - mse: 0.2375\n",
      "Epoch 16: loss did not improve from 0.23288\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.2375 - mse: 0.2375 - val_loss: 0.1920 - val_mse: 0.1920\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2317 - mse: 0.2317\n",
      "Epoch 17: loss improved from 0.23288 to 0.23169, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.2317 - mse: 0.2317 - val_loss: 0.1668 - val_mse: 0.1668\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2177 - mse: 0.2177\n",
      "Epoch 18: loss improved from 0.23169 to 0.21768, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.2177 - mse: 0.2177 - val_loss: 0.1746 - val_mse: 0.1746\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2132 - mse: 0.2132\n",
      "Epoch 19: loss improved from 0.21768 to 0.21322, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.2132 - mse: 0.2132 - val_loss: 0.1485 - val_mse: 0.1485\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2021 - mse: 0.2021\n",
      "Epoch 20: loss improved from 0.21322 to 0.20207, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.2021 - mse: 0.2021 - val_loss: 0.1863 - val_mse: 0.1863\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1927 - mse: 0.1927\n",
      "Epoch 21: loss improved from 0.20207 to 0.19271, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.1927 - mse: 0.1927 - val_loss: 0.1389 - val_mse: 0.1389\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1967 - mse: 0.1967\n",
      "Epoch 22: loss did not improve from 0.19271\n",
      "40/40 [==============================] - 42s 1s/step - loss: 0.1967 - mse: 0.1967 - val_loss: 0.2044 - val_mse: 0.2044\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2165 - mse: 0.2165\n",
      "Epoch 23: loss did not improve from 0.19271\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.2165 - mse: 0.2165 - val_loss: 0.1228 - val_mse: 0.1228\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1793 - mse: 0.1793\n",
      "Epoch 24: loss improved from 0.19271 to 0.17933, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.1793 - mse: 0.1793 - val_loss: 0.2213 - val_mse: 0.2213\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1772 - mse: 0.1772\n",
      "Epoch 25: loss improved from 0.17933 to 0.17716, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.1772 - mse: 0.1772 - val_loss: 0.1126 - val_mse: 0.1126\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1619 - mse: 0.1619\n",
      "Epoch 26: loss improved from 0.17716 to 0.16190, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 43s 1s/step - loss: 0.1619 - mse: 0.1619 - val_loss: 0.1314 - val_mse: 0.1314\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1669 - mse: 0.1669\n",
      "Epoch 27: loss did not improve from 0.16190\n",
      "40/40 [==============================] - 42s 1s/step - loss: 0.1669 - mse: 0.1669 - val_loss: 0.1041 - val_mse: 0.1041\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1526 - mse: 0.1526\n",
      "Epoch 28: loss improved from 0.16190 to 0.15255, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.1526 - mse: 0.1526 - val_loss: 0.1081 - val_mse: 0.1081\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1409 - mse: 0.1409\n",
      "Epoch 29: loss improved from 0.15255 to 0.14092, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.1409 - mse: 0.1409 - val_loss: 0.1130 - val_mse: 0.1130\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1366 - mse: 0.1366\n",
      "Epoch 30: loss improved from 0.14092 to 0.13657, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.1366 - mse: 0.1366 - val_loss: 0.2081 - val_mse: 0.2081\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1408 - mse: 0.1408\n",
      "Epoch 31: loss did not improve from 0.13657\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.1408 - mse: 0.1408 - val_loss: 0.1687 - val_mse: 0.1687\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1319 - mse: 0.1319\n",
      "Epoch 32: loss improved from 0.13657 to 0.13186, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.1319 - mse: 0.1319 - val_loss: 2.0125 - val_mse: 2.0125\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1248 - mse: 0.1248\n",
      "Epoch 33: loss improved from 0.13186 to 0.12483, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.1248 - mse: 0.1248 - val_loss: 0.1168 - val_mse: 0.1168\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1275 - mse: 0.1275\n",
      "Epoch 34: loss did not improve from 0.12483\n",
      "40/40 [==============================] - 42s 1s/step - loss: 0.1275 - mse: 0.1275 - val_loss: 0.4572 - val_mse: 0.4572\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1214 - mse: 0.1214\n",
      "Epoch 35: loss improved from 0.12483 to 0.12139, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.1214 - mse: 0.1214 - val_loss: 0.2178 - val_mse: 0.2178\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1009 - mse: 0.1009\n",
      "Epoch 36: loss improved from 0.12139 to 0.10088, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.1009 - mse: 0.1009 - val_loss: 0.4861 - val_mse: 0.4861\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0979 - mse: 0.0979\n",
      "Epoch 37: loss improved from 0.10088 to 0.09789, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 43s 1s/step - loss: 0.0979 - mse: 0.0979 - val_loss: 0.2358 - val_mse: 0.2358\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0885 - mse: 0.0885\n",
      "Epoch 38: loss improved from 0.09789 to 0.08853, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0885 - mse: 0.0885 - val_loss: 0.2266 - val_mse: 0.2266\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0787 - mse: 0.0787\n",
      "Epoch 39: loss improved from 0.08853 to 0.07871, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0787 - mse: 0.0787 - val_loss: 0.2250 - val_mse: 0.2250\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0806 - mse: 0.0806\n",
      "Epoch 40: loss did not improve from 0.07871\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0806 - mse: 0.0806 - val_loss: 0.3139 - val_mse: 0.3139\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0707 - mse: 0.0707\n",
      "Epoch 41: loss improved from 0.07871 to 0.07071, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.6314 - val_mse: 0.6314\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0705 - mse: 0.0705\n",
      "Epoch 42: loss improved from 0.07071 to 0.07046, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0705 - mse: 0.0705 - val_loss: 0.2518 - val_mse: 0.2518\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0743 - mse: 0.0743\n",
      "Epoch 43: loss did not improve from 0.07046\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0743 - mse: 0.0743 - val_loss: 0.2401 - val_mse: 0.2401\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0600 - mse: 0.0600\n",
      "Epoch 44: loss improved from 0.07046 to 0.05998, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0600 - mse: 0.0600 - val_loss: 0.1889 - val_mse: 0.1889\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0586 - mse: 0.0586\n",
      "Epoch 45: loss improved from 0.05998 to 0.05855, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0586 - mse: 0.0586 - val_loss: 0.1673 - val_mse: 0.1673\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0517 - mse: 0.0517\n",
      "Epoch 46: loss improved from 0.05855 to 0.05167, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0517 - mse: 0.0517 - val_loss: 0.1516 - val_mse: 0.1516\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0519 - mse: 0.0519\n",
      "Epoch 47: loss did not improve from 0.05167\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.4129 - val_mse: 0.4129\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0529 - mse: 0.0529\n",
      "Epoch 48: loss did not improve from 0.05167\n",
      "40/40 [==============================] - 40s 1s/step - loss: 0.0529 - mse: 0.0529 - val_loss: 0.2309 - val_mse: 0.2309\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0481 - mse: 0.0481\n",
      "Epoch 49: loss improved from 0.05167 to 0.04809, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.2180 - val_mse: 0.2180\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0444 - mse: 0.0444\n",
      "Epoch 50: loss improved from 0.04809 to 0.04441, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0444 - mse: 0.0444 - val_loss: 0.2287 - val_mse: 0.2287\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0437 - mse: 0.0437\n",
      "Epoch 51: loss improved from 0.04441 to 0.04371, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.2004 - val_mse: 0.2004\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0402 - mse: 0.0402\n",
      "Epoch 52: loss improved from 0.04371 to 0.04016, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0402 - mse: 0.0402 - val_loss: 0.1529 - val_mse: 0.1529\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0402 - mse: 0.0402\n",
      "Epoch 53: loss improved from 0.04016 to 0.04016, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0402 - mse: 0.0402 - val_loss: 0.1715 - val_mse: 0.1715\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0339 - mse: 0.0339\n",
      "Epoch 54: loss improved from 0.04016 to 0.03391, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.1382 - val_mse: 0.1382\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0342 - mse: 0.0342\n",
      "Epoch 55: loss did not improve from 0.03391\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.1920 - val_mse: 0.1920\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0341 - mse: 0.0341\n",
      "Epoch 56: loss did not improve from 0.03391\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.2036 - val_mse: 0.2036\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0367 - mse: 0.0367\n",
      "Epoch 57: loss did not improve from 0.03391\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.1865 - val_mse: 0.1865\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0383 - mse: 0.0383\n",
      "Epoch 58: loss did not improve from 0.03391\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.1546 - val_mse: 0.1546\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0320 - mse: 0.0320\n",
      "Epoch 59: loss improved from 0.03391 to 0.03199, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 43s 1s/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.1235 - val_mse: 0.1235\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0313 - mse: 0.0313\n",
      "Epoch 60: loss improved from 0.03199 to 0.03135, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0952 - val_mse: 0.0952\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0321 - mse: 0.0321\n",
      "Epoch 61: loss did not improve from 0.03135\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.1414 - val_mse: 0.1414\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0266 - mse: 0.0266\n",
      "Epoch 62: loss improved from 0.03135 to 0.02662, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.1250 - val_mse: 0.1250\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0290 - mse: 0.0290\n",
      "Epoch 63: loss did not improve from 0.02662\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.4676 - val_mse: 0.4676\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0292 - mse: 0.0292\n",
      "Epoch 64: loss did not improve from 0.02662\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.1750 - val_mse: 0.1750\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0252 - mse: 0.0252\n",
      "Epoch 65: loss improved from 0.02662 to 0.02520, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.5816 - val_mse: 0.5816\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 66: loss improved from 0.02520 to 0.02241, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.3597 - val_mse: 0.3597\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 67: loss improved from 0.02241 to 0.01946, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.1713 - val_mse: 0.1713\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 68: loss did not improve from 0.01946\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.1193 - val_mse: 0.1193\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 69: loss improved from 0.01946 to 0.01934, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.1198 - val_mse: 0.1198\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 70: loss did not improve from 0.01934\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0977 - val_mse: 0.0977\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 71: loss improved from 0.01934 to 0.01865, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0980 - val_mse: 0.0980\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 72: loss improved from 0.01865 to 0.01745, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.1265 - val_mse: 0.1265\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 73: loss did not improve from 0.01745\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.1166 - val_mse: 0.1166\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 74: loss did not improve from 0.01745\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.1030 - val_mse: 0.1030\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 75: loss improved from 0.01745 to 0.01632, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.1071 - val_mse: 0.1071\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 76: loss improved from 0.01632 to 0.01595, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.1057 - val_mse: 0.1057\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 77: loss did not improve from 0.01595\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0855 - val_mse: 0.0855\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0148 - mse: 0.0148\n",
      "Epoch 78: loss improved from 0.01595 to 0.01476, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.1004 - val_mse: 0.1004\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0127 - mse: 0.0127\n",
      "Epoch 79: loss improved from 0.01476 to 0.01272, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.1014 - val_mse: 0.1014\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0146 - mse: 0.0146\n",
      "Epoch 80: loss did not improve from 0.01272\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.1107 - val_mse: 0.1107\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 81: loss did not improve from 0.01272\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.1078 - val_mse: 0.1078\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 82: loss did not improve from 0.01272\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.1114 - val_mse: 0.1114\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 83: loss did not improve from 0.01272\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.1608 - val_mse: 0.1608\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0126 - mse: 0.0126\n",
      "Epoch 84: loss improved from 0.01272 to 0.01259, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.1878 - val_mse: 0.1878\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0130 - mse: 0.0130\n",
      "Epoch 85: loss did not improve from 0.01259\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0971 - val_mse: 0.0971\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 86: loss improved from 0.01259 to 0.01130, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.1125 - val_mse: 0.1125\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 87: loss did not improve from 0.01130\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.1206 - val_mse: 0.1206\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 88: loss did not improve from 0.01130\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.1909 - val_mse: 0.1909\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0125 - mse: 0.0125\n",
      "Epoch 89: loss did not improve from 0.01130\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.1224 - val_mse: 0.1224\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0106 - mse: 0.0106\n",
      "Epoch 90: loss improved from 0.01130 to 0.01064, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0943 - val_mse: 0.0943\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0107 - mse: 0.0107\n",
      "Epoch 91: loss did not improve from 0.01064\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0979 - val_mse: 0.0979\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0112 - mse: 0.0112\n",
      "Epoch 92: loss did not improve from 0.01064\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.1081 - val_mse: 0.1081\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0108 - mse: 0.0108\n",
      "Epoch 93: loss did not improve from 0.01064\n",
      "40/40 [==============================] - 40s 1s/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.2226 - val_mse: 0.2226\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 94: loss did not improve from 0.01064\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.1115 - val_mse: 0.1115\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 95: loss improved from 0.01064 to 0.01026, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.1159 - val_mse: 0.1159\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 96: loss improved from 0.01026 to 0.00935, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.1569 - val_mse: 0.1569\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 97: loss improved from 0.00935 to 0.00842, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.2831 - val_mse: 0.2831\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 98: loss did not improve from 0.00842\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0914 - val_mse: 0.0914\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 99: loss improved from 0.00842 to 0.00820, saving model to /data2/models/inception_resnet_2_64x64_small_v1/checkpoints/cp.ckpt\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.1521 - val_mse: 0.1521\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 100: loss did not improve from 0.00820\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.1123 - val_mse: 0.1123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62cbf17c40>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen, batch_size=hparams['batch_size'], epochs=hparams['num_epochs'], shuffle=True, verbose=1, validation_data=val_gen, callbacks=[tensorboard_callback, model_checkpoint_callback, hparam_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec5e631e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f62a1b41240>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(checkpoint_filepath) # model might be overfitting. train mse is lowering but val mse fluctuates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f37d55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 298ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92956d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(TEST_PATH, 'r') as file:\n",
    "    y_test = np.asarray(file['specz_redshift'][:])\n",
    "    oid_test = np.asarray(file['object_id'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8cf4741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAygAAANGCAYAAAAWCqrbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACoc0lEQVR4nOzdeXxU5d3///eZmewkIUBYEvYgSyAsWhYVREQUJJSt1raAWltBWfRre7daS+/e9baW/npXiwiIgNaFtkpZrAhYBcUVQcASVknCGiAECAnZMzPn90dKaiSBmWQmZ2byej4eeWjmXHPOe65ZyGeu6zrHME3TFAAAAAAEAJvVAQAAAADgEgoUAAAAAAGDAgUAAABAwKBAAQAAABAwKFAAAAAABAwKFAAAAAABgwIFAAAAQMCgQAEAAAAQMBxWBwg0pmnK7W68a1fabEajHi+Y0De1o1/qRt/Ujn6pG31TO/qldvRL3Rqzb2w2Q4ZhNMqx6sM0nZLrlNUxarK3k2EEz5/9wZO0kbjdps6fL26UYzkcNiUkxKiwsEROp7tRjhks6Jva0S91o29qR7/Ujb6pHf1SO/qlbo3dNy1axMhuD9wCRa5TMs+OtDpFDUarTZKjg9UxPMYULwAAAAABgxEUAAAAwGdMuRVYo2x2BdfUREZQAAAAAAQMChQAAAAAV/Tee+/pzjvv1LXXXqsbbrhBs2fPVnZ29mXttmzZogkTJigtLU2jRo3SihUrvD4WBQoAAADgQy7THVA/DfXpp59q9uzZ6tKlixYsWKBf/epXOnz4sH74wx+qqKiout2uXbs0c+ZMpaamaunSpZo4caKefPJJrVy50qvjsQYFAAAAQJ3efvttJSUl6fe//331KZ6Tk5N15513aseOHRo+fLgkaeHChUpNTdVTTz0lSRoyZIhOnTql+fPna/LkybLZPBsbYQQFAAAAQJ2cTqdiYmJqXH8mNja2RpuKigpt3bpVY8eOrXH7uHHjlJeXp3379nl8PEZQAAAAAB8xJbkD7KxZpqRTJ09q2rRpdbbZtGlTndu+853v6N5779Wrr76q8ePHq7CwUL///e+VkpKi66+/XpJ07NgxVVZWqmvXrjXu261bN0lSVlaW+vTp41FeRlAAAAAA1GngwIF67rnn9Mwzz2jgwIEaOXKkjh8/rhdffFHh4eGSpIKCAklSXFxcjfte+v3Sdk8wggIAAACEuKSkpCuOklzJzp079bOf/UyTJ0/WLbfcoqKiIj3//PO6//779de//lXNmjWrbvv1aWBfV9fttaFAAQAAAHwo0C7U2FBPPvmkhgwZol/+8pfVt1133XW66aabtHLlSv3whz9UfHy8pMtHSgoLCyVdPrJyJUzxAgAAAFCnrKws9ezZs8ZtLVq0UOvWrXXs2DFJUseOHRUWFnbZtVEyMzMlSSkpKR4fjwIFAAAAQJ2SkpK0d+/eGrfl5eXpzJkzSk5OliSFh4dryJAh2rBhQ41269atU2JiolJTUz0+HlO8AAAAAB9ymYF1Fq+GmjJliv73f/9XTzzxhEaOHKnCwkItWbJE0dHR+va3v13dbtasWZo6darmzp2rcePGaefOnVq5cqWeeOIJj6+BIlGgAAAAALiCKVOmKCwsTH/5y1+0Zs0aRUdHKy0tTb///e/VunXr6nYDBgzQokWL9PTTT2vt2rVq27at5s6dqzvvvNOr41GgAAAAAKiTYRi66667dNddd1217fDhw6uvLF9fFCgAAACAj5gyA/BCjYGV52pYJA8AAAAgYFCgAAAAAAgYTPECAAAAfMgVZFOqAg0jKAAAAAACBgUKAAAAgIDBFC8AAADAhwLtLF7BhhEUAAAAAAGDAgUAAABAwGCKFwAAAOAjpiSXGVhTvAIrzdUxggIAAAAgYFCgAAAAAAgYAVWgFBcX66abblKPHj2UkZFx1fZr1qzR6NGjlZaWpvT0dG3YsKERUgIAAAB1cwfYT7AJqAJl0aJFcrlcHrXduHGjHnvsMY0aNUpLly7VkCFD9Mgjj+jjjz/2c0oAAAAA/hIwBUpWVpb+8pe/aM6cOR61nz9/vkaPHq2f/vSnGjJkiObOnasbb7xRzz77rJ+TAgAAAPCXgClQfvvb3+p73/ueunTpctW2x48fV3Z2ttLT02vcnp6ert27d+v8+fP+igkAAABckUtmQP0Em4A4zfDGjRt14MABPfvss9q7d+9V22dnZ0uSunbtWuP2lJQUmaap7OxstWjRot55HI7GqdvsdluN/+I/6Jva0S91o29qR7/Ujb6pHf1SO/qldk6XW69sPKB2ibEaPaiD1XEQIiwvUEpLSzVv3jz95Cc/UbNmzTy6T0FBgSQpLi6uxu3x8fE1tteHzWYoISGm3vevj7i4qEY9XjChb2pHv9SNvqkd/VI3+qZ29Evt6Jeanlv5pd774oTatozWd2/tbnUchAjLC5TFixerZcuWmjRpktf3NQyjxu/mvy+K883bveF2myosLKn3/b1ht9sUFxelwsJSuVzBeI4F/6Fvake/1I2+qR39Ujf6pnb0S+3ol8tt3nFC72w9KkPSA5P6NlrfxMVFBfRIVtWFGq1OUVOAxbkqSwuUnJwcvfjii1q4cKGKiookSSUlJdX/LS4uVkzM5aMZXx8padWqVfXthYWFki4fWfGW09m4Hzwul7vRjxks6Jva0S91o29qR7/Ujb6pHf1SO/qlylfHL+jVdw5Kku68pZuu69lG+fnF9A18wtIC5cSJE6qsrNT06dMv23b33XerX79+euONNy7bdmntSXZ2tlJSUqpvz8rKkmEYl61NAQAAgG+cLyzTorV75HKbGtiztcZe38nqSAgxlhYovXr10iuvvFLjtv379+t3v/udfvOb3ygtLa3W+3Xo0EFdu3bV+vXrNWrUqOrb161bp759+zZogTwAAABqV+l0aeGaDBUWV6h9YjPdd0evBk2tD1WMIzWMpQVKXFycBg8eXOu23r17q3fv3pKkxx9/XGvXrtW+ffuqtz/00EN65JFH1LFjR91www3atGmTPvnkEy1btqxRsgMAADQlpmnqlY0HdfjURcVEOjRncpoiwu1Wx0IIsnyRvCfcbvdlV5gfM2aMysrK9Pzzz2v58uXq1KmTnnnmGQ0dOtSilAAAAKFr044T+mTPaRmG9OCEPkpszhnN4B8BV6AMHjxYBw8erHHbvHnzNG/evMvaTpw4URMnTmysaAAAAE3SgaP5+tumTEnSXSO6KbUz0+mvxCWmvTVE4J6jDQAAAJY7W1CqRWv3yG2aur53W40ayAUZ4V8UKAAAAKhVeaVLz63KUFFppTq1jdU9o3uwKB5+F3BTvAAAAGA90zT15w0HdOxMkWKjwzRnUprCw1gUfzWmJHeAXRkxwOJcFSMoAAAAuMw7247r8325stsMzZzQRy3iIq2OhCaCAgUAAAA17Dl8Tis/qFoU//1br1GPjgkWJ0JTwhQvAAAAVDuTX6Ilb+6VaUrD+rbTiAHJVkcKOpzFq2EYQQEAAIAkqazCqQWrM1Rc5lRKUpym3saieDQ+ChQAAADINE0tf3u/cvKKFd8sXDMnpinMwZ+KaHxM8QIAAIDWfXZUOw7myWE3NHtimhJiI6yOFLSY4tUwlMUAAABN3JeZZ7X2w2xJ0tTbeiglOd7iRGjKKFAAAACasFPnirX0rb0yJY24Nlk39UuyOhKaOKZ4AQAANFElZU4tWJWh0nKXureP1/dHXmN1pKBXdaHGwJrixYUaAQAAEPDcpqll6/bp9PkSJcRG6MGJaXLY+dMQ1uNVCAAA0AT94+PD+jLzrBx2m2ZPSlN8TLjVkQBJTPECAABocnYczNM/PjkiSbpndA91aRdnbaCQYgTgWbwCLc+VMYICAADQhOTkFWnZ2/skSaO+1UE3prWzOBFQEwUKAABAE1FcVqkFqzJUXuFSr04J+u4tKVZHAi7DFC8AAIAmwO02teTNvTpzoVSt4iP1wPjestv4rtrXTEmuABsD4CxeAAAACDirPszSnsPnFe6oWhQfG82ieAQmChQAAIAQt21/rjZsPSZJum9sL3VsE2txIqBuTPECAAAIYcdyL+rFt/dLksYM6ahBvdpYnCjEmYF3ocZgm+PFCAoAAECIulhSoedWZ6jC6VafLi00+SYWxSPwUaAAAACEIJfbreff3KuzBWVqnRClGeN7y2YLsG/2gVowxQsAACAEvbE5S/uP5isi3K45k9IUExlmdaQmI/Au1BhcGEEBAAAIMZ9knNK7XxyXJP14bKqSE5tZnAjwHAUKAABACDl8qlAvbzwoSfr2jZ11XY9EixMB3mGKFwAAQIgoKK5aFO90udW/Wyt9e2gXqyM1OaYklxlYYwBBdhIvRlAAAABCgdPl1qI1Gcq/WK52LaN1/7hU2QzWQiD4UKAAAACEgL9uOqRDJwoUFWHX7ElpiopgogyCE69cAACAIPfhv07q/Z05MiRNH9db7VrGWB2pCTPkDrgxgOAaSQu03gMAAIAXMnMK9Oo7VYviJ9zUVf26tbI4EdAwFCgAAABBKv9iuRauzpDLbepbPRKVfn0nqyMBDcYULwAAgCBU6XRr4ZoMFRRXKDkxRveN7SWDRfEBgQs1NgwjKAAAAEHGNE29+s+Dyj5ZqJhIh+ZMSlNkON87IzRQoAAAAASZ93fl6OPdp2QY0ozxvdU6IdrqSIDPUGoDAAAEkYPH8vXX9w5Jku68uZv6dGlpcSJ8HRdqbLjA6j0AAADU6XxhmRat3SOX29Tg1Da6fVAHqyMBPkeBAgAAEAQqKl1asDpDF0sq1bF1M907pieL4hGSmOIFAAAQ4EzT1MsbD+jo6YtqFhWm2ZPTFBFmtzoW6uDmLF4NwggKAABAgHt3+3F9tjdXNsPQzAl91Co+yupIgN9QoAAAAASwvUfO6/X3MyVJ3xvZTT07JVicCPAvpngBAAAEqLwLpXp+7R6ZpnRjWluNvK691ZHgARdjAA1C7wEAAASg8gqXFqzKUHGZU13axeru23uwKB5NAgUKAABAgDFNUy+u368TeUWKiwnXrIlpCnOwKB5NA1O8AAAAAsyGz49p+4EzstsMzZrYRy3iIq2OBA+ZMgLwQo3BNfIWWL0HAADQxGVkn9OqD7IkSVNGddc17ZtbGwhoZBQoAAAAASL3fImef3OvTEk390/SzQOSrY4ENDqmeAEAAASA0nKnnl21W6XlTnVrH68fjOpudSTUk5sxgAah9wAAACzmNk0tW7dPp86VqHmzcM2a0EcOO3+moWnilQ8AAGCxdZ8c0a5DZ+WwG5o9qa/im0VYHQmwDFO8AAAALLTrUJ7WfnxYkjTt9h7qmhRncSI0lMsMrrNmBRpGUAAAACxy8myxlr61T5I08rr2GtY3yeJEgPUoUAAAACxQUlapBat2q6zCpR4dmuuuW7pZHQkICBQoAAAAjcztNvXCW/uUm1+qlnERenAii+KBS1iDAgAA0MjWfJSt3VnnFO6wafakvoqLDrc6EnzElOQKsDEA0+oAXgqs3gMAAAhx2w+c0dufHZUk3Tumpzq1jbU4ERBYKFAAAAAayfEzRVr+dtWi+NGDOmpI77YWJwICD1O8AAAAGkFRadWi+IpKt3p3TtDkm7taHQl+YchtBtoYQMNOezxt2jRt27at1m1PP/20xo4dK0nasmWLnnnmGWVlZalt27a69957NWXKFK+PR4ECAADgZy63W0ve3KOzBWVKbB6pGeP7yG4LtD9igdr9+te/VlFRUY3bXn75Zf3zn//U9ddfL0natWuXZs6cqfHjx+uxxx7Tzp079eSTTyo8PFx33nmnV8ejQAEAAPCzVR9ka++RfIWH2TRnUl81iwqzOhLgsW7dLj8F9k9/+lPdeOONatGihSRp4cKFSk1N1VNPPSVJGjJkiE6dOqX58+dr8uTJsnlRkFO6AwAA+NHWvae1cdsxSdKPx6aqfetmFieCv7lkC6gfX9u5c6dOnDihcePGSZIqKiq0devW6qlel4wbN055eXnat2+fV/tnBAUAAMBPjp6+qJc2HJAkjb2+k77Vs7XFidBUnTx5UtOmTatz+6ZNmzze17p16xQVFaWRI0dKko4dO6bKykp17VpzXdWlkZesrCz16dPH4/0zggIAAOAHhcUVWrB6tyqdbvVNaamJw1gUj+DndDq1ceNGjRw5UtHR0ZKkgoICSVJcXFyNtpd+v7TdU4ygAAAA+JjT5dbitXt0vrBcbVpEa/q4VNlsDTuTEoKDKcllBtZzbUpKSkryapSkLp988onOnTun9PT0y7YZRu2Pu67b68IICgAAgI+9vjlTB49fUGS4XXMmpSk6kkXxCA3r1q1T8+bNNXTo0Orb4uPjJV0+UlJYWCjp8pGVq6FAAQAA8KGPdp/Uph0nJEn3j0tVUqsYixMBvlFWVqZNmzZp9OjRCgv7T9HdsWNHhYWFKTs7u0b7zMxMSVJKSopXx6FAAQAA8JGskwV69Z2DkqQJQ7towDWJFieCFdyyBdSPr2zevFnFxcXVZ++6JDw8XEOGDNGGDRtq3L5u3TolJiYqNTXVq+NQoAAAAPhAQVG5Fq7OkNNlasA1rZR+Y2erIwE+9dZbbykpKUnXXXfdZdtmzZqlPXv2aO7cufr888+1ePFirVy5Ug8//LBX10CRKFAAAAAazOlya+GaPbpQVKGkVjH6cXqqbF4uDAYCWUFBgT766CPdcccdtS56HzBggBYtWqSMjAz96Ec/0qpVqzR37lyvryIvcRYvAACABlvx7lfKzClQdIRDcyanKSqCP7GaLNOQywywMQAfnFUsPj5ee/bsuWKb4cOHa/jw4Q0+VoD1HgAAQHD5YFeOtnx5UoakGeN7q01CtNWRgKBGgQIAAFBPXx2/oBXvfiVJmnxzitK6trQ4ERD8GH8EAACoh/OFZVq0do9cblMDe7bWmMEdrY6EAGBKciuw1h+ZVgfwEiMoAAAAXqp0urRwTYYKiyvUPrGZ7rujl9dXywZQOwoUAAAAL5imqVc2HtThUxcVE1m1KD4i3G51LCBkWD7F66OPPtKSJUuUmZmpoqIitWnTRrfeeqtmz56t2NjYOu83bdo0bdu27bLb169f7/XVKgEAADy1accJfbLntAxDenBCHyU2j7I6EgJMwJ3FK8hYXqAUFBRowIABuueeexQXF6dDhw5pwYIFOnTokF588cUr3vfaa6/Vo48+WuO29u3b+zMuAABowvYfOa+/bcqUJN01optSO7ewOBEQeiwvUNLT05Wenl79++DBgxUeHq5f/epXys3NVZs2beq8b1xcnPr3798IKQEAQFN35nyJnludIbdp6vrebTVqYAerIwEhyfICpTbNmzeXJDmdTmuDAAAASCqvdOl3r+7UxZJKdWobq3tG92BRPGplSnIF2DLvYDuLV8AUKC6XS06nU5mZmVq4cKFGjBih5OTkK95n27Zt6t+/v1wul/r166eHH35YAwcObHAWh6NxXlR2u63Gf/Ef9E3t6Je60Te1o1/qRt/Ujn65nGmaWvrmPmWfLFBcdJj+3539FB0VZnWsgMFrBr4WMAXKiBEjlJubK0kaNmyYnn766Su2HzhwoMaPH6/OnTvrzJkzWr58uX74wx/q1Vdf1YABA+qdw2YzlJAQU+/710dcHIvr6kLf1I5+qRt9Uzv6pW70Te3ol/9Y/X6mPttzWnaboV/cO0jdOnMxxtrwmoGvGKZpBsSoz4EDB1RSUqLMzEwtWrRIHTt21EsvvSS73bPT9pWUlCg9PV0pKSlaunRpvXO4XG4VFpbW+/7esNttiouLUmFhqVwud6McM1jQN7WjX+pG39SOfqkbfVM7+qWmjKxz+r+/7ZJpSg9M6qthaW3pl29o7NdMXFxUQI/WFFSc1KvZU62OUcO0rq8pPjzJ6hgeC5gRlJ49e0qqOjNXamqqJk+erHfffVejR4/26P7R0dEaPny43nnnnQZncTob94PH5XI3+jGDBX1TO/qlbvRN7eiXutE3taNfpDP5JVq0JkOmKQ3vn6Q7buisCxdKmny/1IXXDHwlIMvPXr16yW6369ixY17dL0AGgwAAQJArq3BqweoMFZc5lZIUp7tH92RRPNBIAmYE5et27doll8vl1TVNSkpKtGXLFqWlpfkxGQAACHWmaWr52/uVk1es+GbhmjkxTWGNdAIdhAIj4M7iJQVXcW15gTJ79mz16dNHPXr0UGRkpA4cOKBly5apR48euvXWWyVJjz/+uNauXat9+/ZJkr744gstX75co0aNUlJSks6cOaOXXnpJeXl5mj9/vpUPBwAABLl1nx3VjoN5ctgNzZ6YpoTYCKsjAU2K5QVK3759tX79er3wwgsyTVPJycn67ne/qx/96EcKDw+XJLndbrlcrur7JCYmqqKiQk8//bQuXLigqKgoDRgwQL/5zW/Ut29fqx4KAAAIcl9mntXaD7MlSVNv66GU5HiLEwFNj+UFyvTp0zV9+vQrtpk3b57mzZtX/XunTp20fPlyf0cDAABNyKlzxVr61l6ZkkZcm6yb+gXPWY8QWNxmoE3xCi70HgAAaPJKypxasCpDpeUudW8fr++PvMbqSECTRYECAACaNLdpatm6fTp9vkQJsRF6cGKaHAF8nQ0g1Fk+xQsAAMBK//j4sL7MPCuH3abZk9IUHxNudSQEMVOSK8DOmhVsF+Lg6wEAANBk7TiYp398ckSSdM/oHurSLs7aQAAoUAAAQNOUk1ekZW9XXcJg1Lc66Ma0dhYnAiAxxQsAADRBxWWVWrAqQ+UVLvXqlKDv3pJidSSEEM7i1TD0HgAAaFLcblNL3tyrMxdK1So+Ug+M7y27jT+JgEDBuxEAADQpqz7M0p7D5xXuqFoUHxvNonggkDDFCwAANBnb9udqw9ZjkqT7xvZSxzaxFidCqOEsXg3HCAoAAGgSjuVe1Itv75ckjRnSUYN6tbE4EYDaUKAAAICQd7GkQs+tzlCF060+XVpo8k0sigcCFVO8AABASHO53Xr+zb06W1Cm1glRmjG+t2y2wJqCg1BiBOBZvILr9R5ovQcAAOBTb2zO0v6j+YoIt2vOpDTFRIZZHQnAFVCgAACAkPVJxim9+8VxSdKPx6YqObGZxYkAXA1TvAAAQEg6fKpQL288KEn69o2ddV2PRIsToalwBdwUr+BC7wEAgJBTUFy1KN7pcqt/t1b69tAuVkcC4CEKFAAAEFKcLrcWrclQ/sVytWsZrfvHpcpmBNciYaApY4oXAAAIKX/ddEiHThQoKsKu2ZPSFBXBnztoXO4gO2tWoGEEBQAAhIwP/3VS7+/MkSFp+rjeatcyxupIALxEgQIAAEJCZk6BXn2nalH8hJu6ql+3VhYnAlAfjHkCAICgl3+xXAtXZ8jlNvWtHolKv76T1ZHQRJkKvLN4mVYH8FJg9R4AAICXKp1uLVyToYLiCiUnxui+sb1ksCgeCFoUKAAAIGiZpqlX/3lQ2ScLFRPp0JxJaYoMZ4IIEMx4BwMAgKD1/q4cfbz7lAxDmjG+t1onRFsdCU2dKbnNABvBC7I5XoygAACAoHTwWL7++t4hSdKdN3dTny4tLU4EwBcoUAAAQNA5X1imRWv3yOU2NTi1jW4f1MHqSAB8hCleAAAgqFRUurRgdYYullSqY+tmundMTxbFI2CYMuQKsDEAM8guHBlYvQcAAHAFpmnq5Y0HdPT0RTWLCtPsyWmKCLNbHQuAD1GgAACAoPHu9uP6bG+ubIahmRP6qFV8lNWRAPgYU7wAAEBQ2HvkvF5/P1OS9L2R3dSzU4LFiYDaBdxZvIIMIygAACDg5V0o1fNr98g0pRvT2mrkde2tjgTATyhQAABAQCuvcGnBqgwVlznVpV2s7r69B4vigRDGFC8AABCwTNPUi+v360RekeJiwjVrYprCHCyKR2BzMwbQIPQeAAAIWBs+P6btB87IbjM0a2IftYiLtDoSAD+jQAEAAAEpI/ucVn2QJUmaMqq7rmnf3NpAABoFU7wAAEDAyT1fouff3CtT0s39k3TzgGSrIwEec3EWrwZhBAUAAASU0nKnnl21W6XlTnVrH68fjOpudSQAjYgCBQAABAy3aWrZun06da5EzZuFa9aEPnLY+XMFaEqY4gUAAALGuk+OaNehs3LYDc2e1FfxzSKsjgR4xVTgXajRtDqAl/hKAgAABIRdh/K09uPDkqRpt/dQ16Q4ixMBsAIFCgAAsNzJs8Va+tY+SdLI69prWN8kixMBsApTvAAAgKVKyiq1YNVulVW41KNDc911SzerIwENYMhtBtoYQGBNObuaQOs9AADQhLjdpl54a59y80vVMi5CD05kUTzQ1PEJAAAALLPmo2ztzjqncIdNsyf1VVx0uNWRAFiMKV5AEzUleYbHbVfkLPFjEgBN1fYDZ/T2Z0clScVvf6LHn/nrVe/D5xGCgSvIplQFGkZQAABAozt+pkjL365aFD96UEe5vzpmcSIAgYICBQAANKqi0qpF8RWVbvXunKDJN3e1OhKAAMIULwAA0GhcbreWvLlHZwvKlNg8UjPG95HdxvelCB1cqLHh+EQAAACNZtUH2dp7JF/hYTbNmdRXzaLCrI4EIMBQoAAAgEaxde9pbdxWtdbkx2NT1b51M4sTAQhETPECAAB+d/T0Rb204YAkaez1nfStnq0tTgT4T+BdqDG40HsAAMCvCosrtGD1blU63eqb0lITh7EoHkDdKFAAAIDfOF1uLV67R+cLy9WmRbSmj0uVzRZYC4gBBBameAEAAL95fXOmDh6/oMhwu+ZMSlN0JIviEfrcXKixQRhBAQAAfvHR7pPatOOEJOn+calKahVjcSIAwYACBQAA+FzWyQK9+s5BSdKEoV004JpEixMBCBZM8QIAAD5VUFSuhasz5HSZGnBNK6Xf2NnqSECjMU3JFWgXagyyKzVSoABN1IqcJVZHABCCnC63Fq7ZowtFFUpqFaMfp6fKZlz9jzU+kwBcwhQvAADgMyve/UqZOQWKjnBozuQ0RUXwXSgA7/CpAQAAfOKDXTna8uVJGZJmjO+tNgnRVkcCLGAE4IUaA2vK2dUEWu8BAIAg9NXxC1rx7leSpMk3pyita0uLEwEIVhQoAACgQc4XlmnR2j1yuU0N7NlaYwZ3tDoSgCDGFC8AAFBvlU6XFq7JUGFxhdonNtN9d/SS4cGieCCUuQPsLF7BhhEUAABQL6Zp6pWNB3X41EXFRFYtio8It1sdC0CQo0ABAAD1smnHCX2y57QMQ3pwQh8lNo+yOhIAP1q5cqW+/e1vKy0tTddff70eeOCBGtu3bNmiCRMmKC0tTaNGjdKKFSvqdRymeAEAAK8dOJqvv23KlCTdNaKbUju3sDgREDjcQXbWLE8sWLBAf/7zn/XAAw+oX79+Kigo0EcffVS9fdeuXZo5c6bGjx+vxx57TDt37tSTTz6p8PBw3XnnnV4diwIFAAB45WxBqRat3SO3aer63m01amAHqyMB8KOsrCwtXrxYL7zwgoYOHVp9+6hRo6r/f+HChUpNTdVTTz0lSRoyZIhOnTql+fPna/LkybLZPJ+4xRQvAADgsfJKl55blaGi0kp1ahure0b3YFE8EOJWr16tDh061ChOvq6iokJbt27V2LFja9w+btw45eXlad++fV4djxEUAADgEdM09ecNB3TsTJFio8M0Z1KawsNYFA98nanAO4uXKenkyZOaNm1anW02bdpU57Z//etf6t69uxYuXKjXXntNFy9eVP/+/fXLX/5SvXr10rFjx1RZWamuXbvWuF+3bt0kVY3A9OnTx+O8FCgAAMAj72w7rs/35cpuMzRzQh+1iIu0OhKARpCXl6e9e/fq0KFD+s1vfqOwsDA999xz+uEPf6h//vOfKigokCTFxcXVuN+l3y9t9xQFCgAAuKo9h89p5QdVi+K/f+s16tExweJEALyRlJR0xVGSKzFNUyUlJVqwYIGuueYaSVLv3r01cuRIvf7667r22mslqc7pnt5OA6VAAYBGNCV5htURPLIiZ4nP9+npY7fy2P46vpV88djP5JdoyZt7ZZrSsL7ttHzc/2p5A/YHhDq3GVrLvOPj49WqVavq4kSSWrdura5duyozM1MjRoyQdPlISWFhoaTLR1auJrR6DwAA+FRZhVMLVmeouMyplKQ4Tb2th9WRADSylJSUWm83TVM2m00dO3ZUWFiYsrOza2zPzMy84v3rQoECAABqZZqmlr+9Xzl5xYpvFq6ZE9MU5uBPB6Cpufnmm3X27Fl99dVX1bfl5uYqOztbPXr0UHh4uIYMGaINGzbUuN+6deuUmJio1NRUr45n+afMRx99pKlTp2rIkCHq06ePRo4cqd/97ne6ePHiVe+7Zs0ajR49WmlpaUpPT7+sUwAAQP2t++yodhzMk8NuaPbENCXERlgdCQgChtxmYP2ogReOHDVqlHr37q05c+Zo/fr1eu+99/TAAw+oRYsW+u53vytJmjVrlvbs2aO5c+fq888/1+LFi7Vy5Uo9/PDDXl0DRQqANSgFBQUaMGCA7rnnHsXFxenQoUNasGCBDh06pBdffLHO+23cuFGPPfaYpk+frhtvvFHvvfeeHnnkEcXGxtZ5jmYAAOCZXYfytPbDqukaU2/roZTkeIsTAbCK3W7X0qVL9dRTT+m///u/5XQ6NXDgQP3xj39UdHS0JGnAgAFatGiRnn76aa1du1Zt27bV3Llzvb6KvBQABUp6errS09Orfx88eLDCw8P1q1/9Srm5uWrTpk2t95s/f75Gjx6tn/70p5KqrlZ5+PBhPfvssxQoAAA0wIkzF/X82j0yJY24Nlk39UuyOhIAi7Vs2VJ//OMfr9hm+PDhGj58eIOPZfkUr9o0b95ckuR0Omvdfvz4cWVnZ9cobKSqYmf37t06f/68vyMCABCSSsqcevLFbSotd6l7+3h9f+Q1V78TgBrcMgLqJ9hYPoJyicvlktPpVGZmphYuXKgRI0YoOTm51raXzhDwzatVpqSkyDRNZWdnq0WLFvXO4mikBYB2u63Gf/Ef9E3t6Je60Te+1Vifg4F27EA4vpVsdkMvrN6rnLwitYiL0Jzv9FVkRP3/VAilvuQzpm70DXwtYAqUESNGKDc3V5I0bNgwPf3003W2retqlfHx8TW214fNZighIabe96+PuLioRj1eMKFvake/1I2+8Y3G/hwMlGMHwvGttHHbCe38Kk9hDpvm3jdYnTs07GKModiXfMbUjb6BrwRMgfLCCy+opKREmZmZWrRokR544AG99NJLstvtdd7nm1elNE2z1tu94XabKiwsqff9vWG32xQXF6XCwlK5XO5GOWawoG9qR7/Ujb7xrfz84iZ57EA4vlVsXZP1t3cPSpJm39lfbeIjG9wXodSXfMbUrbH7Ji4uKqBHa0zp32fOChym1QG8FDAFSs+ePSVJ1157rVJTUzV58mS9++67Gj169GVtvz5S0qpVq+rb63u1ym9yOhv3g8flcjf6MYMFfVM7+qVu9I1vWNmHVj9/Vh/fCkaLODlGDZYk3T64o275Vgfl5xc3uC9CsS/5jKkbfQNfCcjys1evXrLb7Tp27Fit2y+tPfnm1SqzsrJkGMZla1MAAEAdIsIUNnaojPAw9eqUoO+N7GZ1IgBNXEAWKLt27ZLL5VL79u1r3d6hQwd17dpV69evr3H7unXr1Ldv3wYtkAcAoMkwDIXdfr2M5rEyC4r0wPjesnt5QTUAl7P6woyXX6gxuFg+xWv27Nnq06ePevToocjISB04cEDLli1Tjx49dOutt0qSHn/8ca1du1b79u2rvt9DDz2kRx55RB07dtQNN9ygTZs26ZNPPtGyZcuseihAUJmSPMPjtityllh2bE+9nrvU5/u0mi/63eGwKSEhxifTdRqLP14ftfVlQ/vGH+8hf+zzSu1WfpCpDVuPKdxh0+P/b4Rio8N9emwAqA/LC5S+fftq/fr1euGFF2SappKTk/Xd735XP/rRjxQeXvVB6Xa75XK5atxvzJgxKisr0/PPP6/ly5erU6dOeuaZZ7hIIwAAHti2P1cbtlZNpb5vbC91bBNrcSIAqGJ5gTJ9+nRNnz79im3mzZunefPmXXb7xIkTNXHiRH9FAwAgJB3LvagX394vSRozpKMG9WpjcSIghJiBdxavYDuNFxNNAQBoQi6WVOi51RmqcLrVp0sLTb4pxepIAFADBQoAAE2Ey+3W82/u1dmCMrVOiNKM8b1lswXYN70AmjzLp3gBAIDG8cbmLO0/mq+IcLvmTEpTTGSY1ZGAkBRwU7yCDCMoAAA0AZ9knNK7XxyXJP14bKqSE5tZnAgAakeBAgBAiDt8qlAvbzwoSfr2jZ11XY9EixMBQN2Y4gUAQAgrKK5aFO90udW/Wyt9e2gXqyMBIc2U5FZgTfEKspN4MYICAECocrrcWrQmQ/kXy9WuZbTuH5cqmxFYfzgBwDdRoAAAEKL+uumQDp0oUFSEXbMnpSkqgokTAAIfn1QAAISgD/91Uu/vzJEhafq43mrXMsbqSECTwVm8GoYRFAAAQkxmToFefadqUfyEm7qqX7dWFicCAM8xggI0UStylnjcdkryDJ/v01Oe7vOuNvf7fJ+ePm5v9umPPrKala8PK1n5epeu0O8xkQq/6zYZMVFyHTquvy14XX/zw/Gt4o/3JYDAQoECAECosNkUdsdQGTFRcp+9IOembVYnApogIwCneAVanitjihcAACHCcfN1srVtKbOsXJVvfyxVOq2OBABeo0ABACAE2NK6yd67q0y3W5UbP5MKi62OBAD1whQvAACCnJGUKMewAZIk16e7ZR7PtTgR0HSZCryzeHGhRgAA0HiaRSlszA0y7Da5Dh6Va9dBqxMBQINQoAAAEKzs9qpF8dGRcufly7l5u9WJAKDBmOIFAECQctzyLdnatJBZWla1KN7psjoSAAXeFK9gwwgKAABByN6/u+w9O1ctit/wqXSxxOpIAOATFCgAAASZvUfOy35jP0mS86MvZebkWZwIAHyHKV4AAASRvAulen7tHhk2m1z7Dsu9+5DVkQB8g8kUrwZhBAUAgCBRXuHSglUZKi5zyp17Ts4PvrA6EgD4HAUKAABBwDRNvbh+v07kFSkuJlyVb38iudxWxwIAn6NAAQAgCGz4/Ji2Hzgju83QrIl9pOJSqyMBqINbRkD9BBvWoCBoTEme4XHbFTlL/Jik6fG0Pz19jvzx/Lyeu1QJCTHKzy+W08m3yg3lj/ebN/v09bG9YeXruC4Z2ee06oMsSdKUUd11Tfvmln7OWdlHfL4DoY8RFAAAAlju+RI9/+ZemZJu7p+kmwckWx0JAPyKERQAAAJUablTz67ardJyp7q1j9cPRnW3OhKAqzED8EKNptUBvMMICgAAAchtmlq2bp9OnStR82bhmjWhjxx2/tkGEPr4pAMAIACt++SIdh06K4fd0OxJfRXfLMLqSADQKJjiBQBAgNl1KE9rPz4sSZp2ew91TYqzOBEAT5kKvAs1BtkML0ZQAAAIJCfPFmvpW/skSSOva69hfZMsTgQAjYsCBQCAAFFSVqkFq3arrMKlHh2a665bulkdCQAaHVO8AAAIAG63qRfe2qfc/FK1jIvQgxNZFA8Eq4A7i1eQ4ZMPAIAAsOajbO3OOqdwh02zJ/VVXHS41ZEAwBIUKAAAWGz7gTN6+7OjkqR7x/RUp7axFicCAOswxQsAAAsdP1Ok5W9XLYofPaijhvRua3EiAA1jBNxZvKRAy3NljKAAAGCRotKqRfEVlW717pygyTd3tToSAFiOERQEjRU5S6yOgKvwx3M0JXmGR+1ez13q830aYZ5/RE7tPMujdq8dWejxPj3l6eORPH+OvHkuPT1+qL2Hven3WhmGwr59k2wd28osKNLOx9fI/r0FvgnnZ54+lw3uowYcG0DwokABAMAC9hv6VhUnlU5Vvv2xVF5hdSQAPsJZvBqGKV4AADQyW/eOclzbU5LkfPdzmecKLE4EAIGDAgUAgEZkJCbIMXKgJMm5fZ/cWScsTgQAgYUpXgAANJaoCIWNvVGGwyHX4ZNyfb7H6kQA/MA0rU4Q3BhBAQCgMdgMhY2+QUZsjNz5hXL+cyt/xQBALShQAABoBPah/WVr31pmRaWcb38sVVRaHQkAAhJTvAAA8DNbry5y9OsuSXL+c6vM/IsWJwLgL6Ykd4BdGDHYxmoZQQEAwI+MNi3kGHGdJMm5NUPuwyctTgQAgY0CBQAAf4mOVNgdN8qw2+XKOiHX9n1WJwKAgMcULwAA/MFmU9iYG2U0i5b7XIGc735udSIAjcTkQo0NwggKAAB+4Bh+rWxJrWSWVVRdKb7SaXUkAAgKFCgAAPiYrXeK7H1SZJqmKt/5TCoosjoSAAQNpngBAOBDRrtWcgwfIElyfbpb5rHTFicC0NjcTPFqEAoUIMRMSZ7hUbsVOUv8nKRu07o97HFbT3N+v/Mcn+8zWFzp8TgcNiUkxCg/v1hOp7sRU13OH69Nf+yzIa+P84VleuLlL1RYXKGBPVvrgUf/nwyDP1Q84Y/3ZTB8HgK4HFO8AADwgUqnSwvXZKiwuELtE5vpvjt6UZwAQD0wggIAQAOZpqlXNh7U4VMXFRPp0JzJaYoIt1sdC4AVTMkMtCsjBlqeq2AEBQCABtq044Q+2XNahiE9OKGPEptHWR0JAIIWBQoAAA2w/2i+/rYpU5J014huSu3cwuJEABDcmOIFAEA9nb1QqsVr98htmrq+d1uNGtjB6kgAAgAXamwYRlAAAKiH8kqXnludoaLSSnVqG6t7RvdgUTwA+AAFCgAAXjJNU3/ecEDHzhQpNjpMcyalKTyMRfEA4AtM8QIAwEvvbDuuz/flym4zNHNCH7WIi7Q6EoAAwhSvhmEEBQAAL+w5fE4rP6haFP/9W69Rj44JFicCgNBCgQIAgIfO5JdoyZt7ZZrSsL7tNGJAstWRACDkMMULAAAPlFU4tWB1horLnEpJitPU21gUD+Bypgy5A2yKl6nAynM1jKAAAHAVpmlq+dv7lZNXrPhm4Zo5MU1hDv4JBQB/YAQFCDErcpZYHeGqXs2c7/N9/vXIAiUkxCg/v1hOp9vn+7+aKckzfL5PT5/LqZ1nebzP144s9Pk+ff2a8+bYRphn/4x58/zU9njWfXZUOw7myWE3NHtimhJiIxq8T3/kDDRWZ/RHv7+eu7S+cQB4iAIFAIAr+DLzrNZ+mC1JmnpbD6Ukx1ucCECgM02rEwQ3xqcBAKjDqXPFWvrWXpmSRlybrJv6JVkdCQBCHgUKAAC1KClzasGqDJWWu9S9fby+P/IaqyMBQJPAFC8AAL7BbZpatm6fTp8vUUJshB6cmCaHne/0AHiGCzU2DJ+2AAB8wz8+PqwvM8/KYbdp9qQ0xceEWx0JAJoMChQAAL5mx8E8/eOTI5Kke8f0UJd2cdYGAoAmhileAAD8m9EiTsve3idJum1gB93Qp53FiQAEI6Z4NQwjKAAASFJEmMLGDlV5hUu9OiXozhEpVicCgICwevVq9ejR47Kf//u//6vRbsuWLZowYYLS0tI0atQorVixol7HYwQFAADDUNjt18toHqtW8ZF6YHxv2W18hwcAX7ds2TLFxsZW/96mTZvq/9+1a5dmzpyp8ePH67HHHtPOnTv15JNPKjw8XHfeeadXx6FAAQA0efbr02Tr1E5mpVOzJ6UpNppF8QDqL1Sv09i7d2+1aNGi1m0LFy5UamqqnnrqKUnSkCFDdOrUKc2fP1+TJ0+WzYsvfSz/emjDhg2aOXOmhg8frv79+2vcuHH6y1/+IrfbfcX7TZs2rdahpqysrEZKDgAIBbZrOshxXS9JknPTNnVsE3uVewAAvq6iokJbt27V2LFja9w+btw45eXlad++fV7tz/IRlJdeeklJSUn6+c9/rpYtW+rzzz/Xb3/7Wx0/flyPPvroFe977bXXXtamffv2/owLAAghRqvmcowcJEly7tgv96HjFicCAP84efKkpk2bVuf2TZs2XXUf6enpys/PV1JSkr773e/qxz/+sex2u44dO6bKykp17dq1Rvtu3bpJkrKystSnTx+Ps1peoDz//PM1hoqGDBmikpISrVixQo888ojCw+seZo+Li1P//v0bISWCzdTOszxq99qRhR7vc0ryjPrGqdOKnCU+3yesYeVzeaXXscNhU0JCjPLzi+V0ui19bxhhnv2T482xG6K0wqnf/PkLnTlfoj5dWuj//XymbDbPz7zj6eOxmjefXU31M8mTx33pvXRb+A8sOT6CS6idxSsxMVFz5sxRv379ZBiGNm/erD/96U/Kzc3Vf//3f6ugoEBS1d/mX3fp90vbPWX5p2tt89h69eql8vJyXbhwQa1bt7YgFQAglLncbi1cnaEz50vUJiFKM8b39qo4AYBgk5SU5NEoSW2GDRumYcOGVf8+dOhQRURE6OWXX9YDDzxQfbth1P45WtftdbG8QKnNjh071Lx5c7Vs2fKK7bZt26b+/fvL5XKpX79+evjhhzVw4MAGH9/haJylOXa7rcZ/8R+N1TeN9Vz76vi8ZupG39Suvv1i5XujMY79+j8Pad+RfEVF2PWT7w1QfLMIvx7PH4/JX/vkvVQ7f/aH1f8WNRSvmaZpzJgxevHFF7V//34lJydLunykpLCwUNLlIytXE3AFSkZGhlavXq1Zs2bJbrfX2W7gwIEaP368OnfurDNnzmj58uX64Q9/qFdffVUDBgyo9/FtNkMJCTH1vn99xMVFNerxgom/+6axn2tfHZ/XTN3om9p52y9Wvjf8fezNXxzTO9uq1po88v1rldot0a/Hk/zzmPy9T95Ljcfqf4t8hdfMv5kKvNN4+TlPx44dFRYWpuzsbN10003Vt2dmZkqSUlK8u65UQBUoeXl5euihh5SWlqb777//im0feuihGr/ffPPNSk9P16JFi7R06dJ6Z3C7TRUWltT7/t6w222Ki4tSYWGpXK4rn7WsqWmsvsnPL/bbvv1xfF4zdaNvalfffrHyveHPY2efLNRzb/xLkjTxpq66Pi2pUV4z/nhM/ton76XaXeoXf7D636KGauzXTFxcFKM1AWD9+vWy2+1KTU1VeHi4hgwZog0bNujee++tbrNu3TolJiYqNTXVq30HTIFy8eJF3X///YqMjNTixYsVFhbm1f2jo6M1fPhwvfPOOw3O4nQ27geyy+Vu9GMGC3/3jdX9Xt/j85qpG31TO2/7xco+9NexC4orNH/lv1Tpcqt/t1YaP6yLpMZ5zfhj//7eJ++lxhMq/cxrJnT96Ec/0pAhQ9S9e3dJVWf8euONN3T33XcrMbFqFHrWrFmaOnWq5s6dq3Hjxmnnzp1auXKlnnjiCa+ugSIFSIFSXl6uBx98UGfPntXrr7+uhISEeu3HNANtPA0AEAicLrcWrclQ/sVytWsZrfvHpcrm5aJNAPBUqJ3Fq0uXLvr73/+u06dPy+12q3Pnznr88cdrnLZ4wIABWrRokZ5++mmtXbtWbdu21dy5c72+irwUAAWK0+nUww8/rAMHDui1116rXmTjrZKSEm3ZskVpaWk+TggACHZ/3XRIh04UKCrCrtmT0hQVYfk/fwAQNObOnetRu+HDh2v48OENPp7ln9BPPPGE3n//ff3sZz9TWVmZvvzyy+pt3bp1U7NmzfT4449r7dq11Veh/OKLL7R8+XKNGjVKSUlJOnPmjF566SXl5eVp/vz5Fj0SAEAg+vBfJ/X+zhwZkqaP6612LUNjQTIAhCrLC5SPP/5YkvSHP/zhsm2vvPKKBg8eLLfbLZfLVX17YmKiKioq9PTTT+vChQuKiorSgAED9Jvf/EZ9+/ZttOwAgMCWmVOgV985KEmacFNX9evWyuJEAEKdKSnQVh0EWJyrsrxA2bx581XbzJs3T/Pmzav+vVOnTlq+fLk/YwEAglz+xXItXJ0hl9vUt3okKv36TlZHAgB4gHO0AQBCTqXTrYVrMlRQXKHkxBjdN7aX11cyBgBYw/IRFAAAfMk0Tb36z4PKPlmomEiH5kxKU2Q4/9wBaDyhdhavxsYICgAgpLy/K0cf7z4lw5BmjO+t1gnRVkcCAHiBr5QQkl47stDn+1yRs8Tn+/SHKckzPGrnzePxxz6bKk/70l88fY6mdp7l82OblU6f7/Ob/WkkJSpsws0y7DZVfvSlfvfs65L889r05nOG92XoeD13qUcXI7T6vQ4EMwoUAEBoaBalsDE3yLDb5Dp4VK5dB61OBKCpYopXgzDFCwAQ/Ox2hd0xVEZ0pNxn8uXcvN3qRACAeqJAAQAEPcct35KtTQuZpWWqXP+x5HRd/U4AgIDEFC8AQFCz9+8ue8/OMt1uVW74VLpYYnUkAE1coF2oMdh4PYJy9913Kysrq9Zthw8f1t13393gUAAAeMLo0Eb2G/tJkpwffSkzJ8/iRACAhvK6QNm2bZuKi4tr3VZcXKzt25n3CwDwv7wLpQq7/XoZNptc+w7LvfuQ1ZEAAD7g0yleeXl5ioyM9OUuAQC4THmFSwtWZciIipA795ycH3xhdSQA+A+meDWIRwXKe++9p02bNlX/vmjRIiUkJNRoU15erm3btik1NdW3CQEA+BrTNPXi+v06kVcks7hUlW9/Irmufl0KAEBw8KhAycrK0saNGyVJhmFo69atMoya53cODw9X9+7d9ctf/tL3KQEA+LcNnx/T9gNnZLcZKt3wqVRcanUkAIAPeVSgTJkyRffff79sNpt69uypV155RX379vV3NgAAasjIPqdVH1SdqGXKqO5aOv9vFicCgG8wJTPQLtQYZFPOPFokP3DgQO3Zs0eSNHHixMumdwEA4G+550v0/Jt7ZUq6uX+Sbh6QbHUkAIAfeFSg2O12uVxVF71au3at8vPz/RoKAICvKy136tlVu1Va7lS39vH6wajuVkcCAPiJR1O8kpKStGbNGjkcDpmmqezsbNnt9jrb9+7d22cBAUhTkmdYevwVOUs8auePnJ4e2xtTO8/yqN1rRxZ6vE9PH7s/Hs+VOBw2JSTEKD+/WE6n5wvJvXnsvlZbXzruuFH2lPYyi0q09zdv6p5HX7AgWf3543lv7NcSvMPz08QF2ZSqQONRgTJt2jT99re/1cqVK2UYhn7xi1/U2s40TRmGof379/s0JACg6bIPTK0qTlwuVa7/RCopszoSAMCPPC5QBg4cqK+++ko///nP9eCDD6pjx47+zgYAaOJsXZLkGJImSXK+v0Nm7nmLEwEA/M3jCzX27NlTPXv21MqVK5Wenq6UlBR/5gIANHFGQqwctw2RJDn/9ZXc+w9bnAgAPGEE3lm8FGh5rszrK8m/+uqr/sgBAMB/hIfJMXaYjPAwuU+ckevjL61OBABoJB4VKNu3b1dqaqpiYmK0ffv2q7YfOHBgg4MBAJoow5Dj9iGyJcTKLCxW5YZPJTcrTgGgqfB4Dcobb7yhvn37atq0aZddRf4SFskDABrKPriP7J2TZFY6Vfn2x1JZudWRAMA7fKfSIB4VKK+88kr1mpNXXnnFr4EAAE3X9gNn5BiYKklybt4u8+wFawMBABqdRwXKoEGDav1/AAB85fiZIi1/e58kybnzgNxfHbM4EQDACl4vkgcAwNeKSiu1YNVuVVS65T52Wq5Pd1sdCQAaILjOmhVo6lWgfPHFF1q3bp1OnjypsrKaF8wyDEMvv/yyT8IBAEKfy+3Wkjf36GxBmRKbR+rEC59JJhO4AaCpsnl7h1WrVmnq1KnasGGDCgsLZZpmjR+32+2PnACAELXqg2ztPZKv8DCb5kzqK5VXWB0JAGAhr0dQli1bpjFjxuj3v/+9wsPD/ZEJANBEbN17Whu3Va01+fHYVLVv3cziRADgAwwCN4jXIygnT57UnXfeSXECAGiQo6cv6qUNByRJY6/vpG/1bG1xIgBAIPB6BCUlJUVnz571Rxag0U1JnmHp8VfkLPGqncNhU0JCjPLzi+V01j6d0urH5AlPH7e/vHZkoc/36elj8ub5sbqf/KmwuEILVu9WpdOtviktNXFY1+ptwfK4/fFeC5bHDgD+5PUIyiOPPKKlS5cqNzfXH3kAACHO6XJr8do9Ol9YrjYtojV9XKpsNs54AyCEmAH2E2Q8GkF54IEHavx+8eJF3X777erZs6eaN29eY5thGFq8eLHPAgIAQsvrmzN18PgFRYbbNWdSmqIjw6yOBAAIIB4VKF999VWN3202m1q0aKEzZ87ozJkzNbYZBt+CAQBq99Huk9q044Qk6f5xqUpqFWNxIgBAoPGoQNm8ebO/cwAAQlzWyQK9+s5BSdKEoV004JpEixMBgJ+YfGHfEF6vQQEAwFsFReVauDpDTpepAde0UvqNna2OBAAIUF4XKAcOHND27durfy8uLtb//M//6Lvf/a7mz58vk6v/AgC+xulya+GaPbpQVKGkVjH6cXqqbEwHBgDUwesCZd68eXr//ferf3/mmWe0cuVKVVZW6oUXXtBrr73m04AAgOC24t2vlJlToOgIh+ZMTlNUhNdnuAeAoGKagfUTbLwuUA4dOqRrr71WkmSapt566y3NmTNHa9as0Y9//GOtWrXK5yEBAMHpg1052vLlSRmSZozvrTYJ0VZHAgAEOK8LlMLCwupTCx84cECFhYUaM2aMJOn666/X8ePHfRoQABCcvjp+QSverToL5OSbU5TWtaXFiQAAwcDrcfbmzZvr9OnTkqTPP/9cLVu2VKdOnSRJlZWVrEEBAOh8YZkWrd0jl9vUwJ6tNWZwR6sjAUDjCMSLIwZanqvwukD51re+pQULFig/P19//vOfdfPNN1dvO3r0qNq1a+fLfACAIFPpdGnhmgwVFleofWIz3XdHL66RBQDwmNdTvH7yk5/IMAz99re/VXh4uGbNmlW9bePGjerXr59PAwIAgodpmnpl40EdPnVRMZFVi+Ijwu1WxwIABBGvR1A6dOigjRs36sKFC9VrUS751a9+pcRELryF4LEiZ4nVEXzOyscULP05tfOsqzeS9NqRhR7vc0ryDI/aedNHnu7TG/54jr7en7Y+KXIM7S/TberCys165E+vV28zK50+P7anjydY+jJY+OP1DoQULtTYIPU+1+M3ixNJ6tGjR0OyAACCmJGUKPsNfSVJrq27ZebkWZwIABCMPCpQ1q5d69VOJ0yYUI8oAICgFRstx6jBMmw2uQ4elXt3ptWJAABByqMC5bHHHqvx+6XFjl8/Y9fXF0BSoABAE+Kwy3H79TKiIuQ+ky/XhzutTgQAljKC7KxZgcajAmXTpk3V/3/27Fk98sgjGjp0qNLT09WqVSudPXtWb731lj755BM988wzfgsLAAgspmnKPvxa2Vo1l1laJuc7n0kut9WxAABBzKMCJTk5ufr///jHP+rWW2/V448/Xn1b165dNWjQID311FN66aWX9Kc//cnnQQEAgeedbcdlv6ajTJdbzn9+LhWXWh0JABDkvD7N8Icffljj2idfN3z4cH388ccNzQQACAJ7Dp/Tyg+q1pq4Pv2XzFNnLU4EAAHCDLCfION1geJ2u3XkyJFatx05coQryQNAE3Amv0RL3twr05Rc+w/LvTfb6kgAgBDhdYEybNgw/elPf9IHH3xQ4/b3339f8+fP19ChQ32VDQAQgMoqnFqwOkPFZU6lJMXJ9dGXVkcCAIQQr6+D8stf/lL33nuvHnzwQcXExKhly5Y6d+6ciouL1alTJ/3yl7/0R04AQAAwTVPL396vnLxixTcL18yJaZrz3yyKB4AauFBjg3hdoLRu3Vpr1qzR6tWrtW3bNl24cEGpqakaPHiwJkyYoMjISH/kBAAEgHWfHdWOg3ly2A3NnpimhNgIqyMBAEJMva4kHxERoe9///v6/ve/7+s8AIAA9WXmWa39sGqtydTbeiglOd7iRACAUFSvAkWSsrKytH37duXn5+s73/mOEhMTlZubq/j4eEZRACDEnDpXrKVv7ZUpacS1ybqpX5LVkQAgcHHOqAbxukBxuVz61a9+pTVr1sg0TRmGoZtuukmJiYn69a9/rV69eunhhx/2R1YAgAVKypxasCpDpeUudW8fr++PvMbqSACAEOZ1gbJ48WKtW7dOP//5zzVs2DClp6dXbxs2bJjWrFlDgRLCpiTP8KjdipwlIbdPT03r9VOP2766/48etfP08XjDyv70x+N5PXepx21fO7LQo3be5PTHa8kX+3Q4bEpIiFF+frGcTu8Xs7tNU8vW7dPp8yVKiI3QgxPT5LDXPAGkp/3pqcZ6vTe0b5oyf7zeAeASrwuUNWvWaObMmfrhD38ol8tVY1v79u114sQJn4UDAFjrHx8f1peZZ+Ww2zR7UpriY8KtjgQAgY8pXg3i9XVQcnNz1b9//1q3RUREqLi4uKGZAAABYMfBPP3jkyOSpHvH9FCXdnHWBgIANAleFygtW7bU8ePHa912+PBhtW3btsGhAADWyskr0rK390mSbhvYQTf0aWdxIgBAU+F1gTJ8+HA9//zzys3Nrb7NMAxdvHhRr776qkaMGOHTgACAxlVcVqkFqzJUXuFSr04JunNEitWRACB4mAH6E0S8XoPy0EMP6cMPP9Qdd9yhwYMHyzAMPf300zp06JAcDodmzpzpj5wAgEbgdpta8uZenblQqlbxkXpgfG/ZbV5/lwUAQL15/a9Oq1at9Pe//11jx47V3r17ZbfbdeDAAd10003629/+pubNm/shJgCgMaz6MEt7Dp9XuKNqUXxsNIviAQCNy6sRlPLyci1cuFC33XabnnjiCX9lAgBYYNv+XG3YekySdN/YXurYJtbiRAAQpEzD6gRBzasRlIiICP35z39WaWmpv/IAACxwLPeiXnx7vyRpzJCOGtSrjcWJAABNlddTvFJSUrjWCQCEkIslFXpudYYqnG716dJCk29iUTwAwDpeFygzZ87U4sWLdezYMX/kAQA0Ipfbreff3KuzBWVqnRClGeN7y2ZjagIANIRhBtZPsPH6LF6rVq1SaWmp7rjjDnXv3l2tW7eusd0wDC1evNhnAQEA/vPG5iztP5qviHC75kxKU0xkmNWRAABNnNcFyldffaWwsDC1bt1aFy5c0IULF2psNwy+eQOAYPBJxim9+0XVhXd/PDZVyYnNLE4EAEA9CpTNmzf7IweCxIqcJY2yT4fDpoSEGOXnF8vpdEuSpiTP8HiftqhIn+Xz1qv7/+jzfRphnr9VXzuy0OfH9zV/vI7uanO/z/fpj5yB4vCpQr288aAk6ds3dtZ1PRLrvS9v3pue8Ob1jqbHm9dbKL+HEeCCcFpVIOHqWwDQxBQUVy2Kd7rc6t+tlb49tIvVkQAAqEaBAgBNiNPl1qI1Gcq/WK52LaN1/7hU2ZiaCwAIIBQoANCE/HXTIR06UaCoCLtmT0pTVATTqQAAgcXyAmXDhg2aOXOmhg8frv79+2vcuHH6y1/+IrfbfdX7rlmzRqNHj1ZaWprS09O1YcOGRkgMAMHpw3+d1Ps7c2RImj6ut9q1jLE6EgAAl7H8q7OXXnpJSUlJ+vnPf66WLVvq888/129/+1sdP35cjz76aJ3327hxox577DFNnz5dN954o9577z098sgjio2N1dChQxvxEQBA4Dt04oJefadqUfyEm7qqX7dWFicCAKB2lhcozz//vFq0aFH9+5AhQ1RSUqIVK1bokUceUXh4eK33mz9/vkaPHq2f/vSn1fc7fPiwnn32WQoUAPiacwWlevbvu+Vym/pWj0SlX9/J6kgAENKC8eKIgcTyKV5fL04u6dWrl8rLyy+7xsolx48fV3Z2ttLT02vcnp6ert27d+v8+fP+iAoAQafS6dbv/rxdBUUVSk6M0X1je3G9KgBAQPNoBOWWW27x6h+0TZs21TuQJO3YsUPNmzdXy5Yta92enZ0tSeratWuN21NSUmSaprKzs2stfDzlcDRO3Wa322r8F//RWH3TWM91Y7LyMYVafwb74zFNUy++fUAHj+UrJtKh/3dnPzWLrn1UOlg15DniM7h2odQvvnwPh1K/+Bp9A1/zqEAZNGhQjQJl69atysvL04ABA5SYmKi8vDzt2rVLrVu31uDBgxsUKCMjQ6tXr9asWbNkt9trbVNQUCBJiouLq3F7fHx8je31YbMZSkho3IWjcXFRjXq8YOLvvmns57oxWPmYQq0/g/3xvP3JYW35Mkc2Q/r53QPVM6X+F2MMVL54jvgMrl0o9Is/3sOh0C/+Qt98jRm6I9XFxcUaM2aMcnNz9fe//11paWnV27Zs2aJnnnlGWVlZatu2re69915NmTLF62N4VKDMmzev+v/Xrl2rnTt36p///KeSkpKqb8/JydF9992nQYMGeR3ikry8PD300ENKS0vT/fdf/arQ3xzVMU2z1tu94XabKiwsqff9vWG32xQXF6XCwlK5XFc/a1lT0lh9k59f7Ld9W8XKxxRq/RnMj+fA0XwtXZshSbpnbG91axcb1I+nLg15THwG1y6U+sWXr/lQ6hdfa+y+iYuLYrTGQosWLZLL5brs9l27dmnmzJkaP368HnvsMe3cuVNPPvmkwsPDdeedd3p1DK8XyS9dulRz5sypUZxIUnJysmbNmqXFixdr4sSJ3u5WFy9e1P3336/IyEgtXrxYYWFhdbb9+khJq1b/ORNNYWGhpMtHVrzldDbuB4/L5W70YwYLf/dNKPa7lY8p1PozWB/P+cIyLVhVtSh+SO82mnhzii5cKAnax3MlvnhMfAbXLhT6xR/5Q6Ff/IW+CX1ZWVn6y1/+okcffVS//vWva2xbuHChUlNT9dRTT0mqOoHVqVOnNH/+fE2ePFk2m+dFpdfl57FjxxQbG1vrtvj4eOXk5Hi7S5WXl+vBBx/U2bNntWzZMiUkJFyx/aW1J5fWolySlZUlwzAuW5sCAE1FRaVLC1Zn6GJJpTq2aaYfpaeyKB4AGpsZYD8+8tvf/lbf+9731KVLlxq3V1RUaOvWrRo7dmyN28eNG6e8vDzt27fPq+N4PYKSnJysv//97xo+fPhl2954443LRlauxul06uGHH9aBAwf02muvKTk5+ar36dChg7p27ar169dr1KhR1bevW7dOffv2bdAC+aZqSvIMn+5vRc4Snx/bm336+tiSZIT5/qzcZqXT5/v0R3/6uu+96Xd/PO/+2GcgME1TL288oKOnL6pZVJhmT0pTRFjta/muxsrnyJtjW/n5YTVff25LwdFPVme8q83Vp6BL1ucEvunkyZOaNm1anduvdpKrjRs36sCBA3r22We1d+/eGtuOHTumysrKywYJunXrJqlqEKFPnz4eZ/X6L67p06fr8ccf13e+8x2lp6erVatWOnv2rNatW6e9e/fqySef9Gp/TzzxhN5//3397Gc/U1lZmb788svqbd26dVOzZs30+OOPa+3atTWqr4ceekiPPPKIOnbsqBtuuEGbNm3SJ598omXLlnn7kAAgJLy7/bg+25srm2Fo5oQ+ahXPglUAQMOVlpZq3rx5+slPfqJmzZpdtr2uE1hd+t3bE1h5XaBMmjRJkvSnP/2pxuL5xMRE/e///q8mT57s1f4+/vhjSdIf/vCHy7a98sorGjx4sNxu92WLccaMGaOysjI9//zzWr58uTp16qRnnnmGizQCaJL2Hjmv19/PlCR9b2Q39ex05amyAAA/CsALNSYlJdX7UiCLFy9Wy5Ytq+uAutQ1pdjbqcb1mrMyadIkTZw4UdnZ2bpw4YKaN2+url271mue8+bNm6/aZt68eTWKoUsmTpxYrwX5ABBK8i6U6vm1e2Sa0o1pbTXyuvZWRwIAhIicnBy9+OKLWrhwoYqKiiRJJSUl1f8tLi6u81If9T2BVb0n1RuGoZSUlPreHQDgA+UVLi1YlaHiMqe6tIvV3bf3YFE8AMBnTpw4ocrKSk2fPv2ybXfffbf69eun1157TWFhYcrOztZNN91UvT0zs2pk39uaoV4FSlZWlhYuXKht27bpwoULev3119W7d28999xz+ta3vqUhQ4bUZ7cAAC+YpqkX1+/XibwixcWEa9bENIU56rcoHgDgI6ZkBNoUrwbk6dWrl1555ZUat+3fv1+/+93v9Jvf/EZpaWkKDw/XkCFDtGHDBt17773V7datW6fExESlpqZ6dUyvC5T9+/frBz/4gWJiYjRo0CBt2LCheltxcbH+9re/UaAAQCPY8PkxbT9wRnaboVkT+6hFXKTVkQAAISYuLk6DBw+udVvv3r3Vu3dvSdKsWbM0depUzZ07V+PGjdPOnTu1cuVKPfHEE15dA0Wqx3VQ/u///k89evTQu+++q//v//v/qq/eLkl9+/ZVRkaGt7sEAHgpI/ucVn2QJUmaMqq7rmnf3NpAAIAmbcCAAVq0aJEyMjL0ox/9SKtWrdLcuXO9voq8VI8RlJ07d+oPf/iDoqKiLjuz1qVTDgMA/Cf3fImef3OvTEk390/SzQOufv0oAEAjCrQpXj42ePBgHTx48LLbhw8fXuu1Er3l9QiKJIWFhdV6e0FBgcLDwxsUCABQt9Jyp55dtVul5U51ax+vH4zqbnUkAAB8yusCpUePHnrvvfdq3fbRRx9Vz0MDAPiW2zS1bN0+nTpXoubNwjVrQh857PX6ngkAgIDl9RSvu+++Wz/96U8VFRWl8ePHS5JOnTqlrVu3atWqVXr22Wd9HhIAIK375Ih2HTorh93Q7El9Fd8swupIAIDahPgUL3/zukC54447dOzYMT333HN69dVXJUlz5syR3W7XQw89pFtuucXnIQGgqdt1KE9rPz4sSZp2ew91TfLuolcAAASLel0H5YEHHtCECRP00Ucf6dy5c0pISNDQoUOVnMxCTQDwtZNni7X0rX2SpJHXtdewvkkWJwIAwH+8LlC2b9+u1NRUtW3b9rLThhUXF2vfvn0aOHCgzwKicazIWeJRuynJMxrl2A6HTQkJMcrPL5bT6fZ6n1M7z/JFtBrMSqdH7Tzty/poaL/Ul6fPu6eP3R999HruUkv6xt9Kyiq1YNVulVW41KNDc911S7cG7c/Xz6U/eHNsf7zXQ42Vz2Ww8Obfttdzl4bUZwz8I+Au1BhkvF5deffddysrK6vWbYcPH9bdd9/d4FAAAMntNvXCW/uUm1+qlnERenAii+IBAKHP63/pvn5hxm9yOp1eXykSAFC7NR9la3fWOYU7bJo9qa/iojmNOwAg9Hk0xauoqEiFhYXVv+fl5enkyZM12pSVlWnNmjVq1aqVbxMCQBO0/cAZvf3ZUUnSvWN6qlPbWIsTAQA8Y0imYXWIbwi0PFfmUYHy5z//WQsXLpQkGYah2bNn19rONE3NmOH7NQoA0JQcP1Ok5W9XLYofPaijhvRua3EiAAAaj0cFyo033qjo6GiZpqk//OEPmjp1qpKSap5FJjw8XN27d9egQYP8EhQAmoKi0qpF8RWVbvXunKDJN3e1OhIAAI3KowJlwIABGjBggCSptLRUd955p9q0aePXYADQ1Ljcbi15c4/OFpQpsXmkZozvIzvr+gAg+HAWrwbx+jTDdU3vAgA0zKoPsrX3SL7Cw2yaM6mvmkWFWR0JAIBG5/VXc7/73e/005/+tNZt//Vf/6Xf//73DQ4FAE3N1r2ntXHbMUnSj8emqn3rZhYnAgDAGl4XKJs3b9bQoUNr3TZ06FBt3ry5waEAoCk5evqiXtpwQJKUfkMnfatna4sTAQDqy1DVhRoD6sfqTvGS1wVKbm6ukpOTa92WlJSk06dPNzgUADQVhcUVWrB6tyqdbvVNaakJQ1kUDwBo2rwuUKKionTq1Klat508eVIRERENDgUATYHT5dbitXt0vrBcbVpEa/q4VNlswfY9FwAAvuV1gTJgwAC99NJLqqysrHF7ZWWlXn755eqzfQEAruz1zZk6ePyCIsPtmjMpTdGRLIoHgKBnBuhPEPH6LF4PPvigpkyZovT0dH3nO99RmzZtdPr0aa1atUonT57Ub37zG3/kRIBYkbPEsmNPSfb8IqBGmGcvbW8ejzfH9zVvju2P58jK5z1UfbT7pDbtOCFJun9cqpJaxTTKcf3xXHr6+vTHsV87stDn+wwWvC+vzpevTYfDpoSEGOXnFzc0FoCr8LpA6devnxYvXqwnnnhCf/zjH6tv79ixoxYvXqy+ffv6NCAAhJqskwV69Z2DkqQJQ7towDWJFicCACBweF2gSNKwYcP07rvv6siRIzp//rxatGihzp07+zgaAISegqJyLVydIafL1IBrWin9xs5WRwIA+JgRZFOqAk29CpRLOnfuTGECAB5yutxauGaPLhRVKKlVjH6cniqbwaJ4AAC+zqMCZfv27UpNTVVMTIy2b99+1fYDBw5scDAACDUr3v1KmTkFio5waM7kNEVFNOg7IgAAQpJH/zpOmzZNb7zxhvr27atp06bJqOMbP9M0ZRiG9u/f79OQABDsPtiVoy1fnpQhacb43mqTEG11JACAvzDFq0E8KlBeeeUVpaSkVP8/AMBzXx2/oBXvfiVJmnxzitK6trQ4EQAAgcujAmXQoEG1/j8A4MrOF5Zp0do9crlNDezZWmMGd7Q6EgAAAY0J0ADgJ5VOlxauyVBhcYXaJzbTfXf0qnOKLAAghDDFq0E8KlB+8YtfeLxDwzD01FNP1TsQAIQC0zT1ysaDOnzqomIiqxbFR4TbrY4FAEDA86hA+fzzz2v8fvHiRV28eFEOh0PNmzfXhQsX5HQ6FRsbq7i4OL8EBYBgsmnHCX2y57QMQ3pwQh8lNo+yOhIAAEHBowJl8+bN1f+/e/duzZkzR7/+9a81ZswY2e12uVwurV+/Xn/4wx/0zDPP+C0sAASD/Ufz9bdNmZKku0Z0U2rnFhYnAgA0Ji7U2DA2b+/w+9//Xvfdd5/S09Nlt1dNV7Db7Ro3bpzuu+8+pncBaNLOXijV4rV75DZNXd+7rUYN7GB1JAAAgorXBcrevXvVvXv3Wrd1795dBw4caHAoAAhG5ZUuPbc6Q0WllerUNlb3jO7BongAALzk9Vm8mjVrpk8//VTXX3/9Zds+/fRTNWvWzCfB0HRMSZ7hUbsVOUt8vs+pnWd5vM9g4Y/+9LSfzEqnz4/t6eN5PXepx/v0B9M09ecNB3TsTJFio8M0Z1KawsOaxqJ4b55PT3j6nHvD1xkRHHjegeDkdYHy7W9/W8uXL5fT6dS4cePUqlUrnT17Vm+99ZZefvll3XvvvX6ICQCB7Z1tx/X5vlzZbYZmTuijFnGRVkcCACAoeV2g/OQnP9H58+f10ksv6c9//nP17aZp6tvf/rZ+8pOf+DIfAAS8PYfPaeUHVYviv3/rNerRMcHiRAAABC+vCxSHw6F58+Zp+vTp2rp1qwoKCtS8eXMNGjRIKSkp/sgIAAHrTH6Jlry5V6YpDevbTiMGJFsdCQBgNc7i1SD1vpJ8165d1bVrV19mAYCgUlbh1ILVGSoucyolKU5Tb2NRPAAADeX1WbwkqaKiQn/729/0k5/8RPfdd5+OHDkiSXrvvfd0/PhxX+YDgIBkmqaWv71fOXnFim8WrpkT0xTmqNdHKgAA+BqvR1DOnz+ve+65R4cOHVKrVq107tw5FRcXS5I2bdqkjz/+WP/zP//j65wAEFDWfXZUOw7myWE3NHtimhJiI6yOBAAIEFyosWG8/rrvD3/4gwoLC7Vq1Sp98MEHMs3/PAODBw/W9u3bfRoQAALNl5lntfbDbEnS1Nt6KCU53uJEAACEDq8LlA8++EAPPfSQevfufdlc6zZt2uj06dM+CwcAgebUuWItfWuvTEkjrk3WTf2SrI4EAEBI8XqKV1FRkZKSav8H2el0yuVyNTgUAASikjKnFqzKUGm5S93bx+v7I6+xOhIAIBAxxatBvB5Bad++vb788stat+3evVtdunRpaCYACDhu09Sydft0+nyJEmIj9ODENDnsLIoHAMDXvP7Xddy4cVq6dKnee++96vUnhmFo9+7deuWVVzR+/HifhwQAq/3j48P6MvOsHHabZk9KU3xMuNWRAAAISV5P8br//vu1c+dOzZ49W/HxVQtDf/SjH+nChQsaNmyY7r77bp+HBAAr7TiYp398ckSSdO+YHurSLs7aQACAwGUq8KZ4BVqeq/C6QAkLC9PSpUu1fv16ffDBBzp37pwSEhJ08803a+zYsbLZmPIQjKYkz/Co3YqcJX5OUrepnWd53NYIq/c1SBvM0770F1tUpEftvMlp5fNu5bElKSevSMve3idJum1gB93Qp12D9hcs/W6lpvq4QxGvdwD14dVfcWVlZbr33nv10EMPaezYsRo7dqy/cgGA5YrLKrVgVYbKK1zq1SlBd45IsToSAAAhz6sCJTIyUl999ZXsdru/8gBAQHC7TS15c6/OXChVq/hIPTC+t+yMEAMAPMCFGhvG639tBwwYoN27d/sjCwAEjFUfZmnP4fMKd1Qtio+NZlE8AACNwesC5dFHH9Xrr7+utWvXqri42B+ZAMBS2/bnasPWY5Kk+8b2Usc2sRYnAgCg6fB6JfFdd92lyspK/eIXv9AvfvELRUZG1riivGEY2rFjh09DAkBjOZZ7US++vV+SNGZIRw3q1cbiRACAoMMUrwbxukC5/fbbaxQkABAqLpZU6LnVGapwutWnSwtNvolF8QAANDavC5R58+b5IwcAWMrlduv5N/fqbEGZWidEacb43rLZ+DIGAIDG5nGBUlZWpvfee08nT55UixYtdMstt6hFixb+zAYAjeaNzVnafzRfEeF2zZmUppjIMKsjAQCCFGfxahiPCpTc3FxNnTpVJ06ckGlW9XhsbKyWLl2q/v37+zMfAPjdJxmn9O4XxyVJPx6bquTEZhYnAgCg6fLoLF5/+tOflJubqwcffFBLlizR448/rrCwMP3P//yPn+MBgH8dPlWolzcelCR9+8bOuq5HosWJAABo2jwaQfn00081Y8YMzZo1q/q2jh076sEHH9TZs2fVqlUrvwUEAH8pKK5aFO90udW/Wyt9e2gXqyMBAEIBU7waxKMRlLNnz2rgwIE1bhs0aJBM09TZs2f9EgwA/MnpcmvRmgzlXyxXu5bRun9cqmycoRAAAMt5NILicrkUGRlZ47aIiIjqbWg6piTP8KjdipwlHu+ztrYOh00JCTHKzy+W0+n2eF+XeJrTG0aYZ+eUeO3IQp8f25vH4y4t86idN8+RpzzN6WlfSv7pT0n666ZDOnSiQFERds2elKaoiMszedPv/ujPYOGPzwWEBp5zAPXh8V8J2dnZstvt1b9fKkyys7Mva9u7d28fRAMA//jwXyf1/s4cGZKmj+utdi1jrI4EAAglTPFqEI8LlF/84he13v7zn/+8+v9N05RhGNq/f3/DkwGAH2TmFOjVd6oWxU+4qav6dWMNHQAAgcSjAuV3v/udv3MAgN/lXyzXwtUZcrlNfatHotKv72R1JAAA8A0eFSgTJ070dw4A8KtKp1sL12SooLhCyYkxum9sLxksigcA+AEXamwYj87iBQDBzDRNvfrPg8o+WaiYSIfmTEpTZLjnC/UBAEDjoUABEPLe35Wjj3efkmFIM8b3VuuEaKsjAQCAOvAVIoCQdvBYvv763iFJ0p03d1OfLi0tTgQACGmmAu8sXoGW5yoYQQEQss4XlmnR2j1yuU0NTm2j2wd1sDoSAAC4CgoUACGpotKlBaszdLGkUh3bNNO9Y3qyKB4AgCDAFC8AIcc0Tb288YCOnr6oZlFhmj0pTRFh9qvfEQAAXwiyKVWBhhEUACHn3e3H9dneXNkMQzMn9FGr+CirIwEAAA9ZPoJy9OhRLV++XP/617906NAhde3aVevWrbvq/aZNm6Zt27Zddvv69euVkpLij6gAgsCe7HN6/f1MSdL3RnZTz04JFicCAADesLxAOXTokLZs2aJ+/frJ7XbLND0fE7v22mv16KOP1ritffv2vo4IIEicPleshWv2yDSlG9PaauR1fB4AABofF2psGMsLlFtuuUW33nqrJOmxxx7Tnj17PL5vXFyc+vfv76dkTcuKnCUetZuSPMOn7bxhhPn+5eqPfU7r9rDHbV/NnO9Ru0vPj8NhU0JCjPLzi+V0umttO7XzLI+P7ylPn09fv468UV7h0m9f3aHi0kp1aReru2/v0eBF8Z4+Hqv3aTUrH5OvX5sAAOtZvgbFZrM8AoAgZ5qmlq7bpyOnChUfE65ZE9MU5mBRPAAAwcjyEZSG2LZtm/r37y+Xy6V+/frp4Ycf1sCBAxu8X4ejcYomu91W479oerx9rfnyNeOP17lV+1z36RFt25crh93Qw9/tp9YtuFL8JXzOVKntdUTf1I5+qR39Ujf6phZM8WqQoC1QBg4cqPHjx6tz5846c+aMli9frh/+8Id69dVXNWDAgHrv12YzlJAQ48OkVxcXxxmGmqr6vtZ88Zrxx+vcin1+sT9XK/+9KH76xL4a2CfJ5xlCQVP/nLnS66ip901d6Jfa0S91o2/gK0FboDz00EM1fr/55puVnp6uRYsWaenSpfXer9ttqrCwpKHxPGK32xQXF6XCwlK5XLWvJ0Boy88v9qq9L18z3h47EPd5+nyJ/vDqFzJN6Zbr2mvM9Z15P30DnzNVansd0Te1o19qR7/UrbH7Ji4uitGaEBe0Bco3RUdHa/jw4XrnnXcavK+6Fh/7i8vlbvRjIjDU93n3xWvGH6+5xtxnablTz7z+pUrKnerWPl5Tb+suifdTXZp6v1zpsTf1vqkL/VI7+qVu9E0VQ4F3Fq+GnTKm8YVU+enNKYoBBC+3aWrZun06da5EzZuFa9aEPnLwbRoAACEhZP5FLykp0ZYtW5SWlmZ1FAB+tu6TI9p16KwcdkOzJ/VVfLMIqyMBAAAfsXyKV2lpqbZs2SJJysnJUVFRkTZu3ChJGjRokFq0aKHHH39ca9eu1b59+yRJX3zxhZYvX65Ro0YpKSlJZ86c0UsvvaS8vDzNn+/ZdSUABKddh/K09uPDkqRpt/dQ16Q4ixMBAPANTOppEMsLlHPnzunhh2te2O7S76+88ooGDx4st9stl8tVvT0xMVEVFRV6+umndeHCBUVFRWnAgAH6zW9+o759+zZqfgCN5+TZYi19q+qLipHXtdewvpyxCwCAUGN5gdK+fXsdPHjwim3mzZunefPmVf/eqVMnLV++3N/RAASQkrJKLVi1W2UVLvXo0Fx33dLN6kgAADQJH330kZYsWaLMzEwVFRWpTZs2uvXWWzV79mzFxsZWt9uyZYueeeYZZWVlqW3btrr33ns1ZcoUr49neYECAFfjdpt64a19ys0vVcu4CD04kUXxAAA0loKCAg0YMED33HOP4uLidOjQIS1YsECHDh3Siy++KEnatWuXZs6cqfHjx+uxxx7Tzp079eSTTyo8PFx33nmnV8ejQAEQ8NZ8lK3dWecU7rBp9qS+iosOtzoSAAB1C7E1KOnp6UpPT6/+ffDgwQoPD9evfvUr5ebmqk2bNlq4cKFSU1P11FNPSZKGDBmiU6dOaf78+Zo8ebJsNs+/WKRAgV8YYZ6/tF47svCy2xwOmxISYpSfX1x9TvVp3R6+rF1dbAnNPWrnOnPW4336w5TkGR61W5GzxON91tafDTm2P3jz+th+4Ize/uyoJOneMT3VqW3sVe6BpsSb9wYAwHeaN28uSXI6naqoqNDWrVv1X//1XzXajBs3Tm+88Yb27dunPn36eLxvChQAActoEaflb1ctih89qKOG9G5rcSIAAILTyZMnNW3atDq3b9q06ar7cLlccjqdyszM1MKFCzVixAglJycrMzNTlZWV6tq1a4323bpVrRfNysqiQAEQAiLC5Bh9gyoq3erdOUGTb+569fsAABAAgu3K7Z4aMWKEcnNzJUnDhg3T008/LalqjYokxcXVPPX/pd8vbfcUBQqAwGMYctw6WEZcjBKbR2rG+D6yezF3FQAA1JSUlOTRKMmVvPDCCyopKVFmZqYWLVqkBx54QC+99FL1dsOovTSr6/a6UKAACDj2wX1k69BGZqVTcyb1VbOoMKsjAQDQ5PXs2VOSdO211yo1NVWTJ0/Wu+++Wz2V65sjJYWFhZIuH1m5Gr6SBBBQbN06yN6/uyTJ+f4Xat+6mcWJAADwkhlgP37Qq1cv2e12HTt2TB07dlRYWJiys7NrtMnMzJQkpaSkeLVvChQAAcNo1Vz2m6+TJLl27JeZnWNxIgAAUJtdu3bJ5XKpffv2Cg8P15AhQ7Rhw4YabdatW6fExESlpqZ6tW+meAEIDJERctx+vQyHXe6jp+T6Yp/ViQAAgKTZs2erT58+6tGjhyIjI3XgwAEtW7ZMPXr00K233ipJmjVrlqZOnaq5c+dq3Lhx2rlzp1auXKknnnjCq2ugSBQoAAKBzZDjtsEyYqNlXrgo56btIXeRKwBAE2FKRqD9G9bAPH379tX69ev1wgsvyDRNJScn67vf/a5+9KMfKTy86uLJAwYM0KJFi/T0009r7dq1atu2rebOnev1VeQlChQAAcB+fV/ZkhJlVlSqcuNnUkWl1ZEAAMC/TZ8+XdOnT79qu+HDh2v48OENPh5rUABYytajk+xpVWf/cG7aLl24aHEiAABgJUZQAFjGaJ0g+00DJEnO7XtlHj1lcSIAAHwg0KZ4BRlGUABYI+rfi+LtdrkP58i944DViQAAQACgQAHQ+GyGHLcPkRETJff5Qjk3f2F1IgAAECCY4hXCpiTP8LjtipwlHrUzwnz/kvEmp8dKy3y/Tz/wtN+ndXvYsmP7g/2GfrK1bSWzrEKV6z6SSup+vjx9fbyeu9RX8erF05ze9Ls/9gkAaARM8WoQRlAANKoPduXI3idFpmmq8p3PpIIiqyMBAIAAQoECoNF8dfyCVrz7lSTJ9elumcdOW5wIAAAEGqZ4AWgU5wvLtGjtHrncplyHjsm1k0XxAIDQFHAXagwyjKAA8LtKp0sL12SosLhC7RObyfneNqsjAQCAAEWBAsCvTNPUKxsP6vCpi4qJdGjO5DTJ6bI6FgAACFBM8QLgV5t2nNAne07LMKQHJ/RRYvMoqyMBAOBfTPFqEEZQAPjN/qP5+tumTEnSXSO6KbVzC4sTAQCAQEeBAsAvzl4o1eK1e+Q2TV3fu61GDexgdSQAABAEmOIFwOfKK116bnWGikor1altrO4Z3UOGYVgdCwCARsFZvBqGERQAPmWapv684YCOnSlSbHSY5kxKU3iY3epYAAAgSFCgAPCpd7Yd1+f7cmW3GZo5oY9axEVaHQkAAAQRpngB8Jk9h89p5QdVi+K/f+s16tExweJEAABYgCleDUKBEiCmJM/wuO2KnCWWHd/TYzf08TgcNiUkxCg/v1hOp9vrfdqiPPzWPszzt4BZWuZxW0952++19UugOJNfoiVv7pVpSsP6ttOIAck+2a8/Xu/+4I+cwfLYAQDwJaZ4AWiwsgqnFqzOUHGZUylJcZp6G4viAQBA/TCCAqBBTNPU8rf3KyevWPHNwjVzYprCHHz3AQBoujiLV8PwVwSABln32VHtOJgnh93Q7IlpSoiNsDoSAAAIYhQoAOrty8yzWvthtiRp6m09lJIcb3EiAAAQ7JjiBaBeTp0r1tK39sqUNOLaZN3UL8nqSAAAWM9U4J3FK9DyXAUjKAC8VlLm1IJVGSotd6l7+3h9f+Q1VkcCAAAhggIFgFfcpqll6/bp9PkSJcRG6MGJaXLY+SgBAAC+wRQvAF75x8eH9WXmWTnsNs2elKb4mHCrIwEAEFiCbEpVoOFrTwAe23EwT//45Igk6d4xPdSlXZy1gQAAQMihQAHgkZy8Ii17e58k6baBHXRDn3YWJwIAAKGIKV4Arqq4rFILVmWovMKlXp0SdOeIFKsjAQAQsLhQY8MwggLgitxuU0ve3KszF0rVKj5SD4zvLbuNjw4AAOAf/JUB4IpWfZilPYfPK9xRtSg+NppF8QAAwH+Y4hUgVuQs8bjt1M6zfL5PK3n6eLxhOp0etTO82Kctqa1nDUvLPN6n68xZj9pNSZ7h8T5tUZEetfOkj2wp7eUYNViSdN/YXurYJvaK7UPttQkAQL0wxatBGEEBUCujZbzsN18nSRozpKMG9WpjcSIAANAUUKAAuFxkuBy3Xy8jzCH3sdOafBOL4gEAQONgiheAmgxDjlsHy4iLkVlQJOd722Sz/cDqVAAABAlThhloc7wCLc+VMYICoAb79WmytW8ts6JSzo2fShWVVkcCAABNCAUKgGq27h1l73uNJMm5+QuZ+RctTgQAAJoapngBkCQZic1lv+laSZLri30yj5y0OBEAAEEquGZUBRxGUABIURFVi+IddrmPnJTri/1WJwIAAE0UBQrQ1NkMOW4bIqNZtMz8Qjk3bbc6EQAAaMKY4gU0cfYb+snWrpXM8kpVbvxMqvTsIpcAAOByhiQjwKZ4eXNh6kDACArQhNl6dpa9T4pM05Rz0zapoMjqSAAAoImjQAGaKKNNC9mHDZAkubbvlXnstMWJAAAAmOIFNE3RkVXrTuw2ubNOyL3zoNWJAAAIDaYC7yxegZbnKihQgtBrRxZaduypnWd51M4I8/1LyxbXzOO2RmJLj9qZJ3M9D+D0bG2GedHzaVKe9tOl59zhsCkhIUb5+cVyOt0eH+frKp1u/f4vO5V9slDusxdU+e7nV1134unzbuVr02pTkmd41G5FzhI/JwEAILgxxQtoQkzT1Kv/PKjsk4Uyy8pV+fbHLIoHAAABhREUoAl5f1eOPt59SoYhVWz8TCostjoSAAAhJ9DO4hVsGEEBmoiDx/L11/cOSZLuvLmbzONeTG8DAABoJBQoQBNwvrBMi9bukcttanBqG90+qIPVkQAAAGrFFC8gxFVUurRgdYYullSqY5tmundMTxlGsF2yCQCAIMIUrwZhBAUIYaZp6uWNB3T09EU1iwrT7ElpigizWx0LAACgThQoQAh7d/txfbY3VzbD0MwJfdQqPsrqSAAAAFfEFC8gRO09cl6vv58pSfreyG7q2SnB4kQAADQNnMWrYRhBAUJQ3oVSPb92j0xTujGtrUZe197qSAAAAB6hQAFCTHmFSwtWZai4zKku7WJ19+09WBQPAACCBlO8gBBimqZeXL9fJ/KKFBcTrlkT0xTmYFE8AACNiileDcIIChBCNnx+TNsPnJHdZmjWxD5qERdpdSQAAACvMIIShKYkz/Co3YqcJT4/tuHw/UvGdDo9O3ak539smw4/1N6lZR41M1q38niXxsUij9pN7Tzr6vvq0EaOO26UYRiaMqq7rmnf/IrtbVGe96fbw8du5WvTaqH4mAAAsAIFChAK4pvJcesgGYahm/sn6eYByVYnAgCgyeIsXg3DFC8g2IU5FHb79TIiwuU+dVY/GNXd6kQAAAD1RoECBDnHLd+S0SJOZnGpnP/cKoedtzUAAAheTPECgpjtup6ydUmW6XLJ+c5nUmm51ZEAAIDJHK+GsPyr1qNHj+q///u/NX78eKWmpio9Pd3j+65Zs0ajR49WWlqa0tPTtWHDBj8mBQKL0amdHAN7S5JcH+6SeSbf4kQAAAANZ3mBcujQIW3ZskWdOnVSSkqKx/fbuHGjHnvsMY0aNUpLly7VkCFD9Mgjj+jjjz/2Y1ogQDSPlWPkQEmSKyNT7oNHLQ4EAADgG5ZP8brlllt06623SpIee+wx7dmzx6P7zZ8/X6NHj9ZPf/pTSdKQIUN0+PBhPfvssxo6dKjf8gKWCw9T2OjrZYSHyX0yT67PdludCAAAfA1n8WoYy0dQbDbvIxw/flzZ2dmXTQdLT0/X7t27df78eV/FAwKLITlGDpTRPFbmxWI5/7lVcvMpCAAAQoflIyj1kZ2dLUnq2rVrjdtTUlJkmqays7PVokWLeu/f4Y+L/NXC/u+zLdn9dNalxnocaDz2gb1l69ROZqVTzo2fSWUVl7UJhufdHxn9/X4KVvRL3eib2tEvtaNf6kbfwNeCskApKCiQJMXFxdW4PT4+vsb2+rDZDCUkxNQ/XD3ExUX5Zb+N/TjgX0bXZNmv7SlJcm3ZKfNc7a/zYHje/ZnRX++nYEe/1I2+qR39Ujv6pW70zb+Z//4JJIGW5yqCskC5xDCMGr+b/z6l2zdv94bbbaqwsKRBuTxlt9sUFxelwsJSuVxun+8/P7/Y5/uENYwWcXKM+JYkyfXlV3JnHq+zbTA87/7I6O/3U7CiX+pG39SOfqkd/VK3xu6buLgoRmtCXFAWKF8fKWnVqlX17YWFhZIuH1nxltPZuB88LpfbL8ds7McBPwkPk+P2wTLCHHIfz5Xr8yufSCIYnnd/ZvTX+ynY0S91o29qR7/Ujn6pG30DXwnK8vPS2pNLa1EuycrKkmEYl61NAYKWYcg2tK+MuBiZBUVyvvc5F38CACDAGe7A+gk2QTmC0qFDB3Xt2lXr16/XqFGjqm9ft26d+vbt26AF8sFgRc4Sj9pNSZ7h8316yoiK9LxtbDPPGjqdHu+ztEO8R+2i87y4uGGCZ/t0H8vxeJeG48pvQdugVNnatZJZ6VTl2x/LLCr1eN9X4y4t87itr19zUzvP8vjYrx1Z6HFbAAAQ/CwvUEpLS7VlyxZJUk5OjoqKirRx40ZJ0qBBg9SiRQs9/vjjWrt2rfbt21d9v4ceekiPPPKIOnbsqBtuuEGbNm3SJ598omXLllnyOABfM1KSZe97jSTJ+e7ndS6KBwAACCWWFyjnzp3Tww8/XOO2S7+/8sorGjx4sNxut1wuV402Y8aMUVlZmZ5//nktX75cnTp10jPPPMNFGhEaWsbLPmyAJMm166DcWScsDgQAADzGbOwGsbxAad++vQ4ePHjFNvPmzdO8efMuu33ixImaOHGiv6IB1ogMl2PUIBkOu9zHTsu984DViQAAABpNUC6SB0KWYcg+cqCMZtEyLxTJ9cEOvoUBAABNiuUjKAD+wzakT9Wi+IrKqjN2VXh+YgAAABAYDL5cbBBGUIAAYVzTUfbeVafIdn2wU7pQZHEiAACAxkeBAgQAIzFB9qF9JUmuHftlHjttcSIAAABrMMULsFpUhOy3DpRht8t95JTcu76yOhEAAGgILqrcIIygAFay2aqKk5gomfmFcm3ZaXUiAAAAS1GgABayXZ8mW5uWMssr5Hx3m1TJongAANC0UaAAFrH16iJ7r84yTVOu93dIhcVWRwIAAA1kqOosXgH108DHtGHDBs2cOVPDhw9X//79NW7cOP3lL3+R2+2u0W7Lli2aMGGC0tLSNGrUKK1YsaJex2MNCmABo21L2Yf2lyS5t++TeeKMtYEAAADq8NJLLykpKUk///nP1bJlS33++ef67W9/q+PHj+vRRx+VJO3atUszZ87U+PHj9dhjj2nnzp168sknFR4erjvvvNOr41GgBIhp3R72uK27tMyPSa7s1cz5HrW7e9CvPd6nOz7ao3Z5A+M93mfC/lKP2pmJCR7vU3a7R82MqMgrN4iOlOP2ITLsNrmPnpJ56MRV72ML8/ytenfaox61W5GzxON9esrwMOdrRxb6/NgAAMA/nn/+ebVo0aL69yFDhqikpEQrVqzQI488ovDwcC1cuFCpqal66qmnqtucOnVK8+fP1+TJk2WzeT5xiyleQGOy2WQfcZ2MqEiZ5wvl/myv1YkAAIAvmQH60wBfL04u6dWrl8rLy3XhwgVVVFRo69atGjt2bI0248aNU15envbt2+fV8RhBARqR/fo+srVqLrOsQs73v5DhclkdCQAANAEnT57UtGnT6ty+adMmr/a3Y8cONW/eXC1bttThw4dVWVmprl271mjTrVs3SVJWVpb69Onj8b4ZQQEaia1nZ9m6dZDpNqtOJ1zk2TQ0AACAQJKRkaHVq1frnnvukd1uV0FBgSQpLi6uRrtLv1/a7ilGUIBGYLRtKdvAXpIk9479Mk+fszgRAADwFyMAr9OYlJTk9ShJbfLy8vTQQw8pLS1N999/f41thlH7+cLqur0ujKAA/hYTJfvwa2XYbHJnnZB732GrEwEAAHjt4sWLuv/++xUZGanFixcrLCxMkhQfX3Uio2+OlBQWFkq6fGTlaihQAH+y2+QYcZ2MyHC5z16Q67MMqxMBAAB4rby8XA8++KDOnj2rZcuWKSHhP2dC7dixo8LCwpSdnV3jPpmZmZKklJQUr45FgQL4kf2GvjJaxsssLa+6GKPLffU7AQCA4GaagfXTQE6nUw8//LAOHDigZcuWKTk5ucb28PBwDRkyRBs2bKhx+7p165SYmKjU1FSvjscaFMBPbL27ytY1WabbXbUovsS669cAAADU1xNPPKH3339fP/vZz1RWVqYvv/yyelu3bt3UrFkzzZo1S1OnTtXcuXM1btw47dy5UytXrtQTTzzh1TVQJAoUwC+MpFayXdtTkuTetk9m7nmLEwEAANTPxx9/LEn6wx/+cNm2V155RYMHD9aAAQO0aNEiPf3001q7dq3atm2ruXPnen0VeYkCBfC92GjZbxogw2bI/dUxuQ8etToRAABoRIF4Fq+G2Lx5s0fthg8fruHDhzf4eKxBAXzp0qL4iHC5z+TL9TlXigcAAPAGBQrgQ/bUzjIS4mSWlMn1wQ7JzaJ4AAAAbzDFC/ARW+e2srVOkOlyVZ2xq7Tc6kgAAMAKITbFq7FRoAQId6nnZ3hakbPEo3ZTkmfUN06dpnae5VE745rOHu+zrHW0R+3yUz0fjShNjPKoXcs94R7vM3bbsTq3Ge1aytY1SZLk3vmVVFQmIzLyqvt8ZddvPT6+JDkcNiUkxCg/v1hOZ+394elz5A+vHVlo2bEBAEBoYIoX0FCx0bIN6SPDMOQ+dEJm9kmrEwEAAAQtRlCAhgizyz60r4xwh8wz+XJ/+ZXViQAAgMVC7SxejY0RFKABbIN7y4iLqVoU/+keyc0nEgAAQENQoAD1ZOvdRbbkxKpF8R/vlsorrI4EAAAQ9JjiBdSDkZwoW5+ukiT39gNS/kWLEwEAgIDBjIoGYQQF8FZcjGyDUyVJ7oPHZB49bXEgAACA0EGBAngjzFG1KD7MIXfuebn/lWl1IgAAgJDCFC/AU4Zku76PjNhomUWlcn+6RzIZwgUAAF9jKvAu1Bhoea6CERTAQ7a0FNnatZTpdMn1yW6potLqSAAAACGHERTAA2ExzWTr0k6S5N62T7pQZHEiAACA0ESBAlyFPTxcMa3aSJLc+4/IPH7G4kQAACCQcaHGhmGKF3AFhs2mmNZJMmw2uU+dkzsjy+pIAAAAIY0RlCA0rddPPWpnhHn+9N496Nee7dPh2T7dUWEeHzvnXs8ucGiWeb5PW064x22vJKZ1O9nDwuSqrJD5xQHJg8dvXvR8+teU5BkNiddoPM25ImeJn5MAAIBQR4EC1CGqRSuFRUXLdLtVlHtKMZVOqyMBAIBgwFk+G4QpXkAtwpvFKjI+QZJUnHda7krPRnkAAADQMBQowDfYwyMU3bK1JKk0/5wqS4otTgQAANB0MMUL+BrDZlezNu1k2GyqKC5S2YXzVkcCAABBhrN4NQwjKMDXxLRpJ5sjTK6KChXn5VodBwAAoMmhQAH+LaplosIio2S6XSo6c1Iy3VZHAgAAaHKY4gVICm8Wp8i45jJNU0VnTstdWWl1JAAAEKyY4tUgjKCgybNHRCq6VdWi+LL8c3KWllicCAAAoOmiQEGTZtjtata6nQzDUEXxRZUV5FsdCQAAoEljiheaLlNq1rqdbA6HXBXlLIoHAAA+YXChxgZhBAVNkym1crWSIzJKbpdLRbmnuOorAABAAKBAQZMU545TnBkn0zSrrhTvZFE8AABAIGCKV4Awwnz/VBhRkZ43jozwqFnlgG6etYsP8/jQvdod86jd7oMdPd5nq911Fxz2qChFd2opGZJ73xFFZZ30aJ/m+QsetXOXlnnUTpJW5CzxuK0kORw2JSTEKD+/WE5n450G2ducAAA0WaakQLtSQZBNEmEEBU2K4XAoqn2SDMNQZUGhTA+LEwAAADQOChQ0HYah6PbJVYviy8pUeuq01YkAAADwDUzxQpMR2a6N7FGRcjudKjmew6J4AADgB2YAnsUr0PJcGSMoaBLCWyQoPD5epmmqNOekTKfT6kgAAACoBQUKQp49OloRrRMlSWW5Z+QqKbU4EQAAAOrCFC+ENCMsTFHJVYviKy4UqDL/gtWRAABAqAuuGVUBhxEUhC7DUHT7JNkcdrlKS1V2mivFAwAABDoKFISsqKS2skf+e1H8iZMsigcAAAgCTPFCSApv2UJhcVVXii89waJ4AADQiPhStEEYQUHIiS2KVkRiK0lS2elcuUpZFA8AABAsKFAQUsIrwtQxp13Vovj8C6q8UGB1JAAAAHiBKV4IGTaXoc7Hk2R32+UsKWFRPAAAaHSGJCPAZngZVgfwEgUKQoMpdTjZTpEVEap0OFV24qTViQAAAFAPFCgB4rUjCz1ue3fao541TIj3eJ/Ols08aneuT5RH7dzhHh9a597u6lG7rrsq6twWlthSEW2ayXS7VXnwhKL25Hi0T/NikUftqg7i2dtlReYSj3c5JXmG58f30Iocz4/vKV/n9EdGAAAQGihQEPTssc0U0abqSvHlJ3PlLi2zOBEAAGjSOItXg7BIHkHNiAhXZPt2kqSKc+flZFE8AABAUKNAQfCy2RTVsb0Mu12u4hJVnDpjdSIAAAA0EFO8ELQiOyTJFhEud0WlSo95tuYEAADA3wy31QmCGyMoCErhrVvJEVu1KL7s2AnJ5bI6EgAAAHzg/2/v3qOjKu/9j39mJpkkBAYIBDWBBBJK5BII9nCJUlDUA/4IBywLF2sdKctSaQkVpMUDh3bpwkbBVX/0gILagop4PbqEn0WgImpQK+AFC4IoBCo3hZjbALkMM7N/f3DIMWSGTCaZ7J2Z92stls6zn733d74+gN88z7M3BQraHYerk5w9Lr4pvu7kd/LX1pkcEQAAAFoLS7zQrtgTEv53U3xpmbxVbpMjAgAA+AFD1nuKl8XCaQozKGg/HHYlZqbLZrfLe+68PKdLzY4IAAAArYwCBe2DISX2Spfd6ZTf41HtcTbFAwAARCOWeKFdSPGnKK5j8sVN8d+clHw8HgMAAFhUO1tSZTXMoMDykv3J6uLvIkmqPfGt/HVsigcAAIhWlphBOXr0qIqKivTpp58qKSlJEyZM0IIFC5SYmHjF86ZPn67du3c3at+8ebOys7MjFS7akNNwKtWXKknynPlePvdZkyMCAABAJJleoLjdbs2YMUNpaWlauXKlysvLtXTpUlVWVurRRx9t8vzrrrtOCxcubNDWs2fPSIUbMT8b/kDIfT3Xhvb9vh+SFPI13cNqQ+rX8fPQrtfjk5qQ7x1fdj7wAWec4kYMlC3JLn9ppbShWM4Qp0xDXQBmXPCG2DMyXjj5VLP6x8XZ1bVrsioqzsvrbbtlbs2NEwCAWGaz2lO82hnTC5SXX35ZbrdbGzduVEpKiiTJ4XBowYIFmj17dpMzIS6XS3l5eW0QKdqUzSbH4L6yJSXIOF8j374S1nMCAADEANP3oOzYsUP5+fn1xYkkjRs3Tk6nU8XFxSZGBjPZ+/WSPcUlw+uT9/NDkpc3xQMAAMQC02dQSkpKNGXKlAZtTqdTGRkZKikpafL83bt3Ky8vTz6fT0OGDNG8efM0bNiwFsUUF9c2dZvDYW/wT1xkS+suR+bVknRx5uR8aMvPrCKS44cxExy5CYy8BEduAiMvgZGX4MhNACzxahHTCxS32y2Xy9Wo3eVyqaqq6ornDhs2TJMmTVLv3r115swZrV27VnfddZfWr1+voUOHhhWP3W5T167JYZ0bLpcr9L0i0c7WOVmOAb0lSb7DJ2SUVpoaTzjaYvwwZoIjN4GRl+DITWDkJTDyEhy5QWsxvUAJxjAM2Wy2K/aZO3dug8833nijCgoKtHr1av3lL38J675+vyG3uzqsc5vL4bDL5UqS2x36hvKo5oyXY8iPZLPb5T9dLv+RU2ZHFJaKiiCb/lvBD8eMj3fBNEBuAiMvwZGbwMhLYOQluLbOjcuVxGxNlDO9QHG5XHK73Y3az5492+xHBXfo0EFjxozR3/72txbF1JZPR5LEH3TSxU3xQ/rKluiUca5avi+OmB1R2Npi/Ph8/jYfp+0FuQmMvARHbgIjL4GRl+DIzQ+QhhYxvfzMzs5utNfE4/Ho2LFjYb3LxGDNX7tkvzZT9q6dZFzwyrvnEG+KBwAAiFGmFyijR4/Wzp07VVFRUd+2bds2eTwejRkzplnXqq6uVnFxsXJzc1s7TESQvWeqHL16yDAM+faWSDW8KR4AACBWmV6gTJs2TZ06dVJhYaHef/99bdy4UX/4wx80ceLEBjMoixcv1oABA+o/f/LJJ5o9e7Zef/117dy5U2+88Yb+/d//XaWlpZozZ44ZXwVhsCd3kP3aTEmS/9AJGWVXfjACAACA1dkMw1K/2htL7EFZt26dioqKdM899ygxMVEFBQVasGBBg35+v18+3/++CyM1NVUej0fLly9XZWWlkpKSNHToUC1ZskSDBw9u66+BMNji45SQ3fPipvjvyuT/57dmhwQAAACTmV6gSFKfPn20du3aK/ZZtmyZli1bVv85MzOzyXNgYTabnNm9ZIuPl3G2Wr79R82OCAAAABZgiQIFsceZcY0cyR1keL3yfv41m+IBAEB0MGS9FzVaLJymmL4HBbEnLjVFcd27yjAM1R05IdV4zA4JAAAAFsEMikX4u7lC7lsyzRlSvyOTnwj5mtmv/jKkfmnvhbaJ3dj7dcB2W3oPxQ/tL0nyffC5bJ9/LSUlhnbNC96Q+knSCyefCqnfnb1Df6DC8/9cFXJfAAAAhIcCBW2nUwfF33a9bHa7fAf/Kd/ngYsYAACA9suw3hKvdrbGiyVeaBtxDsVPGCVbUoL8p8vlfecTsyMCAACABVGgoE3EjR0me2pXGdW1urD5A+kHj4wGAAAALmGJFyLOMTRHjpxMGT6/Lmz5u3SuxuyQAAAAIoeHk7YIMyiIKFuvq+S4/uKLM73v75FxqtTkiAAAAGBlFCiIHFey4sfnX9wUv/+I/PsOmx0RAAAALI4lXoiM+LiLm+ITE+T/9nt53/vU7IgAAADahM1yT/FqX5hBQUTE3TJc9u5dZJyr0YUtH0p+FmMCAACgacygoNXZM66So0+aDJ9PFzZ/KJ2vNTskAAAAtBMUKGhVthSXHL2vkSR53/tMxukykyMCAABoYyzxahGWeKH1JCUorn9v2Ww2+fYekv/AEbMjAgAAQDtDgYLW4bArflCWbHEO+SvPyfv+52ZHBAAAgFbwzTff6P7779ekSZM0YMAAFRQUBOxXXFysyZMnKzc3V7feeqteeOGFsO7HEi+LONenU8h9/zbh/4bUL+uteSFfM3NLaG92N/Z+HbA9bsIo2TokyjhbrQuvvS2bwy45Qqt/1x9e0fh6cXZ17Zqsiorz8nojt8H++X+uiti1AQBAjIqyJV6HDh1ScXGxhgwZIr/fLyPA99uzZ48KCws1adIkLVq0SJ999pmKiorkdDo1derUZt2PAgUt5hgxUI6sdBleny5s/kCqqZPiGVoAAADRYOzYsbrlllskSYsWLdIXX3zRqM+qVas0YMAAPfzww5KkkSNH6ttvv9WKFSs0ZcoU2e2hL9xiiRdaxJ6drrjhgyRJ3nc+lnGmwuSIAAAA0JqaKi48Ho927typCRMmNGifOHGiSktLdeDAgWbdjx9zI2y2lM6Ku2WEJMm75yv5v/rG5IgAAAAswIJLvE6dOqXp06cHPb59+/awr33s2DFduHBBWVlZDdr79u0rSSopKdGgQYNCvh4zKAhPQrziJ9wgmzNe/uOn5fvwH2ZHBAAAABNUVVVJklwuV4P2S58vHQ8VMyhoPptN8ePyZevSSUbVOV3Y+ndL/qQAAAAAF6WlpbVoliQUNputWe3BUKCg2Rz5ubJnXiPjgvfim+JrPWaHBAAAYA2GpMg9gDQ8Ef45cufOnSU1nilxu92SGs+sNIUlXmgW+496Ke7H/SVJ3u27ZXxfaW5AAAAAMFVGRobi4+N15EjDl3QfPnxYkpSdnd2s61GgIGT2hATF3TxckuT99Ev5Dx03OSIAAACYzel0auTIkdqyZUuD9k2bNik1NVUDBgxo1vVY4oWQ2BwOdeiZJlt8nPzffCvfR/vMDgkAAMCSbFG2N7empkbFxcWSpJMnT+rcuXPaunWrJGn48OFKSUnRnDlzdOedd+r3v/+9Jk6cqM8++0yvvvqqHnzwwWa9A0WiQEGIktKvkd3plL/yrC787SM2xQMAAMSIsrIyzZs3r0Hbpc/PPfecRowYoaFDh2r16tVavny5Nm7cqKuvvlq///3vm/0WeYkCBSFI6JGquORkGT6/vG9+INVdMDskAAAAtJGePXvqq6++arLfmDFjNGbMmBbfjwIFVxTf2aWEbimSpJpvv5Wj3G1yRAAAABbHSpMWYZM8grInJijx6qskSXWl38t79pzJEQEAACDaMYNiEd+NDP0FNhM+KgypX/pfQ//P+9q6WQ0+V5336MFnP1bF2Trl9e2uXy+8SfZmvmQHAAAAaC4KFDTi9fm1esM+VZyt0zXdOujuiQMoTgAAAEJiSH6rLfGyWjxXxhIvNPLS9kM6dKJKSQkO/fqnuUpKoI4FAABA26BAQQM7/nFK7352UjZJsyYO1DXdks0OCQAAADGEH42j3uGTVVr/t4uPkLt9dJaG9O1uckQAAADtEE/xahFmUCBJqjhbp1Wv75PPb+hfclI1IT/T7JAAAAAQgyhQIElatWGfqs57lJ6arJ9P6C8bm+IBAABgApZ4QckpPXTklFvJiXG656e5SnQyLAAAAMLGEq8WYQYlxiV0dCmho0s2m/TLSQPVo2sHs0MCAABADKNAiWFxCYnq0DVVkjT1xr4a1KebyREBAAAg1rGWJ0bZHXHq2P1q2Ww21Z0/q3HDe5kdEgAAQPtnyHpLvCwWTlOYQYlFNps6dr9adkecvJ5anS8/w6Z4AAAAWAIFSgxKTklVXEKi/D6fzpV+Z70qHwAAADGLJV4W4Uv2h9y358uJIfXruH1/ozb7oCw5Mlwy/H75t36k5G/LQr4vAAAAQuDnh78twQxKDLGlpco+fJAkyb/zCxkUJwAAALAYCpRY0bGDHGP/RTa7Tf6vj8l/4KjZEQEAAACNsMQrFsQ5FHfrcNkSnfKfqZDvw3+YHREAAED0MkJfuo/GmEGJAY7RQ2Xr1llGda18b++WfPymAQAAgDVRoEQ5++C+smely/D55dv+sVRda3ZIAAAAQFAs8Ypitp49ZB82QJLk/2ivjNPlJkcEAAAQA3iFQ4swgxKl7HHxctz0L7LZbPJ9eVT+g9+YHRIAAADQJGZQopHNpo5XXSObM17+78rk/2if2REBAAAAIaFAiULJqVfL4UyQcb7m4r4TXhYEAADQRgwL/r+X1eK5MpZ4RZnELilyJneUYfgvPrGrps7skAAAAICQUaBEkfgOyUrq2k2SVP19qYzSSnMDAgAAAJqJJV5Rwh4fr+TUqyRJtVWV8pxzy2lyTAAAADHHkPWe4mWxcJpCgWIR/dbVhN750y8bfnbGK/6OW2WzO+Q/cVq2/1esDn5D608+1bpBAgAAABHGEq/2zmZT3LiRsnftJMN9Xhe2fGTBjVkAAABAaJhBaeccIwbJ0TtNxgWvLrz5gVTLpngAAABTWW2JVzvDDEo7Zu/bU3H/86Z47zsfy/i+0tyAAAAAgBaiQGmnbN06K+6WEZIk72cH5f/6mMkRAQAAAC3HEq/2KMGp+AmjZIuPk//Yd/L9fa/ZEQEAAOASlni1CDMo7VD8+HzZOneUUXVOF7Z+xG8CAAAARA1mUNoZR+Y1sqen/u+m+DqP2SEBAAAArYYCpR2xd++iuPRUSZJ32y4ZZVUmRwQAAIBG/H6zI2jXWOLVTtiSkxSX3VOS5P14v/wlJ0yOCAAAAGh9FCjtQbxD8ddmyuawy1fulm/XfrMjAgAAACKCJV5WZ5Pi+2XKluCUv6ZO3kPH2BQPAABgZfy/Woswg2Jxjt5psnfuKMPrk/fgPyUfaxoBAAAQvShQLMzeo6virukuSfIeOi6jps7kiAAAAIDIYomXRbzwxr0NPpecqtIjL3wmr8/Q5FF99G+LxpoTGAAAAJqHJV4twgyKBVWdq9Oq1/fJ6zM09EfdVXBDb7NDAgAAANoEBYrFXPD6tWrDF6o851Fa92T9omCA7Dab2WEBAAAAbYIlXhbz4ttf6/DJKnVIiNM9U3KVlMB/IgAAgHbDMCS/xZZ4tbMlZ8ygWMh7e06q+PNTskn65aSBuqprB7NDAgAAANqUJQqUo0ePaubMmcrLy1N+fr6KiopUW1sb0rkbNmzQ+PHjlZubq4KCAm3ZsiXC0UbG18cr9cK2ryVJU27MVm5WN5MjAgAAANqe6euH3G63ZsyYobS0NK1cuVLl5eVaunSpKisr9eijj17x3K1bt2rRokWaNWuWbrjhBr399tuaP3++OnXqpFGjRrXRN2i5cnetVm/8Qj6/oWHX9tBtIzLMDgkAAABhMgzeW9cSphcoL7/8stxutzZu3KiUlBRJksPh0IIFCzR79mxlZ2cHPXfFihUaP368fvvb30qSRo4cqaNHj2rlypXtpkDxXPBp5Wt75T7vUc/Ujvr5/+kvG5viAQAAEKNMX+K1Y8cO5efn1xcnkjRu3Dg5nU4VFxcHPe/48eM6cuSICgoKGrQXFBRo7969Ki8vj1jMrcUwDK167R86csqt5MSLm+ITnA6zwwIAAABMY/oMSklJiaZMmdKgzel0KiMjQyUlJUHPO3LkiCQpKyurQXt2drYMw9CRI0caFD3NERfXNnXb+/84pXc+OS6bTfr1lMG6pntym9y3PXA47A3+iYvIS3DkJjDyEhy5CYy8BEZegiM3AVjtKV7tjOkFitvtlsvlatTucrlUVVUV9LxLxy4/t3Pnzg2ON5fdblPXrm1TKBwrPS9JmvlvgzTqul5tcs/2xuVKMjsESyIvwZGbwMhLcOQmMPISGHkJjtygtZheoARjGEZIezEu72P8z3Oew93H4fcbcrurwzq3ue64KVsTf5Klrh3iVVFxvk3u2V44HHa5XElyu2vk87HR7BLyEhy5CYy8BEduAiMvgZGX4No6Ny5XErM1Uc70AsXlcsntdjdqP3v27BU3yP9wpqR79+717ZeuFWhWJlReb9v8wRMfZ1eP7smqqDjfZvdsb3w+P7kJgLwER24CIy/BkZvAyEtg5CU4cvMD7ezFiFZjevmZnZ3daK+Jx+PRsWPHrligXNp7cmkvyiUlJSWy2WyN9qYAAAAAsD7TC5TRo0dr586dqqioqG/btm2bPB6PxowZE/S8Xr16KSsrS5s3b27QvmnTJg0ePDjsDfIAAAAAzGP6Eq9p06bp+eefV2FhoQoLC1VWVqZly5Zp4sSJDWZQFi9erI0bN+rAgQP1bXPnztX8+fOVkZGh66+/Xtu3b9eHH36oNWvWmPFVAAAAAMnPUreWML1AcblcWrdunYqKinTPPfcoMTFRBQUFWrBgQYN+fr9fPp+vQdttt92m2tpaPfnkk1q7dq0yMzP1pz/9qd28pBEAAABAQ6YXKJLUp08frV279op9li1bpmXLljVqv/3223X77bdHKjQAAAAAbcgSBQoAAAAQFQzDek/xslo8TTB9kzwAAAAAXEKBAgAAAMAyWOIFAAAAtCKDp3i1CDMoAAAAACyDAgUAAACAZbDECwAAAGhN7eypWVbDDAoAAAAAy6BAAQAAAGAZLPECAAAAWpOfJV4twQwKAAAAAMugQAEAAABgGSzxAgAAAFqTwYsaW4IZFAAAAACWQYECAAAAwDJY4gUAAAC0FkMyrPYUL4uF0xRmUAAAAABYBgUKAAAAAMtgiRcAAADQagwLPsWrfa3xYgYFAAAAgGVQoAAAAACwDJZ4AQAAAK3Ick/xameYQQEAAABwRUePHtXMmTOVl5en/Px8FRUVqba2NiL3YgYFAAAAQFBut1szZsxQWlqaVq5cqfLyci1dulSVlZV69NFHW/1+FCgAAABAa7LcU7xa5uWXX5bb7dbGjRuVkpIiSXI4HFqwYIFmz56t7OzsVr0fS7wAAAAABLVjxw7l5+fXFyeSNG7cODmdThUXF7f6/ZhBuYzdblNKSnKb3tPlSmrT+7Un5CYw8hIcuQmMvARHbgIjL4GRl+DaKjd2u61N7hOuHhnd9dzhx80Oo4EeGd116tQpTZ8+PWif7du3Bz1WUlKiKVOmNGhzOp3KyMhQSUlJq8V5CQXKZWw2mxyOth34DgcTWcGQm8DIS3DkJjDyEhy5CYy8BEZegiM3FzniHLom6yqzw2iktLQ07HPdbrdcLlejdpfLpaqqqpaEFRAFCgAAABDlhgwZcsVZknAYhiGbrfV/sE+pCwAAACAol8slt9vdqP3s2bMBZ1ZaigIFAAAAQFDZ2dmN9pp4PB4dO3as1Z/gJVGgAAAAALiC0aNHa+fOnaqoqKhv27Ztmzwej8aMGdPq97MZhmG0+lUBAAAARAW3262CggKlp6ersLBQZWVlWrZsmUaNGhWRFzVSoAAAAAC4oqNHj6qoqEiffvqpEhMTVVBQoAULFigxMbHV70WBAgAAAMAy2IMCAAAAwDIoUAAAAABYBgUKAAAAAMugQAEAAABgGRQoAAAAACyDAgUAAACAZVCgRMjRo0c1c+ZM5eXlKT8/X0VFRaqtrQ3p3A0bNmj8+PHKzc1VQUGBtmzZEuFo21a4uZk+fbpycnIa/SopKWmDqCPvm2++0f33369JkyZpwIABKigoCPncaB4z4eYl2sfLli1bVFhYqDFjxigvL08TJ07Uiy++KL/f3+S50TxepPBzE+1j5v3339edd96pkSNHatCgQbr55pu1dOlSnT17tslzo3nMhJuXaB8vgZw/f16jR49WTk6O9u3b12T/aB43iKw4swOIRm63WzNmzFBaWppWrlyp8vJyLV26VJWVlU2+bXPr1q1atGiRZs2apRtuuEFvv/225s+fr06dOmnUqFFt9A0ipyW5kaTrrrtOCxcubNDWs2fPSIXbpg4dOqTi4mINGTJEfr9fob6iKNrHTLh5kaJ7vDzzzDNKS0vTf/zHf6hbt27atWuXHnroIR0/frzRd/6haB8vUvi5kaJ7zFRVVWno0KGaMWOGXC6XDh06pMcee0yHDh3S008/HfS8aB8z4eZFiu7xEsjq1avl8/lC6hvt4wYRZqDVPfXUU8aQIUOMsrKy+rY33njD6Nevn3H48OErnjt+/Hhj7ty5Ddp+/vOfG1OnTo1IrG2tJbm58847jVmzZkU6RNP4fL76f1+4cKExYcKEkM6L9jETbl6ifbz88PfQJQ8//LCRm5tr1NXVBT0v2seLYYSfm2gfM4G88sorRr9+/YzvvvsuaJ9YGDOXCyUvsTZeDh8+bOTl5RkvvfSS0a9fP2Pv3r1X7B+L4wathyVeEbBjxw7l5+crJSWlvm3cuHFyOp0qLi4Oet7x48d15MiRRktYCgoKtHfvXpWXl0cs5rYSbm5igd3e/N+OsTBmwslLLPjh76FL+vfvr7q6OlVWVgY8JxbGixRebmJVly5dJElerzfg8VgZM5drKi+x6KGHHtK0adPUp0+fJvvG6rhB6+Fv/ggoKSlRdnZ2gzan06mMjIwrrk09cuSIJCkrK6tBe3Z2tgzDqD/enoWbm0t2796tvLw85ebm6s4779THH38cqVDbhVgYMy0Ra+Pl008/VZcuXdStW7eAx2N5vDSVm0tiYcz4fD7V1dVp//79WrVqlW666Salp6cH7BtLY6Y5ebkkFsaLdHG51sGDBzVnzpyQ+sfSuEFksAclAtxut1wuV6N2l8ulqqqqoOddOnb5uZ07d25wvD0LNzeSNGzYME2aNEm9e/fWmTNntHbtWt11111av369hg4dGqmQLS0Wxky4Ym287Nu3T6+//rrmzJkjh8MRsE+sjpdQciPFzpi56aabdPr0aUnST37yEy1fvjxo31gaM83JixQ746WmpkbLli3Tb37zG3Xs2DGkc2Jp3CAyKFDakGEYstlsTfa7vI/xP5uCQzm3vQolN3Pnzm3w+cYbb1RBQYFWr16tv/zlL5EMz/Jiccw0JZbGS2lpqebOnavc3FzdfffdTfaPpfHSnNzEypj585//rOrqah0+fFirV6/Wr371Kz3zzDNXLN5iYcw0Ny+xMl6eeOIJdevWTT/96U+bfW4sjBtEBku8IsDlcsntdjdqP3v2bMDZg0uC/WTh0rWudG57EW5uAunQoYPGjBmj/fv3t1Z47U4sjJnWEq3j5ezZs7r77ruVmJioJ554QvHx8UH7xtp4aU5uAonWMXPttdfquuuu0x133KHHH39cu3bt0rZt2wL2jaUx05y8BBKN4+XkyZN6+umnNXfuXJ07d05ut1vV1dWSpOrqap0/fz7gebE0bhAZFCgRkJ2d3Wg/hcfj0bFjxxrtv/ihS2s1L1+bWVJSIpvN1mgtZ3sUbm6CMZrxyNloFAtjpjVF23ipq6vT7Nmz9f3332vNmjXq2rXrFfvH0nhpbm6CibYxc7n+/fvL4XDo2LFjAY/H0pj5oabyEky0jZcTJ07owoULmjVrloYNG6Zhw4bpV7/6lSTpZz/7me66666A58XquEHroUCJgNGjR2vnzp2qqKiob9u2bZs8Ho/GjBkT9LxevXopKytLmzdvbtC+adMmDR48OOCTadqbcHMTSHV1tYqLi5Wbm9vaYbYbsTBmWku0jRev16t58+bp4MGDWrNmTZObeaXYGS/h5CaQaBszgezZs0c+ny/ouztiZcxcrqm8BBKN46V///567rnnGvz6z//8T0nSkiVL9MADDwQ8L1bHDVoPe1AiYNq0aXr++edVWFiowsJClZWVadmyZZo4cWKDWYLFixdr48aNOnDgQH3b3LlzNX/+fGVkZOj666/X9u3b9eGHH2rNmjVmfJVWF25uPvnkE61du1a33nqr0tLSdObMGT3zzDMqLS3VihUrzPo6raqmpqb+UcsnT57UuXPntHXrVknS8OHDlZKSEpNjJpy8xMJ4efDBB/Xuu+/qvvvuU21trT7//PP6Y3379lXHjh1jcrxI4eUmFsbMr3/9aw0aNEg5OTlKTEysL+BycnJ0yy23SIrNv5fCyUssjBfp4lKsESNGBDw2cOBADRw4UFJsjhtEFgVKBLhcLq1bt05FRUW65557lJiYqIKCAi1YsKBBP7/f3+iNrLfddptqa2v15JNPau3atcrMzNSf/vSnqHnrari5SU1Nlcfj0fLly1VZWamkpCQNHTpUS5Ys0eDBg9v6a0REWVmZ5s2b16Dt0ufnnntOI0aMiMkxE05eYmG8fPDBB5KkP/7xj42OxfJ4kcLLTSyMmcGDB2vz5s3685//LMMwlJ6erjvuuEMzZ86U0+mUFJt/L4WTl1gYL80Ri+MGkWUzom3BJAAAAIB2iz0oAAAAACyDAgUAAACAZVCgAAAAALAMChQAAAAAlkGBAgAAAMAyKFAAAAAAWAYFCgAAAADLoEABAAAAYBkUKABwmZycnJB+7dq1y+xQI+LEiRPKycnR66+/3qzzxo4dq1/+8pdN9tu1a1fA/K1fv1633nqrBg0apJycHLndbj355JN6++23mxUHAKB9izM7AACwmldeeaXB59WrV2vXrl1at25dg/a+ffu2ZVhRY+DAgXrllVca5O/LL79UUVGRpk6dqsmTJysuLk7Jycl66qmnNG7cON1yyy0mRgwAaEsUKABwmby8vAafU1JSZLfbG7VfrqamRklJSZELLAS1tbVKTEw0NYamdOzYsVEuDx06JEm64447NHjwYBOiAgBYBUu8ACAM06dPV0FBgT7++GNNmzZNQ4YM0eLFiyVdXCL22GOPNTpn7NixWrRoUYO20tJS3X///Ro9erQGDRqksWPH6vHHH5fX620yhktLqt566y1NnjxZubm5evzxx5t13dOnT2vevHkaOnSofvzjH+vee+/V999/3+hex48f1/z58zVq1CgNGjRI119/vWbMmKEvv/yyUd8dO3bo9ttv1+DBgzV+/Hi99tprDY5fvsRr+vTpuu+++yRJU6dOVU5OjhYtWqScnBxVV1drw4YN9cvqpk+f3mReAADtGzMoABCm0tJS3XffffrFL36h+fPny25v3s98SktLNXXqVNntds2ZM0cZGRnas2ePnnjiCZ08eVJLly5t8hr79+9XSUmJZs+erZ49eyopKSnk69bW1uquu+7SmTNn9Nvf/la9e/fWe++9p/nz5ze6z9133y2/36/77rtPaWlpqqio0J49e+R2uxv0O3jwoB555BHdfffd6t69u1599VX97ne/U2ZmpoYNGxbwOzzwwAPatGmTnnjiCS1dulRZWVlKSUnRtGnTNGPGDI0YMUKFhYWSLs6+AACiGwUKAISpsrJS//Vf/6X8/Pywzn/sscdUVVWlN998U2lpaZKk/Px8JSYm6pFHHtHMmTOb3OdSXl6uN998U3369Klvu//++0O67oYNG1RSUqLVq1fr5ptvliSNGjVKdXV1+u///u/661VUVOjo0aNavHixJk2aVN/+r//6r43iqaio0EsvvVR/32HDhmnnzp3661//GrRA6du3rzIyMiRJP/rRj5SbmytJysjIkN1uV0pKSpPL6wAA0YMlXgAQps6dO4ddnEjSe++9pxEjRqhHjx7yer31v0aPHi1J2r17d5PXyMnJaVCcNOe6u3btUnJycn1xcklBQUGDz126dFFGRobWrl2rZ555RgcOHJDf7w8YT//+/euLE0lKSEhQ7969derUqSa/CwAAEjMoABC21NTUFp1fVlamd999VwMHDgx4vKKiIqwYQr1uZWWlunfv3uj45W02m03PPvusVq1apTVr1mjZsmXq0qWLJk6cqHvvvbfBsqsuXbo0up7T6VRdXV2T3wUAAIkCBQDCZrPZArY7nU55PJ5G7ZcXHF27dlVOTo7uvffegNfp0aNHWDGEet0uXbpo7969jY4H2iSfnp6uhx9+WJJ09OhRbdmyRY8//rg8Ho8efPDBJuMEACBUFCgA0MrS09P11VdfNWj76KOPVF1d3aDtxhtvVHFxsTIyMtS5c+dWu3+o1x0xYoS2bNmi7du3N1jmtWnTpitev0+fPiosLNRbb72lAwcOtFrcgTidTtXW1kb0HgAAa6FAAYBWNmnSJK1YsUIrVqzQ8OHDdfjwYT3//PPq1KlTg35z587V3//+d02bNk3Tp09Xnz595PF4dOLECe3YsUNLlizR1Vdf3ez7h3rdyZMn69lnn9XChQs1f/58ZWZmqri4WB988EGD6x08eFB/+MMfNH78eGVmZio+Pl47d+7UV199pVmzZrUoV03p16+fdu/erXfeeUepqalKTk5WVlZWRO8JADAXBQoAtLKZM2fq3Llz2rBhg55++mkNHjxYK1asqH9U7iU9evTQa6+9ptWrV2vt2rU6ffq0kpOTlZ6erp/85CdyuVxh3T/U6yYlJem5557TQw89pEcffVQ2m02jRo3S8uXLNW3atPrrpaamKiMjQy+++KK+++47SVKvXr20cOHCiL+X5He/+52WLFmi3/zmN6qpqdHw4cO1fv36iN4TAGAum2EYhtlBAAAAAIDEY4YBAAAAWAgFCgAAAADLoEABAAAAYBkUKAAAAAAsgwIFAAAAgGVQoAAAAACwDAoUAAAAAJZBgQIAAADAMihQAAAAAFgGBQoAAAAAy6BAAQAAAGAZ/x+I+z2xBTW5rQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(np.ravel(pred), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e952dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = get_point_metrics(pd.Series(np.ravel(pred)), pd.Series(y_test), binned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63a46536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zspec_bin</th>\n",
       "      <th>count</th>\n",
       "      <th>L</th>\n",
       "      <th>bias_bw</th>\n",
       "      <th>bias_conv</th>\n",
       "      <th>scatter_bw</th>\n",
       "      <th>scatter_conv</th>\n",
       "      <th>outlier_bw</th>\n",
       "      <th>outlier_conv</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 4.0]</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.456802</td>\n",
       "      <td>0.130006</td>\n",
       "      <td>0.134326</td>\n",
       "      <td>0.126929</td>\n",
       "      <td>0.10669</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.166714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    zspec_bin  count         L   bias_bw  bias_conv  scatter_bw  scatter_conv  \\\n",
       "0  (0.0, 4.0]   2000  0.456802  0.130006   0.134326    0.126929       0.10669   \n",
       "\n",
       "   outlier_bw  outlier_conv       mse  \n",
       "0      0.1135         0.461  0.166714  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1820f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pred, columns=['photoz'])\n",
    "df['specz'] = pd.Series(y_test)\n",
    "df['object_id'] = pd.Series(oid_test)\n",
    "os.makedirs(f'/data2/predictions/{model_name}', exist_ok=True)\n",
    "df.to_csv(f'/data2/predictions/{model_name}/testing_predictions.csv', index=False)\n",
    "metrics.to_csv(f'/data2/predictions/{model_name}/testing_metrics.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

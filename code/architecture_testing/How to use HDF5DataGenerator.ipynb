{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8298e285-e8a4-49c2-911d-3f5434bce708",
   "metadata": {},
   "source": [
    "# How to use the HDF5DataGenerator class in DataMakerPlus.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2cf89-78cd-4eee-b63d-4950efe07617",
   "metadata": {},
   "source": [
    "The purpose of the HDF5DataGenerator class is to implement batching to a large training sample that includes images.\n",
    "All you need are the file paths of the HDF5 files you want to use for training, validation, and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff92d42-b733-4178-bdd7-2928d02b07e1",
   "metadata": {},
   "source": [
    "Here is an example of using the generator for a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64862f82-d9ce-46e3-9524-b183953f35c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import keras\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Input, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from photoz_utils import *\n",
    "from DataMakerPlus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dfa68ce-d0eb-4fb8-9650-099bfaebcb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# It's good practice to limit memory use for models.\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(1000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "345848f2-bccc-4ec7-8b27-e77a31bfb0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare your HDF5 file paths\n",
    "TRAIN_PATH = f'/data/HSC/HSC_v6/step2A/127x127/5x127x127_training_with_morphology_normalized.hdf5'\n",
    "VAL_PATH = f'/data/HSC/HSC_v6/step2A/127x127/5x127x127_validation_with_morphology_normalized.hdf5'\n",
    "TEST_PATH = f'/data/HSC/HSC_v6/step2A/127x127/5x127x127_testing_with_morphology_normalized.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef554c4d-13ba-4de7-809a-e910f79832a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dict to pass in the arguments for the generator.\n",
    "gen_args = {\n",
    "    'image_key': 'image',\n",
    "    'numerical_keys': None,\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': True,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': 256,\n",
    "    'shuffle': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf8f51-9f67-484c-a74a-3ece7c912b24",
   "metadata": {},
   "source": [
    "Put the name of the image column into 'image_key'. Put in the column of your label, what you want to predict, in 'y_key'.\n",
    "Put a list of numerican feature columns that you want to use in 'numerical_keys'. If you only wish to use the images, set \n",
    "'numerical_keys' to none. I recommend setting 'shuffle' to false and it significantly speeds up training. It is also important to\n",
    "set up a batch size. 'scaler' divides pixel values by 255 to normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f9cdaea-09aa-4e79-97ef-8632bfe0864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generator objects with the proper modes.\n",
    "train_gen = HDF5DataGenerator(TRAIN_PATH, mode='train', **gen_args)\n",
    "val_gen = HDF5DataGenerator(VAL_PATH, mode='train', **gen_args)\n",
    "test_gen = HDF5DataGenerator(TEST_PATH, mode='test', **gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a8b6f67-bfd7-4bfa-ab9a-c4394165d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your model.\n",
    "input_ = Input(shape=(5,127,127))\n",
    "conv1 = Conv2D(16, kernel_size=(3, 3), activation='tanh', padding='same', data_format='channels_first')(input_)\n",
    "pool1 = MaxPooling2D(pool_size = (2,2), data_format='channels_first')(conv1)\n",
    "conv2 = Conv2D(32, kernel_size=(3, 3), activation='tanh', padding='same', data_format='channels_first')(pool1)\n",
    "pool2 = MaxPooling2D(pool_size = (2,2), data_format='channels_first')(conv2)\n",
    "flatten = Flatten()(conv2)\n",
    "dense1 = Dense(200, activation='tanh')(flatten)\n",
    "dense2 = Dense(64, activation='tanh')(dense1)\n",
    "output = Dense(1)(dense2)\n",
    "model = Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a48407b-94a1-492e-a763-79faffd6d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='mse', metrics='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f797746-6c56-41c5-927d-3e57d0d75475",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_gen, batch_size=256, epochs=5, shuffle=True, verbose=1, validation_data=val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa758b-3f53-4640-916c-aec7a73bfa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53244d-3d4e-4697-88ac-c27cafdfbd39",
   "metadata": {},
   "source": [
    "This next example is using the generator for both images and photometry/morphology.\n",
    "Specify a list of numerical data columns and then pass it into the args dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2987dc-cb7d-4cf4-ab33-dc5d22430eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_keys = ['g_cmodel_mag', 'g_isophotal_area', 'r_cmodel_mag', 'r_isophotal_area'] # and so on\n",
    "gen_args2 = {\n",
    "    'image_key': 'image',\n",
    "    'numerical_keys': num_keys,\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': True,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': 256,\n",
    "    'shuffle': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d54b4c72-87e0-4770-b277-99ad247cb2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen2 = HDF5DataGenerator(TRAIN_PATH, mode='train', **gen_args2)\n",
    "val_gen2 = HDF5DataGenerator(VAL_PATH, mode='train', **gen_args2)\n",
    "test_gen2 = HDF5DataGenerator(TEST_PATH, mode='test', **gen_args2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b66c1-896d-4288-a237-bb9cc16653ca",
   "metadata": {},
   "source": [
    "Make sure the numerical input layer's shape is dynamic to the length of the num key list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83f81ed-7166-4367-acee-cfc83d569fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the 2 input layers.\n",
    "input_cnn = Input(shape=(5,127,127))\n",
    "input_nn = Input(shape=(len(num_keys),)) # Don't forget to add the shape to correspond with all the num keys.\n",
    "\n",
    "# CNN\n",
    "conv1 = Conv2D(32, kernel_size=(3, 3), activation='tanh', padding='same', data_format='channels_first')(input_cnn)\n",
    "pool1 = MaxPooling2D(pool_size = (2,2), data_format='channels_first')(conv1)\n",
    "conv2 = Conv2D(64, kernel_size=(3, 3), activation='tanh', padding='same', data_format='channels_first')(pool1)\n",
    "pool2 = MaxPooling2D(pool_size = (2,2), data_format='channels_first')(conv2)\n",
    "conv3 = Conv2D(128, kernel_size=(3, 3), activation='tanh', padding='same', data_format='channels_first')(pool2)\n",
    "pool3 = MaxPooling2D(pool_size = (2,2), data_format='channels_first')(conv3)\n",
    "conv4 = Conv2D(256, kernel_size=(3, 3), activation='tanh', padding='same', data_format='channels_first')(pool3)\n",
    "pool4 = MaxPooling2D(pool_size = (2,2), data_format='channels_first')(conv4)\n",
    "conv5 = Conv2D(256, kernel_size=(3, 3), activation='tanh', padding='same', data_format='channels_first')(pool4)\n",
    "pool5 = MaxPooling2D(pool_size = (2,2), data_format='channels_first')(conv5)\n",
    "conv6 = Conv2D(512, kernel_size=(3, 3),activation='relu', padding='same', data_format='channels_first')(pool5)\n",
    "conv7 = Conv2D(512, kernel_size=(3, 3),activation='relu', padding='same', data_format='channels_first')(conv6)\n",
    "flatten = Flatten()(conv7)\n",
    "dense1 = Dense(512, activation='tanh')(flatten)\n",
    "dense2 = Dense(128, activation='tanh')(dense1)\n",
    "dense3 = Dense(32, activation='tanh')(dense2)\n",
    "\n",
    "# NN\n",
    "hidden1 = Dense(hparams['num_dense_units'], activation=\"relu\")(input_nn)\n",
    "hidden2 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden1)\n",
    "hidden3 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden2)\n",
    "hidden4 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden3)\n",
    "hidden5 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden4)\n",
    "hidden6 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden5)\n",
    "\n",
    "# Concat & Output\n",
    "concat = Concatenate()([dense3, hidden6]) # Concat the input layers\n",
    "output = Dense(1)(concat)\n",
    "model2 = Model(inputs=[input_cnn, input_nn], outputs=[output]) # Specify 2 input layers here all well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df45c15-afed-438e-ae28-ba0c5a106fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer=Adam(), loss='mse', metrics='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb21923-eaf7-472d-8ee3-1a6b48199a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(train_gen2, batch_size=256, epochs=5, shuffle=True, verbose=1, validation_data=val_gen2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29cb90c-cfa0-4b41-a09a-bd6002e4b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

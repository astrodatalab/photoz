{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd5cea9",
   "metadata": {},
   "source": [
    "# This notebook uses the Inception-ResNet v2 architecture. The stem has been modified to accommodate for 127x127 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da1d79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 19:12:25.685942: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-27 19:12:26.226795: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-27 19:12:26.226841: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-27 19:12:26.226845: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import keras\n",
    "import os\n",
    "import tensorboard\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Input, concatenate, add, Activation, BatchNormalization, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from photoz_utils import *\n",
    "from DataMakerPlus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c6416a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "GB_LIMIT = 20\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(GB_LIMIT*1000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dece0a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (5, 127, 127)\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 0.0001\n",
    "Z_MAX = 4\n",
    "hparams = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'z_max': Z_MAX\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a546612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = f'/data/HSC/HSC_v6/step2A/127x127/5x127x127_training.hdf5'\n",
    "VAL_PATH = f'/data/HSC/HSC_v6/step2A/127x127/5x127x127_validation.hdf5'\n",
    "TEST_PATH = f'/data/HSC/HSC_v6/step2A/127x127/5x127x127_testing.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e5e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_args = {\n",
    "    'image_key': 'image',\n",
    "    'numerical_keys': None,\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': True,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': hparams['batch_size'],\n",
    "    'shuffle': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8e667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = HDF5DataGenerator(TRAIN_PATH, mode='train', **gen_args)\n",
    "val_gen = HDF5DataGenerator(VAL_PATH, mode='train', **gen_args)\n",
    "test_gen = HDF5DataGenerator(TEST_PATH, mode='test', **gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b1e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def calculate_loss(z_photo, z_spec):\n",
    "    \"\"\"\n",
    "    HSC METRIC. Returns an array. Loss is accuracy metric defined by HSC, meant\n",
    "    to capture the effects of bias, scatter, and outlier all in one. This has\n",
    "    uses for both point and density estimation.\n",
    "    z_photo: array\n",
    "        Photometric or predicted redshifts.\n",
    "    z_spec: array\n",
    "        Spectroscopic or actual redshifts.\n",
    "    \"\"\"\n",
    "    dz = delz(z_photo, z_spec)\n",
    "    gamma = 0.15\n",
    "    denominator = 1.0 + K.square(dz/gamma)\n",
    "    loss = 1 - 1.0 / denominator\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf11cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1,1)):\n",
    "    out = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, data_format='channels_first')(x)\n",
    "    out = BatchNormalization(axis=1, scale=False)(out)\n",
    "    out = Activation('relu')(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0e5ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_block_a(x):\n",
    "    original_in = x\n",
    "\n",
    "    branch1 = conv2d_bn(x, 32, 1, 1)\n",
    "\n",
    "    branch2 = conv2d_bn(x, 32, 1, 1)\n",
    "    branch2 = conv2d_bn(branch2, 32, 3, 3)\n",
    "\n",
    "    branch3 = conv2d_bn(x, 32, 1, 1)\n",
    "    branch3 = conv2d_bn(branch3, 48, 3, 3)\n",
    "    branch3 = conv2d_bn(branch3, 64, 3, 3)\n",
    "\n",
    "    inc_block_out = concatenate([branch1, branch2, branch3], axis=1)\n",
    "    inc_block_out = Conv2D(384, (1,1), strides=(1,1), padding='same', data_format='channels_first')(inc_block_out)\n",
    "    inc_block_out = Lambda(lambda x: x * 0.1)(inc_block_out)\n",
    "    out = add([original_in, inc_block_out])\n",
    "    out = Activation('relu')(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eac7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_block_a(x):\n",
    "    branch1 = conv2d_bn(x, 384, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch2 = conv2d_bn(x, 256, 1, 1)\n",
    "    branch2 = conv2d_bn(branch2, 256, 3, 3)\n",
    "    branch2 = conv2d_bn(branch2, 384, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch3 = MaxPooling2D((3,3), strides=(2,2), padding='valid', data_format='channels_first')(x)\n",
    "\n",
    "    out = concatenate([branch1, branch2, branch3], axis=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50a430e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_block_b(x):\n",
    "    original_in = x\n",
    "\n",
    "    branch1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch2 = conv2d_bn(x, 128, 1, 1)\n",
    "    branch2 = conv2d_bn(branch2, 160, 1, 7)\n",
    "    branch2 = conv2d_bn(branch2, 192, 7, 1)\n",
    "\n",
    "    inc_block_out = concatenate([branch1, branch2], axis=1)\n",
    "    inc_block_out = Conv2D(1152, (1,1), strides=(1,1), padding='same', data_format='channels_first')(inc_block_out)\n",
    "    inc_block_out = Lambda(lambda x: x * 0.1)(inc_block_out)\n",
    "    out = add([original_in, inc_block_out])\n",
    "    out = Activation('relu')(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2b4a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_block_b(x):\n",
    "    branch1 = conv2d_bn(x, 256, 1, 1)\n",
    "    branch1 = conv2d_bn(branch1, 384, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch2 = conv2d_bn(x, 256, 1, 1)\n",
    "    branch2 = conv2d_bn(branch2, 288, 3, 3)\n",
    "    branch2 = conv2d_bn(branch2, 320, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch3 = MaxPooling2D((3,3), strides=(2,2), padding='valid', data_format='channels_first')(x)\n",
    "\n",
    "    branch4 = conv2d_bn(x, 256, 1, 1)\n",
    "    branch4 = conv2d_bn(branch4, 288, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    out = concatenate([branch1, branch2, branch3, branch4], axis=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19668269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_block_c(x):\n",
    "    original_in = x\n",
    "\n",
    "    branch1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch2 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch2 = conv2d_bn(branch2, 224, 1, 3)\n",
    "    branch2 = conv2d_bn(branch2, 256, 3, 1)\n",
    "\n",
    "    inc_block_out = concatenate([branch1, branch2], axis=1)\n",
    "    inc_block_out = Conv2D(2144, (1,1), strides=(1,1), padding='same', data_format='channels_first')(inc_block_out)\n",
    "    inc_block_out = Lambda(lambda x: x * 0.1)(inc_block_out)\n",
    "    out = add([original_in, inc_block_out])\n",
    "    out = Activation('relu')(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3383ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(x):\n",
    "    out = conv2d_bn(x, 32, 3, 3, strides=(2,2))\n",
    "    out = conv2d_bn(out, 32, 3, 3)\n",
    "    out = conv2d_bn(out, 64, 3, 3)\n",
    "\n",
    "    branch1 = MaxPooling2D((3, 3), strides=(2,2), padding='same', data_format='channels_first')(out)\n",
    "    branch2 = conv2d_bn(out, 96, 3, 3, strides=(2,2))\n",
    "    out = concatenate([branch1, branch2], axis=1)\n",
    "\n",
    "    branch1 = conv2d_bn(out, 64, 1, 1)\n",
    "    branch1 = conv2d_bn(branch1, 96, 3, 3)\n",
    "    branch2 = conv2d_bn(out, 64, 1, 1)\n",
    "    branch2 = conv2d_bn(branch2, 64, 7, 1)\n",
    "    branch2 = conv2d_bn(branch2, 64, 1, 7)\n",
    "    branch2 = conv2d_bn(branch2, 96, 3, 3)\n",
    "    out = concatenate([branch1, branch2], axis=1)\n",
    "\n",
    "    out = conv2d_bn(out, 384, 3, 3)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0f962e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape=IMAGE_SHAPE)\n",
    "x = stem(input_)\n",
    "\n",
    "x = inc_block_a(x)\n",
    "x = inc_block_a(x)\n",
    "x = reduction_block_a(x)\n",
    "x = inc_block_b(x)\n",
    "x = inc_block_b(x)\n",
    "x = inc_block_b(x)\n",
    "x = inc_block_b(x)\n",
    "x = reduction_block_b(x)\n",
    "x = inc_block_c(x)\n",
    "x = inc_block_c(x)\n",
    "x = GlobalAveragePooling2D(data_format='channels_first')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1)(x)\n",
    "\n",
    "model = Model(input_, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a32f9746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 127, 127  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 64, 64)   1472        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 64, 64)  96          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 32, 64, 64)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 64, 64)   9248        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 64, 64)  96          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 64, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 64, 64)   18496       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 64, 64, 64)  192         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 64, 64, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 96, 32, 32)   55392       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 96, 32, 32)  288         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 32, 32)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 96, 32, 32)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 160, 32, 32)  0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 64, 32, 32)   10304       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 64, 32, 32)  192         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 64, 32, 32)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 64, 32, 32)   28736       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 64, 32, 32)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 64, 32, 32)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 32, 32)   10304       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 64, 32, 32)   28736       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 32, 32)  192         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 64, 32, 32)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 64, 32, 32)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 64, 32, 32)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 96, 32, 32)   55392       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 96, 32, 32)   55392       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 96, 32, 32)  288         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 96, 32, 32)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 96, 32, 32)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 96, 32, 32)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 192, 32, 32)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 384, 32, 32)  663936      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 384, 32, 32)  1152       ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 384, 32, 32)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 32, 32, 32)   12320       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 32, 32, 32)  96          ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 32, 32)   12320       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 48, 32, 32)   13872       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 32, 32, 32)  96          ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 48, 32, 32)  144         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 48, 32, 32)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 32)   12320       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 32, 32)   9248        ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 64, 32, 32)   27712       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 32, 32, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 32, 32)  96          ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 64, 32, 32)  192         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 64, 32, 32)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 32, 32)  0           ['activation_11[0][0]',          \n",
      "                                                                  'activation_13[0][0]',          \n",
      "                                                                  'activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 384, 32, 32)  49536       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 384, 32, 32)  0           ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 384, 32, 32)  0           ['activation_10[0][0]',          \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 384, 32, 32)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 32, 32, 32)   12320       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 32, 32, 32)  96          ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 32, 32, 32)   12320       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 48, 32, 32)   13872       ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 32, 32, 32)  96          ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 48, 32, 32)  144         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 48, 32, 32)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 32, 32, 32)   12320       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 32, 32, 32)   9248        ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 64, 32, 32)   27712       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 32, 32, 32)  96          ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 32, 32, 32)  96          ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 64, 32, 32)  192         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 32, 32, 32)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 64, 32, 32)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128, 32, 32)  0           ['activation_18[0][0]',          \n",
      "                                                                  'activation_20[0][0]',          \n",
      "                                                                  'activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 384, 32, 32)  49536       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 384, 32, 32)  0           ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 384, 32, 32)  0           ['activation_17[0][0]',          \n",
      "                                                                  'lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 384, 32, 32)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 256, 32, 32)  98560       ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 256, 32, 32)  768        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 256, 32, 32)  0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 256, 32, 32)  590080      ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 256, 32, 32)  768        ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 256, 32, 32)  0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 384, 15, 15)  1327488     ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 384, 15, 15)  885120      ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 384, 15, 15)  1152       ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 384, 15, 15)  1152       ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 384, 15, 15)  0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 384, 15, 15)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 384, 15, 15)  0          ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 1152, 15, 15  0           ['activation_25[0][0]',          \n",
      "                                )                                 'activation_28[0][0]',          \n",
      "                                                                  'max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 128, 15, 15)  147584      ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 128, 15, 15)  384        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 128, 15, 15)  0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 160, 15, 15)  143520      ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 160, 15, 15)  480        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 160, 15, 15)  0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 192, 15, 15)  221376      ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 192, 15, 15)  215232      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 192, 15, 15)  576        ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 192, 15, 15)  576        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 384, 15, 15)  0           ['activation_29[0][0]',          \n",
      "                                                                  'activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 1152, 15, 15  443520      ['concatenate_5[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 1152, 15, 15  0           ['conv2d_33[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 1152, 15, 15  0           ['concatenate_4[0][0]',          \n",
      "                                )                                 'lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 1152, 15, 15  0           ['add_2[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 128, 15, 15)  147584      ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 128, 15, 15)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 128, 15, 15)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 160, 15, 15)  143520      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 160, 15, 15)  480        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 160, 15, 15)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 192, 15, 15)  221376      ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 192, 15, 15)  215232      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 192, 15, 15)  576        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 192, 15, 15)  576        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 384, 15, 15)  0           ['activation_34[0][0]',          \n",
      "                                                                  'activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 1152, 15, 15  443520      ['concatenate_6[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, 1152, 15, 15  0           ['conv2d_38[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 1152, 15, 15  0           ['activation_33[0][0]',          \n",
      "                                )                                 'lambda_3[0][0]']               \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 1152, 15, 15  0           ['add_3[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 128, 15, 15)  147584      ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 128, 15, 15)  384        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 128, 15, 15)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 160, 15, 15)  143520      ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 160, 15, 15)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 160, 15, 15)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 192, 15, 15)  221376      ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 192, 15, 15)  215232      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 192, 15, 15)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 192, 15, 15)  576        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 384, 15, 15)  0           ['activation_39[0][0]',          \n",
      "                                                                  'activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 1152, 15, 15  443520      ['concatenate_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 1152, 15, 15  0           ['conv2d_43[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 1152, 15, 15  0           ['activation_38[0][0]',          \n",
      "                                )                                 'lambda_4[0][0]']               \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 1152, 15, 15  0           ['add_4[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 128, 15, 15)  147584      ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 128, 15, 15)  384        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 128, 15, 15)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 160, 15, 15)  143520      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 160, 15, 15)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 160, 15, 15)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 192, 15, 15)  221376      ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 192, 15, 15)  215232      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 192, 15, 15)  576        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 192, 15, 15)  576        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 192, 15, 15)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 384, 15, 15)  0           ['activation_44[0][0]',          \n",
      "                                                                  'activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 1152, 15, 15  443520      ['concatenate_8[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)              (None, 1152, 15, 15  0           ['conv2d_48[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 1152, 15, 15  0           ['activation_43[0][0]',          \n",
      "                                )                                 'lambda_5[0][0]']               \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 1152, 15, 15  0           ['add_5[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 256, 15, 15)  295168      ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 256, 15, 15)  768        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 256, 15, 15)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 256, 15, 15)  295168      ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 288, 15, 15)  663840      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 256, 15, 15)  295168      ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 256, 15, 15)  768        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 288, 15, 15)  864        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 256, 15, 15)  768        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 256, 15, 15)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 288, 15, 15)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 256, 15, 15)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 384, 7, 7)    885120      ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 320, 7, 7)    829760      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 288, 7, 7)    663840      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 384, 7, 7)   1152        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 320, 7, 7)   960         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 288, 7, 7)   864         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 384, 7, 7)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 320, 7, 7)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 1152, 7, 7)  0           ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 288, 7, 7)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 2144, 7, 7)   0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]',        \n",
      "                                                                  'activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 192, 7, 7)    411840      ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 192, 7, 7)   576         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 192, 7, 7)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 224, 7, 7)    129248      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 224, 7, 7)   672         ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 224, 7, 7)    0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 192, 7, 7)    411840      ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 256, 7, 7)    172288      ['activation_58[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 192, 7, 7)   576         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 256, 7, 7)   768         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 192, 7, 7)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 256, 7, 7)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 448, 7, 7)    0           ['activation_56[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 2144, 7, 7)   962656      ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, 2144, 7, 7)   0           ['conv2d_60[0][0]']              \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 2144, 7, 7)   0           ['concatenate_9[0][0]',          \n",
      "                                                                  'lambda_6[0][0]']               \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 2144, 7, 7)   0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 192, 7, 7)    411840      ['activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 192, 7, 7)   576         ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 192, 7, 7)    0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 224, 7, 7)    129248      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 224, 7, 7)   672         ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 224, 7, 7)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 192, 7, 7)    411840      ['activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 256, 7, 7)    172288      ['activation_63[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 192, 7, 7)   576         ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 256, 7, 7)   768         ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 192, 7, 7)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 256, 7, 7)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 448, 7, 7)    0           ['activation_61[0][0]',          \n",
      "                                                                  'activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 2144, 7, 7)   962656      ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)              (None, 2144, 7, 7)   0           ['conv2d_65[0][0]']              \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 2144, 7, 7)   0           ['activation_60[0][0]',          \n",
      "                                                                  'lambda_7[0][0]']               \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 2144, 7, 7)   0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2144)        0           ['activation_65[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2144)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            2145        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,932,033\n",
      "Trainable params: 16,913,473\n",
      "Non-trainable params: 18,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e5173bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=hparams['learning_rate']), loss=calculate_loss, metrics='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e468ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'inception_resnet_2_v1'\n",
    "\n",
    "checkpoint_filepath = f'/data2/models/{model_name}/checkpoints/cp.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
    "log_dir = os.path.join('/data2/logs/', model_name)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_freq='epoch',\n",
    "    save_best_only=True,\n",
    "    verbose=True)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "hparam_callback = hp.KerasCallback(log_dir, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb6ef640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.4042 - mse: 2.2858\n",
      "Epoch 1: loss improved from inf to 0.40417, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 561s 685ms/step - loss: 0.4042 - mse: 2.2858 - val_loss: 0.3684 - val_mse: 0.5665\n",
      "Epoch 2/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.2584 - mse: 0.5625\n",
      "Epoch 2: loss improved from 0.40417 to 0.25841, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 618s 788ms/step - loss: 0.2584 - mse: 0.5625 - val_loss: 0.3476 - val_mse: 0.4157\n",
      "Epoch 3/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.1889 - mse: 0.5004\n",
      "Epoch 3: loss improved from 0.25841 to 0.18895, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 600s 765ms/step - loss: 0.1889 - mse: 0.5004 - val_loss: 0.3969 - val_mse: 0.5431\n",
      "Epoch 4/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.1527 - mse: 0.4075\n",
      "Epoch 4: loss improved from 0.18895 to 0.15266, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 583s 744ms/step - loss: 0.1527 - mse: 0.4075 - val_loss: 0.2671 - val_mse: 0.7348\n",
      "Epoch 5/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.1375 - mse: 0.9233\n",
      "Epoch 5: loss improved from 0.15266 to 0.13753, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 618s 789ms/step - loss: 0.1375 - mse: 0.9233 - val_loss: 0.1850 - val_mse: 5.1127\n",
      "Epoch 6/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.1240 - mse: 0.6556\n",
      "Epoch 6: loss improved from 0.13753 to 0.12396, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 646s 824ms/step - loss: 0.1240 - mse: 0.6556 - val_loss: 0.2956 - val_mse: 1.6644\n",
      "Epoch 7/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.1131 - mse: 0.7676\n",
      "Epoch 7: loss improved from 0.12396 to 0.11306, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 619s 790ms/step - loss: 0.1131 - mse: 0.7676 - val_loss: 0.2391 - val_mse: 0.4214\n",
      "Epoch 8/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.1076 - mse: 0.9313\n",
      "Epoch 8: loss improved from 0.11306 to 0.10758, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 639s 814ms/step - loss: 0.1076 - mse: 0.9313 - val_loss: 0.2066 - val_mse: 0.9860\n",
      "Epoch 9/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0952 - mse: 0.7649\n",
      "Epoch 9: loss improved from 0.10758 to 0.09520, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 652s 831ms/step - loss: 0.0952 - mse: 0.7649 - val_loss: 0.1909 - val_mse: 2.8194\n",
      "Epoch 10/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0909 - mse: 0.6493\n",
      "Epoch 10: loss improved from 0.09520 to 0.09089, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 633s 807ms/step - loss: 0.0909 - mse: 0.6493 - val_loss: 0.1701 - val_mse: 0.2588\n",
      "Epoch 11/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0908 - mse: 0.9778\n",
      "Epoch 11: loss improved from 0.09089 to 0.09083, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 654s 833ms/step - loss: 0.0908 - mse: 0.9778 - val_loss: 0.2883 - val_mse: 2.0194\n",
      "Epoch 12/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0855 - mse: 0.7428\n",
      "Epoch 12: loss improved from 0.09083 to 0.08554, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 585s 745ms/step - loss: 0.0855 - mse: 0.7428 - val_loss: 0.1956 - val_mse: 4.3381\n",
      "Epoch 13/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0772 - mse: 1.3416\n",
      "Epoch 13: loss improved from 0.08554 to 0.07719, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 655s 834ms/step - loss: 0.0772 - mse: 1.3416 - val_loss: 0.2529 - val_mse: 9.5799\n",
      "Epoch 14/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0771 - mse: 0.8928\n",
      "Epoch 14: loss improved from 0.07719 to 0.07715, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 592s 755ms/step - loss: 0.0771 - mse: 0.8928 - val_loss: 0.2956 - val_mse: 15.4672\n",
      "Epoch 15/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0751 - mse: 1.2136\n",
      "Epoch 15: loss improved from 0.07715 to 0.07509, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 683s 871ms/step - loss: 0.0751 - mse: 1.2136 - val_loss: 0.2222 - val_mse: 40.3163\n",
      "Epoch 16/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0710 - mse: 2.1630\n",
      "Epoch 16: loss improved from 0.07509 to 0.07103, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 596s 760ms/step - loss: 0.0710 - mse: 2.1630 - val_loss: 0.1263 - val_mse: 167.7924\n",
      "Epoch 17/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0676 - mse: 1.6568\n",
      "Epoch 17: loss improved from 0.07103 to 0.06756, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 658s 839ms/step - loss: 0.0676 - mse: 1.6568 - val_loss: 0.1810 - val_mse: 178.6183\n",
      "Epoch 18/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0684 - mse: 2.2850\n",
      "Epoch 18: loss did not improve from 0.06756\n",
      "784/784 [==============================] - 573s 730ms/step - loss: 0.0684 - mse: 2.2850 - val_loss: 0.2238 - val_mse: 25.2618\n",
      "Epoch 19/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0663 - mse: 1.7033\n",
      "Epoch 19: loss improved from 0.06756 to 0.06632, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 660s 842ms/step - loss: 0.0663 - mse: 1.7033 - val_loss: 0.1170 - val_mse: 33.1701\n",
      "Epoch 20/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0625 - mse: 2.6847\n",
      "Epoch 20: loss improved from 0.06632 to 0.06254, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 588s 750ms/step - loss: 0.0625 - mse: 2.6847 - val_loss: 0.1562 - val_mse: 44.3337\n",
      "Epoch 21/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0624 - mse: 3.0724\n",
      "Epoch 21: loss improved from 0.06254 to 0.06236, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 669s 853ms/step - loss: 0.0624 - mse: 3.0724 - val_loss: 0.2613 - val_mse: 21.4759\n",
      "Epoch 22/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0638 - mse: 2.3749\n",
      "Epoch 22: loss did not improve from 0.06236\n",
      "784/784 [==============================] - 592s 754ms/step - loss: 0.0638 - mse: 2.3749 - val_loss: 0.1876 - val_mse: 0.8434\n",
      "Epoch 23/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0635 - mse: 0.8245\n",
      "Epoch 23: loss did not improve from 0.06236\n",
      "784/784 [==============================] - 618s 787ms/step - loss: 0.0635 - mse: 0.8245 - val_loss: 0.1631 - val_mse: 6.1956\n",
      "Epoch 24/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0580 - mse: 0.7728\n",
      "Epoch 24: loss improved from 0.06236 to 0.05799, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 614s 783ms/step - loss: 0.0580 - mse: 0.7728 - val_loss: 0.2216 - val_mse: 56.8145\n",
      "Epoch 25/100\n",
      "297/784 [==========>...................] - ETA: 5:12 - loss: 0.0549 - mse: 0.5535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - ETA: 0s - loss: 0.0398 - mse: 0.4671\n",
      "Epoch 47: loss improved from 0.04221 to 0.03979, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 699s 891ms/step - loss: 0.0398 - mse: 0.4671 - val_loss: 0.1654 - val_mse: 85.1088\n",
      "Epoch 48/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0417 - mse: 0.6633\n",
      "Epoch 48: loss did not improve from 0.03979\n",
      "784/784 [==============================] - 664s 847ms/step - loss: 0.0417 - mse: 0.6633 - val_loss: 0.1111 - val_mse: 53.5583\n",
      "Epoch 49/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0412 - mse: 0.6173\n",
      "Epoch 49: loss did not improve from 0.03979\n",
      "784/784 [==============================] - 763s 973ms/step - loss: 0.0412 - mse: 0.6173 - val_loss: 0.1306 - val_mse: 245.9934\n",
      "Epoch 50/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0476 - mse: 0.3729\n",
      "Epoch 50: loss did not improve from 0.03979\n",
      "784/784 [==============================] - 736s 939ms/step - loss: 0.0476 - mse: 0.3729 - val_loss: 0.1264 - val_mse: 78.9018\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - ETA: 0s - loss: 0.0414 - mse: 0.4186\n",
      "Epoch 61: loss did not improve from 0.03644\n",
      "784/784 [==============================] - 685s 872ms/step - loss: 0.0414 - mse: 0.4186 - val_loss: 0.1945 - val_mse: 585.0474\n",
      "Epoch 62/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0422 - mse: 0.4467\n",
      "Epoch 62: loss did not improve from 0.03644\n",
      "784/784 [==============================] - 745s 951ms/step - loss: 0.0422 - mse: 0.4467 - val_loss: 0.1457 - val_mse: 378.2708\n",
      "Epoch 63/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0380 - mse: 0.3190\n",
      "Epoch 63: loss did not improve from 0.03644\n",
      "784/784 [==============================] - 708s 903ms/step - loss: 0.0380 - mse: 0.3190 - val_loss: 0.2147 - val_mse: 38.4870\n",
      "Epoch 64/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0360 - mse: 0.3668\n",
      "Epoch 64: loss improved from 0.03644 to 0.03601, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 714s 910ms/step - loss: 0.0360 - mse: 0.3668 - val_loss: 0.1411 - val_mse: 1080.0996\n",
      "Epoch 65/100\n",
      "143/784 [====>.........................] - ETA: 11:46 - loss: 0.0368 - mse: 0.4552"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - ETA: 0s - loss: 0.0370 - mse: 1.7806\n",
      "Epoch 76: loss did not improve from 0.03601\n",
      "784/784 [==============================] - 710s 906ms/step - loss: 0.0370 - mse: 1.7806 - val_loss: 0.1432 - val_mse: 565.3639\n",
      "Epoch 77/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0383 - mse: 1.8399\n",
      "Epoch 77: loss did not improve from 0.03601\n",
      "784/784 [==============================] - 664s 846ms/step - loss: 0.0383 - mse: 1.8399 - val_loss: 0.1241 - val_mse: 2418.2366\n",
      "Epoch 78/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0338 - mse: 1.8835\n",
      "Epoch 78: loss improved from 0.03601 to 0.03381, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 665s 848ms/step - loss: 0.0338 - mse: 1.8835 - val_loss: 0.1653 - val_mse: 20454.3398\n",
      "Epoch 79/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0399 - mse: 2.0333\n",
      "Epoch 79: loss did not improve from 0.03381\n",
      "784/784 [==============================] - 656s 836ms/step - loss: 0.0399 - mse: 2.0333 - val_loss: 0.0874 - val_mse: 987.3202\n",
      "Epoch 80/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0326 - mse: 2.3407\n",
      "Epoch 80: loss improved from 0.03381 to 0.03256, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 635s 809ms/step - loss: 0.0326 - mse: 2.3407 - val_loss: 0.1167 - val_mse: 3908.9277\n",
      "Epoch 81/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0364 - mse: 2.5241\n",
      "Epoch 81: loss did not improve from 0.03256\n",
      "784/784 [==============================] - 645s 822ms/step - loss: 0.0364 - mse: 2.5241 - val_loss: 0.1388 - val_mse: 5607.6025\n",
      "Epoch 82/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0350 - mse: 2.0317\n",
      "Epoch 82: loss did not improve from 0.03256\n",
      "784/784 [==============================] - 639s 815ms/step - loss: 0.0350 - mse: 2.0317 - val_loss: 0.1465 - val_mse: 13834.7129\n",
      "Epoch 83/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0370 - mse: 1.9459\n",
      "Epoch 83: loss did not improve from 0.03256\n",
      "784/784 [==============================] - 615s 785ms/step - loss: 0.0370 - mse: 1.9459 - val_loss: 0.1505 - val_mse: 21092.5742\n",
      "Epoch 84/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0330 - mse: 2.0838\n",
      "Epoch 84: loss did not improve from 0.03256\n",
      "784/784 [==============================] - 624s 796ms/step - loss: 0.0330 - mse: 2.0838 - val_loss: 0.1386 - val_mse: 23958.0508\n",
      "Epoch 85/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0388 - mse: 1.7823\n",
      "Epoch 85: loss did not improve from 0.03256\n",
      "784/784 [==============================] - 633s 807ms/step - loss: 0.0388 - mse: 1.7823 - val_loss: 0.1031 - val_mse: 6092.3662\n",
      "Epoch 86/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0380 - mse: 2.1357\n",
      "Epoch 86: loss did not improve from 0.03256\n",
      "784/784 [==============================] - 609s 776ms/step - loss: 0.0380 - mse: 2.1357 - val_loss: 0.1578 - val_mse: 4546.8120\n",
      "Epoch 87/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0326 - mse: 2.0669\n",
      "Epoch 87: loss did not improve from 0.03256\n",
      "784/784 [==============================] - 583s 743ms/step - loss: 0.0326 - mse: 2.0669 - val_loss: 0.1288 - val_mse: 54860.6445\n",
      "Epoch 88/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0346 - mse: 1.6015\n",
      "Epoch 88: loss did not improve from 0.03256\n",
      "784/784 [==============================] - 628s 801ms/step - loss: 0.0346 - mse: 1.6015 - val_loss: 0.1850 - val_mse: 34372.3789\n",
      "Epoch 89/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0331 - mse: 2.0460\n",
      "Epoch 89: loss did not improve from 0.03256\n",
      "784/784 [==============================] - 594s 757ms/step - loss: 0.0331 - mse: 2.0460 - val_loss: 0.1037 - val_mse: 134820.3281\n",
      "Epoch 90/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0356 - mse: 2.2320\n",
      "Epoch 90: loss did not improve from 0.03256\n",
      "784/784 [==============================] - 610s 777ms/step - loss: 0.0356 - mse: 2.2320 - val_loss: 0.1594 - val_mse: 50764.0664\n",
      "Epoch 91/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0326 - mse: 2.6922\n",
      "Epoch 91: loss did not improve from 0.03256\n",
      "784/784 [==============================] - 613s 781ms/step - loss: 0.0326 - mse: 2.6922 - val_loss: 0.1902 - val_mse: 403556.8125\n",
      "Epoch 92/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0319 - mse: 2.5271\n",
      "Epoch 92: loss improved from 0.03256 to 0.03185, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 605s 772ms/step - loss: 0.0319 - mse: 2.5271 - val_loss: 0.1254 - val_mse: 18408.8203\n",
      "Epoch 93/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0441 - mse: 1.3977\n",
      "Epoch 93: loss did not improve from 0.03185\n",
      "784/784 [==============================] - 620s 790ms/step - loss: 0.0441 - mse: 1.3977 - val_loss: 0.1165 - val_mse: 576.6185\n",
      "Epoch 94/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0392 - mse: 1.2431\n",
      "Epoch 94: loss did not improve from 0.03185\n",
      "784/784 [==============================] - 604s 770ms/step - loss: 0.0392 - mse: 1.2431 - val_loss: 0.1009 - val_mse: 25555.1758\n",
      "Epoch 95/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0340 - mse: 1.3045\n",
      "Epoch 95: loss did not improve from 0.03185\n",
      "784/784 [==============================] - 590s 752ms/step - loss: 0.0340 - mse: 1.3045 - val_loss: 0.1524 - val_mse: 285353.7500\n",
      "Epoch 96/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0321 - mse: 1.1961\n",
      "Epoch 96: loss did not improve from 0.03185\n",
      "784/784 [==============================] - 578s 736ms/step - loss: 0.0321 - mse: 1.1961 - val_loss: 0.1663 - val_mse: 529627.5000\n",
      "Epoch 97/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0382 - mse: 0.4163\n",
      "Epoch 97: loss did not improve from 0.03185\n",
      "784/784 [==============================] - 527s 671ms/step - loss: 0.0382 - mse: 0.4163 - val_loss: 0.1648 - val_mse: 46087.6680\n",
      "Epoch 98/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0340 - mse: 0.4363\n",
      "Epoch 98: loss did not improve from 0.03185\n",
      "784/784 [==============================] - 529s 675ms/step - loss: 0.0340 - mse: 0.4363 - val_loss: 0.1754 - val_mse: 423329.9062\n",
      "Epoch 99/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0306 - mse: 0.2752\n",
      "Epoch 99: loss improved from 0.03185 to 0.03064, saving model to /data2/models/inception_resnet_2_v1/checkpoints/cp.ckpt\n",
      "784/784 [==============================] - 552s 704ms/step - loss: 0.0306 - mse: 0.2752 - val_loss: 0.1751 - val_mse: 897307.6250\n",
      "Epoch 100/100\n",
      "784/784 [==============================] - ETA: 0s - loss: 0.0317 - mse: 0.5049\n",
      "Epoch 100: loss did not improve from 0.03064\n",
      "784/784 [==============================] - 599s 764ms/step - loss: 0.0317 - mse: 0.5049 - val_loss: 0.1139 - val_mse: 837727.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50907dd7b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen, batch_size=hparams['batch_size'], epochs=hparams['num_epochs'], shuffle=True, verbose=1, validation_data=val_gen, callbacks=[tensorboard_callback, model_checkpoint_callback, hparam_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec5e631e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f509c206b90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f37d55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 123s 726ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92956d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(TEST_PATH, 'r') as file:\n",
    "    y_test = np.asarray(file['specz_redshift'][:])\n",
    "    oid_test = np.asarray(file['object_id'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8cf4741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(np.ravel(pred), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e952dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = get_point_metrics(pd.Series(np.ravel(pred)), pd.Series(y_test), binned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63a46536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zspec_bin</th>\n",
       "      <th>count</th>\n",
       "      <th>L</th>\n",
       "      <th>bias_bw</th>\n",
       "      <th>bias_conv</th>\n",
       "      <th>scatter_bw</th>\n",
       "      <th>scatter_conv</th>\n",
       "      <th>outlier_bw</th>\n",
       "      <th>outlier_conv</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 4.0]</td>\n",
       "      <td>42960</td>\n",
       "      <td>0.176751</td>\n",
       "      <td>-0.010635</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>0.053139</td>\n",
       "      <td>0.040451</td>\n",
       "      <td>0.203305</td>\n",
       "      <td>0.143855</td>\n",
       "      <td>1.275519e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    zspec_bin  count         L   bias_bw  bias_conv  scatter_bw  scatter_conv  \\\n",
       "0  (0.0, 4.0]  42960  0.176751 -0.010635  -0.008746    0.053139      0.040451   \n",
       "\n",
       "   outlier_bw  outlier_conv           mse  \n",
       "0    0.203305      0.143855  1.275519e+06  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1820f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pred, columns=['photoz'])\n",
    "df['specz'] = pd.Series(y_test)\n",
    "df['object_id'] = pd.Series(oid_test)\n",
    "os.makedirs(f'/data2/predictions/{model_name}', exist_ok=True)\n",
    "df.to_csv(f'/data2/predictions/{model_name}/testing_predictions.csv', index=False)\n",
    "metrics.to_csv(f'/data2/predictions/{model_name}/testing_metrics.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

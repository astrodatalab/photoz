{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a9195a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import keras\n",
    "import os\n",
    "import tensorboard\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Input, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from photoz_utils import *\n",
    "from DataMaker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0276b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (5, 127, 127)\n",
    "GB_LIMIT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399daa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(GB_LIMIT*1000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c193e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DENSE_UNITS = 200\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 1000\n",
    "LEARNING_RATE = 0.0001\n",
    "hparams = {\n",
    "    'num_dense_units': NUM_DENSE_UNITS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'learning_rate': LEARNING_RATE\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab5fe813",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_training.hdf5'\n",
    "VAL_PATH = '/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_validation.hdf5'\n",
    "TEST_PATH = '/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_testing.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ba00a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['object_id', 'specz_redshift', 'g_cmodel_mag', 'r_cmodel_mag', 'i_cmodel_mag', 'z_cmodel_mag', 'y_cmodel_mag']\n",
    "with h5py.File(TRAIN_PATH, 'r') as hf:\n",
    "    train_df = pd.DataFrame()\n",
    "    for name in column_names:\n",
    "        train_df[name] = hf[name][:]\n",
    "    \n",
    "with h5py.File(VAL_PATH, 'r') as hf:\n",
    "    val_df = pd.DataFrame()\n",
    "    for name in column_names:\n",
    "        val_df[name] = hf[name][:]\n",
    "    \n",
    "with h5py.File(TEST_PATH, 'r') as hf:\n",
    "    test_df = pd.DataFrame()\n",
    "    for name in column_names:\n",
    "        test_df[name] = hf[name][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98d6283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mags = ['g_cmodel_mag', 'r_cmodel_mag', 'i_cmodel_mag', 'z_cmodel_mag', 'y_cmodel_mag']\n",
    "X_train, X_val, X_test = train_df[mags], val_df[mags], test_df[mags]\n",
    "y_train, y_val, y_test = train_df['specz_redshift'], val_df['specz_redshift'], test_df['specz_redshift']\n",
    "OID_train, OID_val, OID_test = train_df['object_id'], val_df['object_id'], test_df['object_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ae5f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050c6d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now, only run the NN architecture\n",
    "# add callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6053b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def calculate_loss(z_photo, z_spec):\n",
    "    \"\"\"\n",
    "    HSC METRIC. Returns an array. Loss is accuracy metric defined by HSC, meant\n",
    "    to capture the effects of bias, scatter, and outlier all in one. This has\n",
    "    uses for both point and density estimation.\n",
    "    z_photo: array\n",
    "        Photometric or predicted redshifts.\n",
    "    z_spec: array\n",
    "        Spectroscopic or actual redshifts.\n",
    "    \"\"\"\n",
    "    dz = delz(z_photo, z_spec)\n",
    "    gamma = 0.15\n",
    "    denominator = 1.0 + K.square(dz/gamma)\n",
    "    loss = 1 - 1.0 / denominator\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1b768da",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nn = Input(shape=X_train.shape[1:])\n",
    "hidden1 = Dense(hparams['num_dense_units'], activation=\"relu\")(input_nn)\n",
    "hidden2 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden1)\n",
    "hidden3 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden2)\n",
    "hidden4 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden3)\n",
    "\n",
    "concat = Concatenate()([input_nn, hidden4])\n",
    "distribution_params = Dense(units=2)(concat)\n",
    "output = tfp.layers.IndependentNormal(1)(distribution_params)\n",
    "model = Model(inputs=[input_nn], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51b40cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 200)          1200        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200)          40200       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 200)          40200       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 200)          40200       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 205)          0           input_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            412         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "independent_normal (Independent multiple             0           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 122,212\n",
      "Trainable params: 122,212\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f180343",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=hparams['learning_rate']), loss=calculate_loss, metrics='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83073425",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'HSC_v6_NN_neurips_test_v3'\n",
    "\n",
    "checkpoint_filepath = os.path.join('/models/', model_name)+'/'+model_name\n",
    "log_dir = os.path.join('/logs/', model_name)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='max',\n",
    "    save_freq='epoch',\n",
    "    save_best_only=True)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "hparam_callback = hp.KerasCallback(log_dir, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9d84ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "784/784 [==============================] - 3s 3ms/step - loss: 0.2406 - mse: 0.2452 - val_loss: 0.1535 - val_mse: 0.1405\n",
      "Epoch 2/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1473 - mse: 0.1461 - val_loss: 0.1468 - val_mse: 0.1402\n",
      "Epoch 3/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1406 - mse: 0.1419 - val_loss: 0.1363 - val_mse: 0.1331\n",
      "Epoch 4/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1362 - mse: 0.1390 - val_loss: 0.1326 - val_mse: 0.1309\n",
      "Epoch 5/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1329 - mse: 0.1371 - val_loss: 0.1309 - val_mse: 0.1298\n",
      "Epoch 6/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1304 - mse: 0.1344 - val_loss: 0.1302 - val_mse: 0.1314\n",
      "Epoch 7/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1270 - mse: 0.1318 - val_loss: 0.1283 - val_mse: 0.1244\n",
      "Epoch 8/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1236 - mse: 0.1286 - val_loss: 0.1240 - val_mse: 0.1247\n",
      "Epoch 9/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1211 - mse: 0.1280 - val_loss: 0.1205 - val_mse: 0.1249\n",
      "Epoch 10/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1192 - mse: 0.1273 - val_loss: 0.1212 - val_mse: 0.1209\n",
      "Epoch 11/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1178 - mse: 0.1274 - val_loss: 0.1179 - val_mse: 0.1217\n",
      "Epoch 12/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1167 - mse: 0.1263 - val_loss: 0.1224 - val_mse: 0.1280\n",
      "Epoch 13/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1156 - mse: 0.1258 - val_loss: 0.1146 - val_mse: 0.1232\n",
      "Epoch 14/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1147 - mse: 0.1258 - val_loss: 0.1138 - val_mse: 0.1213\n",
      "Epoch 15/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1139 - mse: 0.1254 - val_loss: 0.1167 - val_mse: 0.1165\n",
      "Epoch 16/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1135 - mse: 0.1248 - val_loss: 0.1144 - val_mse: 0.1170\n",
      "Epoch 17/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1127 - mse: 0.1249 - val_loss: 0.1148 - val_mse: 0.1191\n",
      "Epoch 18/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1119 - mse: 0.1242 - val_loss: 0.1141 - val_mse: 0.1185\n",
      "Epoch 19/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1114 - mse: 0.1243 - val_loss: 0.1111 - val_mse: 0.1180\n",
      "Epoch 20/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1107 - mse: 0.1236 - val_loss: 0.1091 - val_mse: 0.1189\n",
      "Epoch 21/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1103 - mse: 0.1235 - val_loss: 0.1125 - val_mse: 0.1185\n",
      "Epoch 22/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1097 - mse: 0.1235 - val_loss: 0.1123 - val_mse: 0.1172\n",
      "Epoch 23/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1090 - mse: 0.1235 - val_loss: 0.1073 - val_mse: 0.1170\n",
      "Epoch 24/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1083 - mse: 0.1233 - val_loss: 0.1080 - val_mse: 0.1174\n",
      "Epoch 25/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1079 - mse: 0.1232 - val_loss: 0.1090 - val_mse: 0.1147\n",
      "Epoch 26/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1074 - mse: 0.1228 - val_loss: 0.1098 - val_mse: 0.1212\n",
      "Epoch 27/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1071 - mse: 0.1234 - val_loss: 0.1066 - val_mse: 0.1208\n",
      "Epoch 28/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1066 - mse: 0.1227 - val_loss: 0.1058 - val_mse: 0.1173\n",
      "Epoch 29/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1059 - mse: 0.1222 - val_loss: 0.1062 - val_mse: 0.1187\n",
      "Epoch 30/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1057 - mse: 0.1221 - val_loss: 0.1048 - val_mse: 0.1163\n",
      "Epoch 31/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1050 - mse: 0.1219 - val_loss: 0.1038 - val_mse: 0.1158\n",
      "Epoch 32/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1048 - mse: 0.1225 - val_loss: 0.1040 - val_mse: 0.1178\n",
      "Epoch 33/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1043 - mse: 0.1222 - val_loss: 0.1030 - val_mse: 0.1181\n",
      "Epoch 34/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1043 - mse: 0.1221 - val_loss: 0.1098 - val_mse: 0.1160\n",
      "Epoch 35/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1037 - mse: 0.1219 - val_loss: 0.1046 - val_mse: 0.1218\n",
      "Epoch 36/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1034 - mse: 0.1223 - val_loss: 0.1029 - val_mse: 0.1172\n",
      "Epoch 37/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1031 - mse: 0.1223 - val_loss: 0.1048 - val_mse: 0.1204\n",
      "Epoch 38/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1029 - mse: 0.1227 - val_loss: 0.1029 - val_mse: 0.1199\n",
      "Epoch 39/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1023 - mse: 0.1220 - val_loss: 0.1032 - val_mse: 0.1158\n",
      "Epoch 40/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1022 - mse: 0.1219 - val_loss: 0.1023 - val_mse: 0.1177\n",
      "Epoch 41/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1021 - mse: 0.1218 - val_loss: 0.1023 - val_mse: 0.1185\n",
      "Epoch 42/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1015 - mse: 0.1216 - val_loss: 0.1044 - val_mse: 0.1179\n",
      "Epoch 43/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1015 - mse: 0.1217 - val_loss: 0.1012 - val_mse: 0.1178\n",
      "Epoch 44/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1011 - mse: 0.1216 - val_loss: 0.1019 - val_mse: 0.1177\n",
      "Epoch 45/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1010 - mse: 0.1216 - val_loss: 0.1015 - val_mse: 0.1174\n",
      "Epoch 46/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1011 - mse: 0.1219 - val_loss: 0.1007 - val_mse: 0.1186\n",
      "Epoch 47/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1004 - mse: 0.1220 - val_loss: 0.1014 - val_mse: 0.1201\n",
      "Epoch 48/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1004 - mse: 0.1220 - val_loss: 0.1001 - val_mse: 0.1180\n",
      "Epoch 49/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1001 - mse: 0.1218 - val_loss: 0.1012 - val_mse: 0.1176\n",
      "Epoch 50/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.1002 - mse: 0.1215 - val_loss: 0.1004 - val_mse: 0.1144\n",
      "Epoch 51/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0998 - mse: 0.1216 - val_loss: 0.0995 - val_mse: 0.1176\n",
      "Epoch 52/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0995 - mse: 0.1220 - val_loss: 0.1005 - val_mse: 0.1203\n",
      "Epoch 53/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0995 - mse: 0.1217 - val_loss: 0.0986 - val_mse: 0.1149\n",
      "Epoch 54/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0992 - mse: 0.1219 - val_loss: 0.0984 - val_mse: 0.1174\n",
      "Epoch 55/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0993 - mse: 0.1217 - val_loss: 0.0993 - val_mse: 0.1159\n",
      "Epoch 56/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0990 - mse: 0.1218 - val_loss: 0.0984 - val_mse: 0.1168\n",
      "Epoch 57/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0987 - mse: 0.1215 - val_loss: 0.1030 - val_mse: 0.1172\n",
      "Epoch 58/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0985 - mse: 0.1217 - val_loss: 0.0988 - val_mse: 0.1182\n",
      "Epoch 59/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0985 - mse: 0.1220 - val_loss: 0.0992 - val_mse: 0.1189\n",
      "Epoch 60/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0984 - mse: 0.1218 - val_loss: 0.0990 - val_mse: 0.1202\n",
      "Epoch 61/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0980 - mse: 0.1216 - val_loss: 0.0968 - val_mse: 0.1166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0980 - mse: 0.1211 - val_loss: 0.0975 - val_mse: 0.1143\n",
      "Epoch 63/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0980 - mse: 0.1214 - val_loss: 0.0980 - val_mse: 0.1187\n",
      "Epoch 64/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0977 - mse: 0.1217 - val_loss: 0.0985 - val_mse: 0.1191\n",
      "Epoch 65/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0975 - mse: 0.1210 - val_loss: 0.0983 - val_mse: 0.1164\n",
      "Epoch 66/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0975 - mse: 0.1214 - val_loss: 0.0966 - val_mse: 0.1152\n",
      "Epoch 67/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0975 - mse: 0.1211 - val_loss: 0.0968 - val_mse: 0.1155\n",
      "Epoch 68/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0973 - mse: 0.1208 - val_loss: 0.0975 - val_mse: 0.1148\n",
      "Epoch 69/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0972 - mse: 0.1206 - val_loss: 0.0975 - val_mse: 0.1162\n",
      "Epoch 70/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0969 - mse: 0.1211 - val_loss: 0.0969 - val_mse: 0.1155\n",
      "Epoch 71/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0967 - mse: 0.1208 - val_loss: 0.0965 - val_mse: 0.1165\n",
      "Epoch 72/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0965 - mse: 0.1208 - val_loss: 0.0965 - val_mse: 0.1176\n",
      "Epoch 73/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0965 - mse: 0.1212 - val_loss: 0.0975 - val_mse: 0.1202\n",
      "Epoch 74/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0966 - mse: 0.1212 - val_loss: 0.0984 - val_mse: 0.1157\n",
      "Epoch 75/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0964 - mse: 0.1215 - val_loss: 0.0955 - val_mse: 0.1168\n",
      "Epoch 76/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0961 - mse: 0.1210 - val_loss: 0.0959 - val_mse: 0.1163\n",
      "Epoch 77/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0960 - mse: 0.1213 - val_loss: 0.0982 - val_mse: 0.1155\n",
      "Epoch 78/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0959 - mse: 0.1205 - val_loss: 0.0962 - val_mse: 0.1203\n",
      "Epoch 79/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0958 - mse: 0.1210 - val_loss: 0.0968 - val_mse: 0.1202\n",
      "Epoch 80/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0959 - mse: 0.1216 - val_loss: 0.0967 - val_mse: 0.1198\n",
      "Epoch 81/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0955 - mse: 0.1212 - val_loss: 0.0950 - val_mse: 0.1165\n",
      "Epoch 82/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0954 - mse: 0.1211 - val_loss: 0.0953 - val_mse: 0.1153\n",
      "Epoch 83/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0953 - mse: 0.1215 - val_loss: 0.0962 - val_mse: 0.1177\n",
      "Epoch 84/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0954 - mse: 0.1218 - val_loss: 0.0957 - val_mse: 0.1165\n",
      "Epoch 85/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0951 - mse: 0.1210 - val_loss: 0.0957 - val_mse: 0.1152\n",
      "Epoch 86/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0953 - mse: 0.1215 - val_loss: 0.0953 - val_mse: 0.1185\n",
      "Epoch 87/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0950 - mse: 0.1214 - val_loss: 0.0949 - val_mse: 0.1174\n",
      "Epoch 88/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0948 - mse: 0.1211 - val_loss: 0.0951 - val_mse: 0.1173\n",
      "Epoch 89/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0949 - mse: 0.1209 - val_loss: 0.0951 - val_mse: 0.1163\n",
      "Epoch 90/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0948 - mse: 0.1212 - val_loss: 0.0951 - val_mse: 0.1163\n",
      "Epoch 91/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0947 - mse: 0.1212 - val_loss: 0.0950 - val_mse: 0.1155\n",
      "Epoch 92/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0945 - mse: 0.1207 - val_loss: 0.0946 - val_mse: 0.1168\n",
      "Epoch 93/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0945 - mse: 0.1216 - val_loss: 0.0967 - val_mse: 0.1150\n",
      "Epoch 94/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0945 - mse: 0.1210 - val_loss: 0.0951 - val_mse: 0.1194\n",
      "Epoch 95/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0942 - mse: 0.1212 - val_loss: 0.0954 - val_mse: 0.1144\n",
      "Epoch 96/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0942 - mse: 0.1208 - val_loss: 0.0947 - val_mse: 0.1137\n",
      "Epoch 97/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0943 - mse: 0.1213 - val_loss: 0.0958 - val_mse: 0.1167\n",
      "Epoch 98/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0939 - mse: 0.1211 - val_loss: 0.0945 - val_mse: 0.1184\n",
      "Epoch 99/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0940 - mse: 0.1213 - val_loss: 0.0962 - val_mse: 0.1202\n",
      "Epoch 100/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0938 - mse: 0.1206 - val_loss: 0.0958 - val_mse: 0.1214\n",
      "Epoch 101/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0939 - mse: 0.1215 - val_loss: 0.0943 - val_mse: 0.1157\n",
      "Epoch 102/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0937 - mse: 0.1211 - val_loss: 0.0937 - val_mse: 0.1160\n",
      "Epoch 103/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0936 - mse: 0.1210 - val_loss: 0.0937 - val_mse: 0.1161\n",
      "Epoch 104/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0938 - mse: 0.1208 - val_loss: 0.0952 - val_mse: 0.1163\n",
      "Epoch 105/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0935 - mse: 0.1211 - val_loss: 0.0941 - val_mse: 0.1181\n",
      "Epoch 106/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0936 - mse: 0.1207 - val_loss: 0.0959 - val_mse: 0.1188\n",
      "Epoch 107/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0936 - mse: 0.1212 - val_loss: 0.0937 - val_mse: 0.1169\n",
      "Epoch 108/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0931 - mse: 0.1204 - val_loss: 0.0956 - val_mse: 0.1161\n",
      "Epoch 109/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0932 - mse: 0.1209 - val_loss: 0.0949 - val_mse: 0.1163\n",
      "Epoch 110/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0933 - mse: 0.1206 - val_loss: 0.0935 - val_mse: 0.1164\n",
      "Epoch 111/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0932 - mse: 0.1206 - val_loss: 0.0942 - val_mse: 0.1168\n",
      "Epoch 112/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0931 - mse: 0.1213 - val_loss: 0.0938 - val_mse: 0.1178\n",
      "Epoch 113/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0930 - mse: 0.1211 - val_loss: 0.0941 - val_mse: 0.1186\n",
      "Epoch 114/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0928 - mse: 0.1203 - val_loss: 0.0936 - val_mse: 0.1193\n",
      "Epoch 115/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0928 - mse: 0.1204 - val_loss: 0.0936 - val_mse: 0.1147\n",
      "Epoch 116/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0928 - mse: 0.1208 - val_loss: 0.0940 - val_mse: 0.1181\n",
      "Epoch 117/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0927 - mse: 0.1205 - val_loss: 0.0952 - val_mse: 0.1200\n",
      "Epoch 118/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0927 - mse: 0.1205 - val_loss: 0.0940 - val_mse: 0.1176\n",
      "Epoch 119/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0926 - mse: 0.1209 - val_loss: 0.0939 - val_mse: 0.1179\n",
      "Epoch 120/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0924 - mse: 0.1202 - val_loss: 0.0934 - val_mse: 0.1156\n",
      "Epoch 121/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0924 - mse: 0.1200 - val_loss: 0.0948 - val_mse: 0.1175\n",
      "Epoch 122/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0925 - mse: 0.1203 - val_loss: 0.0935 - val_mse: 0.1177\n",
      "Epoch 123/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0922 - mse: 0.1206 - val_loss: 0.0932 - val_mse: 0.1142\n",
      "Epoch 124/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0923 - mse: 0.1204 - val_loss: 0.0933 - val_mse: 0.1166\n",
      "Epoch 125/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0922 - mse: 0.1202 - val_loss: 0.0932 - val_mse: 0.1163\n",
      "Epoch 126/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0921 - mse: 0.1203 - val_loss: 0.0940 - val_mse: 0.1165\n",
      "Epoch 127/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0924 - mse: 0.1204 - val_loss: 0.0935 - val_mse: 0.1160\n",
      "Epoch 128/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0920 - mse: 0.1203 - val_loss: 0.0933 - val_mse: 0.1187\n",
      "Epoch 129/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0919 - mse: 0.1201 - val_loss: 0.0932 - val_mse: 0.1177\n",
      "Epoch 130/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0919 - mse: 0.1202 - val_loss: 0.0942 - val_mse: 0.1168\n",
      "Epoch 131/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0918 - mse: 0.1204 - val_loss: 0.0947 - val_mse: 0.1178\n",
      "Epoch 132/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0920 - mse: 0.1208 - val_loss: 0.0941 - val_mse: 0.1177\n",
      "Epoch 133/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0918 - mse: 0.1193 - val_loss: 0.0928 - val_mse: 0.1136\n",
      "Epoch 134/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0915 - mse: 0.1201 - val_loss: 0.0928 - val_mse: 0.1161\n",
      "Epoch 135/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0916 - mse: 0.1194 - val_loss: 0.0924 - val_mse: 0.1155\n",
      "Epoch 136/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0916 - mse: 0.1200 - val_loss: 0.0933 - val_mse: 0.1195\n",
      "Epoch 137/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0916 - mse: 0.1201 - val_loss: 0.0927 - val_mse: 0.1132\n",
      "Epoch 138/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0914 - mse: 0.1197 - val_loss: 0.0926 - val_mse: 0.1148\n",
      "Epoch 139/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0913 - mse: 0.1203 - val_loss: 0.0926 - val_mse: 0.1167\n",
      "Epoch 140/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0913 - mse: 0.1197 - val_loss: 0.0927 - val_mse: 0.1160\n",
      "Epoch 141/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0912 - mse: 0.1196 - val_loss: 0.0924 - val_mse: 0.1169\n",
      "Epoch 142/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0915 - mse: 0.1197 - val_loss: 0.0921 - val_mse: 0.1155\n",
      "Epoch 143/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0913 - mse: 0.1198 - val_loss: 0.0927 - val_mse: 0.1158\n",
      "Epoch 144/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0911 - mse: 0.1195 - val_loss: 0.0924 - val_mse: 0.1177\n",
      "Epoch 145/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0911 - mse: 0.1197 - val_loss: 0.0931 - val_mse: 0.1165\n",
      "Epoch 146/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0911 - mse: 0.1193 - val_loss: 0.0929 - val_mse: 0.1137\n",
      "Epoch 147/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0910 - mse: 0.1188 - val_loss: 0.0922 - val_mse: 0.1151\n",
      "Epoch 148/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0908 - mse: 0.1192 - val_loss: 0.0930 - val_mse: 0.1150\n",
      "Epoch 149/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0909 - mse: 0.1186 - val_loss: 0.0929 - val_mse: 0.1145\n",
      "Epoch 150/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0909 - mse: 0.1194 - val_loss: 0.0925 - val_mse: 0.1146\n",
      "Epoch 151/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0907 - mse: 0.1187 - val_loss: 0.0921 - val_mse: 0.1157\n",
      "Epoch 152/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0906 - mse: 0.1186 - val_loss: 0.0918 - val_mse: 0.1142\n",
      "Epoch 153/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0908 - mse: 0.1197 - val_loss: 0.0938 - val_mse: 0.1121\n",
      "Epoch 154/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0904 - mse: 0.1194 - val_loss: 0.0941 - val_mse: 0.1149\n",
      "Epoch 155/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0906 - mse: 0.1194 - val_loss: 0.0926 - val_mse: 0.1166\n",
      "Epoch 156/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0905 - mse: 0.1188 - val_loss: 0.0922 - val_mse: 0.1160\n",
      "Epoch 157/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0907 - mse: 0.1197 - val_loss: 0.0926 - val_mse: 0.1175\n",
      "Epoch 158/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0904 - mse: 0.1186 - val_loss: 0.0921 - val_mse: 0.1177\n",
      "Epoch 159/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0903 - mse: 0.1193 - val_loss: 0.0932 - val_mse: 0.1110\n",
      "Epoch 160/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0902 - mse: 0.1185 - val_loss: 0.0916 - val_mse: 0.1129\n",
      "Epoch 161/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0902 - mse: 0.1194 - val_loss: 0.0926 - val_mse: 0.1137\n",
      "Epoch 162/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0902 - mse: 0.1185 - val_loss: 0.0914 - val_mse: 0.1115\n",
      "Epoch 163/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0901 - mse: 0.1184 - val_loss: 0.0927 - val_mse: 0.1136\n",
      "Epoch 164/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0900 - mse: 0.1184 - val_loss: 0.0918 - val_mse: 0.1139\n",
      "Epoch 165/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0900 - mse: 0.1186 - val_loss: 0.0917 - val_mse: 0.1148\n",
      "Epoch 166/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0900 - mse: 0.1178 - val_loss: 0.0914 - val_mse: 0.1152\n",
      "Epoch 167/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0899 - mse: 0.1180 - val_loss: 0.0920 - val_mse: 0.1103\n",
      "Epoch 168/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0898 - mse: 0.1186 - val_loss: 0.0916 - val_mse: 0.1158\n",
      "Epoch 169/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0899 - mse: 0.1184 - val_loss: 0.0912 - val_mse: 0.1132\n",
      "Epoch 170/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0898 - mse: 0.1181 - val_loss: 0.0925 - val_mse: 0.1171\n",
      "Epoch 171/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0897 - mse: 0.1184 - val_loss: 0.0926 - val_mse: 0.1144\n",
      "Epoch 172/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0898 - mse: 0.1181 - val_loss: 0.0919 - val_mse: 0.1168\n",
      "Epoch 173/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0898 - mse: 0.1182 - val_loss: 0.0919 - val_mse: 0.1148\n",
      "Epoch 174/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0897 - mse: 0.1177 - val_loss: 0.0921 - val_mse: 0.1137\n",
      "Epoch 175/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0895 - mse: 0.1179 - val_loss: 0.0912 - val_mse: 0.1149\n",
      "Epoch 176/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0895 - mse: 0.1183 - val_loss: 0.0915 - val_mse: 0.1130\n",
      "Epoch 177/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0896 - mse: 0.1182 - val_loss: 0.0912 - val_mse: 0.1148\n",
      "Epoch 178/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0895 - mse: 0.1182 - val_loss: 0.0910 - val_mse: 0.1147\n",
      "Epoch 179/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0895 - mse: 0.1178 - val_loss: 0.0912 - val_mse: 0.1116\n",
      "Epoch 180/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0896 - mse: 0.1182 - val_loss: 0.0914 - val_mse: 0.1153\n",
      "Epoch 181/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0894 - mse: 0.1178 - val_loss: 0.0911 - val_mse: 0.1145\n",
      "Epoch 182/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0893 - mse: 0.1183 - val_loss: 0.0916 - val_mse: 0.1108\n",
      "Epoch 183/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0894 - mse: 0.1183 - val_loss: 0.0914 - val_mse: 0.1172\n",
      "Epoch 184/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0892 - mse: 0.1181 - val_loss: 0.0916 - val_mse: 0.1145\n",
      "Epoch 185/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0893 - mse: 0.1181 - val_loss: 0.0908 - val_mse: 0.1118\n",
      "Epoch 186/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0891 - mse: 0.1176 - val_loss: 0.0915 - val_mse: 0.1129\n",
      "Epoch 187/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0891 - mse: 0.1183 - val_loss: 0.0915 - val_mse: 0.1112\n",
      "Epoch 188/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0891 - mse: 0.1173 - val_loss: 0.0911 - val_mse: 0.1134\n",
      "Epoch 189/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0891 - mse: 0.1176 - val_loss: 0.0911 - val_mse: 0.1136\n",
      "Epoch 190/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0890 - mse: 0.1179 - val_loss: 0.0913 - val_mse: 0.1141\n",
      "Epoch 191/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0890 - mse: 0.1171 - val_loss: 0.0923 - val_mse: 0.1168\n",
      "Epoch 192/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0891 - mse: 0.1181 - val_loss: 0.0917 - val_mse: 0.1129\n",
      "Epoch 193/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0888 - mse: 0.1173 - val_loss: 0.0914 - val_mse: 0.1105\n",
      "Epoch 194/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0887 - mse: 0.1161 - val_loss: 0.0913 - val_mse: 0.1128\n",
      "Epoch 195/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0887 - mse: 0.1175 - val_loss: 0.0908 - val_mse: 0.1107\n",
      "Epoch 196/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0888 - mse: 0.1169 - val_loss: 0.0909 - val_mse: 0.1146\n",
      "Epoch 197/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0886 - mse: 0.1168 - val_loss: 0.0906 - val_mse: 0.1133\n",
      "Epoch 198/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0886 - mse: 0.1176 - val_loss: 0.0923 - val_mse: 0.1124\n",
      "Epoch 199/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0887 - mse: 0.1176 - val_loss: 0.0911 - val_mse: 0.1162\n",
      "Epoch 200/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0888 - mse: 0.1180 - val_loss: 0.0911 - val_mse: 0.1151\n",
      "Epoch 201/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0885 - mse: 0.1174 - val_loss: 0.0905 - val_mse: 0.1145\n",
      "Epoch 202/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0886 - mse: 0.1174 - val_loss: 0.0911 - val_mse: 0.1157\n",
      "Epoch 203/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0884 - mse: 0.1176 - val_loss: 0.0914 - val_mse: 0.1178\n",
      "Epoch 204/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0884 - mse: 0.1180 - val_loss: 0.0908 - val_mse: 0.1140\n",
      "Epoch 205/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0884 - mse: 0.1171 - val_loss: 0.0915 - val_mse: 0.1126\n",
      "Epoch 206/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0884 - mse: 0.1168 - val_loss: 0.0913 - val_mse: 0.1144\n",
      "Epoch 207/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0882 - mse: 0.1173 - val_loss: 0.0913 - val_mse: 0.1144\n",
      "Epoch 208/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0884 - mse: 0.1170 - val_loss: 0.0914 - val_mse: 0.1108\n",
      "Epoch 209/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0885 - mse: 0.1160 - val_loss: 0.0907 - val_mse: 0.1119\n",
      "Epoch 210/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0881 - mse: 0.1173 - val_loss: 0.0912 - val_mse: 0.1117\n",
      "Epoch 211/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0883 - mse: 0.1177 - val_loss: 0.0906 - val_mse: 0.1115\n",
      "Epoch 212/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0881 - mse: 0.1173 - val_loss: 0.0925 - val_mse: 0.1125\n",
      "Epoch 213/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0880 - mse: 0.1169 - val_loss: 0.0905 - val_mse: 0.1156\n",
      "Epoch 214/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0881 - mse: 0.1168 - val_loss: 0.0913 - val_mse: 0.1136\n",
      "Epoch 215/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0881 - mse: 0.1169 - val_loss: 0.0908 - val_mse: 0.1129\n",
      "Epoch 216/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0879 - mse: 0.1164 - val_loss: 0.0905 - val_mse: 0.1137\n",
      "Epoch 217/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0879 - mse: 0.1170 - val_loss: 0.0911 - val_mse: 0.1129\n",
      "Epoch 218/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0879 - mse: 0.1163 - val_loss: 0.0900 - val_mse: 0.1120\n",
      "Epoch 219/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0878 - mse: 0.1160 - val_loss: 0.0908 - val_mse: 0.1110\n",
      "Epoch 220/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0877 - mse: 0.1160 - val_loss: 0.0902 - val_mse: 0.1125\n",
      "Epoch 221/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0877 - mse: 0.1158 - val_loss: 0.0907 - val_mse: 0.1114\n",
      "Epoch 222/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0879 - mse: 0.1153 - val_loss: 0.0901 - val_mse: 0.1116\n",
      "Epoch 223/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0876 - mse: 0.1158 - val_loss: 0.0906 - val_mse: 0.1111\n",
      "Epoch 224/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0876 - mse: 0.1156 - val_loss: 0.0904 - val_mse: 0.1135\n",
      "Epoch 225/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0877 - mse: 0.1167 - val_loss: 0.0901 - val_mse: 0.1151\n",
      "Epoch 226/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0876 - mse: 0.1165 - val_loss: 0.0911 - val_mse: 0.1100\n",
      "Epoch 227/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0874 - mse: 0.1159 - val_loss: 0.0900 - val_mse: 0.1116\n",
      "Epoch 228/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0876 - mse: 0.1159 - val_loss: 0.0902 - val_mse: 0.1108\n",
      "Epoch 229/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0875 - mse: 0.1157 - val_loss: 0.0899 - val_mse: 0.1126\n",
      "Epoch 230/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0875 - mse: 0.1159 - val_loss: 0.0905 - val_mse: 0.1117\n",
      "Epoch 231/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0874 - mse: 0.1146 - val_loss: 0.0904 - val_mse: 0.1120\n",
      "Epoch 232/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0876 - mse: 0.1158 - val_loss: 0.0894 - val_mse: 0.1127\n",
      "Epoch 233/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0874 - mse: 0.1159 - val_loss: 0.0908 - val_mse: 0.1133\n",
      "Epoch 234/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0874 - mse: 0.1158 - val_loss: 0.0903 - val_mse: 0.1126\n",
      "Epoch 235/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0874 - mse: 0.1155 - val_loss: 0.0908 - val_mse: 0.1107\n",
      "Epoch 236/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0872 - mse: 0.1154 - val_loss: 0.0902 - val_mse: 0.1110\n",
      "Epoch 237/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0871 - mse: 0.1154 - val_loss: 0.0902 - val_mse: 0.1122\n",
      "Epoch 238/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0871 - mse: 0.1153 - val_loss: 0.0900 - val_mse: 0.1136\n",
      "Epoch 239/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0872 - mse: 0.1152 - val_loss: 0.0897 - val_mse: 0.1112\n",
      "Epoch 240/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0872 - mse: 0.1157 - val_loss: 0.0900 - val_mse: 0.1108\n",
      "Epoch 241/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0871 - mse: 0.1152 - val_loss: 0.0899 - val_mse: 0.1142\n",
      "Epoch 242/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0869 - mse: 0.1154 - val_loss: 0.0904 - val_mse: 0.1152\n",
      "Epoch 243/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0871 - mse: 0.1150 - val_loss: 0.0902 - val_mse: 0.1097\n",
      "Epoch 244/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0869 - mse: 0.1146 - val_loss: 0.0900 - val_mse: 0.1134\n",
      "Epoch 245/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0871 - mse: 0.1157 - val_loss: 0.0898 - val_mse: 0.1102\n",
      "Epoch 246/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0869 - mse: 0.1146 - val_loss: 0.0894 - val_mse: 0.1144\n",
      "Epoch 247/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0868 - mse: 0.1152 - val_loss: 0.0902 - val_mse: 0.1124\n",
      "Epoch 248/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0869 - mse: 0.1157 - val_loss: 0.0895 - val_mse: 0.1132\n",
      "Epoch 249/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0867 - mse: 0.1149 - val_loss: 0.0896 - val_mse: 0.1112\n",
      "Epoch 250/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0868 - mse: 0.1145 - val_loss: 0.0902 - val_mse: 0.1113\n",
      "Epoch 251/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0867 - mse: 0.1146 - val_loss: 0.0897 - val_mse: 0.1106\n",
      "Epoch 252/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0866 - mse: 0.1142 - val_loss: 0.0904 - val_mse: 0.1121\n",
      "Epoch 253/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0866 - mse: 0.1140 - val_loss: 0.0896 - val_mse: 0.1105\n",
      "Epoch 254/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0867 - mse: 0.1143 - val_loss: 0.0904 - val_mse: 0.1123\n",
      "Epoch 255/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0868 - mse: 0.1156 - val_loss: 0.0900 - val_mse: 0.1111\n",
      "Epoch 256/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0864 - mse: 0.1141 - val_loss: 0.0896 - val_mse: 0.1122\n",
      "Epoch 257/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0866 - mse: 0.1146 - val_loss: 0.0897 - val_mse: 0.1114\n",
      "Epoch 258/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0864 - mse: 0.1144 - val_loss: 0.0895 - val_mse: 0.1111\n",
      "Epoch 259/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0863 - mse: 0.1138 - val_loss: 0.0901 - val_mse: 0.1109\n",
      "Epoch 260/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0863 - mse: 0.1136 - val_loss: 0.0896 - val_mse: 0.1110\n",
      "Epoch 261/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0863 - mse: 0.1139 - val_loss: 0.0892 - val_mse: 0.1095\n",
      "Epoch 262/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0865 - mse: 0.1144 - val_loss: 0.0895 - val_mse: 0.1107\n",
      "Epoch 263/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0863 - mse: 0.1137 - val_loss: 0.0894 - val_mse: 0.1112\n",
      "Epoch 264/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0864 - mse: 0.1133 - val_loss: 0.0904 - val_mse: 0.1125\n",
      "Epoch 265/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0862 - mse: 0.1137 - val_loss: 0.0896 - val_mse: 0.1106\n",
      "Epoch 266/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0863 - mse: 0.1141 - val_loss: 0.0897 - val_mse: 0.1107\n",
      "Epoch 267/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0863 - mse: 0.1143 - val_loss: 0.0897 - val_mse: 0.1119\n",
      "Epoch 268/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0863 - mse: 0.1140 - val_loss: 0.0901 - val_mse: 0.1108\n",
      "Epoch 269/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0862 - mse: 0.1142 - val_loss: 0.0897 - val_mse: 0.1110\n",
      "Epoch 270/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0860 - mse: 0.1134 - val_loss: 0.0890 - val_mse: 0.1099\n",
      "Epoch 271/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0862 - mse: 0.1136 - val_loss: 0.0902 - val_mse: 0.1120\n",
      "Epoch 272/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0861 - mse: 0.1134 - val_loss: 0.0901 - val_mse: 0.1126\n",
      "Epoch 273/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0863 - mse: 0.1143 - val_loss: 0.0898 - val_mse: 0.1141\n",
      "Epoch 274/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0861 - mse: 0.1134 - val_loss: 0.0898 - val_mse: 0.1129\n",
      "Epoch 275/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0860 - mse: 0.1139 - val_loss: 0.0900 - val_mse: 0.1122\n",
      "Epoch 276/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0858 - mse: 0.1133 - val_loss: 0.0900 - val_mse: 0.1113\n",
      "Epoch 277/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0859 - mse: 0.1133 - val_loss: 0.0901 - val_mse: 0.1117\n",
      "Epoch 278/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0858 - mse: 0.1136 - val_loss: 0.0894 - val_mse: 0.1081\n",
      "Epoch 279/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0859 - mse: 0.1131 - val_loss: 0.0899 - val_mse: 0.1106\n",
      "Epoch 280/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0859 - mse: 0.1129 - val_loss: 0.0899 - val_mse: 0.1109\n",
      "Epoch 281/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0859 - mse: 0.1135 - val_loss: 0.0899 - val_mse: 0.1104\n",
      "Epoch 282/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0858 - mse: 0.1136 - val_loss: 0.0904 - val_mse: 0.1112\n",
      "Epoch 283/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0858 - mse: 0.1129 - val_loss: 0.0891 - val_mse: 0.1081\n",
      "Epoch 284/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0857 - mse: 0.1129 - val_loss: 0.0895 - val_mse: 0.1104\n",
      "Epoch 285/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0856 - mse: 0.1131 - val_loss: 0.0891 - val_mse: 0.1087\n",
      "Epoch 286/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0855 - mse: 0.1127 - val_loss: 0.0898 - val_mse: 0.1110\n",
      "Epoch 287/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0856 - mse: 0.1142 - val_loss: 0.0892 - val_mse: 0.1101\n",
      "Epoch 288/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0856 - mse: 0.1137 - val_loss: 0.0891 - val_mse: 0.1106\n",
      "Epoch 289/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0855 - mse: 0.1122 - val_loss: 0.0898 - val_mse: 0.1099\n",
      "Epoch 290/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0855 - mse: 0.1128 - val_loss: 0.0909 - val_mse: 0.1111\n",
      "Epoch 291/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0859 - mse: 0.1125 - val_loss: 0.0892 - val_mse: 0.1104\n",
      "Epoch 292/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0854 - mse: 0.1130 - val_loss: 0.0900 - val_mse: 0.1098\n",
      "Epoch 293/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0855 - mse: 0.1134 - val_loss: 0.0894 - val_mse: 0.1093\n",
      "Epoch 294/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0855 - mse: 0.1127 - val_loss: 0.0892 - val_mse: 0.1109\n",
      "Epoch 295/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0854 - mse: 0.1131 - val_loss: 0.0901 - val_mse: 0.1110\n",
      "Epoch 296/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0853 - mse: 0.1129 - val_loss: 0.0897 - val_mse: 0.1101\n",
      "Epoch 297/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0855 - mse: 0.1125 - val_loss: 0.0893 - val_mse: 0.1113\n",
      "Epoch 298/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0853 - mse: 0.1126 - val_loss: 0.0894 - val_mse: 0.1086\n",
      "Epoch 299/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0852 - mse: 0.1127 - val_loss: 0.0888 - val_mse: 0.1088\n",
      "Epoch 300/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0852 - mse: 0.1126 - val_loss: 0.0894 - val_mse: 0.1080\n",
      "Epoch 301/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0853 - mse: 0.1133 - val_loss: 0.0891 - val_mse: 0.1092\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0854 - mse: 0.1132 - val_loss: 0.0893 - val_mse: 0.1103\n",
      "Epoch 303/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0853 - mse: 0.1127 - val_loss: 0.0890 - val_mse: 0.1087\n",
      "Epoch 304/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0850 - mse: 0.1124 - val_loss: 0.0895 - val_mse: 0.1126\n",
      "Epoch 305/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0855 - mse: 0.1136 - val_loss: 0.0900 - val_mse: 0.1138\n",
      "Epoch 306/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0851 - mse: 0.1120 - val_loss: 0.0889 - val_mse: 0.1087\n",
      "Epoch 307/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0852 - mse: 0.1122 - val_loss: 0.0895 - val_mse: 0.1080\n",
      "Epoch 308/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0849 - mse: 0.1123 - val_loss: 0.0899 - val_mse: 0.1106\n",
      "Epoch 309/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0851 - mse: 0.1129 - val_loss: 0.0899 - val_mse: 0.1138\n",
      "Epoch 310/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0849 - mse: 0.1123 - val_loss: 0.0893 - val_mse: 0.1101\n",
      "Epoch 311/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0850 - mse: 0.1118 - val_loss: 0.0895 - val_mse: 0.1099\n",
      "Epoch 312/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0852 - mse: 0.1121 - val_loss: 0.0902 - val_mse: 0.1095\n",
      "Epoch 313/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0850 - mse: 0.1126 - val_loss: 0.0889 - val_mse: 0.1097\n",
      "Epoch 314/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0850 - mse: 0.1128 - val_loss: 0.0895 - val_mse: 0.1086\n",
      "Epoch 315/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0849 - mse: 0.1123 - val_loss: 0.0898 - val_mse: 0.1110\n",
      "Epoch 316/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0849 - mse: 0.1126 - val_loss: 0.0889 - val_mse: 0.1092\n",
      "Epoch 317/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0847 - mse: 0.1115 - val_loss: 0.0894 - val_mse: 0.1102\n",
      "Epoch 318/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0847 - mse: 0.1117 - val_loss: 0.0900 - val_mse: 0.1100\n",
      "Epoch 319/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0847 - mse: 0.1118 - val_loss: 0.0892 - val_mse: 0.1107\n",
      "Epoch 320/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0850 - mse: 0.1124 - val_loss: 0.0892 - val_mse: 0.1117\n",
      "Epoch 321/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0847 - mse: 0.1123 - val_loss: 0.0891 - val_mse: 0.1076\n",
      "Epoch 322/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0845 - mse: 0.1121 - val_loss: 0.0888 - val_mse: 0.1101\n",
      "Epoch 323/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0848 - mse: 0.1121 - val_loss: 0.0893 - val_mse: 0.1115\n",
      "Epoch 324/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0847 - mse: 0.1129 - val_loss: 0.0890 - val_mse: 0.1095\n",
      "Epoch 325/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0847 - mse: 0.1116 - val_loss: 0.0892 - val_mse: 0.1109\n",
      "Epoch 326/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0847 - mse: 0.1126 - val_loss: 0.0893 - val_mse: 0.1099\n",
      "Epoch 327/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0846 - mse: 0.1116 - val_loss: 0.0890 - val_mse: 0.1086\n",
      "Epoch 328/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0848 - mse: 0.1128 - val_loss: 0.0893 - val_mse: 0.1107\n",
      "Epoch 329/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0844 - mse: 0.1120 - val_loss: 0.0891 - val_mse: 0.1074\n",
      "Epoch 330/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0846 - mse: 0.1119 - val_loss: 0.0893 - val_mse: 0.1088\n",
      "Epoch 331/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0844 - mse: 0.1111 - val_loss: 0.0892 - val_mse: 0.1081\n",
      "Epoch 332/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0845 - mse: 0.1115 - val_loss: 0.0899 - val_mse: 0.1121\n",
      "Epoch 333/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0847 - mse: 0.1121 - val_loss: 0.0891 - val_mse: 0.1080\n",
      "Epoch 334/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0844 - mse: 0.1109 - val_loss: 0.0888 - val_mse: 0.1097\n",
      "Epoch 335/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0844 - mse: 0.1113 - val_loss: 0.0906 - val_mse: 0.1092\n",
      "Epoch 336/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0844 - mse: 0.1116 - val_loss: 0.0895 - val_mse: 0.1123\n",
      "Epoch 337/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0848 - mse: 0.1120 - val_loss: 0.0891 - val_mse: 0.1112\n",
      "Epoch 338/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0844 - mse: 0.1118 - val_loss: 0.0896 - val_mse: 0.1102\n",
      "Epoch 339/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0844 - mse: 0.1116 - val_loss: 0.0897 - val_mse: 0.1115\n",
      "Epoch 340/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0843 - mse: 0.1114 - val_loss: 0.0889 - val_mse: 0.1102\n",
      "Epoch 341/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0846 - mse: 0.1119 - val_loss: 0.0891 - val_mse: 0.1094\n",
      "Epoch 342/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0844 - mse: 0.1122 - val_loss: 0.0896 - val_mse: 0.1109\n",
      "Epoch 343/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0844 - mse: 0.1111 - val_loss: 0.0896 - val_mse: 0.1086\n",
      "Epoch 344/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0843 - mse: 0.1120 - val_loss: 0.0892 - val_mse: 0.1118\n",
      "Epoch 345/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0842 - mse: 0.1110 - val_loss: 0.0895 - val_mse: 0.1083\n",
      "Epoch 346/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0842 - mse: 0.1108 - val_loss: 0.0893 - val_mse: 0.1080\n",
      "Epoch 347/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0846 - mse: 0.1118 - val_loss: 0.0896 - val_mse: 0.1105\n",
      "Epoch 348/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0841 - mse: 0.1113 - val_loss: 0.0892 - val_mse: 0.1102\n",
      "Epoch 349/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0840 - mse: 0.1106 - val_loss: 0.0892 - val_mse: 0.1109\n",
      "Epoch 350/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0840 - mse: 0.1110 - val_loss: 0.0894 - val_mse: 0.1080\n",
      "Epoch 351/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0841 - mse: 0.1109 - val_loss: 0.0897 - val_mse: 0.1110\n",
      "Epoch 352/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0843 - mse: 0.1112 - val_loss: 0.0889 - val_mse: 0.1079\n",
      "Epoch 353/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0841 - mse: 0.1116 - val_loss: 0.0896 - val_mse: 0.1136\n",
      "Epoch 354/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0840 - mse: 0.1118 - val_loss: 0.0892 - val_mse: 0.1104\n",
      "Epoch 355/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0839 - mse: 0.1111 - val_loss: 0.0892 - val_mse: 0.1070\n",
      "Epoch 356/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0839 - mse: 0.1116 - val_loss: 0.0892 - val_mse: 0.1104\n",
      "Epoch 357/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0841 - mse: 0.1109 - val_loss: 0.0891 - val_mse: 0.1089\n",
      "Epoch 358/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0840 - mse: 0.1103 - val_loss: 0.0893 - val_mse: 0.1111\n",
      "Epoch 359/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0840 - mse: 0.1109 - val_loss: 0.0891 - val_mse: 0.1092\n",
      "Epoch 360/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0838 - mse: 0.1108 - val_loss: 0.0888 - val_mse: 0.1081\n",
      "Epoch 361/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0837 - mse: 0.1105 - val_loss: 0.0889 - val_mse: 0.1087\n",
      "Epoch 362/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0840 - mse: 0.1101 - val_loss: 0.0895 - val_mse: 0.1101\n",
      "Epoch 363/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0838 - mse: 0.1109 - val_loss: 0.0897 - val_mse: 0.1113\n",
      "Epoch 364/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0840 - mse: 0.1112 - val_loss: 0.0894 - val_mse: 0.1087\n",
      "Epoch 365/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0840 - mse: 0.1108 - val_loss: 0.0887 - val_mse: 0.1103\n",
      "Epoch 366/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0836 - mse: 0.1106 - val_loss: 0.0896 - val_mse: 0.1104\n",
      "Epoch 367/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0838 - mse: 0.1107 - val_loss: 0.0889 - val_mse: 0.1088\n",
      "Epoch 368/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0839 - mse: 0.1117 - val_loss: 0.0894 - val_mse: 0.1110\n",
      "Epoch 369/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0838 - mse: 0.1106 - val_loss: 0.0894 - val_mse: 0.1086\n",
      "Epoch 370/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0835 - mse: 0.1100 - val_loss: 0.0889 - val_mse: 0.1080\n",
      "Epoch 371/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0836 - mse: 0.1108 - val_loss: 0.0892 - val_mse: 0.1086\n",
      "Epoch 372/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0836 - mse: 0.1105 - val_loss: 0.0894 - val_mse: 0.1102\n",
      "Epoch 373/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0834 - mse: 0.1102 - val_loss: 0.0891 - val_mse: 0.1073\n",
      "Epoch 374/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0836 - mse: 0.1106 - val_loss: 0.0899 - val_mse: 0.1111\n",
      "Epoch 375/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0835 - mse: 0.1106 - val_loss: 0.0891 - val_mse: 0.1110\n",
      "Epoch 376/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0837 - mse: 0.1107 - val_loss: 0.0895 - val_mse: 0.1077\n",
      "Epoch 377/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0836 - mse: 0.1101 - val_loss: 0.0894 - val_mse: 0.1087\n",
      "Epoch 378/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0839 - mse: 0.1103 - val_loss: 0.0888 - val_mse: 0.1077\n",
      "Epoch 379/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0836 - mse: 0.1105 - val_loss: 0.0899 - val_mse: 0.1093\n",
      "Epoch 380/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0835 - mse: 0.1100 - val_loss: 0.0890 - val_mse: 0.1092\n",
      "Epoch 381/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0836 - mse: 0.1107 - val_loss: 0.0896 - val_mse: 0.1086\n",
      "Epoch 382/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0835 - mse: 0.1101 - val_loss: 0.0891 - val_mse: 0.1090\n",
      "Epoch 383/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0834 - mse: 0.1096 - val_loss: 0.0887 - val_mse: 0.1088\n",
      "Epoch 384/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0833 - mse: 0.1101 - val_loss: 0.0895 - val_mse: 0.1092\n",
      "Epoch 385/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0833 - mse: 0.1108 - val_loss: 0.0893 - val_mse: 0.1090\n",
      "Epoch 386/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0833 - mse: 0.1104 - val_loss: 0.0896 - val_mse: 0.1104\n",
      "Epoch 387/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0834 - mse: 0.1103 - val_loss: 0.0894 - val_mse: 0.1094\n",
      "Epoch 388/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0830 - mse: 0.1096 - val_loss: 0.0887 - val_mse: 0.1084\n",
      "Epoch 389/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0833 - mse: 0.1102 - val_loss: 0.0892 - val_mse: 0.1070\n",
      "Epoch 390/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0833 - mse: 0.1103 - val_loss: 0.0904 - val_mse: 0.1082\n",
      "Epoch 391/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0832 - mse: 0.1098 - val_loss: 0.0893 - val_mse: 0.1087\n",
      "Epoch 392/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0834 - mse: 0.1103 - val_loss: 0.0896 - val_mse: 0.1083\n",
      "Epoch 393/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0831 - mse: 0.1098 - val_loss: 0.0896 - val_mse: 0.1087\n",
      "Epoch 394/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0834 - mse: 0.1095 - val_loss: 0.0889 - val_mse: 0.1097\n",
      "Epoch 395/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0833 - mse: 0.1092 - val_loss: 0.0897 - val_mse: 0.1081\n",
      "Epoch 396/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0832 - mse: 0.1104 - val_loss: 0.0892 - val_mse: 0.1083\n",
      "Epoch 397/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0829 - mse: 0.1099 - val_loss: 0.0891 - val_mse: 0.1085\n",
      "Epoch 398/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0831 - mse: 0.1100 - val_loss: 0.0893 - val_mse: 0.1097\n",
      "Epoch 399/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0830 - mse: 0.1094 - val_loss: 0.0897 - val_mse: 0.1068\n",
      "Epoch 400/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0831 - mse: 0.1100 - val_loss: 0.0888 - val_mse: 0.1084\n",
      "Epoch 401/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0830 - mse: 0.1095 - val_loss: 0.0892 - val_mse: 0.1082\n",
      "Epoch 402/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0831 - mse: 0.1100 - val_loss: 0.0891 - val_mse: 0.1076\n",
      "Epoch 403/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0831 - mse: 0.1096 - val_loss: 0.0900 - val_mse: 0.1103\n",
      "Epoch 404/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0828 - mse: 0.1093 - val_loss: 0.0902 - val_mse: 0.1069\n",
      "Epoch 405/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0830 - mse: 0.1094 - val_loss: 0.0894 - val_mse: 0.1097\n",
      "Epoch 406/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0831 - mse: 0.1097 - val_loss: 0.0891 - val_mse: 0.1094\n",
      "Epoch 407/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0828 - mse: 0.1094 - val_loss: 0.0890 - val_mse: 0.1067\n",
      "Epoch 408/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0829 - mse: 0.1098 - val_loss: 0.0888 - val_mse: 0.1089\n",
      "Epoch 409/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0828 - mse: 0.1098 - val_loss: 0.0893 - val_mse: 0.1075\n",
      "Epoch 410/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0830 - mse: 0.1096 - val_loss: 0.0895 - val_mse: 0.1092\n",
      "Epoch 411/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0829 - mse: 0.1098 - val_loss: 0.0893 - val_mse: 0.1075\n",
      "Epoch 412/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0828 - mse: 0.1091 - val_loss: 0.0892 - val_mse: 0.1072\n",
      "Epoch 413/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0829 - mse: 0.1097 - val_loss: 0.0893 - val_mse: 0.1071\n",
      "Epoch 414/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0830 - mse: 0.1101 - val_loss: 0.0886 - val_mse: 0.1106\n",
      "Epoch 415/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0830 - mse: 0.1094 - val_loss: 0.0886 - val_mse: 0.1084\n",
      "Epoch 416/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0829 - mse: 0.1097 - val_loss: 0.0891 - val_mse: 0.1101\n",
      "Epoch 417/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0827 - mse: 0.1092 - val_loss: 0.0896 - val_mse: 0.1126\n",
      "Epoch 418/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0826 - mse: 0.1095 - val_loss: 0.0896 - val_mse: 0.1083\n",
      "Epoch 419/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0827 - mse: 0.1094 - val_loss: 0.0891 - val_mse: 0.1078\n",
      "Epoch 420/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0825 - mse: 0.1090 - val_loss: 0.0888 - val_mse: 0.1086\n",
      "Epoch 421/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0825 - mse: 0.1089 - val_loss: 0.0890 - val_mse: 0.1095\n",
      "Epoch 422/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0827 - mse: 0.1102 - val_loss: 0.0889 - val_mse: 0.1087\n",
      "Epoch 423/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0825 - mse: 0.1092 - val_loss: 0.0888 - val_mse: 0.1084\n",
      "Epoch 424/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0825 - mse: 0.1091 - val_loss: 0.0894 - val_mse: 0.1091\n",
      "Epoch 425/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0825 - mse: 0.1093 - val_loss: 0.0891 - val_mse: 0.1075\n",
      "Epoch 426/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0824 - mse: 0.1083 - val_loss: 0.0893 - val_mse: 0.1094\n",
      "Epoch 427/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0824 - mse: 0.1088 - val_loss: 0.0893 - val_mse: 0.1092\n",
      "Epoch 428/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0824 - mse: 0.1094 - val_loss: 0.0894 - val_mse: 0.1082\n",
      "Epoch 429/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0825 - mse: 0.1088 - val_loss: 0.0893 - val_mse: 0.1081\n",
      "Epoch 430/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0824 - mse: 0.1089 - val_loss: 0.0890 - val_mse: 0.1110\n",
      "Epoch 431/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0823 - mse: 0.1096 - val_loss: 0.0895 - val_mse: 0.1115\n",
      "Epoch 432/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0825 - mse: 0.1093 - val_loss: 0.0893 - val_mse: 0.1089\n",
      "Epoch 433/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0822 - mse: 0.1084 - val_loss: 0.0889 - val_mse: 0.1080\n",
      "Epoch 434/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0824 - mse: 0.1088 - val_loss: 0.0897 - val_mse: 0.1064\n",
      "Epoch 435/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0824 - mse: 0.1091 - val_loss: 0.0890 - val_mse: 0.1082\n",
      "Epoch 436/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0824 - mse: 0.1087 - val_loss: 0.0894 - val_mse: 0.1079\n",
      "Epoch 437/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0823 - mse: 0.1093 - val_loss: 0.0891 - val_mse: 0.1092\n",
      "Epoch 438/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0827 - mse: 0.1098 - val_loss: 0.0890 - val_mse: 0.1070\n",
      "Epoch 439/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0822 - mse: 0.1090 - val_loss: 0.0894 - val_mse: 0.1096\n",
      "Epoch 440/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0823 - mse: 0.1086 - val_loss: 0.0891 - val_mse: 0.1074\n",
      "Epoch 441/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0823 - mse: 0.1088 - val_loss: 0.0892 - val_mse: 0.1094\n",
      "Epoch 442/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0821 - mse: 0.1087 - val_loss: 0.0904 - val_mse: 0.1090\n",
      "Epoch 443/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0822 - mse: 0.1089 - val_loss: 0.0891 - val_mse: 0.1081\n",
      "Epoch 444/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0822 - mse: 0.1083 - val_loss: 0.0895 - val_mse: 0.1093\n",
      "Epoch 445/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0822 - mse: 0.1089 - val_loss: 0.0889 - val_mse: 0.1092\n",
      "Epoch 446/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0821 - mse: 0.1091 - val_loss: 0.0893 - val_mse: 0.1074\n",
      "Epoch 447/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0820 - mse: 0.1089 - val_loss: 0.0901 - val_mse: 0.1099\n",
      "Epoch 448/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0823 - mse: 0.1095 - val_loss: 0.0892 - val_mse: 0.1099\n",
      "Epoch 449/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0820 - mse: 0.1083 - val_loss: 0.0890 - val_mse: 0.1081\n",
      "Epoch 450/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0821 - mse: 0.1078 - val_loss: 0.0894 - val_mse: 0.1074\n",
      "Epoch 451/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0821 - mse: 0.1086 - val_loss: 0.0891 - val_mse: 0.1071\n",
      "Epoch 452/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0821 - mse: 0.1084 - val_loss: 0.0890 - val_mse: 0.1073\n",
      "Epoch 453/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0820 - mse: 0.1078 - val_loss: 0.0892 - val_mse: 0.1084\n",
      "Epoch 454/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0821 - mse: 0.1082 - val_loss: 0.0890 - val_mse: 0.1070\n",
      "Epoch 455/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0818 - mse: 0.1085 - val_loss: 0.0895 - val_mse: 0.1072\n",
      "Epoch 456/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0819 - mse: 0.1083 - val_loss: 0.0889 - val_mse: 0.1078\n",
      "Epoch 457/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0819 - mse: 0.1085 - val_loss: 0.0893 - val_mse: 0.1063\n",
      "Epoch 458/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0820 - mse: 0.1095 - val_loss: 0.0892 - val_mse: 0.1084\n",
      "Epoch 459/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0821 - mse: 0.1090 - val_loss: 0.0892 - val_mse: 0.1084\n",
      "Epoch 460/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0821 - mse: 0.1084 - val_loss: 0.0903 - val_mse: 0.1110\n",
      "Epoch 461/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0821 - mse: 0.1080 - val_loss: 0.0895 - val_mse: 0.1103\n",
      "Epoch 462/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0821 - mse: 0.1081 - val_loss: 0.0893 - val_mse: 0.1088\n",
      "Epoch 463/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0817 - mse: 0.1079 - val_loss: 0.0891 - val_mse: 0.1071\n",
      "Epoch 464/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0817 - mse: 0.1079 - val_loss: 0.0895 - val_mse: 0.1068\n",
      "Epoch 465/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0822 - mse: 0.1082 - val_loss: 0.0901 - val_mse: 0.1099\n",
      "Epoch 466/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0821 - mse: 0.1081 - val_loss: 0.0898 - val_mse: 0.1107\n",
      "Epoch 467/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0819 - mse: 0.1086 - val_loss: 0.0892 - val_mse: 0.1106\n",
      "Epoch 468/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0818 - mse: 0.1083 - val_loss: 0.0890 - val_mse: 0.1094\n",
      "Epoch 469/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0819 - mse: 0.1082 - val_loss: 0.0899 - val_mse: 0.1086\n",
      "Epoch 470/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0817 - mse: 0.1082 - val_loss: 0.0893 - val_mse: 0.1085\n",
      "Epoch 471/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0817 - mse: 0.1077 - val_loss: 0.0892 - val_mse: 0.1085\n",
      "Epoch 472/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0816 - mse: 0.1078 - val_loss: 0.0893 - val_mse: 0.1063\n",
      "Epoch 473/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0819 - mse: 0.1082 - val_loss: 0.0893 - val_mse: 0.1099\n",
      "Epoch 474/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0815 - mse: 0.1073 - val_loss: 0.0899 - val_mse: 0.1069\n",
      "Epoch 475/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0816 - mse: 0.1074 - val_loss: 0.0890 - val_mse: 0.1072\n",
      "Epoch 476/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0816 - mse: 0.1077 - val_loss: 0.0892 - val_mse: 0.1072\n",
      "Epoch 477/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0816 - mse: 0.1076 - val_loss: 0.0896 - val_mse: 0.1090\n",
      "Epoch 478/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0817 - mse: 0.1079 - val_loss: 0.0893 - val_mse: 0.1075\n",
      "Epoch 479/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0815 - mse: 0.1079 - val_loss: 0.0896 - val_mse: 0.1094\n",
      "Epoch 480/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0817 - mse: 0.1083 - val_loss: 0.0891 - val_mse: 0.1088\n",
      "Epoch 481/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0813 - mse: 0.1071 - val_loss: 0.0895 - val_mse: 0.1082\n",
      "Epoch 482/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0815 - mse: 0.1080 - val_loss: 0.0887 - val_mse: 0.1077\n",
      "Epoch 483/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0813 - mse: 0.1073 - val_loss: 0.0901 - val_mse: 0.1112\n",
      "Epoch 484/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0813 - mse: 0.1075 - val_loss: 0.0896 - val_mse: 0.1093\n",
      "Epoch 485/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0813 - mse: 0.1074 - val_loss: 0.0892 - val_mse: 0.1068\n",
      "Epoch 486/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0815 - mse: 0.1076 - val_loss: 0.0895 - val_mse: 0.1088\n",
      "Epoch 487/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0814 - mse: 0.1072 - val_loss: 0.0898 - val_mse: 0.1082\n",
      "Epoch 488/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0814 - mse: 0.1080 - val_loss: 0.0890 - val_mse: 0.1073\n",
      "Epoch 489/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0812 - mse: 0.1074 - val_loss: 0.0896 - val_mse: 0.1071\n",
      "Epoch 490/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0815 - mse: 0.1073 - val_loss: 0.0894 - val_mse: 0.1087\n",
      "Epoch 491/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0813 - mse: 0.1072 - val_loss: 0.0887 - val_mse: 0.1069\n",
      "Epoch 492/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0814 - mse: 0.1076 - val_loss: 0.0897 - val_mse: 0.1078\n",
      "Epoch 493/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0813 - mse: 0.1075 - val_loss: 0.0890 - val_mse: 0.1093\n",
      "Epoch 494/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0813 - mse: 0.1080 - val_loss: 0.0895 - val_mse: 0.1079\n",
      "Epoch 495/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0813 - mse: 0.1076 - val_loss: 0.0900 - val_mse: 0.1094\n",
      "Epoch 496/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0812 - mse: 0.1068 - val_loss: 0.0895 - val_mse: 0.1078\n",
      "Epoch 497/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0812 - mse: 0.1076 - val_loss: 0.0900 - val_mse: 0.1070\n",
      "Epoch 498/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0813 - mse: 0.1076 - val_loss: 0.0892 - val_mse: 0.1084\n",
      "Epoch 499/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0813 - mse: 0.1067 - val_loss: 0.0898 - val_mse: 0.1086\n",
      "Epoch 500/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0812 - mse: 0.1076 - val_loss: 0.0895 - val_mse: 0.1098\n",
      "Epoch 501/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0813 - mse: 0.1076 - val_loss: 0.0891 - val_mse: 0.1070\n",
      "Epoch 502/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0811 - mse: 0.1080 - val_loss: 0.0891 - val_mse: 0.1102\n",
      "Epoch 503/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0813 - mse: 0.1077 - val_loss: 0.0893 - val_mse: 0.1088\n",
      "Epoch 504/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0814 - mse: 0.1078 - val_loss: 0.0892 - val_mse: 0.1081\n",
      "Epoch 505/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0811 - mse: 0.1073 - val_loss: 0.0900 - val_mse: 0.1085\n",
      "Epoch 506/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0811 - mse: 0.1069 - val_loss: 0.0893 - val_mse: 0.1069\n",
      "Epoch 507/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0811 - mse: 0.1070 - val_loss: 0.0896 - val_mse: 0.1077\n",
      "Epoch 508/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0809 - mse: 0.1077 - val_loss: 0.0896 - val_mse: 0.1063\n",
      "Epoch 509/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0810 - mse: 0.1072 - val_loss: 0.0892 - val_mse: 0.1070\n",
      "Epoch 510/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0809 - mse: 0.1070 - val_loss: 0.0892 - val_mse: 0.1085\n",
      "Epoch 511/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0807 - mse: 0.1072 - val_loss: 0.0891 - val_mse: 0.1067\n",
      "Epoch 512/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0808 - mse: 0.1070 - val_loss: 0.0889 - val_mse: 0.1073\n",
      "Epoch 513/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0810 - mse: 0.1071 - val_loss: 0.0889 - val_mse: 0.1071\n",
      "Epoch 514/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0809 - mse: 0.1074 - val_loss: 0.0894 - val_mse: 0.1083\n",
      "Epoch 515/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0811 - mse: 0.1078 - val_loss: 0.0899 - val_mse: 0.1068\n",
      "Epoch 516/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0809 - mse: 0.1069 - val_loss: 0.0889 - val_mse: 0.1070\n",
      "Epoch 517/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0810 - mse: 0.1070 - val_loss: 0.0899 - val_mse: 0.1056\n",
      "Epoch 518/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0808 - mse: 0.1069 - val_loss: 0.0891 - val_mse: 0.1065\n",
      "Epoch 519/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0808 - mse: 0.1067 - val_loss: 0.0899 - val_mse: 0.1081\n",
      "Epoch 520/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0811 - mse: 0.1078 - val_loss: 0.0902 - val_mse: 0.1074\n",
      "Epoch 521/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0807 - mse: 0.1066 - val_loss: 0.0896 - val_mse: 0.1075\n",
      "Epoch 522/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0808 - mse: 0.1072 - val_loss: 0.0897 - val_mse: 0.1077\n",
      "Epoch 523/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0807 - mse: 0.1068 - val_loss: 0.0893 - val_mse: 0.1083\n",
      "Epoch 524/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0807 - mse: 0.1071 - val_loss: 0.0908 - val_mse: 0.1102\n",
      "Epoch 525/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0807 - mse: 0.1068 - val_loss: 0.0892 - val_mse: 0.1073\n",
      "Epoch 526/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0808 - mse: 0.1065 - val_loss: 0.0904 - val_mse: 0.1059\n",
      "Epoch 527/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0806 - mse: 0.1064 - val_loss: 0.0893 - val_mse: 0.1063\n",
      "Epoch 528/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0806 - mse: 0.1067 - val_loss: 0.0895 - val_mse: 0.1064\n",
      "Epoch 529/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0808 - mse: 0.1067 - val_loss: 0.0896 - val_mse: 0.1088\n",
      "Epoch 530/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0807 - mse: 0.1066 - val_loss: 0.0893 - val_mse: 0.1076\n",
      "Epoch 531/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0806 - mse: 0.1065 - val_loss: 0.0895 - val_mse: 0.1079\n",
      "Epoch 532/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0808 - mse: 0.1070 - val_loss: 0.0894 - val_mse: 0.1051\n",
      "Epoch 533/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0807 - mse: 0.1067 - val_loss: 0.0892 - val_mse: 0.1072\n",
      "Epoch 534/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0806 - mse: 0.1069 - val_loss: 0.0896 - val_mse: 0.1061\n",
      "Epoch 535/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0806 - mse: 0.1069 - val_loss: 0.0893 - val_mse: 0.1090\n",
      "Epoch 536/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0808 - mse: 0.1071 - val_loss: 0.0899 - val_mse: 0.1071\n",
      "Epoch 537/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0805 - mse: 0.1064 - val_loss: 0.0893 - val_mse: 0.1073\n",
      "Epoch 538/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0806 - mse: 0.1066 - val_loss: 0.0895 - val_mse: 0.1069\n",
      "Epoch 539/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0805 - mse: 0.1068 - val_loss: 0.0901 - val_mse: 0.1078\n",
      "Epoch 540/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0806 - mse: 0.1065 - val_loss: 0.0914 - val_mse: 0.1083\n",
      "Epoch 541/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0806 - mse: 0.1066 - val_loss: 0.0891 - val_mse: 0.1054\n",
      "Epoch 542/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0803 - mse: 0.1069 - val_loss: 0.0901 - val_mse: 0.1065\n",
      "Epoch 543/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0804 - mse: 0.1063 - val_loss: 0.0893 - val_mse: 0.1071\n",
      "Epoch 544/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0806 - mse: 0.1065 - val_loss: 0.0894 - val_mse: 0.1077\n",
      "Epoch 545/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0803 - mse: 0.1063 - val_loss: 0.0895 - val_mse: 0.1084\n",
      "Epoch 546/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0803 - mse: 0.1061 - val_loss: 0.0899 - val_mse: 0.1093\n",
      "Epoch 547/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0804 - mse: 0.1068 - val_loss: 0.0894 - val_mse: 0.1069\n",
      "Epoch 548/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0800 - mse: 0.1057 - val_loss: 0.0892 - val_mse: 0.1073\n",
      "Epoch 549/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0803 - mse: 0.1059 - val_loss: 0.0898 - val_mse: 0.1091\n",
      "Epoch 550/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0804 - mse: 0.1065 - val_loss: 0.0894 - val_mse: 0.1072\n",
      "Epoch 551/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0803 - mse: 0.1067 - val_loss: 0.0892 - val_mse: 0.1087\n",
      "Epoch 552/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0803 - mse: 0.1074 - val_loss: 0.0896 - val_mse: 0.1099\n",
      "Epoch 553/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0807 - mse: 0.1075 - val_loss: 0.0894 - val_mse: 0.1084\n",
      "Epoch 554/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0803 - mse: 0.1060 - val_loss: 0.0894 - val_mse: 0.1077\n",
      "Epoch 555/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0801 - mse: 0.1055 - val_loss: 0.0896 - val_mse: 0.1062\n",
      "Epoch 556/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0800 - mse: 0.1061 - val_loss: 0.0896 - val_mse: 0.1061\n",
      "Epoch 557/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0802 - mse: 0.1054 - val_loss: 0.0893 - val_mse: 0.1080\n",
      "Epoch 558/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0800 - mse: 0.1058 - val_loss: 0.0896 - val_mse: 0.1066\n",
      "Epoch 559/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0801 - mse: 0.1057 - val_loss: 0.0895 - val_mse: 0.1063\n",
      "Epoch 560/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0801 - mse: 0.1059 - val_loss: 0.0894 - val_mse: 0.1069\n",
      "Epoch 561/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0800 - mse: 0.1056 - val_loss: 0.0897 - val_mse: 0.1079\n",
      "Epoch 562/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0798 - mse: 0.1053 - val_loss: 0.0893 - val_mse: 0.1077\n",
      "Epoch 563/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0800 - mse: 0.1061 - val_loss: 0.0896 - val_mse: 0.1071\n",
      "Epoch 564/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0805 - mse: 0.1060 - val_loss: 0.0895 - val_mse: 0.1069\n",
      "Epoch 565/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0798 - mse: 0.1053 - val_loss: 0.0893 - val_mse: 0.1062\n",
      "Epoch 566/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0801 - mse: 0.1053 - val_loss: 0.0896 - val_mse: 0.1073\n",
      "Epoch 567/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0801 - mse: 0.1053 - val_loss: 0.0894 - val_mse: 0.1066\n",
      "Epoch 568/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0800 - mse: 0.1045 - val_loss: 0.0897 - val_mse: 0.1067\n",
      "Epoch 569/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0800 - mse: 0.1049 - val_loss: 0.0896 - val_mse: 0.1071\n",
      "Epoch 570/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0797 - mse: 0.1046 - val_loss: 0.0894 - val_mse: 0.1054\n",
      "Epoch 571/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0800 - mse: 0.1046 - val_loss: 0.0901 - val_mse: 0.1054\n",
      "Epoch 572/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0799 - mse: 0.1045 - val_loss: 0.0896 - val_mse: 0.1053\n",
      "Epoch 573/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0800 - mse: 0.1042 - val_loss: 0.0896 - val_mse: 0.1068\n",
      "Epoch 574/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0797 - mse: 0.1037 - val_loss: 0.0893 - val_mse: 0.1046\n",
      "Epoch 575/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0797 - mse: 0.1033 - val_loss: 0.0894 - val_mse: 0.1047\n",
      "Epoch 576/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0798 - mse: 0.1036 - val_loss: 0.0897 - val_mse: 0.1051\n",
      "Epoch 577/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0796 - mse: 0.1026 - val_loss: 0.0900 - val_mse: 0.1049\n",
      "Epoch 578/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0797 - mse: 0.1023 - val_loss: 0.0891 - val_mse: 0.1050\n",
      "Epoch 579/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0796 - mse: 0.1026 - val_loss: 0.0894 - val_mse: 0.1054\n",
      "Epoch 580/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0797 - mse: 0.1014 - val_loss: 0.0898 - val_mse: 0.1026\n",
      "Epoch 581/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0796 - mse: 0.1010 - val_loss: 0.0891 - val_mse: 0.1039\n",
      "Epoch 582/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0796 - mse: 0.1010 - val_loss: 0.0898 - val_mse: 0.1039\n",
      "Epoch 583/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0799 - mse: 0.1009 - val_loss: 0.0891 - val_mse: 0.1026\n",
      "Epoch 584/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0796 - mse: 0.1005 - val_loss: 0.0894 - val_mse: 0.1025\n",
      "Epoch 585/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0793 - mse: 0.0996 - val_loss: 0.0894 - val_mse: 0.1014\n",
      "Epoch 586/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0792 - mse: 0.0994 - val_loss: 0.0894 - val_mse: 0.1040\n",
      "Epoch 587/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0792 - mse: 0.0990 - val_loss: 0.0896 - val_mse: 0.1016\n",
      "Epoch 588/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0793 - mse: 0.0996 - val_loss: 0.0891 - val_mse: 0.1024\n",
      "Epoch 589/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0793 - mse: 0.0988 - val_loss: 0.0897 - val_mse: 0.1021\n",
      "Epoch 590/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0794 - mse: 0.0991 - val_loss: 0.0894 - val_mse: 0.1043\n",
      "Epoch 591/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0793 - mse: 0.0994 - val_loss: 0.0891 - val_mse: 0.1017\n",
      "Epoch 592/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0791 - mse: 0.0987 - val_loss: 0.0893 - val_mse: 0.1016\n",
      "Epoch 593/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0794 - mse: 0.0988 - val_loss: 0.0892 - val_mse: 0.1024\n",
      "Epoch 594/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0792 - mse: 0.0988 - val_loss: 0.0893 - val_mse: 0.1029\n",
      "Epoch 595/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0789 - mse: 0.0983 - val_loss: 0.0900 - val_mse: 0.1005\n",
      "Epoch 596/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0791 - mse: 0.0984 - val_loss: 0.0890 - val_mse: 0.1011\n",
      "Epoch 597/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0790 - mse: 0.0988 - val_loss: 0.0897 - val_mse: 0.0990\n",
      "Epoch 598/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0792 - mse: 0.0986 - val_loss: 0.0892 - val_mse: 0.1013\n",
      "Epoch 599/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0791 - mse: 0.0981 - val_loss: 0.0892 - val_mse: 0.1012\n",
      "Epoch 600/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0790 - mse: 0.0983 - val_loss: 0.0890 - val_mse: 0.0991\n",
      "Epoch 601/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0790 - mse: 0.0975 - val_loss: 0.0896 - val_mse: 0.1010\n",
      "Epoch 602/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0789 - mse: 0.0983 - val_loss: 0.0886 - val_mse: 0.1015\n",
      "Epoch 603/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0788 - mse: 0.0973 - val_loss: 0.0893 - val_mse: 0.1012\n",
      "Epoch 604/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0790 - mse: 0.0979 - val_loss: 0.0899 - val_mse: 0.1000\n",
      "Epoch 605/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0789 - mse: 0.0983 - val_loss: 0.0887 - val_mse: 0.1019\n",
      "Epoch 606/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0785 - mse: 0.0981 - val_loss: 0.0890 - val_mse: 0.1001\n",
      "Epoch 607/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0790 - mse: 0.0982 - val_loss: 0.0892 - val_mse: 0.1028\n",
      "Epoch 608/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0788 - mse: 0.0974 - val_loss: 0.0895 - val_mse: 0.0999\n",
      "Epoch 609/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0787 - mse: 0.0974 - val_loss: 0.0890 - val_mse: 0.1005\n",
      "Epoch 610/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0787 - mse: 0.0979 - val_loss: 0.0888 - val_mse: 0.1009\n",
      "Epoch 611/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0787 - mse: 0.0978 - val_loss: 0.0901 - val_mse: 0.1002\n",
      "Epoch 612/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0786 - mse: 0.0971 - val_loss: 0.0897 - val_mse: 0.0994\n",
      "Epoch 613/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0786 - mse: 0.0974 - val_loss: 0.0906 - val_mse: 0.1037\n",
      "Epoch 614/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0785 - mse: 0.0973 - val_loss: 0.0891 - val_mse: 0.1002\n",
      "Epoch 615/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0784 - mse: 0.0971 - val_loss: 0.0898 - val_mse: 0.1025\n",
      "Epoch 616/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0786 - mse: 0.0987 - val_loss: 0.0895 - val_mse: 0.1003\n",
      "Epoch 617/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0788 - mse: 0.0972 - val_loss: 0.0894 - val_mse: 0.1012\n",
      "Epoch 618/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0786 - mse: 0.0970 - val_loss: 0.0891 - val_mse: 0.0992\n",
      "Epoch 619/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0785 - mse: 0.0973 - val_loss: 0.0891 - val_mse: 0.0977\n",
      "Epoch 620/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0786 - mse: 0.0982 - val_loss: 0.0893 - val_mse: 0.1009\n",
      "Epoch 621/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0782 - mse: 0.0975 - val_loss: 0.0899 - val_mse: 0.1023\n",
      "Epoch 622/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0784 - mse: 0.0967 - val_loss: 0.0890 - val_mse: 0.0995\n",
      "Epoch 623/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0782 - mse: 0.0970 - val_loss: 0.0893 - val_mse: 0.0989\n",
      "Epoch 624/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0783 - mse: 0.0973 - val_loss: 0.0889 - val_mse: 0.0995\n",
      "Epoch 625/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0782 - mse: 0.0970 - val_loss: 0.0888 - val_mse: 0.0991\n",
      "Epoch 626/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0783 - mse: 0.0974 - val_loss: 0.0888 - val_mse: 0.0983\n",
      "Epoch 627/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0781 - mse: 0.0974 - val_loss: 0.0886 - val_mse: 0.0978\n",
      "Epoch 628/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0782 - mse: 0.0970 - val_loss: 0.0898 - val_mse: 0.1027\n",
      "Epoch 629/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0784 - mse: 0.0973 - val_loss: 0.0890 - val_mse: 0.0986\n",
      "Epoch 630/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0782 - mse: 0.0971 - val_loss: 0.0889 - val_mse: 0.1003\n",
      "Epoch 631/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0784 - mse: 0.0972 - val_loss: 0.0887 - val_mse: 0.1010\n",
      "Epoch 632/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0783 - mse: 0.0967 - val_loss: 0.0890 - val_mse: 0.1004\n",
      "Epoch 633/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0781 - mse: 0.0969 - val_loss: 0.0888 - val_mse: 0.0995\n",
      "Epoch 634/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0783 - mse: 0.0966 - val_loss: 0.0889 - val_mse: 0.0979\n",
      "Epoch 635/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0784 - mse: 0.0968 - val_loss: 0.0887 - val_mse: 0.0984\n",
      "Epoch 636/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0780 - mse: 0.0961 - val_loss: 0.0888 - val_mse: 0.0993\n",
      "Epoch 637/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0782 - mse: 0.0971 - val_loss: 0.0888 - val_mse: 0.0995\n",
      "Epoch 638/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0782 - mse: 0.0969 - val_loss: 0.0898 - val_mse: 0.0990\n",
      "Epoch 639/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0782 - mse: 0.0972 - val_loss: 0.0896 - val_mse: 0.1010\n",
      "Epoch 640/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0780 - mse: 0.0966 - val_loss: 0.0891 - val_mse: 0.0993\n",
      "Epoch 641/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0781 - mse: 0.0965 - val_loss: 0.0891 - val_mse: 0.0985\n",
      "Epoch 642/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0781 - mse: 0.0967 - val_loss: 0.0892 - val_mse: 0.0987\n",
      "Epoch 643/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0779 - mse: 0.0967 - val_loss: 0.0889 - val_mse: 0.0981\n",
      "Epoch 644/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0781 - mse: 0.0967 - val_loss: 0.0893 - val_mse: 0.0990\n",
      "Epoch 645/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0780 - mse: 0.0964 - val_loss: 0.0893 - val_mse: 0.0982\n",
      "Epoch 646/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0781 - mse: 0.0964 - val_loss: 0.0897 - val_mse: 0.0985\n",
      "Epoch 647/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0782 - mse: 0.0964 - val_loss: 0.0886 - val_mse: 0.0974\n",
      "Epoch 648/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0779 - mse: 0.0964 - val_loss: 0.0891 - val_mse: 0.0981\n",
      "Epoch 649/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0780 - mse: 0.0968 - val_loss: 0.0888 - val_mse: 0.0978\n",
      "Epoch 650/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0780 - mse: 0.0964 - val_loss: 0.0894 - val_mse: 0.0982\n",
      "Epoch 651/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0779 - mse: 0.0967 - val_loss: 0.0892 - val_mse: 0.0982\n",
      "Epoch 652/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0779 - mse: 0.0970 - val_loss: 0.0892 - val_mse: 0.0993\n",
      "Epoch 653/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0779 - mse: 0.0968 - val_loss: 0.0889 - val_mse: 0.0975\n",
      "Epoch 654/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0780 - mse: 0.0959 - val_loss: 0.0894 - val_mse: 0.0994\n",
      "Epoch 655/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0779 - mse: 0.0964 - val_loss: 0.0895 - val_mse: 0.0992\n",
      "Epoch 656/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0777 - mse: 0.0967 - val_loss: 0.0893 - val_mse: 0.0993\n",
      "Epoch 657/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0778 - mse: 0.0967 - val_loss: 0.0892 - val_mse: 0.0977\n",
      "Epoch 658/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0777 - mse: 0.0965 - val_loss: 0.0891 - val_mse: 0.0975\n",
      "Epoch 659/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0779 - mse: 0.0965 - val_loss: 0.0893 - val_mse: 0.0962\n",
      "Epoch 660/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0777 - mse: 0.0957 - val_loss: 0.0888 - val_mse: 0.0985\n",
      "Epoch 661/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0778 - mse: 0.0962 - val_loss: 0.0888 - val_mse: 0.0988\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0778 - mse: 0.0956 - val_loss: 0.0891 - val_mse: 0.0999\n",
      "Epoch 663/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0777 - mse: 0.0963 - val_loss: 0.0894 - val_mse: 0.0974\n",
      "Epoch 664/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0775 - mse: 0.0961 - val_loss: 0.0895 - val_mse: 0.0994\n",
      "Epoch 665/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0776 - mse: 0.0967 - val_loss: 0.0899 - val_mse: 0.0978\n",
      "Epoch 666/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0777 - mse: 0.0963 - val_loss: 0.0901 - val_mse: 0.0985\n",
      "Epoch 667/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0777 - mse: 0.0962 - val_loss: 0.0889 - val_mse: 0.0982\n",
      "Epoch 668/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0774 - mse: 0.0962 - val_loss: 0.0891 - val_mse: 0.0984\n",
      "Epoch 669/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0777 - mse: 0.0961 - val_loss: 0.0897 - val_mse: 0.0997\n",
      "Epoch 670/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0776 - mse: 0.0963 - val_loss: 0.0887 - val_mse: 0.0984\n",
      "Epoch 671/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0776 - mse: 0.0961 - val_loss: 0.0885 - val_mse: 0.0973\n",
      "Epoch 672/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0776 - mse: 0.0960 - val_loss: 0.0888 - val_mse: 0.0993\n",
      "Epoch 673/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0773 - mse: 0.0959 - val_loss: 0.0888 - val_mse: 0.0979\n",
      "Epoch 674/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0775 - mse: 0.0961 - val_loss: 0.0891 - val_mse: 0.0987\n",
      "Epoch 675/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0776 - mse: 0.0961 - val_loss: 0.0889 - val_mse: 0.0972\n",
      "Epoch 676/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0775 - mse: 0.0957 - val_loss: 0.0889 - val_mse: 0.0993\n",
      "Epoch 677/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0776 - mse: 0.0966 - val_loss: 0.0895 - val_mse: 0.0988\n",
      "Epoch 678/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0775 - mse: 0.0964 - val_loss: 0.0890 - val_mse: 0.0993\n",
      "Epoch 679/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0773 - mse: 0.0964 - val_loss: 0.0890 - val_mse: 0.0987\n",
      "Epoch 680/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0774 - mse: 0.0960 - val_loss: 0.0892 - val_mse: 0.0968\n",
      "Epoch 681/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0773 - mse: 0.0952 - val_loss: 0.0891 - val_mse: 0.0987\n",
      "Epoch 682/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0773 - mse: 0.0957 - val_loss: 0.0888 - val_mse: 0.0979\n",
      "Epoch 683/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0776 - mse: 0.0966 - val_loss: 0.0899 - val_mse: 0.0993\n",
      "Epoch 684/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0772 - mse: 0.0959 - val_loss: 0.0900 - val_mse: 0.0978\n",
      "Epoch 685/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0774 - mse: 0.0959 - val_loss: 0.0897 - val_mse: 0.0980\n",
      "Epoch 686/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0774 - mse: 0.0962 - val_loss: 0.0892 - val_mse: 0.0990\n",
      "Epoch 687/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0776 - mse: 0.0964 - val_loss: 0.0894 - val_mse: 0.1010\n",
      "Epoch 688/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0774 - mse: 0.0958 - val_loss: 0.0891 - val_mse: 0.0994\n",
      "Epoch 689/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0776 - mse: 0.0972 - val_loss: 0.0890 - val_mse: 0.1011\n",
      "Epoch 690/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0772 - mse: 0.0963 - val_loss: 0.0897 - val_mse: 0.0984\n",
      "Epoch 691/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0771 - mse: 0.0960 - val_loss: 0.0898 - val_mse: 0.1021\n",
      "Epoch 692/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0773 - mse: 0.0964 - val_loss: 0.0891 - val_mse: 0.0988\n",
      "Epoch 693/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0770 - mse: 0.0958 - val_loss: 0.0890 - val_mse: 0.0975\n",
      "Epoch 694/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0770 - mse: 0.0956 - val_loss: 0.0889 - val_mse: 0.0974\n",
      "Epoch 695/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0771 - mse: 0.0963 - val_loss: 0.0888 - val_mse: 0.0995\n",
      "Epoch 696/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0771 - mse: 0.0959 - val_loss: 0.0899 - val_mse: 0.0985\n",
      "Epoch 697/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0771 - mse: 0.0962 - val_loss: 0.0890 - val_mse: 0.0973\n",
      "Epoch 698/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0770 - mse: 0.0959 - val_loss: 0.0897 - val_mse: 0.0988\n",
      "Epoch 699/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0770 - mse: 0.0957 - val_loss: 0.0889 - val_mse: 0.0997\n",
      "Epoch 700/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0770 - mse: 0.0962 - val_loss: 0.0892 - val_mse: 0.0997\n",
      "Epoch 701/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0774 - mse: 0.0966 - val_loss: 0.0892 - val_mse: 0.0990\n",
      "Epoch 702/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0772 - mse: 0.0959 - val_loss: 0.0899 - val_mse: 0.0998\n",
      "Epoch 703/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0769 - mse: 0.0957 - val_loss: 0.0890 - val_mse: 0.0992\n",
      "Epoch 704/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0771 - mse: 0.0959 - val_loss: 0.0891 - val_mse: 0.0978\n",
      "Epoch 705/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0769 - mse: 0.0960 - val_loss: 0.0892 - val_mse: 0.0996\n",
      "Epoch 706/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0771 - mse: 0.0958 - val_loss: 0.0894 - val_mse: 0.0972\n",
      "Epoch 707/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0771 - mse: 0.0957 - val_loss: 0.0889 - val_mse: 0.0985\n",
      "Epoch 708/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0769 - mse: 0.0956 - val_loss: 0.0889 - val_mse: 0.0970\n",
      "Epoch 709/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0774 - mse: 0.0960 - val_loss: 0.0890 - val_mse: 0.0987\n",
      "Epoch 710/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0770 - mse: 0.0961 - val_loss: 0.0888 - val_mse: 0.0970\n",
      "Epoch 711/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0769 - mse: 0.0953 - val_loss: 0.0893 - val_mse: 0.1001\n",
      "Epoch 712/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0770 - mse: 0.0956 - val_loss: 0.0894 - val_mse: 0.0988\n",
      "Epoch 713/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0769 - mse: 0.0953 - val_loss: 0.0900 - val_mse: 0.0977\n",
      "Epoch 714/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0768 - mse: 0.0953 - val_loss: 0.0900 - val_mse: 0.1021\n",
      "Epoch 715/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0770 - mse: 0.0958 - val_loss: 0.0905 - val_mse: 0.0979\n",
      "Epoch 716/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0768 - mse: 0.0953 - val_loss: 0.0891 - val_mse: 0.0991\n",
      "Epoch 717/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0770 - mse: 0.0963 - val_loss: 0.0892 - val_mse: 0.0979\n",
      "Epoch 718/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0768 - mse: 0.0958 - val_loss: 0.0899 - val_mse: 0.0982\n",
      "Epoch 719/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0768 - mse: 0.0957 - val_loss: 0.0896 - val_mse: 0.0980\n",
      "Epoch 720/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0767 - mse: 0.0954 - val_loss: 0.0893 - val_mse: 0.0984\n",
      "Epoch 721/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0769 - mse: 0.0957 - val_loss: 0.0896 - val_mse: 0.0968\n",
      "Epoch 722/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0766 - mse: 0.0950 - val_loss: 0.0892 - val_mse: 0.0975\n",
      "Epoch 723/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0769 - mse: 0.0957 - val_loss: 0.0894 - val_mse: 0.0991\n",
      "Epoch 724/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0767 - mse: 0.0960 - val_loss: 0.0889 - val_mse: 0.0989\n",
      "Epoch 725/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0768 - mse: 0.0960 - val_loss: 0.0893 - val_mse: 0.1004\n",
      "Epoch 726/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0765 - mse: 0.0955 - val_loss: 0.0892 - val_mse: 0.0989\n",
      "Epoch 727/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0766 - mse: 0.0953 - val_loss: 0.0892 - val_mse: 0.0986\n",
      "Epoch 728/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0767 - mse: 0.0958 - val_loss: 0.0891 - val_mse: 0.0986\n",
      "Epoch 729/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0766 - mse: 0.0960 - val_loss: 0.0889 - val_mse: 0.0969\n",
      "Epoch 730/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0765 - mse: 0.0955 - val_loss: 0.0893 - val_mse: 0.0982\n",
      "Epoch 731/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0766 - mse: 0.0955 - val_loss: 0.0894 - val_mse: 0.0988\n",
      "Epoch 732/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0766 - mse: 0.0956 - val_loss: 0.0893 - val_mse: 0.0981\n",
      "Epoch 733/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0765 - mse: 0.0955 - val_loss: 0.0895 - val_mse: 0.1001\n",
      "Epoch 734/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0765 - mse: 0.0955 - val_loss: 0.0889 - val_mse: 0.0997\n",
      "Epoch 735/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0765 - mse: 0.0961 - val_loss: 0.0887 - val_mse: 0.0987\n",
      "Epoch 736/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0766 - mse: 0.0960 - val_loss: 0.0899 - val_mse: 0.0997\n",
      "Epoch 737/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0768 - mse: 0.0962 - val_loss: 0.0895 - val_mse: 0.0970\n",
      "Epoch 738/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0767 - mse: 0.0959 - val_loss: 0.0896 - val_mse: 0.1009\n",
      "Epoch 739/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0764 - mse: 0.0957 - val_loss: 0.0893 - val_mse: 0.0995\n",
      "Epoch 740/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0763 - mse: 0.0959 - val_loss: 0.0895 - val_mse: 0.0987\n",
      "Epoch 741/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0764 - mse: 0.0957 - val_loss: 0.0893 - val_mse: 0.0983\n",
      "Epoch 742/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0765 - mse: 0.0960 - val_loss: 0.0899 - val_mse: 0.0981\n",
      "Epoch 743/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0766 - mse: 0.0957 - val_loss: 0.0892 - val_mse: 0.0982\n",
      "Epoch 744/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0763 - mse: 0.0953 - val_loss: 0.0894 - val_mse: 0.1001\n",
      "Epoch 745/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0767 - mse: 0.0954 - val_loss: 0.0895 - val_mse: 0.0970\n",
      "Epoch 746/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0766 - mse: 0.0960 - val_loss: 0.0890 - val_mse: 0.0973\n",
      "Epoch 747/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0765 - mse: 0.0960 - val_loss: 0.0891 - val_mse: 0.0997\n",
      "Epoch 748/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0761 - mse: 0.0952 - val_loss: 0.0895 - val_mse: 0.1000\n",
      "Epoch 749/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0762 - mse: 0.0947 - val_loss: 0.0894 - val_mse: 0.0982\n",
      "Epoch 750/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0762 - mse: 0.0950 - val_loss: 0.0889 - val_mse: 0.0989\n",
      "Epoch 751/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0762 - mse: 0.0953 - val_loss: 0.0890 - val_mse: 0.0991\n",
      "Epoch 752/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0763 - mse: 0.0955 - val_loss: 0.0895 - val_mse: 0.0967\n",
      "Epoch 753/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0762 - mse: 0.0953 - val_loss: 0.0897 - val_mse: 0.0992\n",
      "Epoch 754/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0763 - mse: 0.0953 - val_loss: 0.0893 - val_mse: 0.0985\n",
      "Epoch 755/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0762 - mse: 0.0961 - val_loss: 0.0895 - val_mse: 0.0988\n",
      "Epoch 756/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0762 - mse: 0.0955 - val_loss: 0.0893 - val_mse: 0.0992\n",
      "Epoch 757/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0764 - mse: 0.0959 - val_loss: 0.0892 - val_mse: 0.0993\n",
      "Epoch 758/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0764 - mse: 0.0958 - val_loss: 0.0892 - val_mse: 0.0980\n",
      "Epoch 759/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0767 - mse: 0.0963 - val_loss: 0.0896 - val_mse: 0.1002\n",
      "Epoch 760/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0761 - mse: 0.0959 - val_loss: 0.0891 - val_mse: 0.0986\n",
      "Epoch 761/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0760 - mse: 0.0952 - val_loss: 0.0892 - val_mse: 0.1004\n",
      "Epoch 762/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0762 - mse: 0.0954 - val_loss: 0.0898 - val_mse: 0.0991\n",
      "Epoch 763/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0761 - mse: 0.0954 - val_loss: 0.0891 - val_mse: 0.0982\n",
      "Epoch 764/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0763 - mse: 0.0953 - val_loss: 0.0898 - val_mse: 0.0964\n",
      "Epoch 765/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0759 - mse: 0.0954 - val_loss: 0.0900 - val_mse: 0.1000\n",
      "Epoch 766/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0760 - mse: 0.0954 - val_loss: 0.0902 - val_mse: 0.0980\n",
      "Epoch 767/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0762 - mse: 0.0954 - val_loss: 0.0897 - val_mse: 0.1015\n",
      "Epoch 768/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0762 - mse: 0.0954 - val_loss: 0.0893 - val_mse: 0.0973\n",
      "Epoch 769/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0761 - mse: 0.0953 - val_loss: 0.0892 - val_mse: 0.0981\n",
      "Epoch 770/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0761 - mse: 0.0955 - val_loss: 0.0895 - val_mse: 0.0976\n",
      "Epoch 771/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0759 - mse: 0.0953 - val_loss: 0.0893 - val_mse: 0.0998\n",
      "Epoch 772/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0758 - mse: 0.0951 - val_loss: 0.0892 - val_mse: 0.0987\n",
      "Epoch 773/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0759 - mse: 0.0953 - val_loss: 0.0895 - val_mse: 0.0990\n",
      "Epoch 774/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0759 - mse: 0.0954 - val_loss: 0.0895 - val_mse: 0.0965\n",
      "Epoch 775/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0760 - mse: 0.0952 - val_loss: 0.0888 - val_mse: 0.0980\n",
      "Epoch 776/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0758 - mse: 0.0957 - val_loss: 0.0898 - val_mse: 0.1016\n",
      "Epoch 777/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0760 - mse: 0.0959 - val_loss: 0.0902 - val_mse: 0.0981\n",
      "Epoch 778/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0762 - mse: 0.0954 - val_loss: 0.0895 - val_mse: 0.0993\n",
      "Epoch 779/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0761 - mse: 0.0956 - val_loss: 0.0893 - val_mse: 0.0998\n",
      "Epoch 780/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0758 - mse: 0.0954 - val_loss: 0.0897 - val_mse: 0.1002\n",
      "Epoch 781/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0758 - mse: 0.0953 - val_loss: 0.0894 - val_mse: 0.0991\n",
      "Epoch 782/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0759 - mse: 0.0959 - val_loss: 0.0898 - val_mse: 0.0979\n",
      "Epoch 783/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0758 - mse: 0.0955 - val_loss: 0.0890 - val_mse: 0.0985\n",
      "Epoch 784/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0756 - mse: 0.0952 - val_loss: 0.0912 - val_mse: 0.0972\n",
      "Epoch 785/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0760 - mse: 0.0953 - val_loss: 0.0896 - val_mse: 0.0991\n",
      "Epoch 786/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0758 - mse: 0.0955 - val_loss: 0.0894 - val_mse: 0.0971\n",
      "Epoch 787/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0760 - mse: 0.0955 - val_loss: 0.0893 - val_mse: 0.1003\n",
      "Epoch 788/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0758 - mse: 0.0949 - val_loss: 0.0893 - val_mse: 0.0972\n",
      "Epoch 789/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0760 - mse: 0.0958 - val_loss: 0.0895 - val_mse: 0.0992\n",
      "Epoch 790/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0758 - mse: 0.0954 - val_loss: 0.0892 - val_mse: 0.0993\n",
      "Epoch 791/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0757 - mse: 0.0949 - val_loss: 0.0891 - val_mse: 0.0986\n",
      "Epoch 792/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0758 - mse: 0.0948 - val_loss: 0.0894 - val_mse: 0.0980\n",
      "Epoch 793/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0758 - mse: 0.0951 - val_loss: 0.0892 - val_mse: 0.0995\n",
      "Epoch 794/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0759 - mse: 0.0958 - val_loss: 0.0896 - val_mse: 0.0987\n",
      "Epoch 795/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0755 - mse: 0.0957 - val_loss: 0.0901 - val_mse: 0.0983\n",
      "Epoch 796/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0757 - mse: 0.0952 - val_loss: 0.0891 - val_mse: 0.0980\n",
      "Epoch 797/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0756 - mse: 0.0954 - val_loss: 0.0894 - val_mse: 0.0975\n",
      "Epoch 798/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0757 - mse: 0.0947 - val_loss: 0.0900 - val_mse: 0.0985\n",
      "Epoch 799/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0756 - mse: 0.0948 - val_loss: 0.0893 - val_mse: 0.0994\n",
      "Epoch 800/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0755 - mse: 0.0950 - val_loss: 0.0893 - val_mse: 0.0971\n",
      "Epoch 801/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0756 - mse: 0.0950 - val_loss: 0.0896 - val_mse: 0.0992\n",
      "Epoch 802/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0757 - mse: 0.0949 - val_loss: 0.0894 - val_mse: 0.0996\n",
      "Epoch 803/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0755 - mse: 0.0950 - val_loss: 0.0897 - val_mse: 0.0985\n",
      "Epoch 804/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0754 - mse: 0.0944 - val_loss: 0.0898 - val_mse: 0.0985\n",
      "Epoch 805/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0757 - mse: 0.0950 - val_loss: 0.0898 - val_mse: 0.0983\n",
      "Epoch 806/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0756 - mse: 0.0951 - val_loss: 0.0892 - val_mse: 0.0976\n",
      "Epoch 807/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0758 - mse: 0.0952 - val_loss: 0.0905 - val_mse: 0.0985\n",
      "Epoch 808/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0756 - mse: 0.0951 - val_loss: 0.0899 - val_mse: 0.0991\n",
      "Epoch 809/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0755 - mse: 0.0946 - val_loss: 0.0902 - val_mse: 0.0999\n",
      "Epoch 810/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0753 - mse: 0.0945 - val_loss: 0.0895 - val_mse: 0.0980\n",
      "Epoch 811/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0757 - mse: 0.0949 - val_loss: 0.0899 - val_mse: 0.0986\n",
      "Epoch 812/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0757 - mse: 0.0949 - val_loss: 0.0899 - val_mse: 0.0992\n",
      "Epoch 813/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0754 - mse: 0.0945 - val_loss: 0.0893 - val_mse: 0.0998\n",
      "Epoch 814/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0756 - mse: 0.0955 - val_loss: 0.0896 - val_mse: 0.0995\n",
      "Epoch 815/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0755 - mse: 0.0947 - val_loss: 0.0897 - val_mse: 0.0989\n",
      "Epoch 816/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0754 - mse: 0.0945 - val_loss: 0.0895 - val_mse: 0.0982\n",
      "Epoch 817/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0754 - mse: 0.0953 - val_loss: 0.0907 - val_mse: 0.0981\n",
      "Epoch 818/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0753 - mse: 0.0943 - val_loss: 0.0901 - val_mse: 0.0992\n",
      "Epoch 819/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0753 - mse: 0.0947 - val_loss: 0.0897 - val_mse: 0.0992\n",
      "Epoch 820/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0755 - mse: 0.0947 - val_loss: 0.0892 - val_mse: 0.0977\n",
      "Epoch 821/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0753 - mse: 0.0952 - val_loss: 0.0897 - val_mse: 0.0986\n",
      "Epoch 822/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0754 - mse: 0.0948 - val_loss: 0.0896 - val_mse: 0.0996\n",
      "Epoch 823/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0755 - mse: 0.0948 - val_loss: 0.0894 - val_mse: 0.0993\n",
      "Epoch 824/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0756 - mse: 0.0950 - val_loss: 0.0898 - val_mse: 0.0990\n",
      "Epoch 825/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0755 - mse: 0.0947 - val_loss: 0.0902 - val_mse: 0.0993\n",
      "Epoch 826/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0753 - mse: 0.0950 - val_loss: 0.0895 - val_mse: 0.0984\n",
      "Epoch 827/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0751 - mse: 0.0946 - val_loss: 0.0895 - val_mse: 0.0967\n",
      "Epoch 828/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0756 - mse: 0.0951 - val_loss: 0.0893 - val_mse: 0.0977\n",
      "Epoch 829/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0751 - mse: 0.0946 - val_loss: 0.0895 - val_mse: 0.0986\n",
      "Epoch 830/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0753 - mse: 0.0943 - val_loss: 0.0897 - val_mse: 0.0989\n",
      "Epoch 831/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0753 - mse: 0.0945 - val_loss: 0.0899 - val_mse: 0.1003\n",
      "Epoch 832/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0750 - mse: 0.0946 - val_loss: 0.0906 - val_mse: 0.0990\n",
      "Epoch 833/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0754 - mse: 0.0945 - val_loss: 0.0896 - val_mse: 0.0995\n",
      "Epoch 834/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0751 - mse: 0.0944 - val_loss: 0.0895 - val_mse: 0.0996\n",
      "Epoch 835/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0752 - mse: 0.0949 - val_loss: 0.0901 - val_mse: 0.0997\n",
      "Epoch 836/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0751 - mse: 0.0942 - val_loss: 0.0897 - val_mse: 0.0981\n",
      "Epoch 837/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0750 - mse: 0.0942 - val_loss: 0.0894 - val_mse: 0.0984\n",
      "Epoch 838/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0751 - mse: 0.0941 - val_loss: 0.0895 - val_mse: 0.0995\n",
      "Epoch 839/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0750 - mse: 0.0946 - val_loss: 0.0891 - val_mse: 0.0979\n",
      "Epoch 840/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0750 - mse: 0.0945 - val_loss: 0.0898 - val_mse: 0.0984\n",
      "Epoch 841/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0753 - mse: 0.0948 - val_loss: 0.0899 - val_mse: 0.0983\n",
      "Epoch 842/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0751 - mse: 0.0940 - val_loss: 0.0895 - val_mse: 0.0980\n",
      "Epoch 843/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0750 - mse: 0.0944 - val_loss: 0.0896 - val_mse: 0.1001\n",
      "Epoch 844/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0752 - mse: 0.0944 - val_loss: 0.0893 - val_mse: 0.0986\n",
      "Epoch 845/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0751 - mse: 0.0942 - val_loss: 0.0898 - val_mse: 0.0977\n",
      "Epoch 846/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0749 - mse: 0.0941 - val_loss: 0.0895 - val_mse: 0.0987\n",
      "Epoch 847/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0753 - mse: 0.0945 - val_loss: 0.0895 - val_mse: 0.0983\n",
      "Epoch 848/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0748 - mse: 0.0944 - val_loss: 0.0903 - val_mse: 0.0974\n",
      "Epoch 849/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0749 - mse: 0.0943 - val_loss: 0.0896 - val_mse: 0.0996\n",
      "Epoch 850/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0749 - mse: 0.0947 - val_loss: 0.0900 - val_mse: 0.0993\n",
      "Epoch 851/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0751 - mse: 0.0944 - val_loss: 0.0895 - val_mse: 0.0992\n",
      "Epoch 852/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0749 - mse: 0.0943 - val_loss: 0.0896 - val_mse: 0.0982\n",
      "Epoch 853/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0749 - mse: 0.0941 - val_loss: 0.0898 - val_mse: 0.0988\n",
      "Epoch 854/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0748 - mse: 0.0943 - val_loss: 0.0906 - val_mse: 0.0980\n",
      "Epoch 855/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0750 - mse: 0.0946 - val_loss: 0.0901 - val_mse: 0.0998\n",
      "Epoch 856/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0747 - mse: 0.0940 - val_loss: 0.0901 - val_mse: 0.0997\n",
      "Epoch 857/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0751 - mse: 0.0947 - val_loss: 0.0896 - val_mse: 0.0999\n",
      "Epoch 858/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0751 - mse: 0.0942 - val_loss: 0.0898 - val_mse: 0.0997\n",
      "Epoch 859/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0748 - mse: 0.0943 - val_loss: 0.0891 - val_mse: 0.0985\n",
      "Epoch 860/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0747 - mse: 0.0941 - val_loss: 0.0900 - val_mse: 0.0987\n",
      "Epoch 861/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0748 - mse: 0.0942 - val_loss: 0.0897 - val_mse: 0.0969\n",
      "Epoch 862/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0746 - mse: 0.0939 - val_loss: 0.0896 - val_mse: 0.0986\n",
      "Epoch 863/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0750 - mse: 0.0938 - val_loss: 0.0900 - val_mse: 0.0993\n",
      "Epoch 864/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0746 - mse: 0.0940 - val_loss: 0.0896 - val_mse: 0.0991\n",
      "Epoch 865/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0747 - mse: 0.0939 - val_loss: 0.0896 - val_mse: 0.0965\n",
      "Epoch 866/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0747 - mse: 0.0939 - val_loss: 0.0898 - val_mse: 0.0984\n",
      "Epoch 867/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0748 - mse: 0.0943 - val_loss: 0.0892 - val_mse: 0.0984\n",
      "Epoch 868/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0747 - mse: 0.0940 - val_loss: 0.0895 - val_mse: 0.0979\n",
      "Epoch 869/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0746 - mse: 0.0940 - val_loss: 0.0899 - val_mse: 0.0970\n",
      "Epoch 870/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0750 - mse: 0.0940 - val_loss: 0.0899 - val_mse: 0.0982\n",
      "Epoch 871/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0750 - mse: 0.0946 - val_loss: 0.0910 - val_mse: 0.1024\n",
      "Epoch 872/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0747 - mse: 0.0940 - val_loss: 0.0902 - val_mse: 0.1002\n",
      "Epoch 873/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0745 - mse: 0.0938 - val_loss: 0.0905 - val_mse: 0.0995\n",
      "Epoch 874/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0749 - mse: 0.0941 - val_loss: 0.0904 - val_mse: 0.0992\n",
      "Epoch 875/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0747 - mse: 0.0944 - val_loss: 0.0896 - val_mse: 0.1004\n",
      "Epoch 876/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0747 - mse: 0.0945 - val_loss: 0.0897 - val_mse: 0.1000\n",
      "Epoch 877/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0745 - mse: 0.0940 - val_loss: 0.0897 - val_mse: 0.0991\n",
      "Epoch 878/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0745 - mse: 0.0939 - val_loss: 0.0902 - val_mse: 0.0993\n",
      "Epoch 879/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0744 - mse: 0.0939 - val_loss: 0.0900 - val_mse: 0.1004\n",
      "Epoch 880/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0744 - mse: 0.0938 - val_loss: 0.0893 - val_mse: 0.1004\n",
      "Epoch 881/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0745 - mse: 0.0939 - val_loss: 0.0904 - val_mse: 0.0986\n",
      "Epoch 882/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0744 - mse: 0.0939 - val_loss: 0.0902 - val_mse: 0.0980\n",
      "Epoch 883/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0746 - mse: 0.0939 - val_loss: 0.0894 - val_mse: 0.0998\n",
      "Epoch 884/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0747 - mse: 0.0942 - val_loss: 0.0909 - val_mse: 0.0996\n",
      "Epoch 885/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0746 - mse: 0.0940 - val_loss: 0.0898 - val_mse: 0.0988\n",
      "Epoch 886/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0745 - mse: 0.0942 - val_loss: 0.0902 - val_mse: 0.0984\n",
      "Epoch 887/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0744 - mse: 0.0942 - val_loss: 0.0901 - val_mse: 0.0964\n",
      "Epoch 888/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0744 - mse: 0.0941 - val_loss: 0.0899 - val_mse: 0.0991\n",
      "Epoch 889/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0744 - mse: 0.0942 - val_loss: 0.0895 - val_mse: 0.0983\n",
      "Epoch 890/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0743 - mse: 0.0936 - val_loss: 0.0898 - val_mse: 0.0979\n",
      "Epoch 891/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0744 - mse: 0.0937 - val_loss: 0.0900 - val_mse: 0.1000\n",
      "Epoch 892/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0743 - mse: 0.0939 - val_loss: 0.0900 - val_mse: 0.0986\n",
      "Epoch 893/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0743 - mse: 0.0936 - val_loss: 0.0910 - val_mse: 0.0982\n",
      "Epoch 894/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0743 - mse: 0.0937 - val_loss: 0.0896 - val_mse: 0.0992\n",
      "Epoch 895/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0744 - mse: 0.0942 - val_loss: 0.0903 - val_mse: 0.0965\n",
      "Epoch 896/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0743 - mse: 0.0936 - val_loss: 0.0899 - val_mse: 0.0998\n",
      "Epoch 897/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0743 - mse: 0.0940 - val_loss: 0.0901 - val_mse: 0.1002\n",
      "Epoch 898/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0744 - mse: 0.0937 - val_loss: 0.0902 - val_mse: 0.0986\n",
      "Epoch 899/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0743 - mse: 0.0938 - val_loss: 0.0903 - val_mse: 0.0999\n",
      "Epoch 900/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0743 - mse: 0.0939 - val_loss: 0.0893 - val_mse: 0.0990\n",
      "Epoch 901/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0743 - mse: 0.0940 - val_loss: 0.0900 - val_mse: 0.0986\n",
      "Epoch 902/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0744 - mse: 0.0943 - val_loss: 0.0901 - val_mse: 0.0998\n",
      "Epoch 903/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0742 - mse: 0.0940 - val_loss: 0.0898 - val_mse: 0.0990\n",
      "Epoch 904/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0742 - mse: 0.0938 - val_loss: 0.0913 - val_mse: 0.1011\n",
      "Epoch 905/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0743 - mse: 0.0940 - val_loss: 0.0899 - val_mse: 0.0983\n",
      "Epoch 906/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0743 - mse: 0.0939 - val_loss: 0.0910 - val_mse: 0.0973\n",
      "Epoch 907/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0746 - mse: 0.0945 - val_loss: 0.0902 - val_mse: 0.0991\n",
      "Epoch 908/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0743 - mse: 0.0937 - val_loss: 0.0906 - val_mse: 0.1007\n",
      "Epoch 909/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0742 - mse: 0.0935 - val_loss: 0.0903 - val_mse: 0.0974\n",
      "Epoch 910/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0742 - mse: 0.0936 - val_loss: 0.0905 - val_mse: 0.0983\n",
      "Epoch 911/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0744 - mse: 0.0940 - val_loss: 0.0904 - val_mse: 0.0994\n",
      "Epoch 912/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0746 - mse: 0.0939 - val_loss: 0.0902 - val_mse: 0.0987\n",
      "Epoch 913/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0742 - mse: 0.0936 - val_loss: 0.0900 - val_mse: 0.1002\n",
      "Epoch 914/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0739 - mse: 0.0939 - val_loss: 0.0900 - val_mse: 0.0989\n",
      "Epoch 915/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0741 - mse: 0.0936 - val_loss: 0.0900 - val_mse: 0.0997\n",
      "Epoch 916/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0741 - mse: 0.0934 - val_loss: 0.0898 - val_mse: 0.0986\n",
      "Epoch 917/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0740 - mse: 0.0934 - val_loss: 0.0899 - val_mse: 0.0973\n",
      "Epoch 918/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0741 - mse: 0.0937 - val_loss: 0.0897 - val_mse: 0.0984\n",
      "Epoch 919/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0741 - mse: 0.0937 - val_loss: 0.0901 - val_mse: 0.0979\n",
      "Epoch 920/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0741 - mse: 0.0937 - val_loss: 0.0899 - val_mse: 0.0985\n",
      "Epoch 921/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0738 - mse: 0.0934 - val_loss: 0.0911 - val_mse: 0.0990\n",
      "Epoch 922/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0740 - mse: 0.0933 - val_loss: 0.0900 - val_mse: 0.0996\n",
      "Epoch 923/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0739 - mse: 0.0940 - val_loss: 0.0904 - val_mse: 0.1001\n",
      "Epoch 924/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0741 - mse: 0.0934 - val_loss: 0.0901 - val_mse: 0.0980\n",
      "Epoch 925/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0739 - mse: 0.0937 - val_loss: 0.0906 - val_mse: 0.1012\n",
      "Epoch 926/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0742 - mse: 0.0939 - val_loss: 0.0898 - val_mse: 0.0994\n",
      "Epoch 927/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0738 - mse: 0.0934 - val_loss: 0.0905 - val_mse: 0.1000\n",
      "Epoch 928/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0740 - mse: 0.0932 - val_loss: 0.0901 - val_mse: 0.0991\n",
      "Epoch 929/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0740 - mse: 0.0935 - val_loss: 0.0905 - val_mse: 0.0992\n",
      "Epoch 930/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0738 - mse: 0.0934 - val_loss: 0.0900 - val_mse: 0.0977\n",
      "Epoch 931/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0740 - mse: 0.0937 - val_loss: 0.0899 - val_mse: 0.0989\n",
      "Epoch 932/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0738 - mse: 0.0933 - val_loss: 0.0899 - val_mse: 0.1002\n",
      "Epoch 933/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0739 - mse: 0.0932 - val_loss: 0.0900 - val_mse: 0.0992\n",
      "Epoch 934/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0740 - mse: 0.0936 - val_loss: 0.0903 - val_mse: 0.1004\n",
      "Epoch 935/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0741 - mse: 0.0933 - val_loss: 0.0900 - val_mse: 0.0987\n",
      "Epoch 936/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0737 - mse: 0.0936 - val_loss: 0.0904 - val_mse: 0.0980\n",
      "Epoch 937/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0739 - mse: 0.0934 - val_loss: 0.0901 - val_mse: 0.0987\n",
      "Epoch 938/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0740 - mse: 0.0936 - val_loss: 0.0904 - val_mse: 0.0978\n",
      "Epoch 939/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0738 - mse: 0.0934 - val_loss: 0.0899 - val_mse: 0.0982\n",
      "Epoch 940/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0736 - mse: 0.0937 - val_loss: 0.0901 - val_mse: 0.0989\n",
      "Epoch 941/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0740 - mse: 0.0938 - val_loss: 0.0912 - val_mse: 0.0987\n",
      "Epoch 942/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0738 - mse: 0.0933 - val_loss: 0.0902 - val_mse: 0.0977\n",
      "Epoch 943/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0735 - mse: 0.0934 - val_loss: 0.0907 - val_mse: 0.1000\n",
      "Epoch 944/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0737 - mse: 0.0931 - val_loss: 0.0901 - val_mse: 0.0981\n",
      "Epoch 945/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0738 - mse: 0.0937 - val_loss: 0.0904 - val_mse: 0.0994\n",
      "Epoch 946/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0737 - mse: 0.0932 - val_loss: 0.0901 - val_mse: 0.0984\n",
      "Epoch 947/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0738 - mse: 0.0934 - val_loss: 0.0909 - val_mse: 0.0976\n",
      "Epoch 948/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0738 - mse: 0.0933 - val_loss: 0.0899 - val_mse: 0.0981\n",
      "Epoch 949/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0740 - mse: 0.0929 - val_loss: 0.0908 - val_mse: 0.1001\n",
      "Epoch 950/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0736 - mse: 0.0934 - val_loss: 0.0903 - val_mse: 0.1003\n",
      "Epoch 951/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0735 - mse: 0.0931 - val_loss: 0.0901 - val_mse: 0.0975\n",
      "Epoch 952/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0737 - mse: 0.0930 - val_loss: 0.0905 - val_mse: 0.0993\n",
      "Epoch 953/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0735 - mse: 0.0933 - val_loss: 0.0899 - val_mse: 0.0994\n",
      "Epoch 954/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0736 - mse: 0.0929 - val_loss: 0.0899 - val_mse: 0.0988\n",
      "Epoch 955/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0734 - mse: 0.0932 - val_loss: 0.0899 - val_mse: 0.0971\n",
      "Epoch 956/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0735 - mse: 0.0930 - val_loss: 0.0901 - val_mse: 0.0990\n",
      "Epoch 957/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0736 - mse: 0.0930 - val_loss: 0.0906 - val_mse: 0.0994\n",
      "Epoch 958/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0735 - mse: 0.0934 - val_loss: 0.0902 - val_mse: 0.0981\n",
      "Epoch 959/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0735 - mse: 0.0931 - val_loss: 0.0904 - val_mse: 0.1004\n",
      "Epoch 960/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0736 - mse: 0.0931 - val_loss: 0.0902 - val_mse: 0.0980\n",
      "Epoch 961/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0737 - mse: 0.0932 - val_loss: 0.0905 - val_mse: 0.0980\n",
      "Epoch 962/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0736 - mse: 0.0931 - val_loss: 0.0905 - val_mse: 0.0996\n",
      "Epoch 963/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0736 - mse: 0.0929 - val_loss: 0.0903 - val_mse: 0.0990\n",
      "Epoch 964/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0734 - mse: 0.0928 - val_loss: 0.0903 - val_mse: 0.1006\n",
      "Epoch 965/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0734 - mse: 0.0931 - val_loss: 0.0901 - val_mse: 0.0981\n",
      "Epoch 966/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0735 - mse: 0.0936 - val_loss: 0.0908 - val_mse: 0.1017\n",
      "Epoch 967/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0737 - mse: 0.0941 - val_loss: 0.0905 - val_mse: 0.1004\n",
      "Epoch 968/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0734 - mse: 0.0929 - val_loss: 0.0904 - val_mse: 0.0990\n",
      "Epoch 969/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0735 - mse: 0.0933 - val_loss: 0.0905 - val_mse: 0.1003\n",
      "Epoch 970/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0734 - mse: 0.0927 - val_loss: 0.0905 - val_mse: 0.0998\n",
      "Epoch 971/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0734 - mse: 0.0931 - val_loss: 0.0902 - val_mse: 0.0989\n",
      "Epoch 972/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0733 - mse: 0.0932 - val_loss: 0.0908 - val_mse: 0.0993\n",
      "Epoch 973/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0735 - mse: 0.0935 - val_loss: 0.0907 - val_mse: 0.0985\n",
      "Epoch 974/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0736 - mse: 0.0930 - val_loss: 0.0899 - val_mse: 0.0989\n",
      "Epoch 975/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0733 - mse: 0.0931 - val_loss: 0.0905 - val_mse: 0.0981\n",
      "Epoch 976/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0734 - mse: 0.0933 - val_loss: 0.0905 - val_mse: 0.0999\n",
      "Epoch 977/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0731 - mse: 0.0931 - val_loss: 0.0901 - val_mse: 0.1003\n",
      "Epoch 978/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0734 - mse: 0.0927 - val_loss: 0.0905 - val_mse: 0.0977\n",
      "Epoch 979/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0731 - mse: 0.0932 - val_loss: 0.0904 - val_mse: 0.0999\n",
      "Epoch 980/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0736 - mse: 0.0934 - val_loss: 0.0900 - val_mse: 0.0987\n",
      "Epoch 981/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0734 - mse: 0.0924 - val_loss: 0.0905 - val_mse: 0.0991\n",
      "Epoch 982/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0735 - mse: 0.0935 - val_loss: 0.0902 - val_mse: 0.0996\n",
      "Epoch 983/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0731 - mse: 0.0931 - val_loss: 0.0910 - val_mse: 0.1016\n",
      "Epoch 984/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0732 - mse: 0.0928 - val_loss: 0.0906 - val_mse: 0.0975\n",
      "Epoch 985/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0731 - mse: 0.0926 - val_loss: 0.0904 - val_mse: 0.0982\n",
      "Epoch 986/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0735 - mse: 0.0934 - val_loss: 0.0901 - val_mse: 0.0988\n",
      "Epoch 987/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0733 - mse: 0.0930 - val_loss: 0.0912 - val_mse: 0.1022\n",
      "Epoch 988/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0735 - mse: 0.0937 - val_loss: 0.0903 - val_mse: 0.0993\n",
      "Epoch 989/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0731 - mse: 0.0930 - val_loss: 0.0905 - val_mse: 0.0991\n",
      "Epoch 990/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0732 - mse: 0.0931 - val_loss: 0.0905 - val_mse: 0.0987\n",
      "Epoch 991/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0731 - mse: 0.0931 - val_loss: 0.0903 - val_mse: 0.0992\n",
      "Epoch 992/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0731 - mse: 0.0928 - val_loss: 0.0900 - val_mse: 0.0993\n",
      "Epoch 993/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0734 - mse: 0.0931 - val_loss: 0.0906 - val_mse: 0.0980\n",
      "Epoch 994/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0730 - mse: 0.0928 - val_loss: 0.0902 - val_mse: 0.0981\n",
      "Epoch 995/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0730 - mse: 0.0932 - val_loss: 0.0901 - val_mse: 0.0995\n",
      "Epoch 996/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0730 - mse: 0.0928 - val_loss: 0.0911 - val_mse: 0.0982\n",
      "Epoch 997/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0733 - mse: 0.0929 - val_loss: 0.0904 - val_mse: 0.0999\n",
      "Epoch 998/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0730 - mse: 0.0926 - val_loss: 0.0908 - val_mse: 0.1004\n",
      "Epoch 999/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0731 - mse: 0.0930 - val_loss: 0.0907 - val_mse: 0.0990\n",
      "Epoch 1000/1000\n",
      "784/784 [==============================] - 2s 2ms/step - loss: 0.0732 - mse: 0.0935 - val_loss: 0.0903 - val_mse: 0.0979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4b343dad90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=hparams['batch_size'], epochs=hparams['num_epochs'], shuffle=True, verbose=1, validation_data=(X_val, y_val), callbacks=[tensorboard_callback, model_checkpoint_callback, hparam_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee41038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_model = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c931b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_arr = evaluated_model.mean().numpy()\n",
    "std_arr = evaluated_model.stddev().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84e76080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26918253, 0.23513785, 0.5517509 , ..., 0.6127168 , 1.3161615 ,\n",
       "       0.65500635], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.ravel(mean_arr) # to make ndim = 1\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d8e7244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae63ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = get_point_metrics(pd.Series(y_pred), pd.Series(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3548d01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zspec_bin</th>\n",
       "      <th>count</th>\n",
       "      <th>L</th>\n",
       "      <th>bias_bw</th>\n",
       "      <th>bias_conv</th>\n",
       "      <th>scatter_bw</th>\n",
       "      <th>scatter_conv</th>\n",
       "      <th>outlier_bw</th>\n",
       "      <th>outlier_conv</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 4.0]</td>\n",
       "      <td>42960</td>\n",
       "      <td>0.092342</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.030077</td>\n",
       "      <td>0.025085</td>\n",
       "      <td>0.151909</td>\n",
       "      <td>0.061336</td>\n",
       "      <td>0.099928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    zspec_bin  count         L   bias_bw  bias_conv  scatter_bw  scatter_conv  \\\n",
       "0  (0.0, 4.0]  42960  0.092342  0.001236   0.001622    0.030077      0.025085   \n",
       "\n",
       "   outlier_bw  outlier_conv       mse  \n",
       "0    0.151909      0.061336  0.099928  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e872876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred, columns=['photoz'])\n",
    "df['photz_err'] = np.ravel(std_arr)\n",
    "df['specz'] = y_test\n",
    "df['object_id'] = OID_test\n",
    "if os.path.exists(f'/predictions/{model_name}') == False:\n",
    "    os.makedirs(f'/predictions/{model_name}')\n",
    "    \n",
    "df.to_csv(f'/predictions/{model_name}/testing_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69959e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f'predictions/{model_name}') ==  False:\n",
    "    os.makedirs(f'predictions/{model_name}')\n",
    "    \n",
    "metrics.to_csv(f'/predictions/{model_name}/testing_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6ed7a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2.17865\n",
       "1         0.84550\n",
       "2         0.44850\n",
       "3         0.37001\n",
       "4         0.58149\n",
       "           ...   \n",
       "200476    1.86393\n",
       "200477    0.89864\n",
       "200478    0.24194\n",
       "200479    0.77584\n",
       "200480    1.06695\n",
       "Name: specz_redshift, Length: 200481, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d522aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

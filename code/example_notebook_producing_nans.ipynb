{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import data set\n",
    "import numpy as np\n",
    "mnist = tf.keras.datasets.mnist\n",
    "import random\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import data set\n",
    "import numpy as np\n",
    "mnist = tf.keras.datasets.mnist\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "tfd = tfp.distributions\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import pandas as pd\n",
    "#import data set\n",
    "import numpy as np\n",
    "mnist = tf.keras.datasets.mnist\n",
    "import random\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "#import photoz data:\n",
    "tfd = tfp.distributions\n",
    "#from google.colab import files\n",
    "\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#photozdata = pd.read_csv('~/Downloads/forced_forced2_spec_z_matched_online.csv')\n",
    "\n",
    "#photozdata = pd.read_csv('~/Downloads/forced_forced2_spec_z_matched_online.csv')\n",
    "photozdata = pd.read_csv('~/Downloads/trimmed_forced_forced2_spec_z_matched_online.csv')\n",
    "\n",
    "\n",
    "filt = (photozdata['specz_redshift'] < 4) & (photozdata['specz_redshift'] > 0) & (photozdata['specz_redshift_err'] >0) \\\n",
    "       & (photozdata['specz_redshift_err'] < 1)\n",
    "photozdata_subset = photozdata[filt]\n",
    "\n",
    "photozdata = photozdata_subset\n",
    "spectro_z = np.asarray(photozdata[\"specz_redshift\"])\n",
    "col1 = np.asarray(photozdata[\"g_cmodel_mag\"])\n",
    "col2 = np.asarray(photozdata[\"r_cmodel_mag\"])\n",
    "col3 = np.asarray(photozdata[\"i_cmodel_mag\"])\n",
    "col4 =np.asarray(photozdata[\"z_cmodel_mag\"])\n",
    "col5 = np.asarray(photozdata[\"y_cmodel_mag\"])\n",
    "\n",
    "\n",
    "photodata = {'col1':col1,\n",
    "             'col2':col2,\n",
    "             'col3':col3,\n",
    "             'col4':col4,\n",
    "             'col5':col5,\n",
    "             'specz':spectro_z\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(photodata)\n",
    "photodata = df\n",
    "\n",
    "photodata.replace(-99., np.nan, inplace=True)\n",
    "photodata.replace(-99.9, np.nan, inplace=True)\n",
    "photodata.replace(np.inf, np.nan, inplace=True)\n",
    "\n",
    "spectro_z = photodata['specz']\n",
    "photodata = photodata.drop(\"specz\", axis=1)\n",
    "\n",
    "\n",
    "#normalize\n",
    "#photodata = min_max_scaler.fit_transform(photodata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75f7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[D 17:11:05.590 NotebookApp]\u001b[m Searching ['/home/ejones', '/home/ejones/.jupyter', '/opt/anaconda3/envs/jupyterhub/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files\n",
      "\u001b[34m[D 17:11:05.590 NotebookApp]\u001b[m Looking for jupyter_config in /etc/jupyter\n",
      "\u001b[34m[D 17:11:05.590 NotebookApp]\u001b[m Looking for jupyter_config in /usr/local/etc/jupyter\n",
      "\u001b[34m[D 17:11:05.590 NotebookApp]\u001b[m Looking for jupyter_config in /opt/anaconda3/envs/jupyterhub/etc/jupyter\n",
      "\u001b[34m[D 17:11:05.590 NotebookApp]\u001b[m Loaded config file: /opt/anaconda3/envs/jupyterhub/etc/jupyter/jupyter_config.json\n",
      "\u001b[34m[D 17:11:05.590 NotebookApp]\u001b[m Looking for jupyter_config in /home/ejones/.jupyter\n",
      "\u001b[34m[D 17:11:05.590 NotebookApp]\u001b[m Looking for jupyter_config in /home/ejones\n",
      "\u001b[34m[D 17:11:05.592 NotebookApp]\u001b[m Looking for jupyter_notebook_config in /etc/jupyter\n",
      "\u001b[34m[D 17:11:05.592 NotebookApp]\u001b[m Looking for jupyter_notebook_config in /usr/local/etc/jupyter\n",
      "\u001b[34m[D 17:11:05.592 NotebookApp]\u001b[m Looking for jupyter_notebook_config in /opt/anaconda3/envs/jupyterhub/etc/jupyter\n",
      "\u001b[34m[D 17:11:05.592 NotebookApp]\u001b[m Looking for jupyter_notebook_config in /home/ejones/.jupyter\n",
      "\u001b[34m[D 17:11:05.592 NotebookApp]\u001b[m Loaded config file: /home/ejones/.jupyter/jupyter_notebook_config.json\n",
      "\u001b[34m[D 17:11:05.592 NotebookApp]\u001b[m Looking for jupyter_notebook_config in /home/ejones\n",
      "\u001b[34m[D 17:11:05.593 NotebookApp]\u001b[m [nb_conda_kernels] refreshing conda info\n",
      "\u001b[32m[I 17:11:05.935 NotebookApp]\u001b[m [nb_conda_kernels] enabled, 8 kernels found\n",
      "\u001b[34m[D 17:11:05.938 NotebookApp]\u001b[m Paths used for configuration of jupyter_notebook_config: \n",
      "    \t/etc/jupyter/jupyter_notebook_config.json\n",
      "\u001b[34m[D 17:11:05.939 NotebookApp]\u001b[m Paths used for configuration of jupyter_notebook_config: \n",
      "    \t/usr/local/etc/jupyter/jupyter_notebook_config.json\n",
      "\u001b[34m[D 17:11:05.939 NotebookApp]\u001b[m Paths used for configuration of jupyter_notebook_config: \n",
      "    \t/opt/anaconda3/envs/jupyterhub/etc/jupyter/jupyter_notebook_config.json\n",
      "\u001b[34m[D 17:11:05.939 NotebookApp]\u001b[m Paths used for configuration of jupyter_notebook_config: \n",
      "    \t/home/ejones/.jupyter/jupyter_notebook_config.json\n",
      "\u001b[32m[I 17:11:06.108 NotebookApp]\u001b[m Serving notebooks from local directory: /home/ejones\n",
      "\u001b[32m[I 17:11:06.108 NotebookApp]\u001b[m Jupyter Notebook 6.4.0 is running at:\n",
      "\u001b[32m[I 17:11:06.108 NotebookApp]\u001b[m http://localhost:8888/\n",
      "\u001b[32m[I 17:11:06.108 NotebookApp]\u001b[m Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
      "\u001b[33m[W 17:11:06.110 NotebookApp]\u001b[m No web browser found: could not locate runnable browser.\n"
     ]
    }
   ],
   "source": [
    "!jupyter notebook --debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e908c47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 500)          3000        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 500)          250500      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 500)          250500      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 500)          250500      dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 505)          0           input_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            506         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 755,006\n",
      "Trainable params: 755,006\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/25\n",
      "3/3 [==============================] - 1s 59ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 2/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 3/25\n",
      "3/3 [==============================] - 0s 23ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 4/25\n",
      "3/3 [==============================] - 0s 22ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 5/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 6/25\n",
      "3/3 [==============================] - 0s 21ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 7/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 8/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 9/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 10/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 11/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 12/25\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 13/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 14/25\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 15/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 16/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 17/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 18/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 19/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 20/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 21/25\n",
      "3/3 [==============================] - 0s 21ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 22/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 23/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 24/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 25/25\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% correct:  0.0\n",
      "number of outliers:  0  out of  114849\n",
      "% of outliers:  0.0\n",
      "number of catastrophic outliers:  0  out of  114849\n",
      "% of catastrophic outliers:  0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#bin the redshift:\n",
    "\n",
    "bin_size = 0.1\n",
    "\n",
    "\n",
    "x_train ,x_test,y_train,y_test = train_test_split(photodata,spectro_z,test_size=0.9)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_train = np.round(y_train/bin_size)\n",
    "y_test = np.array(y_test)\n",
    "y_test_original = y_test\n",
    "y_test = np.round(y_test/bin_size)\n",
    "\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "\n",
    "#bin_size = 0.12\n",
    "def random_gaussian_initializer(shape, dtype):\n",
    "    n = int(shape / 2)\n",
    "    loc_norm = tf.random_normal_initializer(mean=0., stddev=0.1)\n",
    "    loc = tf.Variable(\n",
    "        initial_value=loc_norm(shape=(n,), dtype=dtype)\n",
    "    )\n",
    "    scale_norm = tf.random_normal_initializer(mean=-3., stddev=0.1)\n",
    "    scale = tf.Variable(\n",
    "        initial_value=scale_norm(shape=(n,), dtype=dtype)\n",
    "    )\n",
    "    return tf.concat([loc, scale], 0)\n",
    "def prior_trainable(kernel_size: int, bias_size: int, dtype: any) -> tf.keras.Model:\n",
    "    \"\"\"Specify the prior over `keras.layers.Dense` `kernel` and `bias`.\"\"\"\n",
    "    n = kernel_size + bias_size\n",
    "\n",
    "    return tf.keras.Sequential([\n",
    "        tfp.layers.VariableLayer(n, dtype=dtype),  # Returns a trainable variable of shape n, regardless of input\n",
    "        tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "            tfd.Normal(loc=t, scale=1),\n",
    "            reinterpreted_batch_ndims=1)),\n",
    "    ])\n",
    "\n",
    "def posterior_mean_field(kernel_size: int, bias_size: int, dtype: any) -> tf.keras.Model:\n",
    "    \"\"\"Specify the surrogate posterior over `keras.layers.Dense` `kernel` and `bias`.\"\"\"\n",
    "    n = kernel_size + bias_size\n",
    "    c = np.log(np.expm1(1.))\n",
    "\n",
    "    return tf.keras.Sequential([\n",
    "        tfp.layers.VariableLayer(2 * n, dtype=dtype),\n",
    "        tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "            tfd.Normal(loc=t[..., :n],\n",
    "                       scale=1e-5 + 0.000001*tf.nn.softplus(c + t[..., n:])),\n",
    "            reinterpreted_batch_ndims=1)),\n",
    "    ])\n",
    "\n",
    "\n",
    "def prior_trainable(kernel_size: int, bias_size: int, dtype: any) -> tf.keras.Model:\n",
    "    \"\"\"Specify the prior over `keras.layers.Dense` `kernel` and `bias`.\"\"\"\n",
    "    n = kernel_size + bias_size\n",
    "\n",
    "    return tf.keras.Sequential([\n",
    "        tfp.layers.VariableLayer(n, dtype=dtype),  # Returns a trainable variable of shape n, regardless of input\n",
    "        tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "            tfd.Normal(loc=t, scale=1),\n",
    "            reinterpreted_batch_ndims=1)),\n",
    "    ])\n",
    "\n",
    "def negative_loglikelihood(targets, estimated_distribution):\n",
    "    return -estimated_distribution.log_prob(targets)\n",
    "\n",
    "#network architecture\n",
    "#relu stands for rectified linear - modern standard for general application, I think\n",
    "# model = tf.keras.Sequential([\n",
    "#     #tf.keras.layers.Conv2D(40,(3,3),activation='relu',input_shape=(5,)),\n",
    "#     tfp.layers.DenseVariational(320,activation='relu', input_shape=(10,),\n",
    "#                                 make_posterior_fn=posterior_mean_field,\n",
    "#                                 make_prior_fn=prior_trainable),\n",
    "#     tf.keras.layers.Dense(160, activation='relu'),\n",
    "#     tf.keras.layers.Dense(160, activation='relu'),\n",
    "#     tf.keras.layers.Dense(80,activation='softmax'),\n",
    "# ])\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     #tf.keras.layers.Conv2D(40,(3,3),activation='relu',input_shape=(5,)),\n",
    "#     tfp.layers.DenseVariational(320,activation='relu', input_shape=(10,),\n",
    "#                                 make_posterior_fn=posterior_mean_field,\n",
    "#                                 make_prior_fn=prior_trainable),\n",
    "#     tf.keras.layers.Dense(160, activation='relu'),\n",
    "#     tf.keras.layers.Dense(160, activation='relu'),\n",
    "#     tf.keras.layers.Dense(80,activation='softmax'),\n",
    "#     tf.keras.layers.Concatenate()(),\n",
    "#     tf.keras.layers.Dense(1),\n",
    "# ])\n",
    "\n",
    "# input_ = tf.keras.layers.Input(shape=x_train.shape[1:])\n",
    "# hidden1 = tfp.layers.DenseVariational(50, activation='relu', input_shape=(5,),\n",
    "#                                 make_posterior_fn=posterior_mean_field,\n",
    "#                                 make_prior_fn=prior_trainable)(input_)\n",
    "# hidden2 = tfp.layers.DenseVariational(50, activation='relu', input_shape=(5,),\n",
    "#                                 make_posterior_fn=posterior_mean_field,\n",
    "#                                 make_prior_fn=prior_trainable)(hidden1)\n",
    "# hidden3 = tfp.layers.DenseVariational(50, activation='relu', input_shape=(5,),\n",
    "#                                 make_posterior_fn=posterior_mean_field,\n",
    "#                                 make_prior_fn=prior_trainable)(hidden2)\n",
    "# hidden4 = tfp.layers.DenseVariational(50, activation='relu', input_shape=(5,),\n",
    "#                                 make_posterior_fn=posterior_mean_field,\n",
    "#                                 make_prior_fn=prior_trainable)(hidden3)\n",
    "# concat = tf.keras.layers.Concatenate()([input_, hidden4])\n",
    "# #output = tf.keras.layers.Dense(1)(concat)\n",
    "# distribution_params = tf.keras.layers.Dense(units=2)(concat)\n",
    "# output = tfp.layers.IndependentNormal(1)(distribution_params)\n",
    "# model = tf.keras.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "input_ = tf.keras.layers.Input(shape=x_train.shape[1:])\n",
    "hidden1 = tf.keras.layers.Dense(500, activation=\"relu\")(input_)\n",
    "hidden2 = tf.keras.layers.Dense(500, activation=\"relu\")(hidden1)\n",
    "hidden3 = tf.keras.layers.Dense(500, activation=\"relu\")(hidden2)\n",
    "hidden4 = tf.keras.layers.Dense(500, activation=\"relu\")(hidden3)\n",
    "concat = tf.keras.layers.Concatenate()([input_, hidden4])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "model = tf.keras.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "\n",
    "\n",
    "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error',metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "#model.compile(optimizer='adam', loss=negative_loglikelihood,metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#history = model.fit(x_train,y_train,batch_size = 100, epochs=500,shuffle = True,verbose=1,validation_data=(x_test,y_test))\n",
    "history = model.fit(x_train,y_train,batch_size=5000,epochs=25,shuffle = True,verbose=1,validation_data=(x_test,y_test))\n",
    "\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "np.argmax(predictions[0])\n",
    "photoz = []\n",
    "for i in range(0,len(y_test)):\n",
    "    photoz.append(predictions[i]*bin_size)\n",
    "\n",
    "plt.scatter(y_test_original,photoz)\n",
    "#plt.title('Photo-z determination')\n",
    "plt.ylabel('spectro-z')\n",
    "plt.xlabel('photo-z')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "num_correct = 0\n",
    "outliers = []\n",
    "outlier_index = []\n",
    "cat_outlier_index = []\n",
    "#y_test = y_test * bin_size\n",
    "for i in range(0,len(y_test)):\n",
    "\n",
    "    if abs(photoz[i] - (y_test[i])*bin_size) < 0.0001:\n",
    "\n",
    "        num_correct = num_correct + 1\n",
    "\n",
    "    outliers.append(abs(photoz[i] - y_test_original[i])/(1+y_test_original[i]))\n",
    "\n",
    "    if outliers[i] > 0.15:\n",
    "            outlier_index.append(i)\n",
    "\n",
    "\n",
    "    if outliers[i] > 1:\n",
    "            cat_outlier_index.append(i)\n",
    "\n",
    "\n",
    "\n",
    "print(\"% correct: \", 100.0*num_correct/len(y_test))\n",
    "print(\"number of outliers: \", len(outlier_index), \" out of \", len(y_test))\n",
    "print(\"% of outliers: \", 100.0*len(outlier_index)/len(y_test))\n",
    "print(\"number of catastrophic outliers: \", len(cat_outlier_index), \" out of \", len(y_test))\n",
    "print(\"% of catastrophic outliers: \", len(cat_outlier_index)/len(y_test))\n",
    "\n",
    "#calculate RMS error:\n",
    "RMS_error = np.sqrt(np.sum(((abs(photoz - y_test_original)/(1+y_test_original))**2))/len(y_test))\n",
    "squares = [x*x for x in outliers]\n",
    "RMS_error_2 = np.sqrt(np.sum(squares)/len(y_test))\n",
    "print(\"RMS error: \", RMS_error_2)\n",
    "\n",
    "#calculating RMSE another way:\n",
    "RMSE = mean_squared_error(y_test_original,photoz, squared = False)\n",
    "print(\"RMS error = \", RMSE)\n",
    "# ;  if plot EQ 1 then begin\n",
    "# ;    plot, temporary(testredshift), temporary(output), psym = 1, XRANGE = [0, 4], YRANGE = [0,\n",
    "#                                                                                             4], title = 'Photo-z vs Spectro-z', xtitle = 'spectroscopic redshift', ytitle = 'photo-z'\n",
    "# ;    PLOTS, [.18, 1.6 * 2], [0, 1.2 * 2]\n",
    "# ;    PLOTS, [0, 1.6 * 2], [.15, 2 * 2]\n",
    "# ;  endif\n",
    "\n",
    "\n",
    "plt.scatter(y_test_original,photoz, marker='+',color = 'black')\n",
    "#plt.title('Photo-z determination')\n",
    "plt.xlabel('spectroscopic redshift')\n",
    "plt.ylabel('photo z')\n",
    "plt.plot([.18,1.6*2.4],[0,1.2*2.4], color='black')\n",
    "plt.plot([0, 1.6 * 2.4], [.15, 2 * 2.4],color = 'black')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da2073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

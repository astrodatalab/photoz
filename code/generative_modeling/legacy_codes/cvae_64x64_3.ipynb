{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f923d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "write = False # log this version as new\n",
    "MODEL_DESCRIPTION = \"Stratified Learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d23f862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 10:29:56.268622: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-03 10:29:56.776200: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import stdout\n",
    "from datetime import datetime\n",
    "import neptune as neptune\n",
    "from neptune.integrations.tensorflow_keras import NeptuneCallback\n",
    "from astropy.io import fits\n",
    "import random\n",
    "from DataMaker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2032fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import Cropping2D, ZeroPadding2D, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Reshape\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import layers as tfpl\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow.nn import leaky_relu\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e0800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 128\n",
    "BASE_DEPTH = 8\n",
    "IMAGE_SHAPE = (5, 64, 64)\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 250\n",
    "CHECKPOINTS_TO_SAVE = 4\n",
    "KL_WEIGHT = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a44e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 10:29:58.383362: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-03 10:29:58.408283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-03 10:29:58.408484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-03 10:29:58.410202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-03 10:29:58.410352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-03 10:29:58.410485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-03 10:29:59.014671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-03 10:29:59.014869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-03 10:29:59.015006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-03 10:29:59.015113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20000 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU');\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 20000)]);\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU');\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb7cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "DATASET_NAME = \"HSC_v6\"\n",
    "MODEL_TYPE = \"CVAE\"\n",
    "MODEL_VERSION = \"v1.0\"\n",
    "MODEL_SUBVERSION = \"v1.0.\" + now.strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "\n",
    "model_id = '_'.join([DATASET_NAME, MODEL_TYPE, MODEL_VERSION])\n",
    "model_path = os.path.join('/data3/Billy/models', model_id, MODEL_SUBVERSION, 'model')\n",
    "checkpoints_path = os.path.join('/data3/Billy/models', model_id, MODEL_SUBVERSION, 'checkpoints')\n",
    "logs_path = os.path.join('/data3/Billy/logs', model_id, MODEL_SUBVERSION)\n",
    "predictions_path = os.path.join('/data3/Billy/predictions', model_id, MODEL_SUBVERSION)\n",
    "weights_path = model_path + '/data3/Billy/CVAE/weights.h5'\n",
    "\n",
    "os.makedirs(model_path, exist_ok = True)\n",
    "os.makedirs(checkpoints_path, exist_ok = True)\n",
    "os.makedirs(logs_path, exist_ok = True)\n",
    "os.makedirs(predictions_path, exist_ok = True)\n",
    "\n",
    "if write == True:\n",
    "    with open(\"/data3/Billy/models/README.md\", \"a\") as myfile:\n",
    "        myfile.write(MODEL_TYPE + \" \" + MODEL_SUBVERSION + \" - \" + MODEL_DESCRIPTION + \" - B. Li\" + \"\\n\")\n",
    "else:\n",
    "    with open(\"/data3/Billy/models/README.md\", \"a\") as myfile:\n",
    "        myfile.write(MODEL_TYPE + \" \" + MODEL_SUBVERSION + \" - ... \"+ \" - B. Li\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc0eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_gen = {'X_key': 'image',\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': False}\n",
    "\n",
    "train_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step3A/64x64_training.hdf5', **args_gen)\n",
    "test_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step3A/64x64_testing.hdf5', **args_gen)\n",
    "val_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step3A/64x64_validation.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "588c99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = BATCH_SIZE\n",
    "l = len(train_gen._indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d31d75f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(LATENT_DIM), scale = 1.0), reinterpreted_batch_ndims = 1)\n",
    "\n",
    "# Encoder\n",
    "images = Input(shape = IMAGE_SHAPE)\n",
    "redshifts = Input(shape = (1,))\n",
    "conv1 = Conv2D(32, 3, strides = 2, activation = \"relu\", padding = 'same', data_format = 'channels_first')(images)\n",
    "conv2 = Conv2D(64, 3, strides = 2, activation = \"relu\", padding = 'same', data_format = 'channels_first')(conv1)\n",
    "conv3 = Conv2D(128, 2, strides = 1, activation = \"relu\", padding = 'same', data_format = 'channels_first')(conv2)\n",
    "flatten = Flatten()(conv3)\n",
    "concat = tf.keras.layers.Concatenate()([flatten, redshifts])\n",
    "dense1 = Dense(1024, activation = \"relu\")(concat)\n",
    "dense2 = Dense(1024, activation = \"relu\")(dense1)\n",
    "dense3 = Dense(tfpl.MultivariateNormalTriL.params_size(LATENT_DIM), activation = None)(dense2)\n",
    "z = tfpl.MultivariateNormalTriL(LATENT_DIM, activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight = KL_WEIGHT))(dense3)\n",
    "encoder = Model([images, redshifts], z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b25f1d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zc = Input(shape = (LATENT_DIM + 1, ))\n",
    "dense4 = Dense(1024, activation = \"relu\")(zc)\n",
    "dense5 = Dense(1024, activation = \"relu\")(dense4) # Size of the dense layer changed\n",
    "dense6 = Dense(128 * 16 * 16, activation = \"relu\")(dense5) # Size of the dense layer changed\n",
    "reshape = Reshape((128, 16, 16))(dense6) # Reshape size changed\n",
    "conv4 = Conv2DTranspose(64, 3, strides = 2, activation = \"relu\", padding = 'same', data_format = 'channels_first')(reshape)\n",
    "conv5 = Conv2DTranspose(32, 3, strides = 2, activation = \"relu\", padding = 'same', data_format = 'channels_first')(reshape)\n",
    "conv6 = Conv2DTranspose(5, 3, strides = 2, activation = \"sigmoid\", padding = 'same', data_format = 'channels_first')(conv5)\n",
    "outputs = Reshape(IMAGE_SHAPE)(conv6)\n",
    "decoder = Model(zc, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e036f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = encoder([images, redshifts])\n",
    "zc = tf.keras.layers.Concatenate()([z, redshifts])  # Assuming you want to concat the output of encoder and redshifts\n",
    "decoder_output = decoder(zc)\n",
    "\n",
    "model = Model(inputs=[images, redshifts], outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c25fe180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 64, 64)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 32)   1472        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 16, 16)   18496       ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 16, 16)  32896       ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 32768)        0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32769)        0           ['flatten[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         33556480    ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1024)         1049600     ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 8384)         8593600     ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " multivariate_normal_tri_l (Mul  ((None, 128),       0           ['dense_2[0][0]']                \n",
      " tivariateNormalTriL)            (None, 128))                                                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 43,252,544\n",
      "Trainable params: 43,252,544\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 129)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              133120    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32768)             33587200  \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 128, 16, 16)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 32)       36896     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 5, 64, 64)        1445      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 5, 64, 64)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,808,261\n",
      "Trainable params: 34,808,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 64, 64)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 128)          43252544    ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 129)          0           ['model[0][0]',                  \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 5, 64, 64)    34808261    ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 78,060,805\n",
      "Trainable params: 78,060,805\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()\n",
    "decoder.summary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d463c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate = 0.001)\n",
    "model.compile(optimizer = optimizer, loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcbb9c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3257684/1874926983.py:1: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
      "  run = neptune.init_run(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/astro-data-lab/VAE/e/VAE-172\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    name = MODEL_SUBVERSION,\n",
    "    project = \"astro-data-lab/VAE\",\n",
    "    api_token = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGFlZGMxOC04MWU5LTQ2NDctYjlhZS05NGE2NGQ0NmIzMmEifQ==\",\n",
    ")  # your credentials\n",
    "\n",
    "# logs_callback = TensorBoard(log_dir = logs_path)\n",
    "\n",
    "weights_callback = ModelCheckpoint(filepath = os.path.join(checkpoints_path, 'weights_epoch{epoch}.hdf5'), save_freq = int(EPOCHS/CHECKPOINTS_TO_SAVE), save_weights_only = True)\n",
    "\n",
    "LR_callback = ReduceLROnPlateau()\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch <= 100:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr / 10\n",
    "\n",
    "LR_modify_callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 0)\n",
    "\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs_path, histogram_freq = 1)\n",
    "\n",
    "neptune_callback = NeptuneCallback(run = run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a667a1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 10:30:03.231436: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-08-03 10:30:05.671951: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-08-03 10:30:06.151343: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-08-03 10:30:06.225269: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-03 10:30:06.628500: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x2137ef30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-03 10:30:06.628530: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-08-03 10:30:06.632049: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-03 10:30:06.686574: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-08-03 10:30:06.730870: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - ETA: 0s - loss: 9.3382"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 10:31:08.831601: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 81s 204ms/step - loss: 9.3382 - val_loss: 9.4148 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "368/368 [==============================] - 41s 110ms/step - loss: 9.2659 - val_loss: 9.4118 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "368/368 [==============================] - 46s 126ms/step - loss: 9.2646 - val_loss: 9.4109 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2768 - val_loss: 9.4097 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "368/368 [==============================] - 58s 157ms/step - loss: 9.2695 - val_loss: 9.4086 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "368/368 [==============================] - 74s 200ms/step - loss: 9.2622 - val_loss: 9.4075 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "368/368 [==============================] - 43s 117ms/step - loss: 9.2769 - val_loss: 9.4075 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "368/368 [==============================] - 53s 143ms/step - loss: 9.2598 - val_loss: 9.4068 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "368/368 [==============================] - 54s 148ms/step - loss: 9.2595 - val_loss: 9.4067 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "368/368 [==============================] - 40s 110ms/step - loss: 9.2613 - val_loss: 9.4066 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2588 - val_loss: 9.4063 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2584 - val_loss: 9.4061 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2581 - val_loss: 9.4057 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2550 - val_loss: 9.4006 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "368/368 [==============================] - 39s 105ms/step - loss: 9.2527 - val_loss: 9.3985 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "368/368 [==============================] - 39s 106ms/step - loss: 9.2504 - val_loss: 9.3976 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2495 - val_loss: 9.3966 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "368/368 [==============================] - 39s 105ms/step - loss: 9.2496 - val_loss: 9.3962 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "368/368 [==============================] - 39s 106ms/step - loss: 9.2487 - val_loss: 9.3957 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "368/368 [==============================] - 40s 108ms/step - loss: 9.2478 - val_loss: 9.3952 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "368/368 [==============================] - 39s 106ms/step - loss: 9.2474 - val_loss: 9.3946 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "368/368 [==============================] - 39s 107ms/step - loss: 9.2473 - val_loss: 9.3955 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "368/368 [==============================] - 39s 106ms/step - loss: 9.2469 - val_loss: 9.3943 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "368/368 [==============================] - 39s 106ms/step - loss: 9.2459 - val_loss: 9.3929 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "368/368 [==============================] - 39s 105ms/step - loss: 9.2456 - val_loss: 9.3924 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "368/368 [==============================] - 39s 105ms/step - loss: 9.2439 - val_loss: 9.3913 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2431 - val_loss: 9.3904 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2425 - val_loss: 9.3899 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2419 - val_loss: 9.3906 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "368/368 [==============================] - 37s 101ms/step - loss: 9.2417 - val_loss: 9.3891 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2414 - val_loss: 9.3899 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2415 - val_loss: 9.3887 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2409 - val_loss: 9.3884 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2409 - val_loss: 9.3886 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2409 - val_loss: 9.3886 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2406 - val_loss: 9.3882 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "368/368 [==============================] - 39s 105ms/step - loss: 9.2407 - val_loss: 9.3916 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "368/368 [==============================] - 39s 105ms/step - loss: 9.2406 - val_loss: 9.3886 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2403 - val_loss: 9.3881 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "368/368 [==============================] - 38s 102ms/step - loss: 9.2402 - val_loss: 9.3878 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2399 - val_loss: 9.3878 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "368/368 [==============================] - 38s 102ms/step - loss: 9.2403 - val_loss: 9.3889 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2403 - val_loss: 9.3878 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2402 - val_loss: 9.3875 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2397 - val_loss: 9.3889 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2400 - val_loss: 9.3876 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2395 - val_loss: 9.3874 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "368/368 [==============================] - 37s 100ms/step - loss: 9.2398 - val_loss: 9.3923 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "368/368 [==============================] - 39s 105ms/step - loss: 9.2399 - val_loss: 9.3876 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "368/368 [==============================] - 39s 105ms/step - loss: 9.2394 - val_loss: 9.3875 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "368/368 [==============================] - 39s 105ms/step - loss: 9.2393 - val_loss: 9.3875 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "368/368 [==============================] - 39s 105ms/step - loss: 9.2396 - val_loss: 9.3871 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "368/368 [==============================] - 39s 106ms/step - loss: 9.2392 - val_loss: 9.3872 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "368/368 [==============================] - 39s 105ms/step - loss: 9.2394 - val_loss: 9.3874 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2395 - val_loss: 9.3875 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2394 - val_loss: 9.3875 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "368/368 [==============================] - 37s 101ms/step - loss: 9.2394 - val_loss: 9.3870 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2391 - val_loss: 9.3872 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "368/368 [==============================] - 37s 101ms/step - loss: 9.2393 - val_loss: 9.3873 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "368/368 [==============================] - 39s 105ms/step - loss: 9.2396 - val_loss: 9.3869 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2390 - val_loss: 9.3869 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2392 - val_loss: 9.3870 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2390 - val_loss: 9.3872 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "368/368 [==============================] - 38s 102ms/step - loss: 9.2389 - val_loss: 9.3880 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2393 - val_loss: 9.3873 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "368/368 [==============================] - 37s 101ms/step - loss: 9.2388 - val_loss: 9.3872 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "368/368 [==============================] - 39s 105ms/step - loss: 9.2388 - val_loss: 9.3870 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2378 - val_loss: 9.3859 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2374 - val_loss: 9.3858 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "368/368 [==============================] - 38s 102ms/step - loss: 9.2374 - val_loss: 9.3857 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2374 - val_loss: 9.3856 - lr: 1.0000e-04\n",
      "Epoch 72/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2373 - val_loss: 9.3856 - lr: 1.0000e-04\n",
      "Epoch 73/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2372 - val_loss: 9.3856 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2372 - val_loss: 9.3856 - lr: 1.0000e-04\n",
      "Epoch 75/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2372 - val_loss: 9.3856 - lr: 1.0000e-04\n",
      "Epoch 76/100\n",
      "368/368 [==============================] - 37s 100ms/step - loss: 9.2371 - val_loss: 9.3856 - lr: 1.0000e-04\n",
      "Epoch 77/100\n",
      "368/368 [==============================] - 39s 105ms/step - loss: 9.2371 - val_loss: 9.3856 - lr: 1.0000e-04\n",
      "Epoch 78/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2371 - val_loss: 9.3855 - lr: 1.0000e-04\n",
      "Epoch 79/100\n",
      "368/368 [==============================] - 37s 100ms/step - loss: 9.2370 - val_loss: 9.3855 - lr: 1.0000e-04\n",
      "Epoch 80/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2370 - val_loss: 9.3855 - lr: 1.0000e-04\n",
      "Epoch 81/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2370 - val_loss: 9.3855 - lr: 1.0000e-04\n",
      "Epoch 82/100\n",
      "368/368 [==============================] - 37s 100ms/step - loss: 9.2370 - val_loss: 9.3855 - lr: 1.0000e-04\n",
      "Epoch 83/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2370 - val_loss: 9.3855 - lr: 1.0000e-04\n",
      "Epoch 84/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2370 - val_loss: 9.3856 - lr: 1.0000e-04\n",
      "Epoch 85/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2369 - val_loss: 9.3855 - lr: 1.0000e-04\n",
      "Epoch 86/100\n",
      "368/368 [==============================] - 38s 102ms/step - loss: 9.2369 - val_loss: 9.3856 - lr: 1.0000e-04\n",
      "Epoch 87/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2369 - val_loss: 9.3855 - lr: 1.0000e-04\n",
      "Epoch 88/100\n",
      "368/368 [==============================] - 37s 101ms/step - loss: 9.2369 - val_loss: 9.3855 - lr: 1.0000e-04\n",
      "Epoch 89/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2368 - val_loss: 9.3854 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "368/368 [==============================] - 38s 104ms/step - loss: 9.2368 - val_loss: 9.3854 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "368/368 [==============================] - 38s 102ms/step - loss: 9.2368 - val_loss: 9.3854 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2368 - val_loss: 9.3854 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2368 - val_loss: 9.3854 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2368 - val_loss: 9.3854 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2368 - val_loss: 9.3854 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "368/368 [==============================] - 37s 102ms/step - loss: 9.2367 - val_loss: 9.3854 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "368/368 [==============================] - 38s 102ms/step - loss: 9.2367 - val_loss: 9.3854 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "368/368 [==============================] - 38s 102ms/step - loss: 9.2368 - val_loss: 9.3854 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "368/368 [==============================] - 38s 103ms/step - loss: 9.2367 - val_loss: 9.3854 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "368/368 [==============================] - 37s 100ms/step - loss: 9.2367 - val_loss: 9.3854 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen, epochs = 100, callbacks = [neptune_callback, LR_callback], validation_data = val_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a15f899",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to create file (unable to open file: name = '/data3/Billy/models/HSC_v6_CVAE_v1.0/v1.0.20230803_10_29_59/model/data3/Billy/CVAE/weights.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/Diffusion/lib/python3.9/site-packages/h5py/_hl/files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    558\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    560\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    561\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    562\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    563\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    564\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    565\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    566\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 567\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/miniconda3/envs/Diffusion/lib/python3.9/site-packages/h5py/_hl/files.py:237\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mcreate(name, h5f\u001b[38;5;241m.\u001b[39mACC_EXCL, fapl\u001b[38;5;241m=\u001b[39mfapl, fcpl\u001b[38;5;241m=\u001b[39mfcpl)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mACC_TRUNC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfcpl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# Open in append mode (read/write).\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# If that fails, create a new file only if it won't clobber an\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# existing one (ACC_EXCL)\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:126\u001b[0m, in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to create file (unable to open file: name = '/data3/Billy/models/HSC_v6_CVAE_v1.0/v1.0.20230803_10_29_59/model/data3/Billy/CVAE/weights.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"
     ]
    }
   ],
   "source": [
    "model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6736025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = 3\n",
    "index = 466\n",
    "z = test_gen[lib][0][1][index]\n",
    "z_shifted = 2\n",
    "band = 0\n",
    "print(f'z = {z}')\n",
    "str = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str = np.concatenate((str, np.array([z])))\n",
    "str = str.reshape(1, LATENT_DIM + 1)\n",
    "str_shifted = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str_shifted = np.concatenate((str_shifted, np.array([z_shifted])))\n",
    "str_shifted = str_shifted.reshape(1, LATENT_DIM + 1)\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (10, 5))\n",
    "axes[0].imshow(test_gen[lib][0][0][index][band], cmap = 'afmhot')\n",
    "axes[1].imshow(decoder([str])[0][band], cmap = 'afmhot')\n",
    "axes[2].imshow(decoder([str_shifted])[0][band], cmap = 'afmhot')\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "axes[2].axis('off')\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[1].set_title(\"Regenerated\")\n",
    "axes[2].set_title(\"Regenerated Far\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2840186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = 5\n",
    "index = 272\n",
    "z = test_gen[lib][0][1][index]\n",
    "z_shifted = 0.1\n",
    "band = 0\n",
    "print(f'z = {z}')\n",
    "str = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str = np.concatenate((str, np.array([z])))\n",
    "str = str.reshape(1, LATENT_DIM + 1)\n",
    "str_shifted = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str_shifted = np.concatenate((str_shifted, np.array([z_shifted])))\n",
    "str_shifted = str_shifted.reshape(1, LATENT_DIM + 1)\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (10, 5))\n",
    "axes[0].imshow(test_gen[lib][0][0][index][band], cmap = 'afmhot')\n",
    "axes[1].imshow(decoder([str])[0][band], cmap = 'afmhot')\n",
    "axes[2].imshow(decoder([str_shifted])[0][band], cmap = 'afmhot')\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "axes[2].axis('off')\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[1].set_title(\"Regenerated\")\n",
    "axes[2].set_title(\"Regenerated Close\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534af846",
   "metadata": {},
   "outputs": [],
   "source": [
    "band = 0\n",
    "str = prior.sample(1)[0]\n",
    "strlo = np.concatenate((str, np.array([0.1])))\n",
    "strlo = strlo.reshape(1, LATENT_DIM + 1)\n",
    "strhi = np.concatenate((str, np.array([2])))\n",
    "strhi = strhi.reshape(1, LATENT_DIM + 1)\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 5))\n",
    "axes[0].imshow(decoder([strlo])[0][band], cmap = 'afmhot')\n",
    "axes[1].imshow(decoder([strhi])[0][band], cmap = 'afmhot')\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "axes[0].set_title(\"Low z\")\n",
    "axes[1].set_title(\"High z\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e3dd1",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 5))\n",
    "x_array = np.arange(5)\n",
    "lo_array = np.array([])\n",
    "hi_array = np.array([])\n",
    "for j in range(0, 5):\n",
    "    lo_array = np.append(lo_array, decoder([strlo])[0][j][63][63])\n",
    "    hi_array = np.append(hi_array, decoder([strhi])[0][j][63][63])\n",
    "axes[0].scatter(x_array, lo_array, c = 'blue', label = 'Low')\n",
    "axes[1].scatter(x_array, hi_array, c = 'red', label = 'High')\n",
    "axes[0].set_xlabel(\"Bands\")\n",
    "axes[0].set_ylabel(\"Central Pixel Value\")\n",
    "axes[0].legend()\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (5, 5))\n",
    "x_array = np.arange(5)\n",
    "lo_array = np.array([])\n",
    "hi_array = np.array([])\n",
    "for j in range(0, 5):\n",
    "    lo_array = np.append(lo_array, np.amax(np.transpose(np.asarray(decoder([strlo])[0][j][60:67]))[60:67].flatten()))\n",
    "    hi_array = np.append(hi_array, np.amax(np.transpose(np.asarray(decoder([strhi])[0][j][60:67]))[60:67].flatten()))\n",
    "axes.scatter(x_array, lo_array, c = 'blue', label = 'Low')\n",
    "axes.scatter(x_array, hi_array, c = 'red', label = 'High')\n",
    "axes.set_xlabel(\"Bands\")\n",
    "axes.set_ylabel(\"Max Pixel Value Near Center\")\n",
    "axes.legend()\n",
    "axes.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f31360",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3, 80):\n",
    "    for i in range(0, 512):\n",
    "        if test_gen[j][0][1][i] <= 0.1:\n",
    "            print(j)\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166f1bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3, 80):\n",
    "    for i in range(0, 512):\n",
    "        if test_gen[j][0][1][i] >= 3.5:\n",
    "            print(j)\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9448c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 84):\n",
    "    l = 512\n",
    "    if i == 83:\n",
    "        l = 464\n",
    "    for j in range(0, l):\n",
    "        index = i * BATCH_SIZE + j + 1\n",
    "        stdout.write(\"\\rChecking %d samples of \" % (index) + \"42960\")\n",
    "        z = test_gen[i][0][1][j]\n",
    "        str = np.asarray(encoder([np.array([test_gen[i][0][0][j]]), np.array([test_gen[i][0][1][j]])])[0])\n",
    "        str = np.concatenate((str, np.array([z])))\n",
    "        str = str.reshape(1, LATENT_DIM + 1)\n",
    "        hdul = fits.PrimaryHDU(data = test_gen[i][0][0][j])\n",
    "        string = f\"/data/CVAE Generated/Full/Original Galaxy #{index}.fits\"\n",
    "        hdul.writeto(string, overwrite = True)\n",
    "        hdul = fits.PrimaryHDU(data = decoder([str])[0])\n",
    "        string = f\"/data/CVAE Generated/Full/Reconstructed Galaxy #{index}.fits\"\n",
    "        hdul.writeto(string, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8092e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_bands_max_near_center(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.amax(np.array([test_gen[0][0][0][i][j]])))\n",
    "            pred_array = np.append(pred_array, np.amax(np.transpose(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j][60:67]))[60:67].flatten()))\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(f\"Maximum normalized pixel value z = {np.array([test_gen[0][0][1][i]])[0]}\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "\n",
    "def scatter_bands_max(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.amax(np.array([test_gen[0][0][0][i][j]])))\n",
    "            pred_array = np.append(pred_array, np.amax(np.array([model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]])))\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(\"Maximum normalized pixel value\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "        \n",
    "def scatter_bands_center(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.array([test_gen[0][0][0][i][j]])[0][63][63])\n",
    "            pred_array = np.append(pred_array, model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j][63][63])\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(f\"Central pixel value z = {np.array([test_gen[0][0][1][i]])}\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "        \n",
    "def scatter_bands_center_shift(lib = 3, i = 37, z = 1):\n",
    "    print(z)\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (5, 5))\n",
    "    x_array = np.arange(5)\n",
    "    true_array = np.array([])\n",
    "    pred_array = np.array([])\n",
    "    for j in range(0, 5):\n",
    "        true_array = np.append(true_array, np.array([test_gen[lib][0][0][i][j]])[0][63][63])\n",
    "        pred_array = np.append(pred_array, model([np.array([test_gen[lib][0][0][i]]), np.array([z])])[0][j][63][63])\n",
    "    axes.scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "    axes.scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "    axes.set_xlabel(\"Bands\")\n",
    "    axes.set_ylabel(\"Central pixel value\")\n",
    "    axes.legend()\n",
    "    \n",
    "def scatter_bands_max_shift(lib = 3, i = 37, z = 1):\n",
    "    print(z)\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (5, 5))\n",
    "    x_array = np.arange(5)\n",
    "    true_array = np.array([])\n",
    "    pred_array = np.array([])\n",
    "    for j in range(0, 5):\n",
    "        true_array = np.append(true_array, np.amax(np.array([test_gen[lib][0][0][i][j]])))\n",
    "        pred_array = np.append(pred_array, np.amax(np.array([model([np.array([test_gen[lib][0][0][i]]), np.array([z])])[0][j]])))\n",
    "    axes.scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "    axes.scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "    axes.set_xlabel(\"Bands\")\n",
    "    axes.set_ylabel(\"Central pixel value\")\n",
    "    axes.legend()\n",
    "\n",
    "def scatter_bands_percentile(percentile = 90, num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show /  5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_90 = np.percentile(np.array([test_gen[0][0][0][i][j]]).flatten(), percentile)\n",
    "            pred_90 = np.percentile(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]).flatten(), percentile)\n",
    "            true_array = np.append(true_array, true_90)\n",
    "            pred_array = np.append(pred_array, pred_90)\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel('Bands')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(f'{percentile}th percentile normalized pixel value')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "\n",
    "def scatter_bands_mean(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_mean = np.mean(np.array([test_gen[0][0][0][i][j]]).flatten())\n",
    "            pred_mean = np.mean(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]).flatten())\n",
    "            true_array = np.append(true_array, true_mean)\n",
    "            pred_array = np.append(pred_array, pred_mean)\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel('Bands')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel('Mean normalized pixel value')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "\n",
    "def display_histograms(num_to_show = 2, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = num_to_show, ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        for j in range(0, 5):\n",
    "            true_arr = sorted(np.array([test_gen[0][0][0][i][j]]).flatten())\n",
    "            pred_arr = sorted(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]).flatten())\n",
    "            true_arr = true_arr[0 : int(len(true_arr) * .99)]\n",
    "            pred_arr = pred_arr[0 : int(len(pred_arr) * .99)]\n",
    "            axes[i][j].hist(true_arr, 100, color = 'blue', label = 'True', alpha = 0.5)\n",
    "            axes[i][j].hist(pred_arr, 100, color = 'red', label = 'Predicted', alpha = 0.5)\n",
    "            axes[i][j].set_xlabel(\"Pixel Values\")\n",
    "            axes[i][j].set_ylabel(\"Count\")\n",
    "            axes[i][j].legend()\n",
    "    fig.suptitle('Histograms of Predicted vs. True Image, Horizontal are Bands')\n",
    "    \n",
    "def display_5_bands(index):\n",
    "    fig, axes = plt.subplots(nrows = 2, ncols = 5, figsize = (20, 10))\n",
    "    loss = round(model.evaluate([np.array([test_gen[0][0][0][index]]), np.array([test_gen[0][0][1][index]])], np.array([test_gen[0][0][0][index]]), verbose = 0), 2)\n",
    "    for i in range(0, 5):\n",
    "        axes[0][i].imshow(np.array([test_gen[0][0][0][index]])[0][i], cmap = 'afmhot')\n",
    "        max_pixel_true = round(np.amax(np.array([test_gen[0][0][0][index]])[0][i]), 2)\n",
    "        # axes[0][i].set_title(f'True band {i} max = {max_pixel_true}')\n",
    "        pred = model([np.array([test_gen[0][0][0][index]]), np.array([test_gen[0][0][1][index]])])[0][i]\n",
    "        axes[1][i].imshow(pred, cmap = 'afmhot')\n",
    "        max_pixel_pred = round(np.amax(pred), 2)\n",
    "        axes[1][i].set_title(f'\\n loss = {loss}') # f'Pred band {i} max = {max_pixel_pred}' + \n",
    "        \n",
    "def display_high_loss(num_to_show, min_loss):\n",
    "    fig, axes = plt.subplots(nrows = num_to_show, ncols = 5, figsize = (20, 5 * num_to_show))\n",
    "    r = 0\n",
    "    for i in range(BATCH_SIZE):\n",
    "        loss = round(model.evaluate([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])], np.array([test_gen[0][0][0][i]]), verbose = 0), 2)\n",
    "        if loss >= min_loss:\n",
    "            print(i)\n",
    "            for j in range(0, 5):\n",
    "                axes[r][j].imshow(np.array([test_gen[0][0][0][i]])[0][j], cmap = 'afmhot')\n",
    "                axes[r][j].set_title(f'Loss = {loss}')\n",
    "            r += 1\n",
    "        if r >= num_to_show:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77067c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max_near_center(num_to_show = 10, index = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c4266",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array = np.array([])\n",
    "y_array = np.array([])\n",
    "l = len(test_gen[0][0][0])\n",
    "print(l)\n",
    "for i in range(0, l):\n",
    "    x_array = np.append(x_array, np.amax(np.array([test_gen[0][0][0][i][4]])))\n",
    "    y_array = np.append(y_array, np.array([test_gen[0][0][1][i]])[0])\n",
    "    print(i)\n",
    "plt.scatter(y_array, x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81015273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "xy = np.asarray(np.vstack([y_array, x_array])).astype('float32')\n",
    "z = gaussian_kde(xy)(xy)\n",
    "plt.scatter(y_array, x_array, s = 5, c = z)\n",
    "plt.xlim(0,4)\n",
    "plt.ylim(0, 80)\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"Maximum Pixel Value near the Center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac674f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_center_shift(lib = 3, i = 267, z = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dcc7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max_shift(lib = 3, i = 37, z = test_gen[3][0][1][37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa5bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max_shift(lib = 3, i = 37, z = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2457f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_center()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_mean(10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c48efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_percentile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3369ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eeb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_5_bands(38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_high_loss(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d688ff7-5416-4f2d-8c46-f9d20a2fb1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e207b9cd-6a04-443f-b56f-8ba3b3bf56ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('/data3/Billy/64x64_cvae_generated_6.hdf5', 'a')\n",
    "str = prior.sample(1)[0]\n",
    "str = np.concatenate((str, np.array([0.1])))\n",
    "str = str.reshape(1, LATENT_DIM + 1)\n",
    "image_g = decoder([str])[0][0]\n",
    "image_r = decoder([str])[0][1]\n",
    "image_i = decoder([str])[0][2]\n",
    "image_z = decoder([str])[0][3]\n",
    "image_y = decoder([str])[0][4]\n",
    "five_band_image = []\n",
    "five_band_image.append(image_g)\n",
    "five_band_image.append(image_r)\n",
    "five_band_image.append(image_i)\n",
    "five_band_image.append(image_z)\n",
    "five_band_image.append(image_y)\n",
    "five_band_image_reshape = np.reshape(np.array(five_band_image), [1, 5, 64, 64])\n",
    "hf.create_dataset('image', data = five_band_image_reshape, chunks = True, maxshape = (None, 5, 64, 64))\n",
    "hf.create_dataset('specz_redshift', data = [0.1], chunks = True, maxshape = (None, ))\n",
    "for i in tqdm(range(1999)):\n",
    "    z = random.uniform(0, 2)\n",
    "    str = prior.sample(1)[0]\n",
    "    str = np.concatenate((str, np.array([z])))\n",
    "    str = str.reshape(1, LATENT_DIM + 1)\n",
    "    image_g = decoder([str])[0][0]\n",
    "    image_r = decoder([str])[0][1]\n",
    "    image_i = decoder([str])[0][2]\n",
    "    image_z = decoder([str])[0][3]\n",
    "    image_y = decoder([str])[0][4]\n",
    "    five_band_image = []\n",
    "    five_band_image.append(image_g)\n",
    "    five_band_image.append(image_r)\n",
    "    five_band_image.append(image_i)\n",
    "    five_band_image.append(image_z)\n",
    "    five_band_image.append(image_y)\n",
    "    five_band_image_reshape = np.reshape(np.array(five_band_image), [1, 5, 64, 64])\n",
    "    hf['specz_redshift'].resize((hf['specz_redshift'].shape[0] + 1), axis = 0)\n",
    "    hf['specz_redshift'][hf['specz_redshift'].shape[0] - 1] = [z]\n",
    "    hf['image'].resize((hf['image'].shape[0] + 1), axis = 0)\n",
    "    hf['image'][hf['image'].shape[0] - 1, :, :, :] = five_band_image\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diffusion",
   "language": "python",
   "name": "diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

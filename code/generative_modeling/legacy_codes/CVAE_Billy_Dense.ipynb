{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f923d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "write = True # log this version as new\n",
    "MODEL_DESCRIPTION = \"Dense Only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d23f862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 19:41:22.847164: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-08 19:41:23.479873: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/billyli/miniconda3/lib/python3.9/site-packages/neptune_tensorflow_keras/impl/__init__.py:44: NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n",
      "  from neptune.new import Run\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import stdout\n",
    "from datetime import datetime\n",
    "import neptune as neptune\n",
    "from neptune.integrations.tensorflow_keras import NeptuneCallback\n",
    "from astropy.io import fits\n",
    "import random\n",
    "from DataMaker import HDF5ImageGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2032fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import Cropping2D, ZeroPadding2D, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Reshape\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import layers as tfpl\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow.nn import leaky_relu\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e0800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 64\n",
    "BASE_DEPTH = 8\n",
    "IMAGE_SHAPE = (5, 127, 127)\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 250\n",
    "CHECKPOINTS_TO_SAVE = 4\n",
    "KL_WEIGHT = 1e-6\n",
    "# Good value: 1e-6\n",
    "# With KL 0 val_loss = 0.4763\n",
    "# With KL 1e-6 val loss = 1.0732\n",
    "# With KL 1e-8 val loss = 0.5257\n",
    "# With KL 1e-10 val loss = 0.4466 0.4291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a44e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 19:41:25.879785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-08 19:41:25.897807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-08 19:41:25.898003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-08 19:41:25.900157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-08 19:41:25.900305: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-08 19:41:25.900434: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-08 19:41:26.494433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-08 19:41:26.494628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-08 19:41:26.494763: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-08 19:41:26.494871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20000 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU');\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 20000)]);\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU');\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb7cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "DATASET_NAME = \"HSC_v6\"\n",
    "MODEL_TYPE = \"CVAE\"\n",
    "MODEL_VERSION = \"v1.0\"\n",
    "MODEL_SUBVERSION = \"v1.0.\" + now.strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "\n",
    "model_id = '_'.join([DATASET_NAME, MODEL_TYPE, MODEL_VERSION])\n",
    "model_path = os.path.join('/data3/Billy/models', model_id, MODEL_SUBVERSION, 'model')\n",
    "checkpoints_path = os.path.join('/data3/Billy/models', model_id, MODEL_SUBVERSION, 'checkpoints')\n",
    "logs_path = os.path.join('/data3/Billy/logs', model_id, MODEL_SUBVERSION)\n",
    "predictions_path = os.path.join('/data3/Billy/predictions', model_id, MODEL_SUBVERSION)\n",
    "weights_path = model_path + '/data3/Billy/CVAE/weights.h5'\n",
    "\n",
    "os.makedirs(model_path, exist_ok = True)\n",
    "os.makedirs(checkpoints_path, exist_ok = True)\n",
    "os.makedirs(logs_path, exist_ok = True)\n",
    "os.makedirs(predictions_path, exist_ok = True)\n",
    "\n",
    "if write == True:\n",
    "    with open(\"/data3/Billy/models/README.md\", \"a\") as myfile:\n",
    "        myfile.write(MODEL_TYPE + \" \" + MODEL_SUBVERSION + \" - \" + MODEL_DESCRIPTION + \" - B. Li\" + \"\\n\")\n",
    "else:\n",
    "    with open(\"/data3/Billy/models/README.md\", \"a\") as myfile:\n",
    "        myfile.write(MODEL_TYPE + \" \" + MODEL_SUBVERSION + \" - ... \"+ \" - B. Li\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc0eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_gen = {'X_key': 'image',\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': False}\n",
    "\n",
    "train_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/127x127/5x127x127_training.hdf5', **args_gen)\n",
    "val_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/127x127/5x127x127_validation.hdf5', **args_gen)\n",
    "test_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/127x127/5x127x127_testing.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "588c99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = BATCH_SIZE\n",
    "l = len(train_gen._indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d31d75f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(LATENT_DIM), scale = 0.1), reinterpreted_batch_ndims = 1)\n",
    "\n",
    "images = Input(shape = IMAGE_SHAPE)\n",
    "conv1 = Conv2D(5, 1, strides = 1, activation = None, \n",
    "           padding = 'valid', data_format = 'channels_first')(images)\n",
    "flatten = Flatten()(conv1)\n",
    "redshifts = Input(shape = 1,)\n",
    "dense1 = Dense(2048, activation = None)(flatten)\n",
    "dense2 = tf.keras.layers.Dense(256, activation = \"relu\")(redshifts)\n",
    "dense3 = tf.keras.layers.Dense(256, activation = \"relu\")(dense2)\n",
    "concat = tf.keras.layers.Concatenate()([dense1, dense3])\n",
    "dense4 = Dense(tfpl.MultivariateNormalTriL.params_size(LATENT_DIM), activation = None)(concat)\n",
    "z = tfpl.MultivariateNormalTriL(LATENT_DIM,\n",
    "            activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight = KL_WEIGHT))(dense4)\n",
    "encoder = Model([images, redshifts], z)\n",
    "\n",
    "zc = tf.keras.layers.Concatenate()([z, redshifts])\n",
    "\n",
    "# encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b25f1d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense5 = Dense(2048, activation = None)\n",
    "dense6 = Dense(5 * 127 * 127, activation = None)\n",
    "outputs = Reshape(IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcac6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense5_model = dense5(zc)\n",
    "dense6_model = dense6(dense5_model)\n",
    "outputs_model = outputs(dense6_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c11d122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 127, 127  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 5, 127, 127)  30          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 80645)        0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          512         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2048)         165163008   ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256)          65792       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2304)         0           ['dense[0][0]',                  \n",
      "                                                                  'dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2144)         4941920     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " multivariate_normal_tri_l (Mul  ((None, 64),        0           ['dense_3[0][0]']                \n",
      " tivariateNormalTriL)            (None, 64))                                                      \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 65)           0           ['multivariate_normal_tri_l[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 2048)         135168      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 80645)        165241605   ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 5, 127, 127)  0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 335,548,035\n",
      "Trainable params: 335,548,035\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs = [images, redshifts], outputs = [outputs_model])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e036f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = Input(shape = (LATENT_DIM + 1, ))\n",
    "dense5_decoder = dense5(latents)\n",
    "dense6_decoder = dense6(dense5_decoder)\n",
    "outputs_decoder = outputs(dense6_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17a65d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Model(latents, outputs_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d463c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer = optimizer, loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcbb9c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4026138/1874926983.py:1: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
      "  run = neptune.init_run(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/astro-data-lab/VAE/e/VAE-145\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    name = MODEL_SUBVERSION,\n",
    "    project = \"astro-data-lab/VAE\",\n",
    "    api_token = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGFlZGMxOC04MWU5LTQ2NDctYjlhZS05NGE2NGQ0NmIzMmEifQ==\",\n",
    ")  # your credentials\n",
    "\n",
    "# logs_callback = TensorBoard(log_dir = logs_path)\n",
    "\n",
    "weights_callback = ModelCheckpoint(filepath = os.path.join(checkpoints_path, 'weights_epoch{epoch}.hdf5'), save_freq = int(EPOCHS/CHECKPOINTS_TO_SAVE), save_weights_only = True)\n",
    "\n",
    "LR_callback = ReduceLROnPlateau()\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch <= 100:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr / 10\n",
    "\n",
    "LR_modify_callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 0)\n",
    "\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs_path, histogram_freq = 1)\n",
    "\n",
    "neptune_callback = NeptuneCallback(run = run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94cdefc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/127x127/5x127x127_training.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a667a1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 07:13:31.604525: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - ETA: 0s - loss: 1.6483"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 07:17:10.604779: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 255s 648ms/step - loss: 1.6483 - val_loss: 1.6196\n",
      "Epoch 2/150\n",
      "392/392 [==============================] - 246s 626ms/step - loss: 1.6276 - val_loss: 1.6161\n",
      "Epoch 3/150\n",
      "392/392 [==============================] - 273s 696ms/step - loss: 1.6254 - val_loss: 1.6148\n",
      "Epoch 4/150\n",
      "392/392 [==============================] - 260s 665ms/step - loss: 1.6276 - val_loss: 1.6165\n",
      "Epoch 5/150\n",
      "392/392 [==============================] - 243s 621ms/step - loss: 1.6392 - val_loss: 1.6199\n",
      "Epoch 6/150\n",
      "392/392 [==============================] - 278s 711ms/step - loss: 1.6332 - val_loss: 1.6222\n",
      "Epoch 7/150\n",
      "392/392 [==============================] - 260s 664ms/step - loss: 1.6308 - val_loss: 1.6219\n",
      "Epoch 8/150\n",
      "392/392 [==============================] - 235s 601ms/step - loss: 1.6359 - val_loss: 1.6199\n",
      "Epoch 9/150\n",
      "392/392 [==============================] - 264s 673ms/step - loss: 1.6647 - val_loss: 1.6298\n",
      "Epoch 10/150\n",
      "392/392 [==============================] - 257s 657ms/step - loss: 1.6437 - val_loss: 1.6183\n",
      "Epoch 11/150\n",
      "392/392 [==============================] - 261s 666ms/step - loss: 1.6250 - val_loss: 1.6161\n",
      "Epoch 12/150\n",
      "392/392 [==============================] - 272s 692ms/step - loss: 1.6249 - val_loss: 1.6182\n",
      "Epoch 13/150\n",
      "392/392 [==============================] - 263s 671ms/step - loss: 1.6279 - val_loss: 1.6153\n",
      "Epoch 14/150\n",
      "392/392 [==============================] - 275s 702ms/step - loss: 1.6205 - val_loss: 1.6144\n",
      "Epoch 15/150\n",
      "392/392 [==============================] - 267s 681ms/step - loss: 1.6277 - val_loss: 1.6150\n",
      "Epoch 16/150\n",
      "392/392 [==============================] - 291s 743ms/step - loss: 1.6261 - val_loss: 1.6303\n",
      "Epoch 17/150\n",
      "392/392 [==============================] - 241s 614ms/step - loss: 1.6251 - val_loss: 1.6167\n",
      "Epoch 18/150\n",
      "392/392 [==============================] - 266s 680ms/step - loss: 1.6258 - val_loss: 1.6356\n",
      "Epoch 19/150\n",
      "392/392 [==============================] - 273s 697ms/step - loss: 1.6269 - val_loss: 1.6178\n",
      "Epoch 20/150\n",
      "392/392 [==============================] - 242s 617ms/step - loss: 1.6301 - val_loss: 1.6267\n",
      "Epoch 21/150\n",
      "392/392 [==============================] - 268s 683ms/step - loss: 1.6267 - val_loss: 1.6160\n",
      "Epoch 22/150\n",
      "392/392 [==============================] - 278s 707ms/step - loss: 1.6349 - val_loss: 1.6156\n",
      "Epoch 23/150\n",
      "392/392 [==============================] - 265s 675ms/step - loss: 1.6298 - val_loss: 1.6196\n",
      "Epoch 24/150\n",
      "392/392 [==============================] - 274s 701ms/step - loss: 1.6226 - val_loss: 1.6363\n",
      "Epoch 25/150\n",
      "392/392 [==============================] - 257s 655ms/step - loss: 1.6516 - val_loss: 1.6202\n",
      "Epoch 26/150\n",
      "392/392 [==============================] - 246s 628ms/step - loss: 1.6281 - val_loss: 1.6267\n",
      "Epoch 27/150\n",
      "392/392 [==============================] - 295s 754ms/step - loss: 1.6318 - val_loss: 1.6253\n",
      "Epoch 28/150\n",
      "392/392 [==============================] - 276s 704ms/step - loss: 1.6276 - val_loss: 1.6154\n",
      "Epoch 29/150\n",
      "392/392 [==============================] - 353s 900ms/step - loss: 1.6305 - val_loss: 1.6168\n",
      "Epoch 30/150\n",
      "392/392 [==============================] - 341s 871ms/step - loss: 1.6229 - val_loss: 1.6183\n",
      "Epoch 31/150\n",
      "392/392 [==============================] - 328s 834ms/step - loss: 1.6320 - val_loss: 1.6169\n",
      "Epoch 32/150\n",
      "392/392 [==============================] - 322s 819ms/step - loss: 1.6277 - val_loss: 1.6174\n",
      "Epoch 33/150\n",
      "392/392 [==============================] - 343s 875ms/step - loss: 1.6316 - val_loss: 1.6266\n",
      "Epoch 34/150\n",
      "392/392 [==============================] - 275s 700ms/step - loss: 1.6309 - val_loss: 1.6207\n",
      "Epoch 35/150\n",
      "392/392 [==============================] - 307s 784ms/step - loss: 1.6259 - val_loss: 1.6151\n",
      "Epoch 36/150\n",
      "392/392 [==============================] - 297s 758ms/step - loss: 1.6311 - val_loss: 1.6190\n",
      "Epoch 37/150\n",
      "392/392 [==============================] - 293s 748ms/step - loss: 1.6320 - val_loss: 1.7220\n",
      "Epoch 38/150\n",
      "392/392 [==============================] - 339s 865ms/step - loss: 1.6375 - val_loss: 1.6360\n",
      "Epoch 39/150\n",
      "392/392 [==============================] - 316s 806ms/step - loss: 1.6319 - val_loss: 1.6179\n",
      "Epoch 40/150\n",
      "392/392 [==============================] - 348s 886ms/step - loss: 1.6234 - val_loss: 1.6217\n",
      "Epoch 41/150\n",
      "392/392 [==============================] - 316s 807ms/step - loss: 1.6299 - val_loss: 1.6214\n",
      "Epoch 42/150\n",
      "392/392 [==============================] - 343s 873ms/step - loss: 1.6217 - val_loss: 1.6189\n",
      "Epoch 43/150\n",
      "392/392 [==============================] - 322s 820ms/step - loss: 1.6371 - val_loss: 1.6305\n",
      "Epoch 44/150\n",
      "392/392 [==============================] - 300s 763ms/step - loss: 1.6306 - val_loss: 1.6178\n",
      "Epoch 45/150\n",
      "392/392 [==============================] - 269s 684ms/step - loss: 1.6261 - val_loss: 1.6216\n",
      "Epoch 46/150\n",
      "392/392 [==============================] - 266s 677ms/step - loss: 1.6371 - val_loss: 1.6218\n",
      "Epoch 47/150\n",
      "392/392 [==============================] - 276s 703ms/step - loss: 1.6253 - val_loss: 1.6182\n",
      "Epoch 48/150\n",
      "392/392 [==============================] - 262s 666ms/step - loss: 1.6233 - val_loss: 1.6192\n",
      "Epoch 49/150\n",
      "392/392 [==============================] - 262s 668ms/step - loss: 1.6313 - val_loss: 1.6240\n",
      "Epoch 50/150\n",
      "392/392 [==============================] - 257s 657ms/step - loss: 1.6251 - val_loss: 1.6254\n",
      "Epoch 51/150\n",
      "392/392 [==============================] - 259s 660ms/step - loss: 1.6239 - val_loss: 1.6183\n",
      "Epoch 52/150\n",
      "392/392 [==============================] - 265s 677ms/step - loss: 1.6229 - val_loss: 1.6248\n",
      "Epoch 53/150\n",
      "392/392 [==============================] - 269s 686ms/step - loss: 1.6329 - val_loss: 1.6198\n",
      "Epoch 54/150\n",
      "392/392 [==============================] - 255s 650ms/step - loss: 1.6251 - val_loss: 1.6267\n",
      "Epoch 55/150\n",
      "392/392 [==============================] - 270s 691ms/step - loss: 1.6337 - val_loss: 1.6225\n",
      "Epoch 56/150\n",
      "392/392 [==============================] - 261s 667ms/step - loss: 1.6395 - val_loss: 1.6243\n",
      "Epoch 57/150\n",
      "392/392 [==============================] - 258s 658ms/step - loss: 1.6354 - val_loss: 1.6210\n",
      "Epoch 58/150\n",
      "392/392 [==============================] - 274s 700ms/step - loss: 1.6232 - val_loss: 1.6304\n",
      "Epoch 59/150\n",
      "392/392 [==============================] - 290s 741ms/step - loss: 1.6296 - val_loss: 1.6172\n",
      "Epoch 60/150\n",
      "392/392 [==============================] - 335s 855ms/step - loss: 1.6252 - val_loss: 1.6166\n",
      "Epoch 61/150\n",
      "392/392 [==============================] - 321s 820ms/step - loss: 1.6224 - val_loss: 1.6209\n",
      "Epoch 62/150\n",
      "392/392 [==============================] - 331s 844ms/step - loss: 1.6183 - val_loss: 1.6186\n",
      "Epoch 63/150\n",
      "392/392 [==============================] - 319s 814ms/step - loss: 1.6251 - val_loss: 1.6185\n",
      "Epoch 64/150\n",
      "392/392 [==============================] - 360s 918ms/step - loss: 1.6491 - val_loss: 1.6349\n",
      "Epoch 65/150\n",
      "392/392 [==============================] - 372s 948ms/step - loss: 1.6375 - val_loss: 1.6195\n",
      "Epoch 66/150\n",
      "392/392 [==============================] - 362s 922ms/step - loss: 1.6277 - val_loss: 1.6168\n",
      "Epoch 67/150\n",
      "392/392 [==============================] - 357s 910ms/step - loss: 1.6223 - val_loss: 1.6194\n",
      "Epoch 68/150\n",
      "392/392 [==============================] - 328s 835ms/step - loss: 1.6250 - val_loss: 1.6194\n",
      "Epoch 69/150\n",
      "392/392 [==============================] - 360s 917ms/step - loss: 1.6205 - val_loss: 1.6331\n",
      "Epoch 70/150\n",
      "392/392 [==============================] - 362s 922ms/step - loss: 1.6230 - val_loss: 1.6193\n",
      "Epoch 71/150\n",
      "392/392 [==============================] - 436s 1s/step - loss: 1.6239 - val_loss: 1.6213\n",
      "Epoch 72/150\n",
      "392/392 [==============================] - 364s 927ms/step - loss: 1.6363 - val_loss: 1.6220\n",
      "Epoch 73/150\n",
      "392/392 [==============================] - 382s 976ms/step - loss: 1.6271 - val_loss: 1.6207\n",
      "Epoch 74/150\n",
      "392/392 [==============================] - 344s 876ms/step - loss: 1.6186 - val_loss: 1.6468\n",
      "Epoch 75/150\n",
      "392/392 [==============================] - 359s 915ms/step - loss: 1.6504 - val_loss: 1.6341\n",
      "Epoch 76/150\n",
      "392/392 [==============================] - 331s 843ms/step - loss: 1.6365 - val_loss: 1.6212\n",
      "Epoch 77/150\n",
      "392/392 [==============================] - 396s 1s/step - loss: 1.6275 - val_loss: 1.6189\n",
      "Epoch 78/150\n",
      "392/392 [==============================] - 399s 1s/step - loss: 1.6206 - val_loss: 1.6202\n",
      "Epoch 79/150\n",
      "392/392 [==============================] - 334s 854ms/step - loss: 1.6221 - val_loss: 1.6188\n",
      "Epoch 80/150\n",
      "392/392 [==============================] - 298s 761ms/step - loss: 1.6213 - val_loss: 1.6179\n",
      "Epoch 81/150\n",
      "392/392 [==============================] - 337s 860ms/step - loss: 1.6298 - val_loss: 1.6202\n",
      "Epoch 82/150\n",
      "392/392 [==============================] - 320s 817ms/step - loss: 1.6169 - val_loss: 1.6192\n",
      "Epoch 83/150\n",
      "392/392 [==============================] - 328s 836ms/step - loss: 1.6269 - val_loss: 1.6188\n",
      "Epoch 84/150\n",
      "392/392 [==============================] - 308s 786ms/step - loss: 1.6278 - val_loss: 1.6195\n",
      "Epoch 85/150\n",
      "392/392 [==============================] - 321s 816ms/step - loss: 1.6189 - val_loss: 1.6248\n",
      "Epoch 86/150\n",
      "219/392 [===============>..............] - ETA: 1:34 - loss: 1.5734"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mneptune_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen, epochs = 150, callbacks = [neptune_callback], validation_data = val_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b75b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step3/5x127x127_training_min_3.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3634ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(train_gen, epochs = 75, callbacks = [neptune_callback], validation_data = val_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step3/5x127x127_training_min_2.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f8f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(train_gen, epochs = 100, callbacks = [weights_callback, neptune_callback], validation_data = val_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c00d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step3/5x127x127_training_min_1.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(train_gen, epochs = 100, callbacks = [weights_callback, neptune_callback], validation_data = val_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c53ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/127x127/5x127x127_training.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24912cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(train_gen, epochs = 100, callbacks = [neptune_callback, LR_callback], validation_data = val_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6736025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = 3\n",
    "index = 466\n",
    "z = test_gen[lib][0][1][index]\n",
    "z_shifted = 4\n",
    "band = 0\n",
    "print(f'z = {z}')\n",
    "str = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str = np.concatenate((str, np.array([z])))\n",
    "str = str.reshape(1, LATENT_DIM + 1)\n",
    "str_shifted = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str_shifted = np.concatenate((str_shifted, np.array([z_shifted])))\n",
    "str_shifted = str_shifted.reshape(1, LATENT_DIM + 1)\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (10, 5))\n",
    "axes[0].imshow(test_gen[lib][0][0][index][band], cmap = 'afmhot')\n",
    "axes[1].imshow(decoder([str])[0][band], cmap = 'afmhot')\n",
    "axes[2].imshow(decoder([str_shifted])[0][band], cmap = 'afmhot')\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "axes[2].axis('off')\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[1].set_title(\"Regenerated\")\n",
    "axes[2].set_title(\"Regenerated Far\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2840186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = 5\n",
    "index = 271\n",
    "z = test_gen[lib][0][1][index]\n",
    "z_shifted = 3.5\n",
    "band = 0\n",
    "print(f'z = {z}')\n",
    "str = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str = np.concatenate((str, np.array([z])))\n",
    "str = str.reshape(1, LATENT_DIM + 1)\n",
    "str_shifted = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str_shifted = np.concatenate((str_shifted, np.array([z_shifted])))\n",
    "str_shifted = str_shifted.reshape(1, LATENT_DIM + 1)\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (10, 5))\n",
    "axes[0].imshow(test_gen[lib][0][0][index][band], cmap = 'afmhot')\n",
    "axes[1].imshow(decoder([str])[0][band], cmap = 'afmhot')\n",
    "axes[2].imshow(decoder([str_shifted])[0][band], cmap = 'afmhot')\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "axes[2].axis('off')\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[1].set_title(\"Regenerated\")\n",
    "axes[2].set_title(\"Regenerated Close\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534af846",
   "metadata": {},
   "outputs": [],
   "source": [
    "band = 0\n",
    "str = prior.sample(1)[0]\n",
    "strlo = np.concatenate((str, np.array([0.1])))\n",
    "strlo = strlo.reshape(1, LATENT_DIM + 1)\n",
    "strhi = np.concatenate((str, np.array([4])))\n",
    "strhi = strhi.reshape(1, LATENT_DIM + 1)\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 5))\n",
    "axes[0].imshow(decoder([strlo])[0][band], cmap = 'afmhot')\n",
    "axes[1].imshow(decoder([strhi])[0][band], cmap = 'afmhot')\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "axes[0].set_title(\"Low z\")\n",
    "axes[1].set_title(\"High z\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a67b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e3dd1",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 5))\n",
    "x_array = np.arange(5)\n",
    "lo_array = np.array([])\n",
    "hi_array = np.array([])\n",
    "for j in range(0, 5):\n",
    "    lo_array = np.append(lo_array, decoder([strlo])[0][j][63][63])\n",
    "    hi_array = np.append(hi_array, decoder([strhi])[0][j][63][63])\n",
    "axes[0].scatter(x_array, lo_array, c = 'blue', label = 'Low')\n",
    "axes[1].scatter(x_array, hi_array, c = 'red', label = 'High')\n",
    "axes[0].set_xlabel(\"Bands\")\n",
    "axes[0].set_ylabel(\"Central Pixel Value\")\n",
    "axes[0].legend()\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26003c31-8478-4e44-9d11-e74d201a1e54",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (5, 5))\n",
    "x_array = np.arange(5)\n",
    "lo_array = np.array([])\n",
    "hi_array = np.array([])\n",
    "for j in range(0, 5):\n",
    "    lo_array = np.append(lo_array, np.amax(np.transpose(np.asarray(decoder([strlo])[0][j][60:67]))[60:67].flatten()))\n",
    "    hi_array = np.append(hi_array, np.amax(np.transpose(np.asarray(decoder([strhi])[0][j][60:67]))[60:67].flatten()))\n",
    "axes.scatter(x_array, lo_array, c = 'blue', label = 'Low')\n",
    "axes.scatter(x_array, hi_array, c = 'red', label = 'High')\n",
    "axes.set_xlabel(\"Bands\")\n",
    "axes.set_ylabel(\"Max Pixel Value Near Center\")\n",
    "axes.legend()\n",
    "axes.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba8645-14c6-47e9-83bd-35ccc9bb76a0",
   "metadata": {},
   "source": [
    "for j in range(3, 80):\n",
    "    for i in range(0, 512):\n",
    "        if test_gen[j][0][1][i] <= 0.1:\n",
    "            print(j)\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d264e3-0d3c-414e-b44b-441c134236fe",
   "metadata": {},
   "source": [
    "for j in range(3, 80):\n",
    "    for i in range(0, 512):\n",
    "        if test_gen[j][0][1][i] >= 3.5:\n",
    "            print(j)\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9bf849-5bd2-42fa-8731-2b0a1e044742",
   "metadata": {},
   "source": [
    "for i in range(0, 84):\n",
    "    l = 512\n",
    "    if i == 83:\n",
    "        l = 464\n",
    "    for j in range(0, l):\n",
    "        index = i * BATCH_SIZE + j + 1\n",
    "        stdout.write(\"\\rChecking %d samples of \" % (index) + \"42960\")\n",
    "        z = test_gen[i][0][1][j]\n",
    "        str = np.asarray(encoder([np.array([test_gen[i][0][0][j]]), np.array([test_gen[i][0][1][j]])])[0])\n",
    "        str = np.concatenate((str, np.array([z])))\n",
    "        str = str.reshape(1, LATENT_DIM + 1)\n",
    "        hdul = fits.PrimaryHDU(data = test_gen[i][0][0][j])\n",
    "        string = f\"/data/CVAE Generated/Full/Original Galaxy #{index}.fits\"\n",
    "        hdul.writeto(string, overwrite = True)\n",
    "        hdul = fits.PrimaryHDU(data = decoder([str])[0])\n",
    "        string = f\"/data/CVAE Generated/Full/Reconstructed Galaxy #{index}.fits\"\n",
    "        hdul.writeto(string, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8092e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_bands_max_near_center(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.amax(np.array([test_gen[0][0][0][i][j]])))\n",
    "            pred_array = np.append(pred_array, np.amax(np.transpose(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j][60:67]))[60:67].flatten()))\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(f\"Maximum normalized pixel value z = {np.array([test_gen[0][0][1][i]])[0]}\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "\n",
    "def scatter_bands_max(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.amax(np.array([test_gen[0][0][0][i][j]])))\n",
    "            pred_array = np.append(pred_array, np.amax(np.array([model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]])))\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(\"Maximum normalized pixel value\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "        \n",
    "def scatter_bands_center(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.array([test_gen[0][0][0][i][j]])[0][63][63])\n",
    "            pred_array = np.append(pred_array, model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j][63][63])\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(f\"Central pixel value z = {np.array([test_gen[0][0][1][i]])}\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "        \n",
    "def scatter_bands_center_shift(lib = 3, i = 37, z = 1):\n",
    "    print(z)\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (5, 5))\n",
    "    x_array = np.arange(5)\n",
    "    true_array = np.array([])\n",
    "    pred_array = np.array([])\n",
    "    for j in range(0, 5):\n",
    "        true_array = np.append(true_array, np.array([test_gen[lib][0][0][i][j]])[0][63][63])\n",
    "        pred_array = np.append(pred_array, model([np.array([test_gen[lib][0][0][i]]), np.array([z])])[0][j][63][63])\n",
    "    axes.scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "    axes.scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "    axes.set_xlabel(\"Bands\")\n",
    "    axes.set_ylabel(\"Central pixel value\")\n",
    "    axes.legend()\n",
    "    \n",
    "def scatter_bands_max_shift(lib = 3, i = 37, z = 1):\n",
    "    print(z)\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (5, 5))\n",
    "    x_array = np.arange(5)\n",
    "    true_array = np.array([])\n",
    "    pred_array = np.array([])\n",
    "    for j in range(0, 5):\n",
    "        true_array = np.append(true_array, np.amax(np.array([test_gen[lib][0][0][i][j]])))\n",
    "        pred_array = np.append(pred_array, np.amax(np.array([model([np.array([test_gen[lib][0][0][i]]), np.array([z])])[0][j]])))\n",
    "    axes.scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "    axes.scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "    axes.set_xlabel(\"Bands\")\n",
    "    axes.set_ylabel(\"Central pixel value\")\n",
    "    axes.legend()\n",
    "\n",
    "def scatter_bands_percentile(percentile = 90, num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show /  5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_90 = np.percentile(np.array([test_gen[0][0][0][i][j]]).flatten(), percentile)\n",
    "            pred_90 = np.percentile(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]).flatten(), percentile)\n",
    "            true_array = np.append(true_array, true_90)\n",
    "            pred_array = np.append(pred_array, pred_90)\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel('Bands')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(f'{percentile}th percentile normalized pixel value')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "\n",
    "def scatter_bands_mean(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_mean = np.mean(np.array([test_gen[0][0][0][i][j]]).flatten())\n",
    "            pred_mean = np.mean(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]).flatten())\n",
    "            true_array = np.append(true_array, true_mean)\n",
    "            pred_array = np.append(pred_array, pred_mean)\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel('Bands')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel('Mean normalized pixel value')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "\n",
    "def display_histograms(num_to_show = 2, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = num_to_show, ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        for j in range(0, 5):\n",
    "            true_arr = sorted(np.array([test_gen[0][0][0][i][j]]).flatten())\n",
    "            pred_arr = sorted(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]).flatten())\n",
    "            true_arr = true_arr[0 : int(len(true_arr) * .99)]\n",
    "            pred_arr = pred_arr[0 : int(len(pred_arr) * .99)]\n",
    "            axes[i][j].hist(true_arr, 100, color = 'blue', label = 'True', alpha = 0.5)\n",
    "            axes[i][j].hist(pred_arr, 100, color = 'red', label = 'Predicted', alpha = 0.5)\n",
    "            axes[i][j].set_xlabel(\"Pixel Values\")\n",
    "            axes[i][j].set_ylabel(\"Count\")\n",
    "            axes[i][j].legend()\n",
    "    fig.suptitle('Histograms of Predicted vs. True Image, Horizontal are Bands')\n",
    "    \n",
    "def display_5_bands(index):\n",
    "    fig, axes = plt.subplots(nrows = 2, ncols = 5, figsize = (20, 10))\n",
    "    loss = round(model.evaluate([np.array([test_gen[0][0][0][index]]), np.array([test_gen[0][0][1][index]])], np.array([test_gen[0][0][0][index]]), verbose = 0), 2)\n",
    "    for i in range(0, 5):\n",
    "        axes[0][i].imshow(np.array([test_gen[0][0][0][index]])[0][i], cmap = 'afmhot')\n",
    "        max_pixel_true = round(np.amax(np.array([test_gen[0][0][0][index]])[0][i]), 2)\n",
    "        # axes[0][i].set_title(f'True band {i} max = {max_pixel_true}')\n",
    "        pred = model([np.array([test_gen[0][0][0][index]]), np.array([test_gen[0][0][1][index]])])[0][i]\n",
    "        axes[1][i].imshow(pred, cmap = 'afmhot')\n",
    "        max_pixel_pred = round(np.amax(pred), 2)\n",
    "        axes[1][i].set_title(f'\\n loss = {loss}') # f'Pred band {i} max = {max_pixel_pred}' + \n",
    "        \n",
    "def display_high_loss(num_to_show, min_loss):\n",
    "    fig, axes = plt.subplots(nrows = num_to_show, ncols = 5, figsize = (20, 5 * num_to_show))\n",
    "    r = 0\n",
    "    for i in range(BATCH_SIZE):\n",
    "        loss = round(model.evaluate([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])], np.array([test_gen[0][0][0][i]]), verbose = 0), 2)\n",
    "        if loss >= min_loss:\n",
    "            print(i)\n",
    "            for j in range(0, 5):\n",
    "                axes[r][j].imshow(np.array([test_gen[0][0][0][i]])[0][j], cmap = 'afmhot')\n",
    "                axes[r][j].set_title(f'Loss = {loss}')\n",
    "            r += 1\n",
    "        if r >= num_to_show:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77067c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max_near_center(num_to_show = 10, index = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c4266",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array = np.array([])\n",
    "y_array = np.array([])\n",
    "l = len(test_gen[0][0][0])\n",
    "print(l)\n",
    "for i in range(0, l):\n",
    "    x_array = np.append(x_array, np.amax(np.array([test_gen[0][0][0][i][4]])))\n",
    "    y_array = np.append(y_array, np.array([test_gen[0][0][1][i]])[0])\n",
    "    # print(i)\n",
    "plt.scatter(y_array, x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81015273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "xy = np.asarray(np.vstack([y_array, x_array])).astype('float32')\n",
    "z = gaussian_kde(xy)(xy)\n",
    "plt.scatter(y_array, x_array, s = 5, c = z)\n",
    "plt.xlim(0,4)\n",
    "plt.ylim(0, 80)\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"Maximum Pixel Value near the Center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac674f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_center_shift(lib = 3, i = 267, z = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dcc7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max_shift(lib = 3, i = 37, z = test_gen[3][0][1][37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa5bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max_shift(lib = 3, i = 37, z = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2457f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_center()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_mean(10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c48efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_percentile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3369ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eeb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_5_bands(38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_high_loss(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f5ed164-1a0d-4bfd-8137-49f4f3330bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step3/5x127x127_testing_max_1.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "751fe1e6-2ae8-49ba-a6ea-95f3b4658e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('/data/HSC/HSC_v6/step3/127x127_generated_max_1.hdf5', 'a')\n",
    "prior1 = tfd.Independent(tfd.Normal(loc=tf.zeros(LATENT_DIM), scale = 0.1), reinterpreted_batch_ndims = 1)\n",
    "str = prior1.sample(1)[0]\n",
    "str = np.concatenate((str, np.array([0.1])))\n",
    "str = str.reshape(1, LATENT_DIM + 1)\n",
    "image_g = decoder([str])[0][0]\n",
    "image_r = decoder([str])[0][1]\n",
    "image_i = decoder([str])[0][2]\n",
    "image_z = decoder([str])[0][3]\n",
    "image_y = decoder([str])[0][4]\n",
    "five_band_image = []\n",
    "five_band_image.append(image_g)\n",
    "five_band_image.append(image_r)\n",
    "five_band_image.append(image_i)\n",
    "five_band_image.append(image_z)\n",
    "five_band_image.append(image_y)\n",
    "five_band_image_reshape = np.reshape(np.array(five_band_image), [1, 5, 127, 127])\n",
    "hf.create_dataset('image', data = five_band_image_reshape, chunks = True, maxshape = (None, 5, 127, 127))\n",
    "hf.create_dataset('specz_redshift', data = [0.1], chunks = True, maxshape = (None, ))\n",
    "for lib in range(0, 2):\n",
    "    for index in range(0, 512):\n",
    "        z = random.uniform(0, 4)\n",
    "        str = np.asarray(encoder([np.array([train_gen[lib][0][0][index]]), np.array([train_gen[lib][0][1][index]])])[0])\n",
    "        str = np.concatenate((str, np.array([z])))\n",
    "        str = str.reshape(1, LATENT_DIM + 1)\n",
    "        image_g = decoder([str])[0][0]\n",
    "        image_r = decoder([str])[0][1]\n",
    "        image_i = decoder([str])[0][2]\n",
    "        image_z = decoder([str])[0][3]\n",
    "        image_y = decoder([str])[0][4]\n",
    "        five_band_image = []\n",
    "        five_band_image.append(image_g)\n",
    "        five_band_image.append(image_r)\n",
    "        five_band_image.append(image_i)\n",
    "        five_band_image.append(image_z)\n",
    "        five_band_image.append(image_y)\n",
    "        five_band_image_reshape = np.reshape(np.array(five_band_image), [1, 5, 127, 127])\n",
    "        hf['specz_redshift'].resize((hf['specz_redshift'].shape[0] + 1), axis = 0)\n",
    "        hf['specz_redshift'][hf['specz_redshift'].shape[0] - 1] = [z]\n",
    "        hf['image'].resize((hf['image'].shape[0] + 1), axis = 0)\n",
    "        hf['image'][hf['image'].shape[0] - 1, :, :, :] = five_band_image\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e229d3d-7f80-4b94-b0ee-f368d75dac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('/data/HSC/HSC_v6/step3/127x127_generated.hdf5', 'a')\n",
    "prior1 = tfd.Independent(tfd.Normal(loc=tf.zeros(LATENT_DIM), scale = 0.1), reinterpreted_batch_ndims = 1)\n",
    "str = prior1.sample(1)[0]\n",
    "str = np.concatenate((str, np.array([0.1])))\n",
    "str = str.reshape(1, LATENT_DIM + 1)\n",
    "image_g = decoder([str])[0][0]\n",
    "image_r = decoder([str])[0][1]\n",
    "image_i = decoder([str])[0][2]\n",
    "image_z = decoder([str])[0][3]\n",
    "image_y = decoder([str])[0][4]\n",
    "five_band_image = []\n",
    "five_band_image.append(image_g)\n",
    "five_band_image.append(image_r)\n",
    "five_band_image.append(image_i)\n",
    "five_band_image.append(image_z)\n",
    "five_band_image.append(image_y)\n",
    "five_band_image_reshape = np.reshape(np.array(five_band_image), [1, 5, 127, 127])\n",
    "hf.create_dataset('image', data = five_band_image_reshape, chunks = True, maxshape = (None, 5, 127, 127))\n",
    "hf.create_dataset('specz_redshift', data = [0.1], chunks = True, maxshape = (None, ))\n",
    "for i in range(9999):\n",
    "    z = random.uniform(0, 4)\n",
    "    str = prior.sample(1)[0]\n",
    "    str = np.concatenate((str, np.array([z])))\n",
    "    str = str.reshape(1, LATENT_DIM + 1)\n",
    "    image_g = decoder([str])[0][0]\n",
    "    image_r = decoder([str])[0][1]\n",
    "    image_i = decoder([str])[0][2]\n",
    "    image_z = decoder([str])[0][3]\n",
    "    image_y = decoder([str])[0][4]\n",
    "    five_band_image = []\n",
    "    five_band_image.append(image_g)\n",
    "    five_band_image.append(image_r)\n",
    "    five_band_image.append(image_i)\n",
    "    five_band_image.append(image_z)\n",
    "    five_band_image.append(image_y)\n",
    "    five_band_image_reshape = np.reshape(np.array(five_band_image), [1, 5, 127, 127])\n",
    "    hf['specz_redshift'].resize((hf['specz_redshift'].shape[0] + 1), axis = 0)\n",
    "    hf['specz_redshift'][hf['specz_redshift'].shape[0] - 1] = [z]\n",
    "    hf['image'].resize((hf['image'].shape[0] + 1), axis = 0)\n",
    "    hf['image'][hf['image'].shape[0] - 1, :, :, :] = five_band_image\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn",
   "language": "python",
   "name": "bnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d47a89fa-d25d-4dc9-9355-fa324e467b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 15:12:22.247789: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-06 15:12:22.833603: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "from DataMakerNoZ import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d33e88-48be-4fc4-b7b0-d80e0187da57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 15:12:24.454123: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-06 15:12:24.487014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-06 15:12:24.487262: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-06 15:12:24.490519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-06 15:12:24.490717: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-06 15:12:24.490894: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-06 15:12:24.570114: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-06 15:12:24.570358: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-06 15:12:24.570543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-06 15:12:24.570688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20000 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU');\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 20000)]);\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU');\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dd65ff6-462d-46f8-88cc-98ebd2875eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "num_epochs = 1  # Just for the sake of demonstration\n",
    "total_timesteps = 1000\n",
    "norm_groups = 8  # Number of groups used in GroupNormalization layer\n",
    "learning_rate = 2e-3\n",
    "BETA_START = 1e-4\n",
    "BETA_END = 0.02\n",
    "\n",
    "img_size = 64\n",
    "img_channels = 5\n",
    "\n",
    "first_conv_channels = 64\n",
    "channel_multiplier = [1, 2, 4, 8]\n",
    "widths = [first_conv_channels * mult for mult in channel_multiplier]\n",
    "has_attention = [False, False, True, True]\n",
    "num_res_blocks = 2  # Number of residual blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131204d9-b4bc-48a2-8521-986861d51be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = f'/data/HSC/HSC_v6/step2A/64x64/5x64x64_training.hdf5'\n",
    "TEST_PATH = f'/data/HSC/HSC_v6/step2A/64x64/5x64x64_testing.hdf5'\n",
    "\n",
    "gen_args = {\n",
    "    'X_key': 'image',\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'shuffle': False}\n",
    "\n",
    "train_gen = HDF5ImageGenerator(TRAIN_PATH, mode = 'train', **gen_args)\n",
    "test_gen = HDF5ImageGenerator(TEST_PATH, mode = 'train', **gen_args)\n",
    "# print(train_gen[0][0].shape) # a batch of images\n",
    "# print(train_gen[0][1].shape) # a batch of corresponding redshifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3ddc3e54-b9e9-48ae-8d5f-ba6bb3238f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusion:\n",
    "    \"\"\"Gaussian diffusion utility.\n",
    "\n",
    "    Args:\n",
    "        beta_start: Start value of the scheduled variance\n",
    "        beta_end: End value of the scheduled variance\n",
    "        timesteps: Number of time steps in the forward process\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        beta_start=BETA_START,\n",
    "        beta_end=BETA_END,\n",
    "        timesteps=1000,\n",
    "    ):\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "        # Define the linear variance schedule\n",
    "        self.betas = betas = np.linspace(\n",
    "            beta_start,\n",
    "            beta_end,\n",
    "            timesteps,\n",
    "            dtype=np.float64,  # Using float64 for better precision\n",
    "        )\n",
    "        self.num_timesteps = int(timesteps)\n",
    "\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, 0)\n",
    "        alphas_cumprod_prev = np.append(1.0, alphas_cumprod[:-1])\n",
    "\n",
    "        self.betas = tf.constant(betas, dtype=tf.float32)\n",
    "        self.alphas_cumprod = tf.constant(alphas_cumprod, dtype=tf.float32)\n",
    "        self.alphas_cumprod_prev = tf.constant(alphas_cumprod_prev, dtype=tf.float32)\n",
    "\n",
    "        # Calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.sqrt_alphas_cumprod = tf.constant(\n",
    "            np.sqrt(alphas_cumprod), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        self.sqrt_one_minus_alphas_cumprod = tf.constant(\n",
    "            np.sqrt(1.0 - alphas_cumprod), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        self.log_one_minus_alphas_cumprod = tf.constant(\n",
    "            np.log(1.0 - alphas_cumprod), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        self.sqrt_recip_alphas_cumprod = tf.constant(\n",
    "            np.sqrt(1.0 / alphas_cumprod), dtype=tf.float32\n",
    "        )\n",
    "        self.sqrt_recipm1_alphas_cumprod = tf.constant(\n",
    "            np.sqrt(1.0 / alphas_cumprod - 1), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        # Calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = (\n",
    "            betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
    "        )\n",
    "        self.posterior_variance = tf.constant(posterior_variance, dtype=tf.float32)\n",
    "\n",
    "        # Log calculation clipped because the posterior variance is 0 at the beginning\n",
    "        # of the diffusion chain\n",
    "        self.posterior_log_variance_clipped = tf.constant(\n",
    "            np.log(np.maximum(posterior_variance, 1e-20)), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        self.posterior_mean_coef1 = tf.constant(\n",
    "            betas * np.sqrt(alphas_cumprod_prev) / (1.0 - alphas_cumprod),\n",
    "            dtype=tf.float32,\n",
    "        )\n",
    "\n",
    "        self.posterior_mean_coef2 = tf.constant(\n",
    "            (1.0 - alphas_cumprod_prev) * np.sqrt(alphas) / (1.0 - alphas_cumprod),\n",
    "            dtype=tf.float32,\n",
    "        )\n",
    "\n",
    "    def _extract(self, a, t, x_shape):\n",
    "        \"\"\"Extract some coefficients at specified timesteps,\n",
    "        then reshape to [BATCH_SIZE, 1, 1, 1, 1, ...] for broadcasting purposes.\n",
    "\n",
    "        Args:\n",
    "            a: Tensor to extract from\n",
    "            t: Timestep for which the coefficients are to be extracted\n",
    "            x_shape: Shape of the current batched samples\n",
    "        \"\"\"\n",
    "        BATCH_SIZE = x_shape[0]\n",
    "        out = tf.gather(a, t)\n",
    "        return tf.reshape(out, [BATCH_SIZE, 1, 1, 1])\n",
    "\n",
    "    def q_mean_variance(self, x_start, t):\n",
    "        \"\"\"Extracts the mean, and the variance at current timestep.\n",
    "\n",
    "        Args:\n",
    "            x_start: Initial sample (before the first diffusion step)\n",
    "            t: Current timestep\n",
    "        \"\"\"\n",
    "        x_start_shape = tf.shape(x_start)\n",
    "        mean = self._extract(self.sqrt_alphas_cumprod, t, x_start_shape) * x_start\n",
    "        variance = self._extract(1.0 - self.alphas_cumprod, t, x_start_shape)\n",
    "        log_variance = self._extract(\n",
    "            self.log_one_minus_alphas_cumprod, t, x_start_shape\n",
    "        )\n",
    "        return mean, variance, log_variance\n",
    "\n",
    "    def q_sample(self, x_start, t, noise):\n",
    "        \"\"\"Diffuse the data.\n",
    "\n",
    "        Args:\n",
    "            x_start: Initial sample (before the first diffusion step)\n",
    "            t: Current timestep\n",
    "            noise: Gaussian noise to be added at the current timestep\n",
    "        Returns:\n",
    "            Diffused samples at timestep `t`\n",
    "        \"\"\"\n",
    "        x_start_shape = tf.shape(x_start)\n",
    "        return (\n",
    "            self._extract(self.sqrt_alphas_cumprod, t, tf.shape(x_start)) * x_start\n",
    "            + self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start_shape)\n",
    "            * noise\n",
    "        )\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        x_t_shape = tf.shape(x_t)\n",
    "        return (\n",
    "            self._extract(self.sqrt_recip_alphas_cumprod, t, x_t_shape) * x_t\n",
    "            - self._extract(self.sqrt_recipm1_alphas_cumprod, t, x_t_shape) * noise\n",
    "        )\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        \"\"\"Compute the mean and variance of the diffusion\n",
    "        posterior q(x_{t-1} | x_t, x_0).\n",
    "\n",
    "        Args:\n",
    "            x_start: Stating point(sample) for the posterior computation\n",
    "            x_t: Sample at timestep `t`\n",
    "            t: Current timestep\n",
    "        Returns:\n",
    "            Posterior mean and variance at current timestep\n",
    "        \"\"\"\n",
    "\n",
    "        x_t_shape = tf.shape(x_t)\n",
    "        posterior_mean = (\n",
    "            self._extract(self.posterior_mean_coef1, t, x_t_shape) * x_start\n",
    "            + self._extract(self.posterior_mean_coef2, t, x_t_shape) * x_t\n",
    "        )\n",
    "        posterior_variance = self._extract(self.posterior_variance, t, x_t_shape)\n",
    "        posterior_log_variance_clipped = self._extract(\n",
    "            self.posterior_log_variance_clipped, t, x_t_shape\n",
    "        )\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(self, pred_noise, x, t, clip_denoised=True):\n",
    "        x_recon = self.predict_start_from_noise(x, t=t, noise=pred_noise)\n",
    "        if clip_denoised:\n",
    "            x_recon = x_recon\n",
    "\n",
    "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(\n",
    "            x_start=x_recon, x_t=x, t=t\n",
    "        )\n",
    "        return model_mean, posterior_variance, posterior_log_variance\n",
    "\n",
    "    def p_sample(self, pred_noise, x, t, clip_denoised=True):\n",
    "        \"\"\"Sample from the diffusion model.\n",
    "\n",
    "        Args:\n",
    "            pred_noise: Noise predicted by the diffusion model\n",
    "            x: Samples at a given timestep for which the noise was predicted\n",
    "            t: Current timestep\n",
    "            clip_denoised (bool): Whether to clip the predicted noise\n",
    "                within the specified range or not.\n",
    "        \"\"\"\n",
    "        model_mean, _, model_log_variance = self.p_mean_variance(\n",
    "            pred_noise, x=x, t=t, clip_denoised=clip_denoised\n",
    "        )\n",
    "        noise = tf.random.normal(shape=x.shape, dtype=x.dtype)\n",
    "        # No noise when t == 0\n",
    "        nonzero_mask = tf.reshape(\n",
    "            1 - tf.cast(tf.equal(t, 0), tf.float32), [tf.shape(x)[0], 1, 1, 1]\n",
    "        )\n",
    "        return model_mean + nonzero_mask * tf.exp(0.5 * model_log_variance) * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2c0e417b-4a24-4a22-b508-b96955b8c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel initializer to use\n",
    "def kernel_init(scale):\n",
    "    scale = max(scale, 1e-10)\n",
    "    return keras.initializers.VarianceScaling(\n",
    "        scale, mode=\"fan_avg\", distribution=\"uniform\"\n",
    "    )\n",
    "\n",
    "\n",
    "class AttentionBlock(layers.Layer):\n",
    "    \"\"\"Applies self-attention.\n",
    "\n",
    "    Args:\n",
    "        units: Number of units in the dense layers\n",
    "        groups: Number of groups to be used for GroupNormalization layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, units, groups=8, **kwargs):\n",
    "        self.units = units\n",
    "        self.groups = groups\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.norm = layers.GroupNormalization(groups=groups)\n",
    "        self.query = layers.Dense(units, kernel_initializer=kernel_init(1.0))\n",
    "        self.key = layers.Dense(units, kernel_initializer=kernel_init(1.0))\n",
    "        self.value = layers.Dense(units, kernel_initializer=kernel_init(1.0))\n",
    "        self.proj = layers.Dense(units, kernel_initializer=kernel_init(0.0))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        channels = tf.shape(inputs)[1]\n",
    "        height = tf.shape(inputs)[2]\n",
    "        width = tf.shape(inputs)[3]\n",
    "        scale = tf.cast(self.units, tf.float32) ** (-0.5)\n",
    "\n",
    "        # Normalization and Dense layers are applied\n",
    "        inputs = self.norm(inputs)\n",
    "        q = self.query(inputs)\n",
    "        k = self.key(inputs)\n",
    "        v = self.value(inputs)\n",
    "        \n",
    "        v = tf.reshape(v, [batch_size, channels, height, width])\n",
    "\n",
    "        # Adjust tensor operations for channels-first format\n",
    "        attn_score = tf.einsum(\"bchw, bcHW->bhwHW\", q, k) * scale\n",
    "        attn_score = tf.reshape(attn_score, [batch_size, height, width, height * width])\n",
    "\n",
    "        attn_score = tf.nn.softmax(attn_score, -1)\n",
    "        attn_score = tf.reshape(attn_score, [batch_size, height, width, height, width])\n",
    "\n",
    "        proj = tf.einsum(\"bhwHW, bchw -> bchw\", attn_score, v)\n",
    "        proj = self.proj(proj)\n",
    "        \n",
    "        proj = tf.reshape(proj, [batch_size, channels, height, width])\n",
    "        return inputs + proj\n",
    "\n",
    "class TimeEmbedding(layers.Layer):\n",
    "    def __init__(self, dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.half_dim = dim // 2\n",
    "        self.emb = math.log(10000) / (self.half_dim - 1)\n",
    "        self.emb = tf.exp(tf.range(self.half_dim, dtype=tf.float32) * -self.emb)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.cast(inputs, dtype=tf.float32)\n",
    "        emb = inputs[:, None] * self.emb[None, :]\n",
    "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=-1)\n",
    "        return emb\n",
    "\n",
    "\n",
    "def ResidualBlock(width, groups=8, activation_fn=keras.activations.swish):\n",
    "    def apply(inputs):\n",
    "        x, t = inputs\n",
    "        input_width = x.shape[1]\n",
    "\n",
    "        if input_width == width:\n",
    "            residual = x\n",
    "        else:\n",
    "            residual = layers.Conv2D(\n",
    "                width, kernel_size=1, kernel_initializer=kernel_init(1.0), data_format='channels_first'\n",
    "            )(x)\n",
    "\n",
    "        temb = activation_fn(t)\n",
    "        temb = layers.Dense(width, kernel_initializer=kernel_init(1.0))(temb)[\n",
    "            :, :, None, None\n",
    "        ]\n",
    "\n",
    "        x = layers.GroupNormalization(groups=groups)(x)\n",
    "        x = activation_fn(x)\n",
    "        x = layers.Conv2D(\n",
    "            width, kernel_size=3, padding=\"same\", kernel_initializer=kernel_init(1.0), data_format='channels_first'\n",
    "        )(x)\n",
    "\n",
    "        x = layers.Add()([x, temb])\n",
    "        x = layers.GroupNormalization(groups=groups)(x)\n",
    "        x = activation_fn(x)\n",
    "\n",
    "        x = layers.Conv2D(\n",
    "            width, kernel_size=3, padding=\"same\", kernel_initializer=kernel_init(0.0), data_format='channels_first'\n",
    "        )(x)\n",
    "        x = layers.Add()([x, residual])\n",
    "        return x\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "def DownSample(width):\n",
    "    def apply(x):\n",
    "        x = layers.Conv2D(\n",
    "            width,\n",
    "            kernel_size=3,\n",
    "            strides=2,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=kernel_init(1.0),\n",
    "            data_format='channels_first',\n",
    "        )(x)\n",
    "        return x\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "def UpSample(width, interpolation=\"nearest\"):\n",
    "    def apply(x):\n",
    "        x = layers.UpSampling2D(size=2, interpolation=interpolation, data_format='channels_first')(x)\n",
    "        x = layers.Conv2D(\n",
    "            width, kernel_size=3, padding=\"same\", kernel_initializer=kernel_init(1.0), data_format='channels_first'\n",
    "        )(x)\n",
    "        return x\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "def TimeMLP(units, activation_fn=keras.activations.swish):\n",
    "    def apply(inputs):\n",
    "        temb = layers.Dense(\n",
    "            units, activation=activation_fn, kernel_initializer=kernel_init(1.0)\n",
    "        )(inputs)\n",
    "        temb = layers.Dense(units, kernel_initializer=kernel_init(1.0))(temb)\n",
    "        return temb\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "def build_model(\n",
    "    img_size,\n",
    "    img_channels,\n",
    "    widths,\n",
    "    has_attention,\n",
    "    num_res_blocks=2,\n",
    "    norm_groups=8,\n",
    "    interpolation=\"nearest\",\n",
    "    activation_fn=keras.activations.swish,\n",
    "):\n",
    "    image_input = layers.Input(\n",
    "        shape=(img_channels, img_size, img_size), name=\"image_input\"\n",
    "    )\n",
    "    time_input = keras.Input(shape=(), dtype=tf.int64, name=\"time_input\")\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "        first_conv_channels,\n",
    "        kernel_size=(3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=kernel_init(1.0), \n",
    "        data_format='channels_first',\n",
    "    )(image_input)\n",
    "\n",
    "    temb = TimeEmbedding(dim=first_conv_channels * 4)(time_input)\n",
    "    temb = TimeMLP(units=first_conv_channels * 4, activation_fn=activation_fn)(temb)\n",
    "\n",
    "    skips = [x]\n",
    "\n",
    "    # DownBlock\n",
    "    for i in range(len(widths)):\n",
    "        for _ in range(num_res_blocks):\n",
    "            x = ResidualBlock(\n",
    "                widths[i], groups=norm_groups, activation_fn=activation_fn\n",
    "            )([x, temb])\n",
    "            if has_attention[i]:\n",
    "                x = AttentionBlock(widths[i], groups=norm_groups)(x)\n",
    "            skips.append(x)\n",
    "\n",
    "        if widths[i] != widths[-1]:\n",
    "            x = DownSample(widths[i])(x)\n",
    "            skips.append(x)\n",
    "\n",
    "    # MiddleBlock\n",
    "    x = ResidualBlock(widths[-1], groups=norm_groups, activation_fn=activation_fn)(\n",
    "        [x, temb]\n",
    "    )\n",
    "    x = AttentionBlock(widths[-1], groups=norm_groups)(x)\n",
    "    x = ResidualBlock(widths[-1], groups=norm_groups, activation_fn=activation_fn)(\n",
    "        [x, temb]\n",
    "    )\n",
    "\n",
    "    # UpBlock\n",
    "    for i in reversed(range(len(widths))):\n",
    "        for _ in range(num_res_blocks + 1):\n",
    "            x = layers.Concatenate(axis=1)([x, skips.pop()])\n",
    "            x = ResidualBlock(\n",
    "                widths[i], groups=norm_groups, activation_fn=activation_fn\n",
    "            )([x, temb])\n",
    "            if has_attention[i]:\n",
    "                x = AttentionBlock(widths[i], groups=norm_groups)(x)\n",
    "\n",
    "        if i != 0:\n",
    "            x = UpSample(widths[i], interpolation=interpolation)(x)\n",
    "\n",
    "    # End block\n",
    "    x = layers.GroupNormalization(groups=norm_groups)(x)\n",
    "    x = activation_fn(x)\n",
    "    x = layers.Conv2D(5, (3, 3), padding=\"same\", kernel_initializer=kernel_init(0.0), data_format='channels_first')(x)\n",
    "    return keras.Model([image_input, time_input], x, name=\"unet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "745b24bf-ebd4-421d-987e-c6fe8836af1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 18:58:26.707587: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-01-06 18:58:54.227019: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: Input to reshape is a tensor with 33554432 values, but the requested shape has 2097152\n",
      "\t [[{{node unet/attention_block_102/Reshape}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'unet/attention_block_102/Reshape' defined at (most recent call last):\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3820630/740245610.py\", line 125, in <module>\n      model.fit(\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/tmp/ipykernel_3820630/740245610.py\", line 27, in train_step\n      pred_noise = self.network([images_t, t], training=True)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/tmp/ipykernel_3820630/1447819773.py\", line 41, in call\n      v = tf.reshape(v, [batch_size, channels, height, width])\nNode: 'unet/attention_block_102/Reshape'\nInput to reshape is a tensor with 33554432 values, but the requested shape has 2097152\n\t [[{{node unet/attention_block_102/Reshape}}]] [Op:__inference_train_function_275735]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 125\u001b[0m\n\u001b[1;32m    119\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m    120\u001b[0m     loss\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMeanSquaredError(),\n\u001b[1;32m    121\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate),\n\u001b[1;32m    122\u001b[0m )\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLambdaCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mon_epoch_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_images\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/Diffusion/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'unet/attention_block_102/Reshape' defined at (most recent call last):\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3820630/740245610.py\", line 125, in <module>\n      model.fit(\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/tmp/ipykernel_3820630/740245610.py\", line 27, in train_step\n      pred_noise = self.network([images_t, t], training=True)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/tmp/ipykernel_3820630/1447819773.py\", line 41, in call\n      v = tf.reshape(v, [batch_size, channels, height, width])\nNode: 'unet/attention_block_102/Reshape'\nInput to reshape is a tensor with 33554432 values, but the requested shape has 2097152\n\t [[{{node unet/attention_block_102/Reshape}}]] [Op:__inference_train_function_275735]"
     ]
    }
   ],
   "source": [
    "class DiffusionModel(keras.Model):\n",
    "    def __init__(self, network, ema_network, timesteps, gdf_util, ema=0.999):\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.ema_network = ema_network\n",
    "        self.timesteps = timesteps\n",
    "        self.gdf_util = gdf_util\n",
    "        self.ema = ema\n",
    "\n",
    "    def train_step(self, images):\n",
    "        # 1. Get the batch size\n",
    "        BATCH_SIZE = tf.shape(images)[0]\n",
    "\n",
    "        # 2. Sample timesteps uniformly\n",
    "        t = tf.random.uniform(\n",
    "            minval=0, maxval=self.timesteps, shape=(BATCH_SIZE,), dtype=tf.int64\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 3. Sample random noise to be added to the images in the batch\n",
    "            noise = tf.random.normal(shape=tf.shape(images), dtype=images.dtype)\n",
    "\n",
    "            # 4. Diffuse the images with noise\n",
    "            images_t = self.gdf_util.q_sample(images, t, noise)\n",
    "\n",
    "            # 5. Pass the diffused images and time steps to the network\n",
    "            pred_noise = self.network([images_t, t], training=True)\n",
    "\n",
    "            # 6. Calculate the loss\n",
    "            loss = self.loss(noise, pred_noise)\n",
    "\n",
    "        # 7. Get the gradients\n",
    "        gradients = tape.gradient(loss, self.network.trainable_weights)\n",
    "\n",
    "        # 8. Update the weights of the network\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.network.trainable_weights))\n",
    "\n",
    "        # 9. Updates the weight values for the network with EMA weights\n",
    "        for weight, ema_weight in zip(self.network.weights, self.ema_network.weights):\n",
    "            ema_weight.assign(self.ema * ema_weight + (1 - self.ema) * weight)\n",
    "\n",
    "        # 10. Return loss values\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def generate_images(self, num_images=16):\n",
    "        # 1. Randomly sample noise (starting point for reverse process)\n",
    "        samples = tf.random.normal(\n",
    "            shape=(num_images, img_channels, img_size, img_size), dtype=tf.float32\n",
    "        )\n",
    "        # 2. Sample from the model iteratively\n",
    "        for t in reversed(range(0, self.timesteps)):\n",
    "            tt = tf.cast(tf.fill(num_images, t), dtype=tf.int64)\n",
    "            pred_noise = self.ema_network.predict(\n",
    "                [samples, tt], verbose=0, batch_size=num_images\n",
    "            )\n",
    "            samples = self.gdf_util.p_sample(\n",
    "                pred_noise, samples, tt, clip_denoised=True\n",
    "            )\n",
    "        # 3. Return generated samples\n",
    "        return samples\n",
    "\n",
    "    def plot_images(\n",
    "        self, epoch=None, logs=None, num_rows=2, num_cols=8, figsize=(12, 5)\n",
    "    ):\n",
    "        \"\"\"Utility to plot images using the diffusion model during training.\"\"\"\n",
    "        generated_samples = self.generate_images(num_images=num_rows * num_cols)\n",
    "        generated_samples = (\n",
    "            generated_samples\n",
    "            .numpy()\n",
    "            .astype(np.uint8)\n",
    "        )\n",
    "\n",
    "        _, ax = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "        for i, image in enumerate(generated_samples):\n",
    "            if num_rows == 1:\n",
    "                ax[i].imshow(image)\n",
    "                ax[i].axis(\"off\")\n",
    "            else:\n",
    "                ax[i // num_cols, i % num_cols].imshow(image[0])\n",
    "                ax[i // num_cols, i % num_cols].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Build the unet model\n",
    "network = build_model(\n",
    "    img_size=img_size,\n",
    "    img_channels=img_channels,\n",
    "    widths=widths,\n",
    "    has_attention=has_attention,\n",
    "    num_res_blocks=num_res_blocks,\n",
    "    norm_groups=norm_groups,\n",
    "    activation_fn=keras.activations.swish,\n",
    ")\n",
    "ema_network = build_model(\n",
    "    img_size=img_size,\n",
    "    img_channels=img_channels,\n",
    "    widths=widths,\n",
    "    has_attention=has_attention,\n",
    "    num_res_blocks=num_res_blocks,\n",
    "    norm_groups=norm_groups,\n",
    "    activation_fn=keras.activations.swish,\n",
    ")\n",
    "ema_network.set_weights(network.get_weights())  # Initially the weights are the same\n",
    "\n",
    "# Get an instance of the Gaussian Diffusion utilities\n",
    "gdf_util = GaussianDiffusion(timesteps=total_timesteps)\n",
    "\n",
    "# Get the model\n",
    "model = DiffusionModel(\n",
    "    network=network,\n",
    "    ema_network=ema_network,\n",
    "    gdf_util=gdf_util,\n",
    "    timesteps=total_timesteps,\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[keras.callbacks.LambdaCallback(on_epoch_end=model.plot_images)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02180a69-6da2-4414-b5d9-e7f38536b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_gen,\n",
    "    epochs=1000,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[keras.callbacks.LambdaCallback(on_epoch_end=model.plot_images)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bf529d-aaea-4a9f-8667-ae088fb8ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_images(num_rows=4, num_cols=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de134613-0260-426d-9edb-ded5d20f680e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99045c8-66b5-4b53-b96c-77961cf4a27c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diffusion",
   "language": "python",
   "name": "diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

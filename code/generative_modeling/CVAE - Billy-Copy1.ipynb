{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f923d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "write = False # log this version as new\n",
    "MODEL_DESCRIPTION = \"Increase KL weight\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d23f862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import stdout\n",
    "from datetime import datetime\n",
    "import neptune.new as neptune\n",
    "from neptune.new.integrations.tensorflow_keras import NeptuneCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2032fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Cropping2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Reshape\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import layers as tfpl\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow.nn import leaky_relu\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82e0800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 128\n",
    "BASE_DEPTH = 8\n",
    "IMAGE_SHAPE = (5, 127, 127)\n",
    "EPOCHS = 200\n",
    "CHECKPOINTS_TO_SAVE = 4\n",
    "KL_WEIGHT = 1e-5\n",
    "# Good value: 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a44e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU');\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 20000)]);\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU');\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb7cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "DATASET_NAME = \"HSC_v6_small\"\n",
    "MODEL_TYPE = \"VAE\"\n",
    "MODEL_VERSION = \"v1.0\"\n",
    "MODEL_SUBVERSION = \"v1.0.\" + now.strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "\n",
    "model_id = '_'.join([DATASET_NAME, MODEL_TYPE, MODEL_VERSION])\n",
    "model_path = os.path.join('/models', model_id, MODEL_SUBVERSION, 'model')\n",
    "checkpoints_path = os.path.join('/models', model_id, MODEL_SUBVERSION, 'checkpoints')\n",
    "logs_path = os.path.join('/logs', model_id, MODEL_SUBVERSION)\n",
    "predictions_path = os.path.join('/predictions', model_id, MODEL_SUBVERSION)\n",
    "weights_path = model_path + '/weights.h5'\n",
    "\n",
    "os.makedirs(model_path, exist_ok = True)\n",
    "os.makedirs(checkpoints_path, exist_ok = True)\n",
    "os.makedirs(logs_path, exist_ok = True)\n",
    "os.makedirs(predictions_path, exist_ok = True)\n",
    "\n",
    "if write == True:\n",
    "    with open(\"/models/README.md\", \"a\") as myfile:\n",
    "        myfile.write(MODEL_TYPE + \" \" + MODEL_SUBVERSION + \" - \" + MODEL_DESCRIPTION + \" - B. Li\" + \"\\n\")\n",
    "else:\n",
    "    with open(\"/models/README.md\", \"a\") as myfile:\n",
    "        myfile.write(MODEL_TYPE + \" \" + MODEL_SUBVERSION + \" - ... \"+ \" - B. Li\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06c90a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_train = h5py.File('/data/HSC/HSC_v6/step2A/127x127/5x127x127_training_small.hdf5', 'r')\n",
    "hf_test = h5py.File('/data/HSC/HSC_v6/step2A/127x127/5x127x127_testing_small.hdf5', 'r')\n",
    "hf_validation = h5py.File('/data/HSC/HSC_v6/step2A/127x127/5x127x127_validation_small.hdf5', 'r')\n",
    "x_train = np.asarray(hf_train['image'][0:])\n",
    "x_test = np.asarray(hf_test['image'][0:])\n",
    "x_validation = np.asarray(hf_validation['image'][0:])\n",
    "max_value = 4.16\n",
    "x_train = np.true_divide(x_train, max_value)\n",
    "x_test = np.true_divide(x_test, max_value)\n",
    "x_validation = np.true_divide(x_validation, max_value)\n",
    "y_train = np.asarray(hf_train['specz_redshift'][0:])\n",
    "y_test = np.asarray(hf_test['specz_redshift'][0:])\n",
    "y_validation = np.asarray(hf_validation['specz_redshift'][0:])\n",
    "# object_id_train = np.asarray(hf_train['object_id'][0:])\n",
    "# object_id = np.asarray(hf_test['object_id'][0:])\n",
    "# object_id_validation = np.asarray(hf_validation['object_id'][0:])\n",
    "hf_train.close()\n",
    "hf_test.close()\n",
    "hf_validation.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4a73521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(y_train)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c9f1147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = len(x_train) - 1\n",
    "# while i >= 0:\n",
    "#     if y_train[i]>=0.1:\n",
    "#         x_train = np.delete(x_train, i)\n",
    "#         y_train = np.delete(y_train, i)\n",
    "#     i -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca6fd86",
   "metadata": {},
   "source": [
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(LATENT_DIM), scale = 0.1), reinterpreted_batch_ndims = 1)\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        images = Input(shape = IMAGE_SHAPE)\n",
    "        redshifts = Input(shape = 1,)\n",
    "        conv1 = Conv2D(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "                   padding = 'same', data_format = 'channels_first')(images)\n",
    "        conv2 = Conv2D(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "                   padding = 'same', data_format = 'channels_first')(conv1)\n",
    "        flatten = Flatten()(conv2)\n",
    "        dense1 = Dense(4096, activation = None)(flatten)\n",
    "        dense2 = tf.keras.layers.Dense(32, activation = \"relu\")(redshifts)\n",
    "        dense3 = tf.keras.layers.Dense(32, activation = \"relu\")(dense2)\n",
    "        concat = tf.keras.layers.Concatenate()([dense1, dense3])\n",
    "        dense4 = Dense(tfpl.MultivariateNormalTriL.params_size(LATENT_DIM), activation = None)(concat)\n",
    "        z = tfpl.MultivariateNormalTriL(LATENT_DIM,\n",
    "                  activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight = KL_WEIGHT))(dense4)\n",
    "        self.encoder = Model([images, redshifts], z, name = 'encoder')\n",
    "\n",
    "        latents = Input(shape = LATENT_DIM)\n",
    "        x = Dense(8 * LATENT_DIM * 32 * 32, activation = None)(latents)\n",
    "        x = Reshape((8 * LATENT_DIM, 32, 32))(x)\n",
    "        x = Conv2DTranspose(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "                            padding = 'same', data_format = 'channels_first')(x)\n",
    "        x = Conv2DTranspose(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "                            padding = 'same', data_format = 'channels_first')(x)\n",
    "        x = Conv2DTranspose(BASE_DEPTH, 3, strides = 1, activation = leaky_relu,\n",
    "                            padding = 'same', data_format = 'channels_first')(x)\n",
    "        x = Conv2D(IMAGE_SHAPE[0], 3, strides = 1, activation = None, \n",
    "                   padding = 'same', data_format = 'channels_first')(x)\n",
    "        outputs = Cropping2D(cropping=((0, 1), (0, 1)), data_format = 'channels_first')(x)\n",
    "        self.decoder = Model(latents, outputs, name = 'decoder')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def summary(self):\n",
    "        print(self.encoder.summary())\n",
    "        print(self.decoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d31d75f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(LATENT_DIM), scale = 0.1), reinterpreted_batch_ndims = 1)\n",
    "\n",
    "images = Input(shape = IMAGE_SHAPE)\n",
    "redshifts = Input(shape = 1,)\n",
    "conv1 = Conv2D(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "            padding = 'same', data_format = 'channels_first')(images)\n",
    "conv2 = Conv2D(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "            padding = 'same', data_format = 'channels_first')(conv1)\n",
    "flatten = Flatten()(conv2)\n",
    "dense1 = Dense(4096, activation = None)(flatten)\n",
    "dense2 = tf.keras.layers.Dense(32, activation = \"relu\")(redshifts)\n",
    "dense3 = tf.keras.layers.Dense(32, activation = \"relu\")(dense2)\n",
    "concat = tf.keras.layers.Concatenate()([dense1, dense3])\n",
    "dense4 = Dense(tfpl.MultivariateNormalTriL.params_size(LATENT_DIM), activation = None)(concat)\n",
    "z = tfpl.MultivariateNormalTriL(LATENT_DIM,\n",
    "            activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight = KL_WEIGHT))(dense4)\n",
    "encoder = Model([images, redshifts], z)\n",
    "\n",
    "zc = tf.keras.layers.Concatenate()([z, redshifts])\n",
    "\n",
    "dense5 = Dense(8 * LATENT_DIM * 32 * 32, activation = None)(z)\n",
    "reshape = Reshape((8 * LATENT_DIM, 32, 32))(dense5)\n",
    "conv3 = Conv2DTranspose(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "                    padding = 'same', data_format = 'channels_first')(reshape)\n",
    "conv4 = Conv2DTranspose(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "                    padding = 'same', data_format = 'channels_first')(conv3)\n",
    "conv5 = Conv2DTranspose(BASE_DEPTH, 3, strides = 1, activation = leaky_relu, \n",
    "                    padding = 'same', data_format = 'channels_first')(conv4)\n",
    "conv6 = Conv2D(IMAGE_SHAPE[0], 3, strides = 1, activation = None, \n",
    "           padding = 'same', data_format = 'channels_first')(conv5)\n",
    "cropping = Cropping2D(cropping=((0, 1), (0, 1)), data_format = 'channels_first')(conv6)\n",
    "outputs = Reshape(IMAGE_SHAPE)(cropping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c11d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = [images, redshifts], outputs = [outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e036f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = Input(shape = LATENT_DIM)\n",
    "dense5 = Dense(8 * LATENT_DIM * 32 * 32, activation = None)(latents)\n",
    "reshape = Reshape((8 * LATENT_DIM, 32, 32))(dense5)\n",
    "conv3 = Conv2DTranspose(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "                    padding = 'same', data_format = 'channels_first')(reshape)\n",
    "conv4 = Conv2DTranspose(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "                    padding = 'same', data_format = 'channels_first')(conv3)\n",
    "conv5 = Conv2DTranspose(BASE_DEPTH, 3, strides = 1, activation = leaky_relu, \n",
    "                    padding = 'same', data_format = 'channels_first')(conv4)\n",
    "conv6 = Conv2D(IMAGE_SHAPE[0], 3, strides = 1, activation = None, \n",
    "           padding = 'same', data_format = 'channels_first')(conv5)\n",
    "cropping = Cropping2D(cropping=((0, 1), (0, 1)), data_format = 'channels_first')(conv6)\n",
    "outputs = Reshape(IMAGE_SHAPE)(cropping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17a65d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Model(latents, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c25fe180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 5, 127, 127) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 8, 64, 64)    368         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 8, 32, 32)    584         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8192)         0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           64          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4096)         33558528    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           1056        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4128)         0           dense[0][0]                      \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 8384)         34617536    concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multivariate_normal_tri_l (Mult multiple             0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1048576)      135266304   multivariate_normal_tri_l[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1024, 32, 32) 0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 8, 64, 64)    73736       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 8, 128, 128)  584         conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 8, 128, 128)  584         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 5, 128, 128)  365         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d (Cropping2D)         (None, 5, 127, 127)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 5, 127, 127)  0           cropping2d[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 203,519,709\n",
      "Trainable params: 203,519,709\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "102f84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def vae_loss(y_true, y_pred):\n",
    "    loss = K.sum(K.binary_crossentropy(y_true, y_pred), axis = -1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d463c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = vae_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4994aa27",
   "metadata": {},
   "source": [
    "model = VAE()\n",
    "model.compile(optimizer = 'adam', loss = 'mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcbb9c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/astro-data-lab/VAE/e/VAE-72\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init(\n",
    "    name = MODEL_SUBVERSION,\n",
    "    project = \"astro-data-lab/VAE\",\n",
    "    api_token = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGFlZGMxOC04MWU5LTQ2NDctYjlhZS05NGE2NGQ0NmIzMmEifQ==\",\n",
    ")  # your credentials\n",
    "\n",
    "# logs_callback = TensorBoard(log_dir = logs_path)\n",
    "\n",
    "weights_callback = ModelCheckpoint(filepath = os.path.join(checkpoints_path, 'weights_epoch{epoch}.hdf5'), save_freq = int(EPOCHS/CHECKPOINTS_TO_SAVE), save_weights_only = True)\n",
    "\n",
    "LR_callback = ReduceLROnPlateau()\n",
    "\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs_path, histogram_freq = 1)\n",
    "\n",
    "neptune_callback = NeptuneCallback(run = run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c65f61a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "313/313 [==============================] - 457s 120ms/step - loss: 74.8977 - val_loss: 46.2043\n",
      "Epoch 2/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 30.8552 - val_loss: 11.0054\n",
      "Epoch 3/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 11.2625 - val_loss: 51.7636\n",
      "Epoch 4/200\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 29.4781 - val_loss: 13.0189\n",
      "Epoch 5/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 13.8440 - val_loss: 4.1647\n",
      "Epoch 6/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 18.0308 - val_loss: 10.9453\n",
      "Epoch 7/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 10.4135 - val_loss: 6.7101\n",
      "Epoch 8/200\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 5.2424 - val_loss: 3.7860\n",
      "Epoch 9/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 4.5106 - val_loss: 2.6850\n",
      "Epoch 10/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 6.2619 - val_loss: 2.2581\n",
      "Epoch 11/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 3.5912 - val_loss: 3.9761\n",
      "Epoch 12/200\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 46.2809 - val_loss: 77.8722\n",
      "Epoch 13/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 80.6751 - val_loss: 46.3003\n",
      "Epoch 14/200\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 49.8647 - val_loss: 30.3354\n",
      "Epoch 15/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 29.1582 - val_loss: 20.8087\n",
      "Epoch 16/200\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 19.7235 - val_loss: 9.4136\n",
      "Epoch 17/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 4.7104 - val_loss: 6.3617\n",
      "Epoch 18/200\n",
      "313/313 [==============================] - 34s 110ms/step - loss: -1.6633 - val_loss: -3.5559\n",
      "Epoch 19/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 2.9457 - val_loss: 0.7992\n",
      "Epoch 20/200\n",
      "313/313 [==============================] - 43s 138ms/step - loss: -0.5175 - val_loss: -6.7569\n",
      "Epoch 21/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: -3.7198 - val_loss: -2.0586\n",
      "Epoch 22/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: -6.9406 - val_loss: -7.2949\n",
      "Epoch 23/200\n",
      "313/313 [==============================] - 37s 120ms/step - loss: -7.9286 - val_loss: -7.5409\n",
      "Epoch 24/200\n",
      "313/313 [==============================] - 42s 135ms/step - loss: -7.3808 - val_loss: -7.1146\n",
      "Epoch 25/200\n",
      "313/313 [==============================] - 38s 121ms/step - loss: -7.0202 - val_loss: -3.6472\n",
      "Epoch 26/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: -5.5088 - val_loss: 3.7945\n",
      "Epoch 27/200\n",
      "313/313 [==============================] - 42s 136ms/step - loss: 1.7546 - val_loss: -5.7950\n",
      "Epoch 28/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: -7.2823 - val_loss: -7.8885\n",
      "Epoch 29/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: -8.1366 - val_loss: -7.4910\n",
      "Epoch 30/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: -7.2111 - val_loss: 10.9050\n",
      "Epoch 31/200\n",
      "313/313 [==============================] - 41s 132ms/step - loss: -4.1377 - val_loss: -8.0156\n",
      "Epoch 32/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: -7.1383 - val_loss: -8.7482\n",
      "Epoch 33/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.9304 - val_loss: -1.7985\n",
      "Epoch 34/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -5.7873 - val_loss: 2.4639\n",
      "Epoch 35/200\n",
      "313/313 [==============================] - 42s 133ms/step - loss: -8.8370 - val_loss: -9.3112\n",
      "Epoch 36/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 1.1957 - val_loss: -8.9532\n",
      "Epoch 37/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 7.4706 - val_loss: -8.5335\n",
      "Epoch 38/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: -10.5850 - val_loss: -8.5873\n",
      "Epoch 39/200\n",
      "313/313 [==============================] - 41s 132ms/step - loss: -9.3496 - val_loss: -7.8274\n",
      "Epoch 40/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: 4.9041 - val_loss: -0.6001\n",
      "Epoch 41/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: -4.2908 - val_loss: 32.0554\n",
      "Epoch 42/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 3.1120 - val_loss: -6.6911\n",
      "Epoch 43/200\n",
      "313/313 [==============================] - 41s 132ms/step - loss: -0.7128 - val_loss: -9.2009\n",
      "Epoch 44/200\n",
      "313/313 [==============================] - 35s 113ms/step - loss: -6.6017 - val_loss: -6.6625\n",
      "Epoch 45/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: -5.7415 - val_loss: 1.4655\n",
      "Epoch 46/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -4.9808 - val_loss: -5.5651\n",
      "Epoch 47/200\n",
      "313/313 [==============================] - 42s 136ms/step - loss: -8.8034 - val_loss: -7.9287\n",
      "Epoch 48/200\n",
      "313/313 [==============================] - 39s 124ms/step - loss: -10.1910 - val_loss: -9.2330\n",
      "Epoch 49/200\n",
      "313/313 [==============================] - 39s 124ms/step - loss: -10.9556 - val_loss: -9.9053\n",
      "Epoch 50/200\n",
      "313/313 [==============================] - 43s 139ms/step - loss: -11.5836 - val_loss: -10.0086\n",
      "Epoch 51/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: -12.0220 - val_loss: -9.7596\n",
      "Epoch 52/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -12.0062 - val_loss: -10.2709\n",
      "Epoch 53/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: -12.5661 - val_loss: -10.1344\n",
      "Epoch 54/200\n",
      "313/313 [==============================] - 39s 126ms/step - loss: -12.6479 - val_loss: -11.5126\n",
      "Epoch 55/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: -10.1583 - val_loss: -9.6040\n",
      "Epoch 56/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -11.7861 - val_loss: -10.4510\n",
      "Epoch 57/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -12.7743 - val_loss: -11.2684\n",
      "Epoch 58/200\n",
      "313/313 [==============================] - 41s 131ms/step - loss: -12.9272 - val_loss: -10.9937\n",
      "Epoch 59/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -13.5440 - val_loss: -11.1342\n",
      "Epoch 60/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: -13.6419 - val_loss: -11.6872\n",
      "Epoch 61/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: -13.8464 - val_loss: -11.6255\n",
      "Epoch 62/200\n",
      "313/313 [==============================] - 41s 131ms/step - loss: -13.7668 - val_loss: -11.6091\n",
      "Epoch 63/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -14.2115 - val_loss: -11.7712\n",
      "Epoch 64/200\n",
      "313/313 [==============================] - 36s 117ms/step - loss: -13.8288 - val_loss: -11.9652\n",
      "Epoch 65/200\n",
      "313/313 [==============================] - 36s 117ms/step - loss: -14.0163 - val_loss: -12.3004\n",
      "Epoch 66/200\n",
      "313/313 [==============================] - 41s 132ms/step - loss: -14.4477 - val_loss: -12.5921\n",
      "Epoch 67/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -14.5661 - val_loss: -6.0314\n",
      "Epoch 68/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: -13.4948 - val_loss: -12.4357\n",
      "Epoch 69/200\n",
      "313/313 [==============================] - 39s 123ms/step - loss: -14.6752 - val_loss: -12.4257\n",
      "Epoch 70/200\n",
      "313/313 [==============================] - 41s 132ms/step - loss: -15.0286 - val_loss: -12.5085\n",
      "Epoch 71/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: -14.8543 - val_loss: -12.7789\n",
      "Epoch 72/200\n",
      "313/313 [==============================] - 38s 121ms/step - loss: -13.8947 - val_loss: -12.3911\n",
      "Epoch 73/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: -14.7391 - val_loss: -12.4222\n",
      "Epoch 74/200\n",
      "313/313 [==============================] - 42s 136ms/step - loss: -12.9969 - val_loss: -11.4377\n",
      "Epoch 75/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -14.5702 - val_loss: -12.2785\n",
      "Epoch 76/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: -14.8236 - val_loss: -12.9268\n",
      "Epoch 77/200\n",
      "313/313 [==============================] - 42s 135ms/step - loss: -15.0963 - val_loss: -12.4672\n",
      "Epoch 78/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: -15.3215 - val_loss: -13.1013\n",
      "Epoch 79/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: -15.1868 - val_loss: -13.0001\n",
      "Epoch 80/200\n",
      "313/313 [==============================] - 37s 120ms/step - loss: -15.1049 - val_loss: -12.7635\n",
      "Epoch 81/200\n",
      "313/313 [==============================] - 42s 135ms/step - loss: -15.3357 - val_loss: -13.4178\n",
      "Epoch 82/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: -15.7064 - val_loss: -13.4875\n",
      "Epoch 83/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: -11.3369 - val_loss: -11.6264\n",
      "Epoch 84/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: -14.4826 - val_loss: -12.6402\n",
      "Epoch 85/200\n",
      "313/313 [==============================] - 41s 131ms/step - loss: -14.6325 - val_loss: -12.8788\n",
      "Epoch 86/200\n",
      "313/313 [==============================] - 36s 117ms/step - loss: -14.5211 - val_loss: -12.9387\n",
      "Epoch 87/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -15.4552 - val_loss: -13.2754\n",
      "Epoch 88/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: -15.1418 - val_loss: -12.5331\n",
      "Epoch 89/200\n",
      "313/313 [==============================] - 41s 131ms/step - loss: -15.6046 - val_loss: -13.5398\n",
      "Epoch 90/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: -15.9289 - val_loss: -13.7210\n",
      "Epoch 91/200\n",
      "313/313 [==============================] - 35s 112ms/step - loss: -15.8468 - val_loss: -13.2371\n",
      "Epoch 92/200\n",
      "313/313 [==============================] - 35s 113ms/step - loss: -15.9767 - val_loss: -13.6258\n",
      "Epoch 93/200\n",
      "313/313 [==============================] - 41s 132ms/step - loss: -16.1742 - val_loss: -14.0507\n",
      "Epoch 94/200\n",
      "313/313 [==============================] - 35s 113ms/step - loss: -16.3951 - val_loss: -13.9603\n",
      "Epoch 95/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: -16.3893 - val_loss: -13.8515\n",
      "Epoch 96/200\n",
      "313/313 [==============================] - 38s 123ms/step - loss: -16.2530 - val_loss: -14.3591\n",
      "Epoch 97/200\n",
      "313/313 [==============================] - 40s 129ms/step - loss: -15.5230 - val_loss: -12.7983\n",
      "Epoch 98/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -16.4671 - val_loss: -14.1231\n",
      "Epoch 99/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -16.1704 - val_loss: -14.1383\n",
      "Epoch 100/200\n",
      "313/313 [==============================] - 41s 131ms/step - loss: -16.6225 - val_loss: -14.0409\n",
      "Epoch 101/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -16.5281 - val_loss: -14.0895\n",
      "Epoch 102/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: -16.6966 - val_loss: -14.2452\n",
      "Epoch 103/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -16.8857 - val_loss: -14.5180\n",
      "Epoch 104/200\n",
      "313/313 [==============================] - 44s 141ms/step - loss: -16.9278 - val_loss: -14.2883\n",
      "Epoch 105/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: -16.9336 - val_loss: -14.6112\n",
      "Epoch 106/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: -16.5443 - val_loss: -14.8157\n",
      "Epoch 107/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: -17.0812 - val_loss: -14.8065\n",
      "Epoch 108/200\n",
      "313/313 [==============================] - 40s 127ms/step - loss: -17.2195 - val_loss: -14.6411\n",
      "Epoch 109/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: -13.8468 - val_loss: -14.0063\n",
      "Epoch 110/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: -16.3078 - val_loss: -13.9483\n",
      "Epoch 111/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: -16.6223 - val_loss: -14.3048\n",
      "Epoch 112/200\n",
      "313/313 [==============================] - 41s 132ms/step - loss: -16.5059 - val_loss: -14.5549\n",
      "Epoch 113/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: -17.1441 - val_loss: -14.8987\n",
      "Epoch 114/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: -17.1147 - val_loss: -14.9300\n",
      "Epoch 115/200\n",
      "313/313 [==============================] - 35s 113ms/step - loss: -17.2638 - val_loss: -15.0057\n",
      "Epoch 116/200\n",
      "313/313 [==============================] - 40s 129ms/step - loss: -17.4590 - val_loss: -15.2390\n",
      "Epoch 117/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -17.2340 - val_loss: -14.9649\n",
      "Epoch 118/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -17.5138 - val_loss: -15.1257\n",
      "Epoch 119/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -17.6066 - val_loss: -15.4086\n",
      "Epoch 120/200\n",
      "313/313 [==============================] - 42s 136ms/step - loss: -17.6533 - val_loss: -15.1632\n",
      "Epoch 121/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: -17.3538 - val_loss: -15.2834\n",
      "Epoch 122/200\n",
      "313/313 [==============================] - 37s 120ms/step - loss: -17.3547 - val_loss: -13.5569\n",
      "Epoch 123/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -17.2480 - val_loss: -15.1750\n",
      "Epoch 124/200\n",
      "313/313 [==============================] - 42s 134ms/step - loss: -17.5723 - val_loss: -15.3492\n",
      "Epoch 125/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -17.9245 - val_loss: -15.3422\n",
      "Epoch 126/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: -17.8233 - val_loss: -15.1395\n",
      "Epoch 127/200\n",
      "313/313 [==============================] - 41s 132ms/step - loss: -17.5923 - val_loss: -15.1111\n",
      "Epoch 128/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: -16.8186 - val_loss: -15.6928\n",
      "Epoch 129/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: -17.6751 - val_loss: -15.2388\n",
      "Epoch 130/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: -17.8991 - val_loss: -15.8491\n",
      "Epoch 131/200\n",
      "313/313 [==============================] - 41s 133ms/step - loss: -17.3916 - val_loss: -15.2961\n",
      "Epoch 132/200\n",
      "313/313 [==============================] - 38s 120ms/step - loss: -17.8417 - val_loss: -15.7448\n",
      "Epoch 133/200\n",
      "313/313 [==============================] - 38s 121ms/step - loss: -17.8452 - val_loss: -15.3999\n",
      "Epoch 134/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: -18.1538 - val_loss: -15.7915\n",
      "Epoch 135/200\n",
      "313/313 [==============================] - 42s 135ms/step - loss: -18.3193 - val_loss: -15.9508\n",
      "Epoch 136/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: -17.9163 - val_loss: -15.8886\n",
      "Epoch 137/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: -18.1594 - val_loss: -16.1721\n",
      "Epoch 138/200\n",
      "313/313 [==============================] - 35s 114ms/step - loss: -18.2103 - val_loss: -15.9485\n",
      "Epoch 139/200\n",
      "313/313 [==============================] - 41s 131ms/step - loss: -17.8743 - val_loss: -15.8827\n",
      "Epoch 140/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -17.2012 - val_loss: -15.2170\n",
      "Epoch 141/200\n",
      "313/313 [==============================] - 37s 117ms/step - loss: -18.2878 - val_loss: -16.0467\n",
      "Epoch 142/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: -18.3628 - val_loss: -16.1784\n",
      "Epoch 143/200\n",
      "313/313 [==============================] - 43s 138ms/step - loss: -18.4959 - val_loss: -15.4096\n",
      "Epoch 144/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: -18.4382 - val_loss: -16.3038\n",
      "Epoch 145/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: -18.4213 - val_loss: -16.1603\n",
      "Epoch 146/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: -18.6673 - val_loss: -16.4264\n",
      "Epoch 147/200\n",
      "313/313 [==============================] - 40s 128ms/step - loss: -18.5443 - val_loss: -15.8391\n",
      "Epoch 148/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -18.4219 - val_loss: -16.4943\n",
      "Epoch 149/200\n",
      "313/313 [==============================] - 36s 117ms/step - loss: -18.6526 - val_loss: -15.3220\n",
      "Epoch 150/200\n",
      "313/313 [==============================] - 41s 131ms/step - loss: -18.6428 - val_loss: -16.2679\n",
      "Epoch 151/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: -18.4793 - val_loss: -15.9335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: -18.6517 - val_loss: -15.7796\n",
      "Epoch 153/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: -17.9607 - val_loss: -15.9360\n",
      "Epoch 154/200\n",
      "313/313 [==============================] - 41s 133ms/step - loss: -18.2873 - val_loss: -15.7299\n",
      "Epoch 155/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: -18.6112 - val_loss: -16.3567\n",
      "Epoch 156/200\n",
      "313/313 [==============================] - 38s 121ms/step - loss: -18.6985 - val_loss: -16.6511\n",
      "Epoch 157/200\n",
      "313/313 [==============================] - 38s 122ms/step - loss: -19.0702 - val_loss: -16.6671\n",
      "Epoch 158/200\n",
      "313/313 [==============================] - 42s 134ms/step - loss: -18.9256 - val_loss: -16.4824\n",
      "Epoch 159/200\n",
      "313/313 [==============================] - 37s 120ms/step - loss: -19.0254 - val_loss: -16.4458\n",
      "Epoch 160/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: -19.0736 - val_loss: -16.7222\n",
      "Epoch 161/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: -19.0163 - val_loss: -16.7602\n",
      "Epoch 162/200\n",
      "313/313 [==============================] - 42s 135ms/step - loss: -19.2444 - val_loss: -16.4176\n",
      "Epoch 163/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: -19.2849 - val_loss: -17.0231\n",
      "Epoch 164/200\n",
      "313/313 [==============================] - 37s 120ms/step - loss: -19.1998 - val_loss: -16.9563\n",
      "Epoch 165/200\n",
      "313/313 [==============================] - 38s 121ms/step - loss: -19.1165 - val_loss: -16.8372\n",
      "Epoch 166/200\n",
      "313/313 [==============================] - 42s 134ms/step - loss: -19.0625 - val_loss: -16.5503\n",
      "Epoch 167/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: -19.1796 - val_loss: -15.4612\n",
      "Epoch 168/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: -19.2694 - val_loss: -17.0023\n",
      "Epoch 169/200\n",
      "313/313 [==============================] - 36s 117ms/step - loss: -19.4324 - val_loss: -17.0995\n",
      "Epoch 170/200\n",
      "313/313 [==============================] - 41s 130ms/step - loss: -18.0441 - val_loss: -15.6999\n",
      "Epoch 171/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -19.0454 - val_loss: -17.0633\n",
      "Epoch 172/200\n",
      "313/313 [==============================] - 35s 113ms/step - loss: -19.2377 - val_loss: -16.9806\n",
      "Epoch 173/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: -19.4438 - val_loss: -17.0468\n",
      "Epoch 174/200\n",
      "313/313 [==============================] - 41s 133ms/step - loss: -19.5386 - val_loss: -17.2500\n",
      "Epoch 175/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -19.5807 - val_loss: -17.2527\n",
      "Epoch 176/200\n",
      "313/313 [==============================] - 36s 117ms/step - loss: -19.5064 - val_loss: -16.8621\n",
      "Epoch 177/200\n",
      "313/313 [==============================] - 41s 131ms/step - loss: -19.5095 - val_loss: -17.3974\n",
      "Epoch 178/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: -19.7045 - val_loss: -17.0771\n",
      "Epoch 179/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: -19.6533 - val_loss: -17.2554\n",
      "Epoch 180/200\n",
      "313/313 [==============================] - 35s 113ms/step - loss: -19.7724 - val_loss: -17.4239\n",
      "Epoch 181/200\n",
      "313/313 [==============================] - 41s 130ms/step - loss: -19.5877 - val_loss: -17.4006\n",
      "Epoch 182/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -19.6291 - val_loss: -17.4254\n",
      "Epoch 183/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -19.6604 - val_loss: -13.6378\n",
      "Epoch 184/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: -18.9745 - val_loss: -17.3755\n",
      "Epoch 185/200\n",
      "313/313 [==============================] - 43s 138ms/step - loss: -19.6066 - val_loss: -17.1103\n",
      "Epoch 186/200\n",
      "313/313 [==============================] - 38s 121ms/step - loss: -19.4973 - val_loss: -17.3454\n",
      "Epoch 187/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: -19.1721 - val_loss: -17.3970\n",
      "Epoch 188/200\n",
      "313/313 [==============================] - 37s 119ms/step - loss: -19.2391 - val_loss: -17.1801\n",
      "Epoch 189/200\n",
      "313/313 [==============================] - 41s 131ms/step - loss: -19.6122 - val_loss: -17.4015\n",
      "Epoch 190/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: -19.5551 - val_loss: -17.3146\n",
      "Epoch 191/200\n",
      "313/313 [==============================] - 36s 115ms/step - loss: -19.7653 - val_loss: -17.3396\n",
      "Epoch 192/200\n",
      "313/313 [==============================] - 36s 116ms/step - loss: -20.0794 - val_loss: -17.7785\n",
      "Epoch 193/200\n",
      "313/313 [==============================] - 41s 131ms/step - loss: -19.7887 - val_loss: -16.9995\n",
      "Epoch 194/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: -19.8617 - val_loss: -17.6329\n",
      "Epoch 195/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: -20.0632 - val_loss: -17.5114\n",
      "Epoch 196/200\n",
      "313/313 [==============================] - 37s 118ms/step - loss: -19.6594 - val_loss: -17.6128\n",
      "Epoch 197/200\n",
      "313/313 [==============================] - 40s 130ms/step - loss: -20.0052 - val_loss: -17.5592\n",
      "Epoch 198/200\n",
      "313/313 [==============================] - 35s 113ms/step - loss: -19.7547 - val_loss: -17.1013\n",
      "Epoch 199/200\n",
      "313/313 [==============================] - 36s 114ms/step - loss: -19.2526 - val_loss: -16.8465\n",
      "Epoch 200/200\n",
      "313/313 [==============================] - 40s 129ms/step - loss: -18.6368 - val_loss: -16.7758\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = [x_train, y_train], y = x_train, epochs = EPOCHS, callbacks = [weights_callback, LR_callback, neptune_callback], validation_data = ([x_validation, y_validation], x_validation), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a75f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5c09e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2a9162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preds(dataset = 'train', num_to_save = None):\n",
    "    if dataset == 'train':\n",
    "        datagen = x_train\n",
    "    elif dataset == 'val':\n",
    "        datagen = x_validation\n",
    "    else:\n",
    "        dataset = 'test'\n",
    "        datagen = x_test\n",
    "    preds_path = os.path.join(predictions_path, dataset + \"_preds.hdf5\")\n",
    "    print(\"Saving predictions for\", dataset, \"dataset in\", preds_path)\n",
    "    \n",
    "    if num_to_save is None:\n",
    "        size = len(datagen)\n",
    "    else:\n",
    "        size = num_to_save\n",
    "\n",
    "    with h5py.File(preds_path, 'w') as f:\n",
    "        f.create_dataset('true', (size, ) + IMAGE_SHAPE)\n",
    "        f.create_dataset('pred', (size, ) + IMAGE_SHAPE)\n",
    "        f.create_dataset('loss', (size, ))\n",
    "        for i in range(size):\n",
    "            x = datagen[i]\n",
    "            f['true'][i] = x\n",
    "            f['pred'][i] = model(np.array([x]))\n",
    "            f['loss'][i] = model.evaluate(np.array([x]), np.array([x]), verbose = 0)\n",
    "            stdout.write(\"\\rSaved %d samples of \" % (i + 1) + str(size))\n",
    "            stdout.flush()\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0619570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions for train dataset in /predictions/HSC_v6_small_VAE_v1.0/v1.0.20230113_01_20_30/train_preds.hdf5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer model_1 expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor: shape=(1, 5, 127, 127), dtype=float32, numpy=\narray([[[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-11668af5e8b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-a0385638a495>\u001b[0m in \u001b[0;36msave_preds\u001b[0;34m(dataset, num_to_save)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\rSaved %d samples of \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         training=training_mode):\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     raise ValueError('Layer ' + layer_name + ' expects ' +\n\u001b[0m\u001b[1;32m    201\u001b[0m                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                      \u001b[0;34m'but it received '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer model_1 expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor: shape=(1, 5, 127, 127), dtype=float32, numpy=\narray([[[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]],\n\n        [[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>]"
     ]
    }
   ],
   "source": [
    "save_preds('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c6bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_preds('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc44cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_preds('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcda568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_bands_max(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show/5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.amax(np.array([x_test[i]])[0][j]))\n",
    "            pred_array = np.append(pred_array, np.amax(model(np.array([x_test[i]]))[0][j]))\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].set_ylabel(\"Maximum normalized pixel value\")\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].legend()\n",
    "        \n",
    "def scatter_bands_center(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show/5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.array([x_test[i]])[0][j][63][63])\n",
    "            pred_array = np.append(pred_array, model(np.array([x_test[i]]))[0][j][63][63])\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].set_ylabel(\"Central pixel value\")\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].legend()\n",
    "\n",
    "def scatter_bands_percentile(percentile = 90, num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show/5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_90 = np.percentile(np.array([x_test[i]])[0][j].flatten(), percentile)\n",
    "            pred_90 = np.percentile(np.asarray(model(np.array([x_test[i]]))[0][j]).flatten(), percentile)\n",
    "            true_array = np.append(true_array, true_90)\n",
    "            pred_array = np.append(pred_array, pred_90)\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].set_xlabel('Bands')\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].set_ylabel(f'{percentile}th percentile normalized pixel value')\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].legend()\n",
    "\n",
    "def scatter_bands_mean(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show/5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_mean = np.mean(np.array([x_test[i]])[0][j].flatten())\n",
    "            pred_mean = np.mean(np.asarray(model(np.array([x_test[i]]))[0][j]).flatten())\n",
    "            true_array = np.append(true_array, true_mean)\n",
    "            pred_array = np.append(pred_array, pred_mean)\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].set_xlabel('Bands')\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].set_ylabel('Mean normalized pixel value')\n",
    "        axes[int((i - index)/5)][int((i - index)%5)].legend()\n",
    "\n",
    "def display_histograms(num_to_show = 2, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = num_to_show, ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        for j in range(0, 5):\n",
    "            true_arr = sorted(np.array([x_test[i]])[0][j].flatten())\n",
    "            pred_arr = sorted(np.asarray(model(np.array([x_test[i]]))[0][j]).flatten())\n",
    "            true_arr = true_arr[0:int(len(true_arr)*.99)]\n",
    "            pred_arr = pred_arr[0:int(len(pred_arr)*.99)]\n",
    "            axes[i][j].hist(true_arr, 100, color = 'blue', label = 'True', alpha=0.5)\n",
    "            axes[i][j].hist(pred_arr, 100, color = 'red', label = 'Predicted', alpha=0.5)\n",
    "            axes[i][j].set_xlabel(\"Pixel Values\")\n",
    "            axes[i][j].set_ylabel(\"Count\")\n",
    "            axes[i][j].legend()\n",
    "    fig.suptitle('Histograms of Predicted vs. True Image, Horizontal are Bands')\n",
    "    \n",
    "def display_5_bands(index):\n",
    "    fig, axes = plt.subplots(nrows = 2, ncols = 5, figsize = (20, 10))\n",
    "    loss = round(model.evaluate(np.array([x_test[index]]), np.array([x_test[index]]), verbose = 0), 2)\n",
    "    for i in range(0, 5):\n",
    "        axes[0][i].imshow(np.array([x_test[index]])[0][i], cmap = 'afmhot')\n",
    "        max_pixel_true = round(np.amax(np.array([x_test[index]])[0][i]), 2)\n",
    "        axes[0][i].set_title(f'True band {i} max = ' + str(max_pixel_true))\n",
    "        pred = model(np.array([x_test[index]]))[0][i]\n",
    "        axes[1][i].imshow(pred, cmap = 'afmhot')\n",
    "        max_pixel_pred = round(np.amax(pred), 2)\n",
    "        axes[1][i].set_title(f'Pred band {i} max = ' + str(max_pixel_pred) + '\\n loss =' + str(loss))\n",
    "        \n",
    "def display_high_loss(num_to_show, min_loss):\n",
    "    fig, axes = plt.subplots(nrows = num_to_show, ncols = 5, figsize = (20, 5 * num_to_show))\n",
    "    r = 0\n",
    "    for i in range(len(x_test)):\n",
    "        loss = round(model.evaluate(np.array([x_test[i]]), np.array([x_test[i]]), verbose = 0), 2)\n",
    "        if loss >= min_loss:\n",
    "            print(str(i) + '\\n')\n",
    "            for j in range(0, 5):\n",
    "                axes[r][j].imshow(np.array([x_test[i]])[0][j], cmap = 'afmhot')\n",
    "                axes[r][j].set_title('Loss =' + str(loss))\n",
    "            r += 1\n",
    "        if r >= num_to_show:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfce4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter_bands_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e98006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_center(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af73da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter_bands_mean(10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d13de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter_bands_percentile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df1749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0abdaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_5_bands(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faa5b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_high_loss(40, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58761e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_test = h5py.File('/data/HSC/HSC_v6/step2A/127x127/5x127x127_testing_small.hdf5', 'r')\n",
    "x_test = np.asarray(hf_test['image'][0:])\n",
    "max_value = 4.16\n",
    "x_test = np.true_divide(x_test, max_value)\n",
    "y_test = np.asarray(hf_test['specz_redshift'][0:])[..., None]\n",
    "object_id = np.asarray(hf_test['object_id'][0:])\n",
    "ra_test = np.asarray(hf_test['ra'][0:])\n",
    "dec_test = np.asarray(hf_test['dec'][0:])\n",
    "hf_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_id[240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4458d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_id[212]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_test[240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f8741",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_test[212]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c4a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_test[240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e68218",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_test[212]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c763340b",
   "metadata": {},
   "source": [
    "look at RA dec of these objects, see if they are already present\n",
    "\n",
    "galaxies?\n",
    "clusters in galaxies\n",
    "merging galaxies\n",
    "artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b542cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array = np.array([])\n",
    "for i in range(len(x_test)):\n",
    "    loss = model.evaluate(np.array([x_test[i]]), np.array([x_test[i]]), verbose = 0)\n",
    "    loss_array = np.append(loss_array, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1806e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(loss_array, bins = 100, range = (0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf6a3d",
   "metadata": {},
   "source": [
    "Look at the loss of those galaxies\n",
    "Put data through VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca798a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_example_galaxies(num_to_generate = 10):\n",
    "    z = prior.sample(num_to_generate)\n",
    "    xhat = model.decoder(z)\n",
    "    fig, axes = plt.subplots(nrows = num_to_generate, ncols = 5, figsize = (4 * 5, 4 * num_to_generate))\n",
    "    for i in range(num_to_generate):\n",
    "        for j in range(0,5):\n",
    "            axes[i][j].imshow(xhat[i][j], cmap = 'afmhot')\n",
    "            axes[i][j].set_title(f'Generated image {i} band {j}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb5dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_example_galaxies(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fadc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

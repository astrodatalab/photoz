{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f923d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "write = True # log this version as new\n",
    "MODEL_DESCRIPTION = \"Conditional Diffusion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8fc210-73b8-4a4e-a0ef-a05711c926fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 07:21:57.014038: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-01 07:21:57.547828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/billyli/miniconda3/envs/Diffusion/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf;\n",
    "from tensorflow import keras, einsum\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow.keras.layers as nn\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.tensorflow import Rearrange\n",
    "from functools import partial\n",
    "from inspect import isfunction\n",
    "\n",
    "import pandas as pd\n",
    "from sys import stdout\n",
    "from datetime import datetime\n",
    "import neptune as neptune\n",
    "from neptune.integrations.tensorflow_keras import NeptuneCallback\n",
    "from astropy.io import fits\n",
    "import random\n",
    "from DataMakerPlus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a44e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 07:21:58.941339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 07:21:58.963523: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 07:21:58.963712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 07:21:58.965787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 07:21:58.965928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 07:21:58.966049: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 07:21:59.462067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 07:21:59.462260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 07:21:59.462387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 07:21:59.462493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20000 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "gpus = tf.config.list_physical_devices('GPU');\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 20000)]);\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU');\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb7cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "DATASET_NAME = \"HSC_v6\"\n",
    "MODEL_TYPE = \"Conditional Diffusion\"\n",
    "MODEL_VERSION = \"v1.0\"\n",
    "MODEL_SUBVERSION = \"v1.0.\" + now.strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "\n",
    "model_id = '_'.join([DATASET_NAME, MODEL_TYPE, MODEL_VERSION])\n",
    "model_path = os.path.join('/data3/Billy/models', model_id, MODEL_SUBVERSION, 'model')\n",
    "checkpoints_path = os.path.join('/data3/Billy/models', model_id, MODEL_SUBVERSION, 'checkpoints')\n",
    "logs_path = os.path.join('/data3/Billy/logs', model_id, MODEL_SUBVERSION)\n",
    "predictions_path = os.path.join('/data3/Billy/predictions', model_id, MODEL_SUBVERSION)\n",
    "weights_path = model_path + '/data3/Billy/Diffusion/weights.h5'\n",
    "\n",
    "os.makedirs(model_path, exist_ok = True)\n",
    "os.makedirs(checkpoints_path, exist_ok = True)\n",
    "os.makedirs(logs_path, exist_ok = True)\n",
    "os.makedirs(predictions_path, exist_ok = True)\n",
    "\n",
    "if write == True:\n",
    "    with open(\"/data3/Billy/models/README.md\", \"a\") as myfile:\n",
    "        myfile.write(MODEL_TYPE + \" \" + MODEL_SUBVERSION + \" - \" + MODEL_DESCRIPTION + \" - B. Li\" + \"\\n\")\n",
    "else:\n",
    "    with open(\"/data3/Billy/models/README.md\", \"a\") as myfile:\n",
    "        myfile.write(MODEL_TYPE + \" \" + MODEL_SUBVERSION + \" - ... \"+ \" - B. Li\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84bcf60-c403-4b14-be17-6908a9bd15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 5\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ade43f55-0b73-48af-bb97-ad30103aedde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 5, 127, 127)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = f'/data/HSC/HSC_v6/step2A/127x127/5x127x127_training_with_morphology_normalized.hdf5'\n",
    "gen_args = {\n",
    "    'image_key': 'image',\n",
    "    'numerical_keys': None,\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': True,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'shuffle': False}\n",
    "train_gen = HDF5DataGenerator(TRAIN_PATH, mode='train', **gen_args)\n",
    "print(train_gen[0][0].shape)\n",
    "print(train_gen[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6878ec36-85cc-472d-b950-a7774409dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_count = 0\n",
    "def next_batch():\n",
    "    global batch_count\n",
    "    x_train = np.asarray(np.transpose(train_gen[batch_count][0], (0, 2, 3, 1)))\n",
    "    x_train = np.pad(x_train, [(0, 0), (0, 1), (0, 1), (0, 0)], mode = 'constant') # Padding to 128x128\n",
    "    y_train = train_gen[batch_count][1]\n",
    "    batch_count = batch_count + 1\n",
    "    if batch_count == len(train_gen) - 1:\n",
    "        batch_count = 0\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da216099-362e-4bb3-95e4-e72f57806b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 200\n",
    "max_noise = 0.1\n",
    "\n",
    "# create a fixed beta schedule\n",
    "beta = np.linspace(max_noise / timesteps, max_noise, timesteps)\n",
    "\n",
    "# this will be used as discussed in the reparameterization trick\n",
    "alpha = 1 - beta\n",
    "alpha_bar = np.cumprod(alpha, 0)\n",
    "alpha_bar = np.concatenate((np.array([1.]), alpha_bar[ : -1]), axis = 0)\n",
    "sqrt_alpha_bar = np.sqrt(alpha_bar)\n",
    "one_minus_sqrt_alpha_bar = np.sqrt(1 - alpha_bar)\n",
    "\n",
    "# this function will help us set the RNG key for Numpy\n",
    "def set_key(key):\n",
    "    np.random.seed(key)\n",
    "\n",
    "# this function will add noise to the input as per the given timestamp\n",
    "def forward_noise(key, x_0, t):\n",
    "    set_key(key)\n",
    "    noise = np.random.normal(size = x_0.shape)\n",
    "    reshaped_sqrt_alpha_bar_t = np.reshape(np.take(sqrt_alpha_bar, t), (-1, 1, 1, 1))\n",
    "    reshaped_one_minus_sqrt_alpha_bar_t = np.reshape(np.take(one_minus_sqrt_alpha_bar, t), (-1, 1, 1, 1))\n",
    "    noisy_image = reshaped_sqrt_alpha_bar_t  * x_0 + reshaped_one_minus_sqrt_alpha_bar_t  * noise\n",
    "    return noisy_image, noise\n",
    "\n",
    "# this function will be used to create sample timestamps between 0 & T\n",
    "def generate_timestamp(key, num):\n",
    "    set_key(key)\n",
    "    return tf.random.uniform(shape = [num], minval = 0, maxval = timesteps, dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438565c5-d1b2-40e0-976f-f68c67d3e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us visualize the output image at a few timestamps\n",
    "sample = next_batch()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae674c9-63b6-4813-b15f-cde614403081",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arr = np.array([])\n",
    "for index, i in enumerate(range(timesteps)):\n",
    "    noisy_im, noise = forward_noise(0, np.expand_dims(sample, 0), np.array([i, ]))\n",
    "    y_arr = np.append(y_arr, np.var(noisy_im[0][:, :, 0].flatten()))\n",
    "\n",
    "x_arr = np.linspace(0, timesteps, timesteps)\n",
    "\n",
    "\n",
    "# plt.plot(x_arr, y_arr)\n",
    "# plt.title(\"\")\n",
    "# plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(x_arr, y_arr)\n",
    "ax1.set_xlabel(\"Steps of Noise\")\n",
    "ax1.set_ylabel(\"Variance in Noised Image\")\n",
    "\n",
    "ax2 = ax1.twiny()\n",
    "ax2.plot(beta, 0 * np.ones(timesteps), alpha = 0) # Create a dummy plot\n",
    "ax2.set_xlabel(\"Variance of the Gaussian Noise Added at Each Step\")\n",
    "# fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3904c03-13a9-467f-a816-81e92f353c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 5, ncols = 5, figsize = (50, 50))\n",
    "\n",
    "j = 0\n",
    "for index, i in enumerate([0, 20, 100, 150, 195]):\n",
    "    noisy_im, noise = forward_noise(0, np.expand_dims(sample, 0), np.array([i, ]))\n",
    "    axes[0][j].imshow(noisy_im[0][:, :, 0], cmap = 'gray')\n",
    "    axes[1][j].imshow(noisy_im[0][:, :, 1], cmap = 'gray')\n",
    "    axes[2][j].imshow(noisy_im[0][:, :, 2], cmap = 'gray')\n",
    "    axes[3][j].imshow(noisy_im[0][:, :, 3], cmap = 'gray')\n",
    "    axes[4][j].imshow(noisy_im[0][:, :, 4], cmap = 'gray')\n",
    "    j += 1\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ce6c6-09c0-4731-8d17-710976f4e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Initialization Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c4bd9-4fb6-456d-b5f5-750c3e020ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers functions\n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "# We will use this to convert timestamps to time encodings\n",
    "class SinusoidalPosEmb(Layer):\n",
    "    def __init__(self, dim, max_positions = 10000):\n",
    "        super(SinusoidalPosEmb, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.max_positions = max_positions\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(self.max_positions) / (half_dim - 1)\n",
    "        emb = tf.exp(tf.range(half_dim, dtype = tf.float32) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "\n",
    "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis = -1)\n",
    "\n",
    "        return emb\n",
    "        \n",
    "# small helper modules\n",
    "class Identity(Layer):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        return tf.identity(x)\n",
    "\n",
    "\n",
    "class Residual(Layer):\n",
    "    def __init__(self, fn):\n",
    "        super(Residual, self).__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        return self.fn(x, training = training) + x\n",
    "\n",
    "def Upsample(dim):\n",
    "    return nn.Conv2DTranspose(filters = dim, kernel_size = 4, strides = 2, padding = 'SAME')\n",
    "\n",
    "def Downsample(dim):\n",
    "    return nn.Conv2D(filters = dim, kernel_size = 4, strides = 2, padding = 'SAME')\n",
    "\n",
    "class LayerNorm(Layer):\n",
    "    def __init__(self, dim, eps = 1e-5, **kwargs):\n",
    "        super(LayerNorm, self).__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "\n",
    "        self.g = tf.Variable(tf.ones([1, 1, 1, dim]))\n",
    "        self.b = tf.Variable(tf.zeros([1, 1, 1, dim]))\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        var = tf.math.reduce_variance(x, axis = -1, keepdims = True)\n",
    "        mean = tf.reduce_mean(x, axis = -1, keepdims = True)\n",
    "\n",
    "        x = (x - mean) / tf.sqrt((var + self.eps)) * self.g + self.b\n",
    "        return x\n",
    "\n",
    "class PreNorm(Layer):\n",
    "    def __init__(self, dim, fn):\n",
    "        super(PreNorm, self).__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = LayerNorm(dim)\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)\n",
    "\n",
    "class SiLU(Layer):\n",
    "    def __init__(self):\n",
    "        super(SiLU, self).__init__()\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        return x * tf.nn.sigmoid(x)\n",
    "\n",
    "def gelu(x, approximate = False):\n",
    "    if approximate:\n",
    "        coeff = tf.cast(0.044715, x.dtype)\n",
    "        return 0.5 * x * (1.0 + tf.tanh(0.7978845608028654 * (x + coeff * tf.pow(x, 3))))\n",
    "    else:\n",
    "        return 0.5 * x * (1.0 + tf.math.erf(x / tf.cast(1.4142135623730951, x.dtype)))\n",
    "\n",
    "class GELU(Layer):\n",
    "    def __init__(self, approximate = False):\n",
    "        super(GELU, self).__init__()\n",
    "        self.approximate = approximate\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        return gelu(x, self.approximate)\n",
    "\n",
    "class MLP(Layer):\n",
    "    def __init__(self, hidden_dim, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.net = Sequential([\n",
    "            Rearrange('... -> ... 1'),  # expand_dims(axis=-1)\n",
    "            nn.Dense(units=hidden_dim),\n",
    "            GELU(),\n",
    "            LayerNorm(hidden_dim),\n",
    "            nn.Dense(units=hidden_dim),\n",
    "            GELU(),\n",
    "            LayerNorm(hidden_dim),\n",
    "            nn.Dense(units=hidden_dim),\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        return self.net(x, training=training)\n",
    "\n",
    "\n",
    "class ValueConditioning(Layer):  # Modify class name\n",
    "    def __init__(self, res, num_channels = 5):\n",
    "        super().__init__()\n",
    "        self.block = Sequential([\n",
    "            nn.Dense(res * res * num_channels),\n",
    "            SiLU(),\n",
    "            nn.Reshape((res, res, num_channels))\n",
    "        ])\n",
    "\n",
    "        self.block.compile()\n",
    "\n",
    "    def call(self, x):  # Modify method signature\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf57659-c611-4f91-b309-05cc09870a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building block modules\n",
    "class Block(Layer):\n",
    "    def __init__(self, dim, groups = 8):\n",
    "        super(Block, self).__init__()\n",
    "        self.proj = nn.Conv2D(dim, kernel_size = 3, strides = 1, padding = 'SAME')\n",
    "        self.norm = tfa.layers.GroupNormalization(groups, epsilon = 1e-05)\n",
    "        self.act = SiLU()\n",
    "\n",
    "\n",
    "    def call(self, x, gamma_beta = None, training = True):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x, training=training)\n",
    "\n",
    "        if exists(gamma_beta):\n",
    "            gamma, beta = gamma_beta\n",
    "            x = x * (gamma + 1) + beta\n",
    "\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class ResnetBlock(Layer):\n",
    "    def __init__(self, dim, dim_out, time_emb_dim = None, groups = 8):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "\n",
    "        self.mlp = Sequential([\n",
    "            SiLU(),\n",
    "            nn.Dense(units = dim_out * 2)\n",
    "        ]) if exists(time_emb_dim) else None\n",
    "\n",
    "        self.block1 = Block(dim_out, groups = groups)\n",
    "        self.block2 = Block(dim_out, groups = groups)\n",
    "        self.res_conv = nn.Conv2D(filters = dim_out, kernel_size = 1, strides = 1) if dim != dim_out else Identity()\n",
    "\n",
    "    def call(self, x, time_emb = None, training = True):\n",
    "        gamma_beta = None\n",
    "        if exists(self.mlp) and exists(time_emb):\n",
    "            time_emb = self.mlp(time_emb)\n",
    "            time_emb = rearrange(time_emb, 'b c -> b 1 1 c')\n",
    "            gamma_beta = tf.split(time_emb, num_or_size_splits = 2, axis = -1)\n",
    "\n",
    "        h = self.block1(x, gamma_beta = gamma_beta, training = training)\n",
    "        h = self.block2(h, training = training)\n",
    "\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "class LinearAttention(Layer):\n",
    "    def __init__(self, dim, heads = 4, dim_head = 127):\n",
    "        super(LinearAttention, self).__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        self.hidden_dim = dim_head * heads\n",
    "\n",
    "        self.attend = nn.Softmax()\n",
    "        self.to_qkv = nn.Conv2D(filters = self.hidden_dim * 3, kernel_size = 1, strides = 1, use_bias = False)\n",
    "\n",
    "        self.to_out = Sequential([\n",
    "            nn.Conv2D(filters = dim, kernel_size = 1, strides = 1),\n",
    "            LayerNorm(dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        b, h, w, c = x.shape\n",
    "        qkv = self.to_qkv(x)\n",
    "        qkv = tf.split(qkv, num_or_size_splits = 3, axis = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b x y (h c) -> b h c (x y)', h = self.heads), qkv)\n",
    "\n",
    "        q = tf.nn.softmax(q, axis = -2)\n",
    "        k = tf.nn.softmax(k, axis = -1)\n",
    "\n",
    "        q = q * self.scale\n",
    "        context = einsum('b h d n, b h e n -> b h d e', k, v)\n",
    "\n",
    "        out = einsum('b h d e, b h d n -> b h e n', context, q)\n",
    "        out = rearrange(out, 'b h c (x y) -> b x y (h c)', h = self.heads, x = h, y = w)\n",
    "        out = self.to_out(out, training = training)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, dim, heads = 4, dim_head = 127):\n",
    "        super(Attention, self).__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        self.hidden_dim = dim_head * heads\n",
    "\n",
    "        self.to_qkv = nn.Conv2D(filters = self.hidden_dim * 3, kernel_size = 1, strides = 1, use_bias = False)\n",
    "        self.to_out = nn.Conv2D(filters = dim, kernel_size = 1, strides = 1)\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        b, h, w, c = x.shape\n",
    "        qkv = self.to_qkv(x)\n",
    "        qkv = tf.split(qkv, num_or_size_splits = 3, axis = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b x y (h c) -> b h c (x y)', h=self.heads), qkv)\n",
    "        q = q * self.scale\n",
    "\n",
    "        sim = einsum('b h d i, b h d j -> b h i j', q, k)\n",
    "        sim_max = tf.stop_gradient(tf.expand_dims(tf.argmax(sim, axis = -1), axis = -1))\n",
    "        sim_max = tf.cast(sim_max, tf.float32)\n",
    "        sim = sim - sim_max\n",
    "        attn = tf.nn.softmax(sim, axis = -1)\n",
    "\n",
    "        out = einsum('b h i j, b h d j -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h (x y) d -> b x y (h d)', x = h, y = w)\n",
    "        out = self.to_out(out, training = training)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d763030c-8144-4ab7-8771-4169acaedb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet_conditional(Model):\n",
    "    def __init__(self,\n",
    "                 dim = 128,\n",
    "                 init_dim = None,\n",
    "                 out_dim = None,\n",
    "                 dim_mults = (1, 2, 4, 8),\n",
    "                 channels = 5,\n",
    "                 resnet_block_groups = 8,\n",
    "                 learned_variance = False,\n",
    "                 sinusoidal_cond_mlp = True,\n",
    "                 class_embedder = None,\n",
    "                 class_emb_dim = 64,\n",
    "                 in_res = 128\n",
    "                 ):\n",
    "        super(Unet_conditional, self).__init__()\n",
    "\n",
    "        # determine dimensions\n",
    "        self.channels = channels\n",
    "        self.in_res = in_res\n",
    "\n",
    "        # self.class_embeddings = nn.Embedding(num_classes, class_emb_dim) if class_embedder is None else class_embedder\n",
    "\n",
    "        init_dim = default(init_dim, dim // 3 * 2)\n",
    "        self.init_conv = nn.Conv2D(filters=init_dim, kernel_size=7, strides=1, padding='SAME')\n",
    "\n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        block_klass = partial(ResnetBlock, groups = resnet_block_groups)\n",
    "        \n",
    "        # time embeddings\n",
    "        time_dim = dim * 4\n",
    "        self.sinusoidal_cond_mlp = sinusoidal_cond_mlp\n",
    "\n",
    "        if sinusoidal_cond_mlp:\n",
    "            self.time_mlp = Sequential([\n",
    "                SinusoidalPosEmb(dim),\n",
    "                nn.Dense(units=time_dim),\n",
    "                GELU(),\n",
    "                nn.Dense(units=time_dim)\n",
    "            ], name=\"time embeddings\")\n",
    "        else:\n",
    "            self.time_mlp = MLP(time_dim)\n",
    "\n",
    "        # layers\n",
    "        self.downs = []\n",
    "        self.ups = []\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        now_res = in_res\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append([\n",
    "                ValueConditioning(now_res),\n",
    "                block_klass(dim_in+1, dim_out, time_emb_dim=time_dim),\n",
    "                block_klass(dim_out, dim_out, time_emb_dim=time_dim),\n",
    "                Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
    "                Downsample(dim_out) if not is_last else Identity()\n",
    "            ])\n",
    "\n",
    "            now_res //= 2 if not is_last else 1\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_conditioning = ValueConditioning(now_res)\n",
    "        self.mid_block1 = block_klass(mid_dim+1, mid_dim, time_emb_dim=time_dim)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
    "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.ups.append([\n",
    "                ValueConditioning(now_res),\n",
    "                block_klass((dim_out * 2) + 1, dim_in, time_emb_dim=time_dim),\n",
    "                block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n",
    "                Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
    "                Upsample(dim_in) if not is_last else Identity()\n",
    "            ])\n",
    "\n",
    "            now_res *= 2 if not is_last else 1\n",
    "\n",
    "        default_out_dim = channels * (1 if not learned_variance else 2)\n",
    "        self.out_dim = default(out_dim, default_out_dim)\n",
    "\n",
    "        self.final_conv = Sequential([\n",
    "            block_klass(dim * 2, dim),\n",
    "            nn.Conv2D(filters=self.out_dim, kernel_size=1, strides=1)\n",
    "        ], name=\"output\")\n",
    "\n",
    "    def call(self, x, time=None, condition_vector=None, training=True, **kwargs):\n",
    "        x = self.init_conv(x)\n",
    "        t = self.time_mlp(time)\n",
    "\n",
    "        # class_vector = self.class_embeddings(class_vector)\n",
    "        \n",
    "        h = []\n",
    "\n",
    "        for conditioning, block1, block2, attn, downsample in self.downs:\n",
    "            cv = conditioning(condition_vector)\n",
    "            x = tf.concat([x, cv], axis=-1)\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "        \n",
    "        cv = self.mid_conditioning(condition_vector)\n",
    "        x = tf.concat([x, cv], axis=-1)\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "\n",
    "        for conditioning, block1, block2, attn, upsample in self.ups:\n",
    "            cv = conditioning(condition_vector)\n",
    "            x = tf.concat([x, cv], axis=-1)\n",
    "            x = tf.concat([x, h.pop()], axis=-1)\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            x = upsample(x)\n",
    "\n",
    "        x = tf.concat([x, h.pop()], axis=-1)\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7f7ea7-3a99-4fe6-82a0-05df8abc9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our unet model\n",
    "unet = Unet_conditional(in_res = 128, channels = 5)\n",
    "\n",
    "# initialize the model in the memory of our GPU\n",
    "test_images = np.ones([1, 128, 128, channels])\n",
    "test_timestamps = generate_timestamp(0, 1)\n",
    "test_condition = np.array([[3.5]])\n",
    "k = unet(test_images, test_timestamps, test_condition)\n",
    "\n",
    "# create our optimizer, we will use adam with a Learning rate of 1e-4\n",
    "opt = keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b6f9d-5f56-4bd0-9a52-11ba43af03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa1884-4c2d-4d6f-af38-58f756667739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(real, generated):\n",
    "    loss = tf.math.reduce_mean((real - generated) ** 2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc7928-3c0c-40a3-89d1-c0b1ef8c9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Network Initialization Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971a0c7-442e-4fd9-9436-d78b34611fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch, condition):\n",
    "    rng, tsrng = np.random.randint(0, 100000, size=(2,))\n",
    "    timestep_values = generate_timestamp(tsrng, batch.shape[0])\n",
    "\n",
    "    noised_image, noise = forward_noise(rng, batch, tf.cast(timestep_values, tf.int32))\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = unet(noised_image, timestep_values, condition)\n",
    "        \n",
    "        loss_value = loss_fn(noise, prediction)\n",
    "    \n",
    "    gradients = tape.gradient(loss_value, unet.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, unet.trainable_variables))\n",
    "\n",
    "    return loss_value\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for e in range(1, epochs + 1):\n",
    "    bar = tf.keras.utils.Progbar(10000 / 8 - 1)\n",
    "    losses = []\n",
    "    for i in range(0, int(10000 / 8)):\n",
    "        batch, condition = next_batch()\n",
    "        loss = train_step(batch, condition)\n",
    "        losses.append(loss)\n",
    "        bar.update(i, values=[(\"loss\", loss)])  \n",
    "\n",
    "    avg = np.mean(losses)\n",
    "    if e > 5:\n",
    "        opt.learning_rate = 1e-5\n",
    "    if e > 6:\n",
    "        opt.learning_rate = 1e-6\n",
    "    else: \n",
    "        opt.learning_rate = 1e-7\n",
    "    print(f\"Average loss for epoch {e}/{epochs}: {avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d22901-a814-4a8a-ae12-3b52cc44ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.save_weights('/data3/Billy/unnormalized_weights_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7fad16-5512-4596-a74c-073878b1bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.load_weights('/data3/Billy/unnormalized_weights_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd3d4a1-4be1-4574-8e99-c8409c5b1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8c16a7-a04b-478a-8a83-6b665ca7536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gif(img_list, path = \"\", interval = 200):\n",
    "    # Transform images from [-1,1] to [0, 255]\n",
    "    imgs = []\n",
    "    for im in img_list:\n",
    "        im = np.array(im)\n",
    "        max = np.amax(np.nan_to_num(im))\n",
    "        min = np.amin(np.nan_to_num(im))\n",
    "        im = (im - min) / (max - min) * 255\n",
    "        im = np.clip(im, 0, 255).astype(np.int32)\n",
    "        im = Image.fromarray(im)\n",
    "        imgs.append(im)\n",
    "    \n",
    "    imgs = iter(imgs)\n",
    "\n",
    "    # Extract first image from iterator\n",
    "    img = next(imgs)\n",
    "\n",
    "    # Append the other images and save as GIF\n",
    "    img.save(fp = path, format='GIF', append_images = imgs,\n",
    "             save_all = True, duration = interval, loop = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42818bb-743c-414c-9ac6-fc45ededce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpm(x_t, pred_noise, t):\n",
    "    alpha_t = np.take(alpha, t)\n",
    "    alpha_t_bar = np.take(alpha_bar, t)\n",
    "\n",
    "    eps_coef = (1 - alpha_t) / (1 - alpha_t_bar) ** .5\n",
    "    mean = (1 / (alpha_t ** .5)) * (x_t - eps_coef * pred_noise)\n",
    "\n",
    "    var = np.take(beta, t)\n",
    "    z = np.random.normal(size=x_t.shape)\n",
    "\n",
    "    return mean + (var ** .5) * z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de591b0-88b1-48d7-9b05-907e3682a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(0, 5):\n",
    "    z = k / 2 + 0.1\n",
    "    x = tf.random.normal((1, 128, 128, 5))\n",
    "\n",
    "    img_list_g = []\n",
    "    img_list_r = []\n",
    "    img_list_i = []\n",
    "    img_list_z = []\n",
    "    img_list_y = []\n",
    "    img_list_g.append(np.squeeze(x, 0)[: , : , 0])\n",
    "    img_list_r.append(np.squeeze(x, 0)[: , : , 1])\n",
    "    img_list_i.append(np.squeeze(x, 0)[: , : , 2])\n",
    "    img_list_z.append(np.squeeze(x, 0)[: , : , 3])\n",
    "    img_list_y.append(np.squeeze(x, 0)[: , : , 4])\n",
    "    \n",
    "    for i in tqdm(range(timesteps - 1)):\n",
    "        t = np.expand_dims(np.array(timesteps - i - 1, np.int32), 0)\n",
    "        pred_noise = unet(x, np.array([z]), t)\n",
    "        x = ddpm(x, pred_noise, t)\n",
    "        img_list_g.append(np.squeeze(x, 0)[: , : , 0])\n",
    "        img_list_r.append(np.squeeze(x, 0)[: , : , 1])\n",
    "        img_list_i.append(np.squeeze(x, 0)[: , : , 2])\n",
    "        img_list_z.append(np.squeeze(x, 0)[: , : , 3])\n",
    "        img_list_y.append(np.squeeze(x, 0)[: , : , 4])\n",
    "            \n",
    "\n",
    "    save_gif(img_list_g + ([img_list_g[-1]] * 100), f\"diffusion_generations/conditional_z_{z}_band_g.gif\", interval = 20)\n",
    "    save_gif(img_list_r + ([img_list_r[-1]] * 100), f\"diffusion_generations/conditional_z_{z}_band_r.gif\", interval = 20)\n",
    "    save_gif(img_list_i + ([img_list_i[-1]] * 100), f\"diffusion_generations/conditional_z_{z}_band_i.gif\", interval = 20)\n",
    "    save_gif(img_list_z + ([img_list_z[-1]] * 100), f\"diffusion_generations/conditional_z_{z}_band_z.gif\", interval = 20)\n",
    "    save_gif(img_list_y + ([img_list_y[-1]] * 100), f\"diffusion_generations/conditional_z_{z}_band_y.gif\", interval = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b7bb5-18e6-41c8-842d-389a7982b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = random.uniform(0, 4)\n",
    "\n",
    "x = tf.random.normal((1, 128, 128, 5))\n",
    "\n",
    "for i in tqdm(range(timesteps - 1)):\n",
    "    \n",
    "    t = np.expand_dims(np.array(timesteps - i - 1, np.int32), 0)\n",
    "    pred_noise = unet(x, np.array([z]), t)\n",
    "    x = ddpm(x, pred_noise, t)\n",
    "    \n",
    "image_g = np.squeeze(x, 0)[: , : , 0][:-1, :-1]\n",
    "image_r = np.squeeze(x, 0)[: , : , 1][:-1, :-1]\n",
    "image_i = np.squeeze(x, 0)[: , : , 2][:-1, :-1]\n",
    "image_z = np.squeeze(x, 0)[: , : , 3][:-1, :-1]\n",
    "image_y = np.squeeze(x, 0)[: , : , 4][:-1, :-1]\n",
    "\n",
    "five_band_image = np.array([image_g, image_r, image_i, image_z, image_y])\n",
    "five_band_image_reshape = np.reshape(np.array(five_band_image), [1, 5, 127, 127])\n",
    "\n",
    "hf = h5py.File('/data3/Diffusion/127x127_diffusion_generated.hdf5', 'a')\n",
    "hf.create_dataset('image', data = five_band_image_reshape, chunks = True, maxshape = (None, 5, 127, 127))\n",
    "hf.create_dataset('specz_redshift', data = [z], chunks = True, maxshape = (None, ))\n",
    "\n",
    "for i in range(1999):\n",
    "    \n",
    "    stdout.write(\"\\rChecking %d samples of \" % (i + 1) + \"2000\")\n",
    "    \n",
    "    z = random.uniform(0, 4)\n",
    "    \n",
    "    x = tf.random.normal((1, 128, 128, 5))\n",
    "    \n",
    "    for i in tqdm(range(timesteps - 1)):\n",
    "        \n",
    "        t = np.expand_dims(np.array(timesteps - i - 1, np.int32), 0)\n",
    "        pred_noise = unet(x, np.array([z]), t)\n",
    "        x = ddpm(x, pred_noise, t)\n",
    "    \n",
    "    image_g = np.squeeze(x, 0)[: , : , 0][:-1, :-1]\n",
    "    image_r = np.squeeze(x, 0)[: , : , 1][:-1, :-1]\n",
    "    image_i = np.squeeze(x, 0)[: , : , 2][:-1, :-1]\n",
    "    image_z = np.squeeze(x, 0)[: , : , 3][:-1, :-1]\n",
    "    image_y = np.squeeze(x, 0)[: , : , 4][:-1, :-1]\n",
    "    \n",
    "    five_band_image = np.array([image_g, image_r, image_i, image_z, image_y])\n",
    "    five_band_image_reshape = np.reshape(np.array(five_band_image), [1, 5, 127, 127])\n",
    "    \n",
    "    hf['specz_redshift'].resize((hf['specz_redshift'].shape[0] + 1), axis = 0)\n",
    "    hf['specz_redshift'][hf['specz_redshift'].shape[0] - 1] = [z]\n",
    "    hf['image'].resize((hf['image'].shape[0] + 1), axis = 0)\n",
    "    hf['image'][hf['image'].shape[0] - 1, :, :, :] = five_band_image\n",
    "\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd973b7-479d-4dc6-9b37-13cb751cff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Generation Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diffusion",
   "language": "python",
   "name": "diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

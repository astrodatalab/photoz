{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f923d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "write = True # log this version as new\n",
    "MODEL_DESCRIPTION = \"Back to Dense Layers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d23f862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import stdout\n",
    "from datetime import datetime\n",
    "import neptune.new as neptune\n",
    "from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
    "from astropy.io import fits\n",
    "import random\n",
    "from DataMaker import HDF5ImageGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2032fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import Cropping2D, ZeroPadding2D, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Reshape\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import layers as tfpl\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow.nn import leaky_relu\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82e0800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 256\n",
    "BASE_DEPTH = 8\n",
    "IMAGE_SHAPE = (5, 127, 127)\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 250\n",
    "CHECKPOINTS_TO_SAVE = 4\n",
    "KL_WEIGHT = 1e-8\n",
    "# Good value: 1e-6\n",
    "# With KL 0 val_loss = 0.4763\n",
    "# With KL 1e-6 val loss = 1.0732\n",
    "# With KL 1e-8 val loss = 0.5257\n",
    "# With KL 1e-10 val loss = 0.4466 0.4291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a44e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 21:21:56.583574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-23 21:21:56.601019: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/billyli/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-04-23 21:21:56.601035: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU');\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 20000)]);\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU');\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb7cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "DATASET_NAME = \"HSC_v6\"\n",
    "MODEL_TYPE = \"CVAE\"\n",
    "MODEL_VERSION = \"v1.0\"\n",
    "MODEL_SUBVERSION = \"v1.0.\" + now.strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "\n",
    "model_id = '_'.join([DATASET_NAME, MODEL_TYPE, MODEL_VERSION])\n",
    "model_path = os.path.join('/data3/Billy/models', model_id, MODEL_SUBVERSION, 'model')\n",
    "checkpoints_path = os.path.join('/data3/Billy/models', model_id, MODEL_SUBVERSION, 'checkpoints')\n",
    "logs_path = os.path.join('/data3/Billy/logs', model_id, MODEL_SUBVERSION)\n",
    "predictions_path = os.path.join('/data3/Billy/predictions', model_id, MODEL_SUBVERSION)\n",
    "weights_path = model_path + '/data3/Billy/CVAE/weights.h5'\n",
    "\n",
    "os.makedirs(model_path, exist_ok = True)\n",
    "os.makedirs(checkpoints_path, exist_ok = True)\n",
    "os.makedirs(logs_path, exist_ok = True)\n",
    "os.makedirs(predictions_path, exist_ok = True)\n",
    "\n",
    "if write == True:\n",
    "    with open(\"/data3/Billy/models/README.md\", \"a\") as myfile:\n",
    "        myfile.write(MODEL_TYPE + \" \" + MODEL_SUBVERSION + \" - \" + MODEL_DESCRIPTION + \" - B. Li\" + \"\\n\")\n",
    "else:\n",
    "    with open(\"/data3/Billy/models/README.md\", \"a\") as myfile:\n",
    "        myfile.write(MODEL_TYPE + \" \" + MODEL_SUBVERSION + \" - ... \"+ \" - B. Li\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbc0eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_gen = {'X_key': 'image',\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': False}\n",
    "\n",
    "train_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/127x127/5x127x127_training.hdf5', **args_gen)\n",
    "val_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/127x127/5x127x127_validation.hdf5', **args_gen)\n",
    "test_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/127x127/5x127x127_testing.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "588c99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = BATCH_SIZE\n",
    "l = len(train_gen._indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d31d75f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 21:21:56.786679: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(LATENT_DIM), scale = 0.1), reinterpreted_batch_ndims = 1)\n",
    "\n",
    "images = Input(shape = IMAGE_SHAPE)\n",
    "redshifts = Input(shape = 1,)\n",
    "conv1 = Conv2D(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "            padding = 'same', data_format = 'channels_first')(images)\n",
    "conv2 = Conv2D(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "            padding = 'same', data_format = 'channels_first')(conv1)\n",
    "flatten = Flatten()(conv2)\n",
    "dense1 = Dense(1024, activation = None)(flatten)\n",
    "dense2 = tf.keras.layers.Dense(512, activation = \"relu\")(redshifts)\n",
    "dense3 = tf.keras.layers.Dense(512, activation = \"relu\")(dense2)\n",
    "dense4 = tf.keras.layers.Dense(512, activation = \"relu\")(dense3)\n",
    "concat = tf.keras.layers.Concatenate()([dense1, dense4])\n",
    "dense5 = Dense(tfpl.MultivariateNormalTriL.params_size(LATENT_DIM), activation = None)(concat)\n",
    "z = tfpl.MultivariateNormalTriL(LATENT_DIM,\n",
    "            activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight = KL_WEIGHT))(dense5)\n",
    "encoder = Model([images, redshifts], z)\n",
    "\n",
    "zc = tf.keras.layers.Concatenate()([z, redshifts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b25f1d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense6 = Dense(8 * LATENT_DIM * 32 * 32, activation = None)\n",
    "reshape = Reshape((8 * LATENT_DIM, 32, 32))\n",
    "conv3 = Conv2DTranspose(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "                    padding = 'same', data_format = 'channels_first')\n",
    "conv4 = Conv2DTranspose(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "                    padding = 'same', data_format = 'channels_first')\n",
    "conv5 = Conv2DTranspose(BASE_DEPTH, 3, strides = 1, activation = leaky_relu, \n",
    "                    padding = 'same', data_format = 'channels_first')\n",
    "conv6 = Conv2D(IMAGE_SHAPE[0], 3, strides = 1, activation = None, \n",
    "           padding = 'same', data_format = 'channels_first')\n",
    "cropping = Cropping2D(cropping=((0, 1), (0, 1)), data_format = 'channels_first')\n",
    "outputs = Reshape(IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcac6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense6_model = dense6(zc)\n",
    "reshape_model = reshape(dense6_model)\n",
    "conv3_model = conv3(reshape_model)\n",
    "conv4_model = conv4(conv3_model)\n",
    "conv5_model = conv5(conv4_model)\n",
    "conv6_model = conv6(conv5_model)\n",
    "cropping_model = cropping(conv6_model)\n",
    "outputs_model = outputs(cropping_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c11d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = [images, redshifts], outputs = [outputs_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e036f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = Input(shape = (LATENT_DIM + 1, ))\n",
    "dense6_decoder = dense6(latents)\n",
    "reshape_decoder = reshape(dense6_decoder)\n",
    "conv3_decoder = conv3(reshape_decoder)\n",
    "conv4_decoder = conv4(conv3_decoder)\n",
    "conv5_decoder = conv5(conv4_decoder)\n",
    "conv6_decoder = conv6(conv5_decoder)\n",
    "cropping_decoder = cropping(conv6_decoder)\n",
    "outputs_decoder = outputs(cropping_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17a65d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Model(latents, outputs_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c25fe180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 127, 127  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 8, 64, 64)    368         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 32, 32)    584         ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          1024        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8192)         0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 512)          262656      ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         8389632     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 512)          262656      ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1536)         0           ['dense[0][0]',                  \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 33152)        50954624    ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " multivariate_normal_tri_l (Mul  ((None, 256),       0           ['dense_4[0][0]']                \n",
      " tivariateNormalTriL)            (None, 256))                                                     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 257)          0           ['multivariate_normal_tri_l[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 2097152)      541065216   ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 2048, 32, 32  0           ['dense_5[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 8, 64, 64)   147464      ['reshape[0][0]']                \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 8, 128, 128)  584        ['conv2d_transpose[0][0]']       \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 8, 128, 128)  584        ['conv2d_transpose_1[0][0]']     \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 5, 128, 128)  365         ['conv2d_transpose_2[0][0]']     \n",
      "                                                                                                  \n",
      " cropping2d (Cropping2D)        (None, 5, 127, 127)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 5, 127, 127)  0           ['cropping2d[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 601,085,757\n",
      "Trainable params: 601,085,757\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d463c7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/billyli/miniconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr = 0.0001)\n",
    "model.compile(optimizer = optimizer, loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcbb9c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/billyli/miniconda3/lib/python3.9/site-packages/neptune/new/internal/utils/git.py:35: UserWarning: GitPython could not be initialized\n",
      "  warnings.warn(\"GitPython could not be initialized\")\n",
      "/home/billyli/miniconda3/lib/python3.9/site-packages/neptune/new/internal/utils/git.py:35: UserWarning: GitPython could not be initialized\n",
      "  warnings.warn(\"GitPython could not be initialized\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/astro-data-lab/VAE/e/VAE-133\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    name = MODEL_SUBVERSION,\n",
    "    project = \"astro-data-lab/VAE\",\n",
    "    api_token = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGFlZGMxOC04MWU5LTQ2NDctYjlhZS05NGE2NGQ0NmIzMmEifQ==\",\n",
    ")  # your credentials\n",
    "\n",
    "# logs_callback = TensorBoard(log_dir = logs_path)\n",
    "\n",
    "weights_callback = ModelCheckpoint(filepath = os.path.join(checkpoints_path, 'weights_epoch{epoch}.hdf5'), save_freq = int(EPOCHS/CHECKPOINTS_TO_SAVE), save_weights_only = True)\n",
    "\n",
    "LR_callback = ReduceLROnPlateau()\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch <= 100:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr / 10\n",
    "\n",
    "LR_modify_callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 0)\n",
    "\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs_path, histogram_freq = 1)\n",
    "\n",
    "neptune_callback = NeptuneCallback(run = run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b7c72",
   "metadata": {},
   "source": [
    "train_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/127x127/5x127x127_training.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4871e88f",
   "metadata": {},
   "source": [
    "history = model.fit(train_gen, epochs = 50, callbacks = [neptune_callback], validation_data = val_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d488d57",
   "metadata": {},
   "source": [
    "train_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step3/5x127x127_training_min_3.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f8a28",
   "metadata": {},
   "source": [
    "history = model.fit(train_gen, epochs = 75, callbacks = [neptune_callback], validation_data = val_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc4991",
   "metadata": {},
   "source": [
    "train_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step3/5x127x127_training_min_2.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf5ea43",
   "metadata": {},
   "source": [
    "history = model.fit(train_gen, epochs = 100, callbacks = [weights_callback, neptune_callback], validation_data = val_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56a2d02",
   "metadata": {},
   "source": [
    "train_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step3/5x127x127_training_min_1.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d72dc89",
   "metadata": {},
   "source": [
    "history = model.fit(train_gen, epochs = 100, callbacks = [weights_callback, neptune_callback], validation_data = val_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c53ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/127x127/5x127x127_training.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24912cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/model_1/conv2d_2/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"/home/billyli/miniconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/billyli/miniconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2158165/1208470448.py\", line 1, in <cell line: 1>\n      history = model.fit(train_gen, epochs = 200, callbacks = [neptune_callback, LR_callback], validation_data = val_gen, verbose = 1)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model_1/conv2d_2/Conv2D/Conv2DBackpropInput'\nConv2DCustomBackpropInputOp only supports NHWC.\n\t [[{{node gradient_tape/model_1/conv2d_2/Conv2D/Conv2DBackpropInput}}]] [Op:__inference_train_function_7713]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mneptune_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLR_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model_1/conv2d_2/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"/home/billyli/miniconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/billyli/miniconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2158165/1208470448.py\", line 1, in <cell line: 1>\n      history = model.fit(train_gen, epochs = 200, callbacks = [neptune_callback, LR_callback], validation_data = val_gen, verbose = 1)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model_1/conv2d_2/Conv2D/Conv2DBackpropInput'\nConv2DCustomBackpropInputOp only supports NHWC.\n\t [[{{node gradient_tape/model_1/conv2d_2/Conv2D/Conv2DBackpropInput}}]] [Op:__inference_train_function_7713]"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen, epochs = 200, callbacks = [neptune_callback, LR_callback], validation_data = val_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6736025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = 3\n",
    "index = 466\n",
    "z = test_gen[lib][0][1][index]\n",
    "z_shifted = 4\n",
    "band = 0\n",
    "print(f'z = {z}')\n",
    "str = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str = np.concatenate((str, np.array([z])))\n",
    "str = str.reshape(1, LATENT_DIM + 1)\n",
    "str_shifted = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str_shifted = np.concatenate((str_shifted, np.array([z_shifted])))\n",
    "str_shifted = str_shifted.reshape(1, LATENT_DIM + 1)\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (10, 5))\n",
    "axes[0].imshow(test_gen[lib][0][0][index][band], cmap = 'afmhot')\n",
    "axes[1].imshow(decoder([str])[0][band], cmap = 'afmhot')\n",
    "axes[2].imshow(decoder([str_shifted])[0][band], cmap = 'afmhot')\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "axes[2].axis('off')\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[1].set_title(\"Regenerated\")\n",
    "axes[2].set_title(\"Regenerated Far\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2840186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = 5\n",
    "index = 271\n",
    "z = test_gen[lib][0][1][index]\n",
    "z_shifted = 0.1\n",
    "band = 0\n",
    "print(f'z = {z}')\n",
    "str = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str = np.concatenate((str, np.array([z])))\n",
    "str = str.reshape(1, LATENT_DIM + 1)\n",
    "str_shifted = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str_shifted = np.concatenate((str_shifted, np.array([z_shifted])))\n",
    "str_shifted = str_shifted.reshape(1, LATENT_DIM + 1)\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (10, 5))\n",
    "axes[0].imshow(test_gen[lib][0][0][index][band], cmap = 'afmhot')\n",
    "axes[1].imshow(decoder([str])[0][band], cmap = 'afmhot')\n",
    "axes[2].imshow(decoder([str_shifted])[0][band], cmap = 'afmhot')\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "axes[2].axis('off')\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[1].set_title(\"Regenerated\")\n",
    "axes[2].set_title(\"Regenerated Close\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534af846",
   "metadata": {},
   "outputs": [],
   "source": [
    "band = 0\n",
    "str = prior.sample(1)[0]\n",
    "strlo = np.concatenate((str, np.array([0.1])))\n",
    "strlo = strlo.reshape(1, LATENT_DIM + 1)\n",
    "strhi = np.concatenate((str, np.array([4])))\n",
    "strhi = strhi.reshape(1, LATENT_DIM + 1)\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 5))\n",
    "axes[0].imshow(decoder([strlo])[0][band], cmap = 'afmhot')\n",
    "axes[1].imshow(decoder([strhi])[0][band], cmap = 'afmhot')\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "axes[0].set_title(\"Low z\")\n",
    "axes[1].set_title(\"High z\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a67b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e3dd1",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 5))\n",
    "x_array = np.arange(5)\n",
    "lo_array = np.array([])\n",
    "hi_array = np.array([])\n",
    "for j in range(0, 5):\n",
    "    lo_array = np.append(lo_array, decoder([strlo])[0][j][63][63])\n",
    "    hi_array = np.append(hi_array, decoder([strhi])[0][j][63][63])\n",
    "axes[0].scatter(x_array, lo_array, c = 'blue', label = 'Low')\n",
    "axes[1].scatter(x_array, hi_array, c = 'red', label = 'High')\n",
    "axes[0].set_xlabel(\"Bands\")\n",
    "axes[0].set_ylabel(\"Central Pixel Value\")\n",
    "axes[0].legend()\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (5, 5))\n",
    "x_array = np.arange(5)\n",
    "lo_array = np.array([])\n",
    "hi_array = np.array([])\n",
    "for j in range(0, 5):\n",
    "    lo_array = np.append(lo_array, np.amax(np.transpose(np.asarray(decoder([strlo])[0][j][60:67]))[60:67].flatten()))\n",
    "    hi_array = np.append(hi_array, np.amax(np.transpose(np.asarray(decoder([strhi])[0][j][60:67]))[60:67].flatten()))\n",
    "axes.scatter(x_array, lo_array, c = 'blue', label = 'Low')\n",
    "axes.scatter(x_array, hi_array, c = 'red', label = 'High')\n",
    "axes.set_xlabel(\"Bands\")\n",
    "axes.set_ylabel(\"Max Pixel Value Near Center\")\n",
    "axes.legend()\n",
    "axes.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b218b7",
   "metadata": {},
   "source": [
    "for j in range(3, 80):\n",
    "    for i in range(0, 512):\n",
    "        if test_gen[j][0][1][i] <= 0.1:\n",
    "            print(j)\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e737db36",
   "metadata": {},
   "source": [
    "for j in range(3, 80):\n",
    "    for i in range(0, 512):\n",
    "        if test_gen[j][0][1][i] >= 3.5:\n",
    "            print(j)\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ab0405",
   "metadata": {},
   "source": [
    "for i in range(0, 84):\n",
    "    l = 512\n",
    "    if i == 83:\n",
    "        l = 464\n",
    "    for j in range(0, l):\n",
    "        index = i * BATCH_SIZE + j + 1\n",
    "        stdout.write(\"\\rChecking %d samples of \" % (index) + \"42960\")\n",
    "        z = test_gen[i][0][1][j]\n",
    "        str = np.asarray(encoder([np.array([test_gen[i][0][0][j]]), np.array([test_gen[i][0][1][j]])])[0])\n",
    "        str = np.concatenate((str, np.array([z])))\n",
    "        str = str.reshape(1, LATENT_DIM + 1)\n",
    "        hdul = fits.PrimaryHDU(data = test_gen[i][0][0][j])\n",
    "        string = f\"/data/CVAE Generated/Full/Original Galaxy #{index}.fits\"\n",
    "        hdul.writeto(string, overwrite = True)\n",
    "        hdul = fits.PrimaryHDU(data = decoder([str])[0])\n",
    "        string = f\"/data/CVAE Generated/Full/Reconstructed Galaxy #{index}.fits\"\n",
    "        hdul.writeto(string, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8092e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_bands_max_near_center(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.amax(np.array([test_gen[0][0][0][i][j]])))\n",
    "            pred_array = np.append(pred_array, np.amax(np.transpose(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j][60:67]))[60:67].flatten()))\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(f\"Maximum normalized pixel value z = {np.array([test_gen[0][0][1][i]])[0]}\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "\n",
    "def scatter_bands_max(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.amax(np.array([test_gen[0][0][0][i][j]])))\n",
    "            pred_array = np.append(pred_array, np.amax(np.array([model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]])))\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(\"Maximum normalized pixel value\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "        \n",
    "def scatter_bands_center(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.array([test_gen[0][0][0][i][j]])[0][63][63])\n",
    "            pred_array = np.append(pred_array, model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j][63][63])\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(f\"Central pixel value z = {np.array([test_gen[0][0][1][i]])}\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "        \n",
    "def scatter_bands_center_shift(lib = 3, i = 37, z = 1):\n",
    "    print(z)\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (5, 5))\n",
    "    x_array = np.arange(5)\n",
    "    true_array = np.array([])\n",
    "    pred_array = np.array([])\n",
    "    for j in range(0, 5):\n",
    "        true_array = np.append(true_array, np.array([test_gen[lib][0][0][i][j]])[0][63][63])\n",
    "        pred_array = np.append(pred_array, model([np.array([test_gen[lib][0][0][i]]), np.array([z])])[0][j][63][63])\n",
    "    axes.scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "    axes.scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "    axes.set_xlabel(\"Bands\")\n",
    "    axes.set_ylabel(\"Central pixel value\")\n",
    "    axes.legend()\n",
    "    \n",
    "def scatter_bands_max_shift(lib = 3, i = 37, z = 1):\n",
    "    print(z)\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (5, 5))\n",
    "    x_array = np.arange(5)\n",
    "    true_array = np.array([])\n",
    "    pred_array = np.array([])\n",
    "    for j in range(0, 5):\n",
    "        true_array = np.append(true_array, np.amax(np.array([test_gen[lib][0][0][i][j]])))\n",
    "        pred_array = np.append(pred_array, np.amax(np.array([model([np.array([test_gen[lib][0][0][i]]), np.array([z])])[0][j]])))\n",
    "    axes.scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "    axes.scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "    axes.set_xlabel(\"Bands\")\n",
    "    axes.set_ylabel(\"Central pixel value\")\n",
    "    axes.legend()\n",
    "\n",
    "def scatter_bands_percentile(percentile = 90, num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show /  5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_90 = np.percentile(np.array([test_gen[0][0][0][i][j]]).flatten(), percentile)\n",
    "            pred_90 = np.percentile(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]).flatten(), percentile)\n",
    "            true_array = np.append(true_array, true_90)\n",
    "            pred_array = np.append(pred_array, pred_90)\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel('Bands')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(f'{percentile}th percentile normalized pixel value')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "\n",
    "def scatter_bands_mean(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_mean = np.mean(np.array([test_gen[0][0][0][i][j]]).flatten())\n",
    "            pred_mean = np.mean(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]).flatten())\n",
    "            true_array = np.append(true_array, true_mean)\n",
    "            pred_array = np.append(pred_array, pred_mean)\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel('Bands')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel('Mean normalized pixel value')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "\n",
    "def display_histograms(num_to_show = 2, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = num_to_show, ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        for j in range(0, 5):\n",
    "            true_arr = sorted(np.array([test_gen[0][0][0][i][j]]).flatten())\n",
    "            pred_arr = sorted(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]).flatten())\n",
    "            true_arr = true_arr[0 : int(len(true_arr) * .99)]\n",
    "            pred_arr = pred_arr[0 : int(len(pred_arr) * .99)]\n",
    "            axes[i][j].hist(true_arr, 100, color = 'blue', label = 'True', alpha = 0.5)\n",
    "            axes[i][j].hist(pred_arr, 100, color = 'red', label = 'Predicted', alpha = 0.5)\n",
    "            axes[i][j].set_xlabel(\"Pixel Values\")\n",
    "            axes[i][j].set_ylabel(\"Count\")\n",
    "            axes[i][j].legend()\n",
    "    fig.suptitle('Histograms of Predicted vs. True Image, Horizontal are Bands')\n",
    "    \n",
    "def display_5_bands(index):\n",
    "    fig, axes = plt.subplots(nrows = 2, ncols = 5, figsize = (20, 10))\n",
    "    loss = round(model.evaluate([np.array([test_gen[0][0][0][index]]), np.array([test_gen[0][0][1][index]])], np.array([test_gen[0][0][0][index]]), verbose = 0), 2)\n",
    "    for i in range(0, 5):\n",
    "        axes[0][i].imshow(np.array([test_gen[0][0][0][index]])[0][i], cmap = 'afmhot')\n",
    "        max_pixel_true = round(np.amax(np.array([test_gen[0][0][0][index]])[0][i]), 2)\n",
    "        # axes[0][i].set_title(f'True band {i} max = {max_pixel_true}')\n",
    "        pred = model([np.array([test_gen[0][0][0][index]]), np.array([test_gen[0][0][1][index]])])[0][i]\n",
    "        axes[1][i].imshow(pred, cmap = 'afmhot')\n",
    "        max_pixel_pred = round(np.amax(pred), 2)\n",
    "        axes[1][i].set_title(f'\\n loss = {loss}') # f'Pred band {i} max = {max_pixel_pred}' + \n",
    "        \n",
    "def display_high_loss(num_to_show, min_loss):\n",
    "    fig, axes = plt.subplots(nrows = num_to_show, ncols = 5, figsize = (20, 5 * num_to_show))\n",
    "    r = 0\n",
    "    for i in range(BATCH_SIZE):\n",
    "        loss = round(model.evaluate([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])], np.array([test_gen[0][0][0][i]]), verbose = 0), 2)\n",
    "        if loss >= min_loss:\n",
    "            print(i)\n",
    "            for j in range(0, 5):\n",
    "                axes[r][j].imshow(np.array([test_gen[0][0][0][i]])[0][j], cmap = 'afmhot')\n",
    "                axes[r][j].set_title(f'Loss = {loss}')\n",
    "            r += 1\n",
    "        if r >= num_to_show:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77067c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max_near_center(num_to_show = 10, index = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c4266",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array = np.array([])\n",
    "y_array = np.array([])\n",
    "l = len(test_gen[0][0][0])\n",
    "print(l)\n",
    "for i in range(0, l):\n",
    "    x_array = np.append(x_array, np.amax(np.array([test_gen[0][0][0][i][4]])))\n",
    "    y_array = np.append(y_array, np.array([test_gen[0][0][1][i]])[0])\n",
    "    print(i)\n",
    "plt.scatter(y_array, x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81015273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "xy = np.asarray(np.vstack([y_array, x_array])).astype('float32')\n",
    "z = gaussian_kde(xy)(xy)\n",
    "plt.scatter(y_array, x_array, s = 5, c = z)\n",
    "plt.xlim(0,4)\n",
    "plt.ylim(0, 80)\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"Maximum Pixel Value near the Center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac674f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_center_shift(lib = 3, i = 267, z = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dcc7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max_shift(lib = 3, i = 37, z = test_gen[3][0][1][37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa5bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max_shift(lib = 3, i = 37, z = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2457f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_center()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_mean(10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c48efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_percentile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3369ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eeb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_5_bands(38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_high_loss(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn",
   "language": "python",
   "name": "bnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

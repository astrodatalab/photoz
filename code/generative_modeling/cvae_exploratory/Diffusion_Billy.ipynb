{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f923d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "write = True # log this version as new\n",
    "MODEL_DESCRIPTION = \"Diffusion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8fc210-73b8-4a4e-a0ef-a05711c926fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf;\n",
    "from tensorflow import keras, einsum\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow.keras.layers as nn\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.tensorflow import Rearrange\n",
    "from functools import partial\n",
    "from inspect import isfunction\n",
    "\n",
    "import pandas as pd\n",
    "from sys import stdout\n",
    "from datetime import datetime\n",
    "import neptune as neptune\n",
    "from neptune.integrations.tensorflow_keras import NeptuneCallback\n",
    "from astropy.io import fits\n",
    "import random\n",
    "from DataMaker import HDF5ImageGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a44e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "gpus = tf.config.list_physical_devices('GPU');\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 20000)]);\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU');\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb7cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "DATASET_NAME = \"HSC_v6\"\n",
    "MODEL_TYPE = \"Diffusion\"\n",
    "MODEL_VERSION = \"v1.0\"\n",
    "MODEL_SUBVERSION = \"v1.0.\" + now.strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "\n",
    "model_id = '_'.join([DATASET_NAME, MODEL_TYPE, MODEL_VERSION])\n",
    "model_path = os.path.join('/data3/Billy/models', model_id, MODEL_SUBVERSION, 'model')\n",
    "checkpoints_path = os.path.join('/data3/Billy/models', model_id, MODEL_SUBVERSION, 'checkpoints')\n",
    "logs_path = os.path.join('/data3/Billy/logs', model_id, MODEL_SUBVERSION)\n",
    "predictions_path = os.path.join('/data3/Billy/predictions', model_id, MODEL_SUBVERSION)\n",
    "weights_path = model_path + '/data3/Billy/Diffusion/weights.h5'\n",
    "\n",
    "os.makedirs(model_path, exist_ok = True)\n",
    "os.makedirs(checkpoints_path, exist_ok = True)\n",
    "os.makedirs(logs_path, exist_ok = True)\n",
    "os.makedirs(predictions_path, exist_ok = True)\n",
    "\n",
    "if write == True:\n",
    "    with open(\"/data3/Billy/models/README.md\", \"a\") as myfile:\n",
    "        myfile.write(MODEL_TYPE + \" \" + MODEL_SUBVERSION + \" - \" + MODEL_DESCRIPTION + \" - B. Li\" + \"\\n\")\n",
    "else:\n",
    "    with open(\"/data3/Billy/models/README.md\", \"a\") as myfile:\n",
    "        myfile.write(MODEL_TYPE + \" \" + MODEL_SUBVERSION + \" - ... \"+ \" - B. Li\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bcf60-c403-4b14-be17-6908a9bd15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 5\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcf25f1-c25d-49d0-92a0-d756213dd817",
   "metadata": {},
   "source": [
    "hf_train = h5py.File('/data/HSC/HSC_v6/step2A/127x127/5x127x127_training_small.hdf5', 'r')\n",
    "hf_test = h5py.File('/data/HSC/HSC_v6/step2A/127x127/5x127x127_testing_small.hdf5', 'r')\n",
    "hf_validation = h5py.File('/data/HSC/HSC_v6/step2A/127x127/5x127x127_validation_small.hdf5', 'r')\n",
    "x_train = np.asarray(np.transpose(hf_train['image'][0:],(0,2,3,1)))\n",
    "x_test = np.asarray(np.transpose(hf_test['image'][0:],(0,2,3,1)))\n",
    "x_validation = np.asarray(np.transpose(hf_validation['image'][0:],(0,2,3,1)))\n",
    "x_train = np.pad(x_train, [(0, 0), (0, 1), (0, 1), (0, 0)], mode = 'constant') # Padding to 128x128\n",
    "x_test = np.pad(x_test, [(0, 0), (0, 1), (0, 1), (0, 0)], mode = 'constant') # Padding to 128x128\n",
    "x_validation = np.pad(x_validation, [(0, 0), (0, 1), (0, 1), (0, 0)], mode = 'constant') # Padding to 128x128\n",
    "y_train = np.asarray(hf_train['specz_redshift'][0:])[..., None]\n",
    "y_test = np.asarray(hf_test['specz_redshift'][0:])[..., None]\n",
    "y_validation = np.asarray(hf_validation['specz_redshift'][0:])[..., None]\n",
    "hf_train.close()\n",
    "hf_test.close()\n",
    "hf_validation.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6878ec36-85cc-472d-b950-a7774409dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_count = 0\n",
    "def next_batch():\n",
    "    global batch_count\n",
    "    hf_train = h5py.File('/data/HSC/HSC_v6/step2A/127x127/5x127x127_training_small.hdf5', 'r')\n",
    "    \n",
    "    x_train = np.asarray(np.transpose(hf_train['image'][0:],(0,2,3,1)))\n",
    "    for i in range(len(x_train)):\n",
    "        x_train[i] = np.true_divide(x_train[i], np.max(np.nan_to_num(x_train[i])))\n",
    "    x_train = x_train[batch_count * BATCH_SIZE : batch_count * BATCH_SIZE + BATCH_SIZE]\n",
    "    x_train = np.pad(x_train, [(0, 0), (0, 1), (0, 1), (0, 0)], mode = 'constant') # Padding to 128x128\n",
    "    hf_train.close()\n",
    "    batch_count = batch_count + 1\n",
    "    if batch_count == 10000 / BATCH_SIZE - 1:\n",
    "        batch_count = 0\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da216099-362e-4bb3-95e4-e72f57806b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 200\n",
    "max_noise = 0.1\n",
    "\n",
    "# create a fixed beta schedule\n",
    "beta = np.linspace(max_noise / timesteps, max_noise, timesteps)\n",
    "\n",
    "# this will be used as discussed in the reparameterization trick\n",
    "alpha = 1 - beta\n",
    "alpha_bar = np.cumprod(alpha, 0)\n",
    "alpha_bar = np.concatenate((np.array([1.]), alpha_bar[ : -1]), axis = 0)\n",
    "sqrt_alpha_bar = np.sqrt(alpha_bar)\n",
    "one_minus_sqrt_alpha_bar = np.sqrt(1 - alpha_bar)\n",
    "\n",
    "# this function will help us set the RNG key for Numpy\n",
    "def set_key(key):\n",
    "    np.random.seed(key)\n",
    "\n",
    "# this function will add noise to the input as per the given timestamp\n",
    "def forward_noise(key, x_0, t):\n",
    "    set_key(key)\n",
    "    noise = np.random.normal(size = x_0.shape)\n",
    "    reshaped_sqrt_alpha_bar_t = np.reshape(np.take(sqrt_alpha_bar, t), (-1, 1, 1, 1))\n",
    "    reshaped_one_minus_sqrt_alpha_bar_t = np.reshape(np.take(one_minus_sqrt_alpha_bar, t), (-1, 1, 1, 1))\n",
    "    noisy_image = reshaped_sqrt_alpha_bar_t  * x_0 + reshaped_one_minus_sqrt_alpha_bar_t  * noise\n",
    "    return noisy_image, noise\n",
    "\n",
    "# this function will be used to create sample timestamps between 0 & T\n",
    "def generate_timestamp(key, num):\n",
    "    set_key(key)\n",
    "    return tf.random.uniform(shape = [num], minval = 0, maxval = timesteps, dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438565c5-d1b2-40e0-976f-f68c67d3e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us visualize the output image at a few timestamps\n",
    "sample = next_batch()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae674c9-63b6-4813-b15f-cde614403081",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arr = np.array([])\n",
    "for index, i in enumerate(range(timesteps)):\n",
    "    noisy_im, noise = forward_noise(0, np.expand_dims(sample, 0), np.array([i, ]))\n",
    "    y_arr = np.append(y_arr, np.var(noisy_im[0][:, :, 0].flatten()))\n",
    "\n",
    "x_arr = np.linspace(0, timesteps, timesteps)\n",
    "\n",
    "\n",
    "# plt.plot(x_arr, y_arr)\n",
    "# plt.title(\"\")\n",
    "# plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(x_arr, y_arr)\n",
    "ax1.set_xlabel(\"Steps of Noise\")\n",
    "ax1.set_ylabel(\"Variance in Noised Image\")\n",
    "\n",
    "ax2 = ax1.twiny()\n",
    "ax2.plot(beta, 0.5 * np.ones(timesteps), alpha = 0) # Create a dummy plot\n",
    "ax2.set_xlabel(\"Variance of the Gaussian Noise Added at Each Step\")\n",
    "# fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3904c03-13a9-467f-a816-81e92f353c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 5, ncols = 5, figsize = (50, 50))\n",
    "\n",
    "j = 0\n",
    "for index, i in enumerate([0, 20, 100, 150, 195]):\n",
    "    noisy_im, noise = forward_noise(0, np.expand_dims(sample, 0), np.array([i, ]))\n",
    "    axes[0][j].imshow(noisy_im[0][:, :, 0], cmap = 'gray')\n",
    "    axes[1][j].imshow(noisy_im[0][:, :, 1], cmap = 'gray')\n",
    "    axes[2][j].imshow(noisy_im[0][:, :, 2], cmap = 'gray')\n",
    "    axes[3][j].imshow(noisy_im[0][:, :, 3], cmap = 'gray')\n",
    "    axes[4][j].imshow(noisy_im[0][:, :, 4], cmap = 'gray')\n",
    "    j += 1\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c4bd9-4fb6-456d-b5f5-750c3e020ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers functions\n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "# We will use this to convert timestamps to time encodings\n",
    "class SinusoidalPosEmb(Layer):\n",
    "    def __init__(self, dim, max_positions = 10000):\n",
    "        super(SinusoidalPosEmb, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.max_positions = max_positions\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(self.max_positions) / (half_dim - 1)\n",
    "        emb = tf.exp(tf.range(half_dim, dtype = tf.float32) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "\n",
    "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis = -1)\n",
    "\n",
    "        return emb\n",
    "        \n",
    "# small helper modules\n",
    "class Identity(Layer):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        return tf.identity(x)\n",
    "\n",
    "\n",
    "class Residual(Layer):\n",
    "    def __init__(self, fn):\n",
    "        super(Residual, self).__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        return self.fn(x, training = training) + x\n",
    "\n",
    "def Upsample(dim):\n",
    "    return nn.Conv2DTranspose(filters = dim, kernel_size = 4, strides = 2, padding = 'SAME')\n",
    "\n",
    "def Downsample(dim):\n",
    "    return nn.Conv2D(filters = dim, kernel_size = 4, strides = 2, padding = 'SAME')\n",
    "\n",
    "class LayerNorm(Layer):\n",
    "    def __init__(self, dim, eps = 1e-5, **kwargs):\n",
    "        super(LayerNorm, self).__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "\n",
    "        self.g = tf.Variable(tf.ones([1, 1, 1, dim]))\n",
    "        self.b = tf.Variable(tf.zeros([1, 1, 1, dim]))\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        var = tf.math.reduce_variance(x, axis = -1, keepdims = True)\n",
    "        mean = tf.reduce_mean(x, axis = -1, keepdims = True)\n",
    "\n",
    "        x = (x - mean) / tf.sqrt((var + self.eps)) * self.g + self.b\n",
    "        return x\n",
    "\n",
    "class PreNorm(Layer):\n",
    "    def __init__(self, dim, fn):\n",
    "        super(PreNorm, self).__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = LayerNorm(dim)\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)\n",
    "\n",
    "class SiLU(Layer):\n",
    "    def __init__(self):\n",
    "        super(SiLU, self).__init__()\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        return x * tf.nn.sigmoid(x)\n",
    "\n",
    "def gelu(x, approximate = False):\n",
    "    if approximate:\n",
    "        coeff = tf.cast(0.044715, x.dtype)\n",
    "        return 0.5 * x * (1.0 + tf.tanh(0.7978845608028654 * (x + coeff * tf.pow(x, 3))))\n",
    "    else:\n",
    "        return 0.5 * x * (1.0 + tf.math.erf(x / tf.cast(1.4142135623730951, x.dtype)))\n",
    "\n",
    "class GELU(Layer):\n",
    "    def __init__(self, approximate = False):\n",
    "        super(GELU, self).__init__()\n",
    "        self.approximate = approximate\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        return gelu(x, self.approximate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf57659-c611-4f91-b309-05cc09870a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building block modules\n",
    "class Block(Layer):\n",
    "    def __init__(self, dim, groups = 8):\n",
    "        super(Block, self).__init__()\n",
    "        self.proj = nn.Conv2D(dim, kernel_size = 3, strides = 1, padding = 'SAME')\n",
    "        self.norm = tfa.layers.GroupNormalization(groups, epsilon = 1e-05)\n",
    "        self.act = SiLU()\n",
    "\n",
    "\n",
    "    def call(self, x, gamma_beta = None, training = True):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x, training=training)\n",
    "\n",
    "        if exists(gamma_beta):\n",
    "            gamma, beta = gamma_beta\n",
    "            x = x * (gamma + 1) + beta\n",
    "\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class ResnetBlock(Layer):\n",
    "    def __init__(self, dim, dim_out, time_emb_dim = None, groups = 8):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "\n",
    "        self.mlp = Sequential([\n",
    "            SiLU(),\n",
    "            nn.Dense(units = dim_out * 2)\n",
    "        ]) if exists(time_emb_dim) else None\n",
    "\n",
    "        self.block1 = Block(dim_out, groups = groups)\n",
    "        self.block2 = Block(dim_out, groups = groups)\n",
    "        self.res_conv = nn.Conv2D(filters = dim_out, kernel_size = 1, strides = 1) if dim != dim_out else Identity()\n",
    "\n",
    "    def call(self, x, time_emb = None, training = True):\n",
    "        gamma_beta = None\n",
    "        if exists(self.mlp) and exists(time_emb):\n",
    "            time_emb = self.mlp(time_emb)\n",
    "            time_emb = rearrange(time_emb, 'b c -> b 1 1 c')\n",
    "            gamma_beta = tf.split(time_emb, num_or_size_splits = 2, axis = -1)\n",
    "\n",
    "        h = self.block1(x, gamma_beta = gamma_beta, training = training)\n",
    "        h = self.block2(h, training = training)\n",
    "\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "class LinearAttention(Layer):\n",
    "    def __init__(self, dim, heads = 4, dim_head = 127):\n",
    "        super(LinearAttention, self).__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        self.hidden_dim = dim_head * heads\n",
    "\n",
    "        self.attend = nn.Softmax()\n",
    "        self.to_qkv = nn.Conv2D(filters = self.hidden_dim * 3, kernel_size = 1, strides = 1, use_bias = False)\n",
    "\n",
    "        self.to_out = Sequential([\n",
    "            nn.Conv2D(filters = dim, kernel_size = 1, strides = 1),\n",
    "            LayerNorm(dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        b, h, w, c = x.shape\n",
    "        qkv = self.to_qkv(x)\n",
    "        qkv = tf.split(qkv, num_or_size_splits = 3, axis = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b x y (h c) -> b h c (x y)', h = self.heads), qkv)\n",
    "\n",
    "        q = tf.nn.softmax(q, axis = -2)\n",
    "        k = tf.nn.softmax(k, axis = -1)\n",
    "\n",
    "        q = q * self.scale\n",
    "        context = einsum('b h d n, b h e n -> b h d e', k, v)\n",
    "\n",
    "        out = einsum('b h d e, b h d n -> b h e n', context, q)\n",
    "        out = rearrange(out, 'b h c (x y) -> b x y (h c)', h = self.heads, x = h, y = w)\n",
    "        out = self.to_out(out, training = training)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, dim, heads = 4, dim_head = 127):\n",
    "        super(Attention, self).__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        self.hidden_dim = dim_head * heads\n",
    "\n",
    "        self.to_qkv = nn.Conv2D(filters = self.hidden_dim * 3, kernel_size = 1, strides = 1, use_bias = False)\n",
    "        self.to_out = nn.Conv2D(filters = dim, kernel_size = 1, strides = 1)\n",
    "\n",
    "    def call(self, x, training = True):\n",
    "        b, h, w, c = x.shape\n",
    "        qkv = self.to_qkv(x)\n",
    "        qkv = tf.split(qkv, num_or_size_splits = 3, axis = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b x y (h c) -> b h c (x y)', h=self.heads), qkv)\n",
    "        q = q * self.scale\n",
    "\n",
    "        sim = einsum('b h d i, b h d j -> b h i j', q, k)\n",
    "        sim_max = tf.stop_gradient(tf.expand_dims(tf.argmax(sim, axis = -1), axis = -1))\n",
    "        sim_max = tf.cast(sim_max, tf.float32)\n",
    "        sim = sim - sim_max\n",
    "        attn = tf.nn.softmax(sim, axis = -1)\n",
    "\n",
    "        out = einsum('b h i j, b h d j -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h (x y) d -> b x y (h d)', x = h, y = w)\n",
    "        out = self.to_out(out, training = training)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee365c-cd1f-4ec3-9b14-71dfd6914664",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(Model):\n",
    "    def __init__(self,\n",
    "                 dim = 128,\n",
    "                 init_dim = None,\n",
    "                 out_dim = None,\n",
    "                 dim_mults = (1, 2, 4, 8),\n",
    "                 channels = 5,\n",
    "                 resnet_block_groups = 4,\n",
    "                 learned_variance = False,\n",
    "                 sinusoidal_cond_mlp = True\n",
    "                 ):\n",
    "        super(Unet, self).__init__()\n",
    "        \n",
    "        # determine dimensions\n",
    "        self.channels = channels\n",
    "        \n",
    "        init_dim = default(init_dim, dim // 3 * 2)\n",
    "        self.init_conv = nn.Conv2D(filters = init_dim, kernel_size = 7, strides = 1, padding = 'SAME')\n",
    "        \n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[ : -1], dims[1 : ]))\n",
    "        \n",
    "        block_klass = partial(ResnetBlock, groups = resnet_block_groups)\n",
    "        \n",
    "        # time embeddings\n",
    "        time_dim = dim * 4\n",
    "        self.sinusoidal_cond_mlp = sinusoidal_cond_mlp\n",
    "        \n",
    "        self.time_mlp = Sequential([\n",
    "            SinusoidalPosEmb(dim),\n",
    "            nn.Dense(units = time_dim),\n",
    "            GELU(),\n",
    "            nn.Dense(units = time_dim)\n",
    "        ], name=\"time embeddings\")\n",
    "        \n",
    "        # layers\n",
    "        self.downs = []\n",
    "        self.ups = []\n",
    "        num_resolutions = len(in_out)\n",
    "        \n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append([\n",
    "                block_klass(dim_in, dim_out, time_emb_dim = time_dim),\n",
    "                block_klass(dim_out, dim_out, time_emb_dim = time_dim),\n",
    "                Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
    "                Downsample(dim_out) if not is_last else Identity()\n",
    "            ])\n",
    "  \n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
    "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
    "        \n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.ups.append([\n",
    "                block_klass(dim_out * 2, dim_in, time_emb_dim = time_dim),\n",
    "                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n",
    "                Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
    "                Upsample(dim_in) if not is_last else Identity()\n",
    "            ])\n",
    "        \n",
    "        default_out_dim = channels * (1 if not learned_variance else 2)\n",
    "        self.out_dim = default(out_dim, default_out_dim)\n",
    "        \n",
    "        self.final_conv = Sequential([\n",
    "            block_klass(dim * 2, dim),\n",
    "            nn.Conv2D(filters = self.out_dim, kernel_size = 1, strides = 1)\n",
    "        ], name = \"output\")\n",
    "        \n",
    "    def call(self, x, time = None, training = True, **kwargs):\n",
    "        x = self.init_conv(x)\n",
    "        t = self.time_mlp(time)\n",
    "        \n",
    "        h = []\n",
    "\n",
    "        for block1, block2, attn, downsample in self.downs:\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "\n",
    "        for block1, block2, attn, upsample in self.ups:\n",
    "            x = tf.concat([x, h.pop()], axis = -1)\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            x = upsample(x)\n",
    "\n",
    "        x = tf.concat([x, h.pop()], axis = -1)\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7f7ea7-3a99-4fe6-82a0-05df8abc9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our unet model\n",
    "unet = Unet(channels = 5)\n",
    "\n",
    "# initialize the model in the memory of our GPU\n",
    "test_images = np.ones([1, 128, 128, channels])\n",
    "test_timestamps = generate_timestamp(0, 1)\n",
    "k = unet(test_images, test_timestamps)\n",
    "\n",
    "# create our optimizer, we will use adam with a Learning rate of 1e-4\n",
    "opt = keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b6f9d-5f56-4bd0-9a52-11ba43af03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e216c57-aa5c-406e-a76c-b394dfffdec3",
   "metadata": {},
   "source": [
    "def loss_fn(real, generated):\n",
    "    mse = tf.reshape((real - generated) ** 2, (channels * BATCH_SIZE * 128 * 128))\n",
    "    real_flatten = tf.reshape(real, (channels * BATCH_SIZE * 128 * 128))\n",
    "\n",
    "    mse = tf.cast(mse, dtype = tf.float32)\n",
    "    real_flatten = tf.cast(tf.abs(real_flatten), dtype = tf.float32)\n",
    "\n",
    "    loss_modified = tf.reduce_sum(tf.multiply(mse, real_flatten))\n",
    "    return loss_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa1884-4c2d-4d6f-af38-58f756667739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(real, generated):\n",
    "    loss = tf.math.reduce_mean((real - generated) ** 2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971a0c7-442e-4fd9-9436-d78b34611fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = 0\n",
    "\n",
    "def train_step(batch):\n",
    "    rng, tsrng = np.random.randint(0, 100000, size = (2,))\n",
    "    timestep_values = generate_timestamp(tsrng, batch.shape[0])\n",
    "\n",
    "    noised_image, noise = forward_noise(rng, batch, timestep_values)\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = unet(noised_image, timestep_values)\n",
    "        loss_value = loss_fn(noise, prediction)\n",
    "    \n",
    "    gradients = tape.gradient(loss_value, unet.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, unet.trainable_variables))\n",
    "\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f612e54-129b-490c-bd95-e5307abe9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for e in range(1, epochs + 1):\n",
    "    # this is cool utility in Tensorflow that will create a nice looking progress bar\n",
    "    bar = tf.keras.utils.Progbar(10000 / 8 - 1)\n",
    "    losses = []\n",
    "    for i in range(0, int(10000 / 8)):\n",
    "        batch = next_batch()\n",
    "        loss = train_step(batch)\n",
    "        losses.append(loss)\n",
    "        bar.update(i, values = [(\"loss\", loss)])\n",
    "        \n",
    "    avg = np.mean(losses)\n",
    "    print(f\"Average loss for epoch {e}/{epochs}: {avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e811581-fdc1-4ef4-ac5a-d9e8de86c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8c16a7-a04b-478a-8a83-6b665ca7536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a GIF using logged images\n",
    "\n",
    "def save_gif(img_list, path=\"\", interval=200):\n",
    "    # Transform images from [-1,1] to [0, 255]\n",
    "    imgs = []\n",
    "    for im in img_list:\n",
    "        im = np.array(im)\n",
    "        im = (im + 1) * 127.5\n",
    "        im = np.clip(im, 0, 255).astype(np.int32)\n",
    "        im = Image.fromarray(im)\n",
    "        imgs.append(im)\n",
    "    \n",
    "    imgs = iter(imgs)\n",
    "\n",
    "    # Extract first image from iterator\n",
    "    img = next(imgs)\n",
    "\n",
    "    # Append the other images and save as GIF\n",
    "    img.save(fp=path, format='GIF', append_images=imgs,\n",
    "             save_all=True, duration=interval, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42818bb-743c-414c-9ac6-fc45ededce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpm(x_t, pred_noise, t):\n",
    "    alpha_t = np.take(alpha, t)\n",
    "    alpha_t_bar = np.take(alpha_bar, t)\n",
    "\n",
    "    eps_coef = (1 - alpha_t) / (1 - alpha_t_bar) ** .5\n",
    "    mean = (1 / (alpha_t ** .5)) * (x_t - eps_coef * pred_noise)\n",
    "\n",
    "    var = np.take(beta, t)\n",
    "    z = np.random.normal(size=x_t.shape)\n",
    "\n",
    "    return mean + (var ** .5) * z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de591b0-88b1-48d7-9b05-907e3682a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(0, 5):\n",
    "    for j in range(0, 5):\n",
    "        x = tf.random.normal((1, 128, 128, 5))\n",
    "\n",
    "        img_list = []\n",
    "        img_list.append(np.squeeze(x, 0)[: , : , j])\n",
    "    \n",
    "        for i in tqdm(range(timesteps - 1)):\n",
    "            t = np.expand_dims(np.array(timesteps - i - 1, np.int32), 0)\n",
    "            pred_noise = unet(x, t)\n",
    "            x = ddpm(x, pred_noise, t)\n",
    "            img_list.append(np.squeeze(x, 0)[: , : , j])\n",
    "\n",
    "        save_gif(img_list + ([img_list[-1]] * 100), f\"diffusion_generations/rand_max_{max_noise}_image_{k}_band_{j}.gif\", interval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2449afa-3188-4103-b01d-e70a59945bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e4fa4-2bb0-4649-b289-13d68bc3bde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_count = 0\n",
    "hf_train = h5py.File('/data/HSC/HSC_v6/step2A/127x127/5x127x127_testing_small.hdf5', 'r')\n",
    "x_train = np.asarray(np.transpose(hf_train['image'][0:],(0,2,3,1)))\n",
    "for i in range(len(x_train)):\n",
    "    x_train[i] = np.true_divide(x_train[i], np.max(np.nan_to_num(x_train[i])))\n",
    "x_train = np.pad(x_train, [(0, 0), (0, 1), (0, 1), (0, 0)], mode = 'constant') # Padding to 128x128\n",
    "hf_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c942fc-4f19-40f0-9a09-2d5a2df3b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = x_train[15]\n",
    "\n",
    "for j in range(0, 5):\n",
    "    x, noise_x = forward_noise(0, np.expand_dims(sample, 0), np.array([199, ]))\n",
    "    print(x.shape)\n",
    "    img_list = []\n",
    "    img_list.append(np.squeeze(x, 0)[: , : , j])\n",
    "\n",
    "    for i in tqdm(range(timesteps - 1)):\n",
    "        t = np.expand_dims(np.array(timesteps - i - 1, np.int32), 0)\n",
    "        pred_noise = unet(x, t)\n",
    "        x = ddpm(x, pred_noise, t)\n",
    "        img_list.append(np.squeeze(x, 0)[: , : , j])\n",
    "\n",
    "    save_gif(img_list + ([img_list[-1]] * 100), f\"diffusion_generations/five_band_{j}.gif\", interval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94651177-6e6f-42e0-b1c7-b1a6a22619df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(0, 10):\n",
    "    sample = x_train[k]\n",
    "\n",
    "    for j in range(0, 5):\n",
    "        x, noise_x = forward_noise(0, np.expand_dims(sample, 0), np.array([199, ]))\n",
    "        print(x.shape)\n",
    "        img_list = []\n",
    "        img_list.append(np.squeeze(x, 0)[: , : , j])\n",
    "\n",
    "        for i in tqdm(range(timesteps - 1)):\n",
    "            t = np.expand_dims(np.array(timesteps - i - 1, np.int32), 0)\n",
    "            pred_noise = unet(x, t)\n",
    "            x = ddpm(x, pred_noise, t)\n",
    "            img_list.append(np.squeeze(x, 0)[: , : , j])\n",
    "\n",
    "        save_gif(img_list + ([img_list[-1]] * 100), f\"diffusion_generations/five_band_#{k}_band_{j}.gif\", interval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201c4e6-b777-4e50-8fda-4fc7ef70e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0, 100):\n",
    "\n",
    "    sample = x_train[j]\n",
    "\n",
    "    x, noise_x = forward_noise(0, np.expand_dims(sample, 0), np.array([199, ]))\n",
    "    print(x.shape)\n",
    "    img_list = []\n",
    "    img_list.append(np.squeeze(x, 0)[: , : , 0])\n",
    "\n",
    "    for i in tqdm(range(timesteps - 1)):\n",
    "        t = np.expand_dims(np.array(timesteps - i - 1, np.int32), 0)\n",
    "        pred_noise = unet(x, t)\n",
    "        x = ddpm(x, pred_noise, t)\n",
    "        img_list.append(np.squeeze(x, 0)[: , : , 0])\n",
    "\n",
    "    save_gif(img_list + ([img_list[-1]] * 100), f\"diffusion_generations/train_noise_{j}.gif\", interval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e5532-e09e-4b9e-a825-0bf094696d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = x_train[0]\n",
    "\n",
    "print(sample.shape)\n",
    "\n",
    "x, noise_x = forward_noise(0, np.expand_dims(sample, 0), np.array([timesteps - 1, ]))\n",
    "print(x.shape)\n",
    "img_list = []\n",
    "img_list.append(np.squeeze(x, 0)[: , : , 0])\n",
    "\n",
    "for i in tqdm(range(timesteps - 1)):\n",
    "    t = np.expand_dims(np.array(timesteps - i - 1, np.int32), 0)\n",
    "    pred_noise = unet(x, t)\n",
    "    x = ddpm(x, pred_noise, t)\n",
    "\n",
    "x = x[:, :-1, :-1, :] \n",
    "x = np.asarray(np.transpose(x,(0,3,1,2)))\n",
    "print(x.shape)\n",
    "plt.imshow(x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4961691-2662-4e36-b6d4-42cc5a1ccaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_g = sorted(os.listdir(\"/data/HSC/HSC_v6/step1/g_band\"))\n",
    "image_list_r = sorted(os.listdir(\"/data/HSC/HSC_v6/step1/r_band\"))\n",
    "image_list_i = sorted(os.listdir(\"/data/HSC/HSC_v6/step1/i_band\"))\n",
    "image_list_z = sorted(os.listdir(\"/data/HSC/HSC_v6/step1/z_band\"))\n",
    "image_list_y = sorted(os.listdir(\"/data/HSC/HSC_v6/step1/y_band\"))\n",
    "\n",
    "photozdata = pd.read_csv('/data/HSC/HSC_v6/HSC_v6.csv')\n",
    "photozdata.describe()\n",
    "\n",
    "b = np.argsort(photozdata['object_id'])\n",
    "sorted_photozdata = photozdata.iloc[b][:]\n",
    "photozdata = sorted_photozdata\n",
    "\n",
    "hf = h5py.File('/data3/Diffusion/127x127_diffusion_regenerated_normalized.hdf5', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c71fd9-fc81-429d-8a86-48778023f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_in = 0\n",
    "count_out = 0\n",
    "size = len(image_list_g)\n",
    "for i in range(2000):\n",
    "    \n",
    "    stdout.write(\"\\rChecking %d samples of \" % (i + 1) + str(size))\n",
    "    \n",
    "    object_id = image_list_g[i][0:17]\n",
    "\n",
    "    five_band_image = []\n",
    "\n",
    "    image_g = fits.open(\"/data/HSC/HSC_v6/step1/g_band/\" + image_list_g[i])\n",
    "    image_r = fits.open(\"/data/HSC/HSC_v6/step1/r_band/\" + image_list_r[i])\n",
    "    image_i = fits.open(\"/data/HSC/HSC_v6/step1/i_band/\" + image_list_i[i])\n",
    "    image_z = fits.open(\"/data/HSC/HSC_v6/step1/z_band/\" + image_list_z[i])\n",
    "    image_y = fits.open(\"/data/HSC/HSC_v6/step1/y_band/\" + image_list_y[i])\n",
    "\n",
    "    image_g_data = image_g[1].data\n",
    "    image_r_data = image_r[1].data\n",
    "    image_i_data = image_i[1].data\n",
    "    image_z_data = image_z[1].data\n",
    "    image_y_data = image_y[1].data\n",
    "\n",
    "    pad1 = int((127 - len(image_g_data)) / 2)\n",
    "    pad2 = 127 - len(image_g_data) - pad1\n",
    "    pad3 = int((127 - len(image_g_data[0])) / 2)\n",
    "    pad4 = 127 - len(image_g_data[0]) - pad3\n",
    "\n",
    "\n",
    "    im_g = np.pad(image_g_data, ((pad1, pad2), (pad3, pad4)), \"constant\", constant_values = ((0, 0), (0, 0)))\n",
    "    im_r = np.pad(image_r_data, ((pad1, pad2), (pad3, pad4)), \"constant\", constant_values = ((0, 0), (0, 0)))\n",
    "    im_i = np.pad(image_i_data, ((pad1, pad2), (pad3, pad4)), \"constant\", constant_values = ((0, 0), (0, 0)))\n",
    "    im_z = np.pad(image_z_data, ((pad1, pad2), (pad3, pad4)), \"constant\", constant_values = ((0, 0), (0, 0)))\n",
    "    im_y = np.pad(image_y_data, ((pad1, pad2), (pad3, pad4)), \"constant\", constant_values = ((0, 0), (0, 0)))\n",
    "\n",
    "    im = np.true_divide(np.array([im_g, im_r, im_i, im_z, im_y]), np.max(np.array([im_g, im_r, im_i, im_z, im_y])))\n",
    "    im = np.asarray(np.transpose(im, (1, 2, 0)))\n",
    "    im = np.pad(im, [(0, 1), (0, 1), (0, 0)], mode = 'constant')\n",
    "    x, noise_x = forward_noise(0, np.expand_dims(im, 0), np.array([timesteps - 1, ]))\n",
    "    for k in tqdm(range(timesteps - 1)):\n",
    "        t = np.expand_dims(np.array(timesteps - k - 1, np.int32), 0)\n",
    "        pred_noise = unet(x, t)\n",
    "        x = ddpm(x, pred_noise, t)\n",
    "    \n",
    "    x = x[:, :-1, :-1, :] \n",
    "    five_band_image_reshape = np.asarray(np.transpose(x, (0, 3, 1, 2)))\n",
    "    \n",
    "    if True:\n",
    "    \n",
    "        photozdata_subset = photozdata.iloc[i]\n",
    "\n",
    "        specz = photozdata_subset['specz_redshift']\n",
    "        specz_reshape = np.reshape(specz, [1, 1])\n",
    "\n",
    "        if count_in == 0:\n",
    "        \n",
    "            for (columnName, columnData) in photozdata.items():\n",
    "                \n",
    "                if columnName == 'specz_name' or columnName == 'coord':\n",
    "                    \n",
    "                    hf.create_dataset(columnName, data = np.reshape(np.array(photozdata[columnName]).astype(str), [286401, 1]).astype('S')[i], maxshape = (None, ))\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    hf.create_dataset(columnName, data = photozdata[columnName][i : i + 1], maxshape = (None, ))\n",
    "            \n",
    "            hf.create_dataset('image', data = five_band_image_reshape, chunks = True, maxshape = (None, 5, 127, 127))\n",
    "\n",
    "        else:\n",
    "        \n",
    "            for (columnName, columnData) in photozdata.items():\n",
    "        \n",
    "                hf[columnName].resize((hf[columnName].shape[0] + 1), axis = 0)\n",
    "            \n",
    "                if columnName == 'specz_name' or columnName == 'coord':\n",
    "                    \n",
    "                    hf[columnName][hf[columnName].shape[0] - 1] = np.reshape(np.array(photozdata[columnName]).astype(str), [286401, 1]).astype('S')[i]\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    hf[columnName][hf[columnName].shape[0] - 1] = photozdata[columnName][i : i + 1]\n",
    "            \n",
    "            hf['image'].resize((hf['image'].shape[0] + 1), axis = 0)\n",
    "            hf['image'][hf['image'].shape[0] - 1, :, :, :] = five_band_image_reshape\n",
    "        \n",
    "        count_in = count_in + 1\n",
    "    \n",
    "    image_g.close()\n",
    "    image_r.close()\n",
    "    image_i.close()\n",
    "    image_z.close()\n",
    "    image_y.close()\n",
    "\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diffusion",
   "language": "python",
   "name": "diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a9195a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 19:10:51.096277: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-27 19:10:51.678276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import keras\n",
    "import os\n",
    "import tensorboard\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, GlobalMaxPooling2D, Dropout, Input, Concatenate\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from photoz_utils import *\n",
    "from DataMakerPlus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0276b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_LIMIT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399daa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 19:10:53.504584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-27 19:10:53.532081: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-27 19:10:53.532330: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-27 19:10:53.535563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-27 19:10:53.535759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-27 19:10:53.535935: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-27 19:10:53.614031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-27 19:10:53.614255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-27 19:10:53.614445: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-27 19:10:53.614592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10000 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(GB_LIMIT*1000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c193e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (5, 127, 127)\n",
    "NUM_DENSE_UNITS = 200\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 0.0001\n",
    "Z_MAX = 4\n",
    "hparams = {\n",
    "    'num_dense_units': NUM_DENSE_UNITS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'z_max': Z_MAX\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab5fe813",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = f'/data/HSC_generated/HSC_generated_v1/step1/127x127/5x127x127_training.hdf5'\n",
    "VAL_PATH = f'/data/HSC_generated/HSC_generated_v1/step1/127x127/5x127x127_validation.hdf5'\n",
    "TEST_PATH = f'/data/HSC_generated/HSC_generated_v1/step1/127x127/5x127x127_testing.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0707677-e504-49b6-85fa-d117b00d0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_names = []\n",
    "# for i in ['g', 'r', 'i', 'z', 'y']:\n",
    "#     for j in ['cmodel_mag', 'isophotal_area', 'half_light_radius', 'major_axis', 'minor_axis', 'ellipticity', 'sersic_index', 'peak_surface_brightness']:\n",
    "#         param_names.append(i + '_' + j)\n",
    "# v17\n",
    "\n",
    "param_names = []\n",
    "for i in ['g', 'r', 'i', 'z', 'y']:\n",
    "    for j in ['cmodel_mag']:\n",
    "        param_names.append(i + '_' + j)\n",
    "        # v19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37f177ac-bba7-49f8-8b92-089e8d6159f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g_cmodel_mag',\n",
       " 'r_cmodel_mag',\n",
       " 'i_cmodel_mag',\n",
       " 'z_cmodel_mag',\n",
       " 'y_cmodel_mag']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c819380-4242-4601-8e21-d8c0ca082768",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_args = {\n",
    "    'image_key': 'image',\n",
    "    'numerical_keys': param_names,\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': True,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': hparams['batch_size'],\n",
    "    'shuffle': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dab2417c-c644-4a5a-86a4-bef945c9b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = HDF5DataGenerator(TRAIN_PATH, mode='train', **gen_args)\n",
    "val_gen = HDF5DataGenerator(VAL_PATH, mode='train', **gen_args)\n",
    "test_gen = HDF5DataGenerator(TEST_PATH, mode='test', **gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6053b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def calculate_loss(z_photo, z_spec):\n",
    "    \"\"\"\n",
    "    HSC METRIC. Returns an array. Loss is accuracy metric defined by HSC, meant\n",
    "    to capture the effects of bias, scatter, and outlier all in one. This has\n",
    "    uses for both point and density estimation.\n",
    "    z_photo: array\n",
    "        Photometric or predicted redshifts.\n",
    "    z_spec: array\n",
    "        Spectroscopic or actual redshifts.\n",
    "    \"\"\"\n",
    "    dz = delz(z_photo, z_spec)\n",
    "    gamma = 0.15\n",
    "    denominator = 1.0 + K.square(dz/gamma)\n",
    "    loss = 1 - 1.0 / denominator\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1b768da",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cnn = Input(shape=(5,127,127))\n",
    "input_nn = Input(shape=(len(param_names),)) # don't forget to change this\n",
    "\n",
    "# CNN\n",
    "conv1 = Conv2D(32, kernel_size=(3, 3), activation='tanh', padding='same', data_format='channels_first')(input_cnn)\n",
    "pool1 = MaxPooling2D(pool_size = (2,2), data_format='channels_first')(conv1)\n",
    "conv2 = Conv2D(64, kernel_size=(3, 3), activation='tanh', padding='same', data_format='channels_first')(pool1)\n",
    "pool2 = MaxPooling2D(pool_size = (2,2), data_format='channels_first')(conv2)\n",
    "conv3 = Conv2D(128, kernel_size=(3, 3), activation='tanh', padding='same', data_format='channels_first')(pool2)\n",
    "pool3 = MaxPooling2D(pool_size = (2,2), data_format='channels_first')(conv3)\n",
    "conv4 = Conv2D(256, kernel_size=(3, 3), activation='tanh', padding='same', data_format='channels_first')(pool3)\n",
    "pool4 = MaxPooling2D(pool_size = (2,2), data_format='channels_first')(conv4)\n",
    "conv5 = Conv2D(256, kernel_size=(3, 3), activation='tanh', padding='same', data_format='channels_first')(pool4)\n",
    "pool5 = MaxPooling2D(pool_size = (2,2), data_format='channels_first')(conv5)\n",
    "conv6 = Conv2D(512, kernel_size=(3, 3),activation='relu', padding='same', data_format='channels_first')(pool5)\n",
    "conv7 = Conv2D(512, kernel_size=(3, 3),activation='relu', padding='same', data_format='channels_first')(conv6)\n",
    "flatten = GlobalMaxPooling2D(data_format='channels_first')(conv7)\n",
    "dense1 = Dense(512, activation='tanh')(flatten)\n",
    "dense2 = Dense(128, activation='tanh')(dense1)\n",
    "dense3 = Dense(32, activation='tanh')(dense2)\n",
    "\n",
    "# NN\n",
    "hidden1 = Dense(hparams['num_dense_units'], activation=\"relu\")(input_nn)\n",
    "hidden2 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden1)\n",
    "hidden3 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden2)\n",
    "hidden4 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden3)\n",
    "hidden5 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden4)\n",
    "hidden6 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden5)\n",
    "\n",
    "# Concat & Output\n",
    "concat = Concatenate()([dense3, hidden6])\n",
    "output = Dense(1)(concat)\n",
    "model = Model(inputs=[input_cnn, input_nn], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51b40cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 127, 127  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 127, 127  1472        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 32, 63, 63)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 63, 63)   18496       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 31, 31)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 31, 31)  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 128, 15, 15)  0          ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 256, 15, 15)  295168      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 256, 7, 7)   0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 256, 7, 7)    590080      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 256, 3, 3)   0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 512, 3, 3)    1180160     ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 200)          1200        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 512, 3, 3)    2359808     ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 200)          40200       ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " global_max_pooling2d (GlobalMa  (None, 512)         0           ['conv2d_6[0][0]']               \n",
      " xPooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 200)          40200       ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          262656      ['global_max_pooling2d[0][0]']   \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 200)          40200       ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          65664       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 200)          40200       ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           4128        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 200)          40200       ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 232)          0           ['dense_2[0][0]',                \n",
      "                                                                  'dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            233         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,053,921\n",
      "Trainable params: 5,053,921\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f180343",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=hparams['learning_rate']), loss=calculate_loss, metrics='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83073425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 19:11:39.092566: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at summary_kernels.cc:58 : PERMISSION_DENIED: /data2/logs/HSC_v6_NN_neurips_combined_with_5pool_v25/events.out.tfevents.1701141099.aurora.4128706.0.v2; Permission denied\n",
      "\tCreating writable file /data2/logs/HSC_v6_NN_neurips_combined_with_5pool_v25/events.out.tfevents.1701141099.aurora.4128706.0.v2\n",
      "\tCould not initialize events writer.\n"
     ]
    },
    {
     "ename": "PermissionDeniedError",
     "evalue": "{{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} /data2/logs/HSC_v6_NN_neurips_combined_with_5pool_v25/events.out.tfevents.1701141099.aurora.4128706.0.v2; Permission denied\n\tCreating writable file /data2/logs/HSC_v6_NN_neurips_combined_with_5pool_v25/events.out.tfevents.1701141099.aurora.4128706.0.v2\n\tCould not initialize events writer. [Op:CreateSummaryFileWriter]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m      7\u001b[0m model_checkpoint_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m      8\u001b[0m     filepath\u001b[38;5;241m=\u001b[39mcheckpoint_filepath,\n\u001b[1;32m      9\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m tensorboard_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(log_dir\u001b[38;5;241m=\u001b[39mlog_dir, histogram_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m hparam_callback \u001b[38;5;241m=\u001b[39m \u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKerasCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorboard/plugins/hparams/_keras.py:68\u001b[0m, in \u001b[0;36mCallback.__init__\u001b[0;34m(self, writer, hparams, trial_id)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwriter must be a `SummaryWriter` or `str`, not None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m     )\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(writer, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_file_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer \u001b[38;5;241m=\u001b[39m writer\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/summary_ops_v2.py:559\u001b[0m, in \u001b[0;36mcreate_file_writer_v2\u001b[0;34m(logdir, max_queue, flush_millis, filename_suffix, name, experimental_trackable)\u001b[0m\n\u001b[1;32m    556\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _TrackableResourceSummaryWriter(\n\u001b[1;32m    557\u001b[0m       create_fn\u001b[38;5;241m=\u001b[39mcreate_fn, init_op_fn\u001b[38;5;241m=\u001b[39minit_op_fn)\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 559\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ResourceSummaryWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcreate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_op_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_op_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/summary_ops_v2.py:311\u001b[0m, in \u001b[0;36m_ResourceSummaryWriter.__init__\u001b[0;34m(self, create_fn, init_op_fn)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, create_fn, init_op_fn):\n\u001b[1;32m    310\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource \u001b[38;5;241m=\u001b[39m create_fn()\n\u001b[0;32m--> 311\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_op \u001b[38;5;241m=\u001b[39m \u001b[43minit_op_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    313\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_summary_ops.py:145\u001b[0m, in \u001b[0;36mcreate_summary_file_writer\u001b[0;34m(writer, logdir, max_queue, flush_millis, filename_suffix, name)\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 145\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m    147\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: {{function_node __wrapped__CreateSummaryFileWriter_device_/job:localhost/replica:0/task:0/device:CPU:0}} /data2/logs/HSC_v6_NN_neurips_combined_with_5pool_v25/events.out.tfevents.1701141099.aurora.4128706.0.v2; Permission denied\n\tCreating writable file /data2/logs/HSC_v6_NN_neurips_combined_with_5pool_v25/events.out.tfevents.1701141099.aurora.4128706.0.v2\n\tCould not initialize events writer. [Op:CreateSummaryFileWriter]"
     ]
    }
   ],
   "source": [
    "model_name = 'HSC_v6_NN_neurips_combined_with_5pool_v25'\n",
    "\n",
    "# checkpoint_filepath = f'/data2/models/{model_name}/checkpoints/cp.ckpt'\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
    "# log_dir = os.path.join('/data2/logs/', model_name)\n",
    "\n",
    "# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    # filepath=checkpoint_filepath,\n",
    "    # save_weights_only=True,\n",
    "    # monitor='loss',\n",
    "    # mode='min',\n",
    "    # save_freq='epoch',\n",
    "    # save_best_only=True,\n",
    "    # verbose=True)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "hparam_callback = hp.KerasCallback(log_dir, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d84ce7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_gen, batch_size=hparams['batch_size'], epochs=hparams['num_epochs'], shuffle=True, verbose=1, validation_data=val_gen, callbacks=[tensorboard_callback, model_checkpoint_callback, hparam_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fcc3e5-7c65-43d0-95c5-4bd291986438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might take too much memory, use PCA on morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3519a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91426254",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2de867",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(TEST_PATH, 'r') as file:\n",
    "    y_test = np.asarray(file['specz_redshift'][:])\n",
    "    oid_test = np.asarray(file['object_id'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66950f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(np.ravel(pred), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70f4f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = get_point_metrics(pd.Series(np.ravel(pred)), pd.Series(y_test), binned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7cf11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b14400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pred, columns=['photoz'])\n",
    "df['specz'] = pd.Series(y_test)\n",
    "df['object_id'] = pd.Series(oid_test)\n",
    "os.makedirs(f'/data2/predictions/{model_name}', exist_ok=True)\n",
    "df.to_csv(f'/data2/predictions/{model_name}/testing_predictions.csv', index=False)\n",
    "metrics.to_csv(f'/data2/predictions/{model_name}/testing_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0975da5d-1711-4205-a0fe-3cbbaea7aed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

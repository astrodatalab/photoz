{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a9195a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import keras\n",
    "import os\n",
    "import tensorboard\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, GlobalMaxPooling2D, Dropout, Input, Concatenate\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from photoz_utils import *\n",
    "from DataMaker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0276b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_LIMIT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399daa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 10:23:41.029252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 10:23:41.134614: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 10:23:41.134868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 10:23:41.185032: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 10:23:41.185337: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 10:23:41.185559: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 10:23:41.308095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 10:23:41.308345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 10:23:41.308526: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 10:23:41.308945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10000 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(GB_LIMIT*1000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c193e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (5, 64, 64)\n",
    "NUM_DENSE_UNITS = 200\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 0.0001\n",
    "Z_MAX = 4\n",
    "hparams = {\n",
    "    'num_dense_units': NUM_DENSE_UNITS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'z_max': Z_MAX\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab5fe813",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = f'/data/HSC/HSC_v6/step2A/64x64/5x64x64_training.hdf5'\n",
    "VAL_PATH = f'/data/HSC/HSC_v6/step2A/64x64/5x64x64_validation.hdf5'\n",
    "TEST_PATH = f'/data/HSC_generated/HSC_generated_v1/ddpm/64x64/5x64x64_testing.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0707677-e504-49b6-85fa-d117b00d0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_names = []\n",
    "# for i in ['g', 'r', 'i', 'z', 'y']:\n",
    "#     for j in ['cmodel_mag', 'isophotal_area', 'half_light_radius', 'major_axis', 'minor_axis', 'ellipticity', 'sersic_index', 'peak_surface_brightness']:\n",
    "#         param_names.append(i + '_' + j)\n",
    "# v17\n",
    "\n",
    "param_names = []\n",
    "for i in ['g', 'r', 'i', 'z', 'y']:\n",
    "    for j in ['cmodel_mag']:\n",
    "        param_names.append(i + '_' + j)\n",
    "        # v19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c819380-4242-4601-8e21-d8c0ca082768",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_args = {\n",
    "    'X_key': 'image',\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': hparams['batch_size'],\n",
    "    'shuffle': False}\n",
    "\n",
    "train_gen = HDF5ImageGenerator(TRAIN_PATH, mode = 'train', **gen_args)\n",
    "val_gen = HDF5ImageGenerator(VAL_PATH, mode = 'train', **gen_args)\n",
    "test_gen = HDF5ImageGenerator(TEST_PATH, mode = 'train', **gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6053b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def calculate_loss(z_photo, z_spec):\n",
    "    \"\"\"\n",
    "    HSC METRIC. Returns an array. Loss is accuracy metric defined by HSC, meant\n",
    "    to capture the effects of bias, scatter, and outlier all in one. This has\n",
    "    uses for both point and density estimation.\n",
    "    z_photo: array\n",
    "        Photometric or predicted redshifts.\n",
    "    z_spec: array\n",
    "        Spectroscopic or actual redshifts.\n",
    "    \"\"\"\n",
    "    dz = delz(z_photo, z_spec)\n",
    "    gamma = 0.15\n",
    "    denominator = 1.0 + K.square(dz/gamma)\n",
    "    loss = 1 - 1.0 / denominator\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1b768da",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cnn = Input(shape=(5,64,64))\n",
    "# input_nn = Input(shape=(len(param_names),)) # don't forget to change this\n",
    "\n",
    "# CNN\n",
    "conv1 = Conv2D(32, kernel_size = (3, 3), activation = 'tanh', padding = 'same', data_format = 'channels_first')(input_cnn)\n",
    "pool1 = MaxPooling2D(pool_size = (2,2), data_format = 'channels_first')(conv1)\n",
    "conv2 = Conv2D(64, kernel_size = (3, 3), activation = 'tanh', padding = 'same', data_format = 'channels_first')(pool1)\n",
    "pool2 = MaxPooling2D(pool_size = (2,2), data_format = 'channels_first')(conv2)\n",
    "conv3 = Conv2D(128, kernel_size = (3, 3), activation = 'tanh', padding = 'same', data_format = 'channels_first')(pool2)\n",
    "pool3 = MaxPooling2D(pool_size = (2,2), data_format = 'channels_first')(conv3)\n",
    "conv4 = Conv2D(256, kernel_size = (3, 3), activation = 'tanh', padding = 'same', data_format = 'channels_first')(pool3)\n",
    "pool4 = MaxPooling2D(pool_size = (2,2), data_format = 'channels_first')(conv4)\n",
    "conv5 = Conv2D(256, kernel_size = (3, 3), activation = 'tanh', padding = 'same', data_format = 'channels_first')(pool4)\n",
    "pool5 = MaxPooling2D(pool_size = (2,2), data_format = 'channels_first')(conv5)\n",
    "conv6 = Conv2D(512, kernel_size = (3, 3),activation = 'relu', padding = 'same', data_format = 'channels_first')(pool5)\n",
    "conv7 = Conv2D(512, kernel_size = (3, 3),activation = 'relu', padding = 'same', data_format = 'channels_first')(conv6)\n",
    "flatten = GlobalMaxPooling2D(data_format = 'channels_first')(conv7)\n",
    "dense1 = Dense(512, activation = 'tanh')(flatten)\n",
    "dense2 = Dense(128, activation = 'tanh')(dense1)\n",
    "dense3 = Dense(32, activation = 'tanh')(dense2)\n",
    "\n",
    "# NN\n",
    "# hidden1 = Dense(hparams['num_dense_units'], activation=\"relu\")(input_nn)\n",
    "# hidden2 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden1)\n",
    "# hidden3 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden2)\n",
    "# hidden4 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden3)\n",
    "# hidden5 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden4)\n",
    "# hidden6 = Dense(hparams['num_dense_units'], activation=\"relu\")(hidden5)\n",
    "\n",
    "# Concat & Output\n",
    "# concat = Concatenate()([dense3, hidden6])\n",
    "output = Dense(1)(dense3)\n",
    "model = Model(inputs=[input_cnn], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51b40cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 5, 64, 64)]       0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 32, 64, 64)        1472      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 64, 32, 32)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 64, 16, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 128, 16, 16)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 128, 8, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 256, 8, 8)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 256, 4, 4)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 256, 4, 4)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 256, 2, 2)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 512, 2, 2)         1180160   \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 512, 2, 2)         2359808   \n",
      "                                                                 \n",
      " global_max_pooling2d_2 (Glo  (None, 512)              0         \n",
      " balMaxPooling2D)                                                \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,851,521\n",
      "Trainable params: 4,851,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f180343",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=hparams['learning_rate']), loss=calculate_loss, metrics='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d84ce7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 11:10:48.118940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-01-15 11:10:50.342743: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2024-01-15 11:10:50.580340: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-15 11:10:51.023275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-01-15 11:10:51.079821: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f09d8200690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-15 11:10:51.079850: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2024-01-15 11:10:51.111031: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-15 11:10:51.358472: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-15 11:10:51.430497: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - ETA: 0s - loss: 0.2105 - mse: 0.1370"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 11:14:04.325068: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 222s 270ms/step - loss: 0.2105 - mse: 0.1370 - val_loss: 0.1433 - val_mse: 0.0907\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 235s 294ms/step - loss: 0.1330 - mse: 0.0871 - val_loss: 0.1428 - val_mse: 0.0898\n",
      "Epoch 3/100\n",
      "781/800 [============================>.] - ETA: 4s - loss: 0.1211 - mse: 0.0827"
     ]
    }
   ],
   "source": [
    "model.fit(train_gen, batch_size=hparams['batch_size'], epochs=hparams['num_epochs'], shuffle=True, verbose=1, validation_data=val_gen, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fcc3e5-7c65-43d0-95c5-4bd291986438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might take too much memory, use PCA on morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3519a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91426254",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2de867",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(TEST_PATH, 'r') as file:\n",
    "    y_test = np.asarray(file['specz_redshift'][:])\n",
    "    oid_test = np.asarray(file['object_id'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66950f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(np.ravel(pred), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70f4f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = get_point_metrics(pd.Series(np.ravel(pred)), pd.Series(y_test), binned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7cf11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b14400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pred, columns=['photoz'])\n",
    "df['specz'] = pd.Series(y_test)\n",
    "df['object_id'] = pd.Series(oid_test)\n",
    "os.makedirs(f'/data2/predictions/{model_name}', exist_ok=True)\n",
    "df.to_csv(f'/data2/predictions/{model_name}/testing_predictions.csv', index=False)\n",
    "metrics.to_csv(f'/data2/predictions/{model_name}/testing_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0975da5d-1711-4205-a0fe-3cbbaea7aed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

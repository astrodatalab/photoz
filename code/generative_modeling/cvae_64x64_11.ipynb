{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d56f26f-0259-4940-9ab2-7d3689d30b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 10:18:53.837212: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-06 10:18:54.370216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import random\n",
    "import neptune\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from tensorflow_probability import layers as tfpl\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Add, Activation, Layer, Concatenate, Input, MaxPooling2D, Conv2D, Conv2DTranspose, Flatten, Dropout, Dense, BatchNormalization, Activation, Reshape, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_probability.python.distributions import kl_divergence\n",
    "from neptune.integrations.tensorflow_keras import NeptuneCallback\n",
    "from DataMakerCVAE import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "998ecdb5-f513-44b2-ba6d-235a2450e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 128\n",
    "IMAGE_SHAPE = (5, 64, 64)\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 250\n",
    "CHECKPOINTS_TO_SAVE = 4\n",
    "KL_WEIGHT = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a44e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 10:18:55.187818: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 10:18:55.207654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 10:18:55.207843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 10:18:55.209714: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 10:18:55.209864: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 10:18:55.209995: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 10:18:55.841620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 10:18:55.841817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 10:18:55.841956: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 10:18:55.842063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20000 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU');\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 20000)]);\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU');\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb7cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_gen = {'X_key' : 'image',\n",
    "    'y_key' : 'specz_redshift',\n",
    "    'scaler' : False,\n",
    "    'labels_encoding' : False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode' : 'train',\n",
    "    'shuffle' : False}\n",
    "\n",
    "train_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/64x64/5x64x64_training_z_less_than_2.hdf5', **args_gen)\n",
    "test_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/64x64/5x64x64_testing_z_less_than_2.hdf5', **args_gen)\n",
    "val_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/64x64/5x64x64_validation_z_less_than_2.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70549883-ce44-4977-a92f-e315f1d37ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseAttention(Layer):\n",
    "    def __init__(self, units, heads = 4):\n",
    "        super(DenseAttention, self).__init__()\n",
    "        self.units = units\n",
    "        self.heads = heads\n",
    "        self.scale = (units // heads) ** -0.5\n",
    "\n",
    "        self.W_q = Dense(units)\n",
    "        self.W_k = Dense(units)\n",
    "        self.W_v = Dense(units)\n",
    "        self.W_o = Dense(units)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        dim = self.units // self.heads\n",
    "\n",
    "        Q = self.W_q(inputs)\n",
    "        K = self.W_k(inputs)\n",
    "        V = self.W_v(inputs)\n",
    "\n",
    "        # Split for multi-head attention\n",
    "        Q = tf.reshape(Q, (batch_size, self.heads, dim))\n",
    "        K = tf.reshape(K, (batch_size, self.heads, dim))\n",
    "        V = tf.reshape(V, (batch_size, self.heads, dim))\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        attention_score = tf.matmul(Q, K, transpose_b = True) * self.scale\n",
    "        attention_weight = tf.nn.softmax(attention_score, axis = -1)\n",
    "        attention_output = tf.matmul(attention_weight, V)\n",
    "\n",
    "        # Concatenate heads back and keep track of dimensions\n",
    "        attention_output = tf.reshape(attention_output, (batch_size, self.heads * dim))\n",
    "\n",
    "        # Final dense layer\n",
    "        output = self.W_o(attention_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d31d75f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "# Prior\n",
    "prior = tfd.Independent(tfd.Normal(loc = tf.zeros(LATENT_DIM), scale = 1.0), reinterpreted_batch_ndims = 1)\n",
    "\n",
    "# Encoder\n",
    "images = Input(shape = IMAGE_SHAPE)\n",
    "redshifts = Input(shape = (1,))\n",
    "conv1 = Conv2D(32, 3, strides = 2, activation = \"relu\", padding = 'same', data_format = 'channels_first')(images)\n",
    "\n",
    "conv2 = Conv2D(64, 3, strides = 2, activation = \"relu\", padding = 'same', data_format = 'channels_first')(conv1)\n",
    "conv2_res = Conv2D(64, 3, strides = 1, activation = \"relu\", padding = 'same', data_format = 'channels_first')(conv2)\n",
    "conv2_res = Conv2D(64, 3, strides = 1, activation = None, padding = 'same', data_format = 'channels_first')(conv2_res)\n",
    "conv2 = Add()([conv2, conv2_res])\n",
    "conv2 = Activation('relu')(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, 2, strides = 1, activation = \"relu\", padding = 'same', data_format = 'channels_first')(conv2)\n",
    "conv3_res = Conv2D(128, 2, strides = 1, activation = \"relu\", padding = 'same', data_format = 'channels_first')(conv3)\n",
    "conv3_res = Conv2D(128, 2, strides = 1, activation = None, padding = 'same', data_format = 'channels_first')(conv3_res)\n",
    "conv3 = Add()([conv3, conv3_res])\n",
    "conv3 = Activation('relu')(conv3)\n",
    "\n",
    "flatten1 = Flatten()(conv1)\n",
    "flatten2 = Flatten()(conv2)\n",
    "flatten3 = Flatten()(conv3)\n",
    "x = tf.keras.layers.Concatenate()([flatten1, flatten2, flatten3, redshifts])\n",
    "x = Dense(512, activation = \"relu\")(x)\n",
    "x = DenseAttention(512)(x)\n",
    "x = Dense(512, activation = \"relu\")(x)\n",
    "x = Dense(tfpl.MultivariateNormalTriL.params_size(LATENT_DIM), activation = None)(x)\n",
    "z = tfpl.MultivariateNormalTriL(LATENT_DIM, activity_regularizer = tfpl.KLDivergenceRegularizer(prior, weight=KL_WEIGHT))(x)\n",
    "\n",
    "encoder = Model([images, redshifts], z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b25f1d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zc = Input(shape = (LATENT_DIM + 1,))\n",
    "x = Dense(512, activation = \"relu\")(zc)\n",
    "x = DenseAttention(512)(x)\n",
    "x = Dense(512, activation = \"relu\")(x)\n",
    "x = Dense(128 * 16 * 16 + 64 * 16 * 16 + 32 * 32 * 32, activation = \"relu\")(x)\n",
    "dense1, dense2, dense3 = tf.split(x, [128 * 16 * 16, 64 * 16 * 16, 32 * 32 * 32], axis = 1)\n",
    "reshape1 = Reshape((128, 16, 16))(dense1)\n",
    "reshape2 = Reshape((64, 16, 16))(dense2)\n",
    "reshape3 = Reshape((32, 32, 32))(dense3)\n",
    "\n",
    "deconv1 = Conv2DTranspose(64, 2, strides = 1, activation = \"relu\", padding = 'same', data_format = 'channels_first')(reshape1)\n",
    "deconv1_res = Conv2DTranspose(64, 2, strides = 1, activation = \"relu\", padding = 'same', data_format = 'channels_first')(deconv1)\n",
    "deconv1_res = Conv2DTranspose(64, 2, strides = 1, activation = None, padding = 'same', data_format = 'channels_first')(deconv1_res)\n",
    "deconv1 = Add()([deconv1, deconv1_res])\n",
    "deconv1 = Activation('relu')(deconv1)\n",
    "\n",
    "deconv2 = Conv2DTranspose(32, 3, strides = 2, activation = \"relu\", padding = 'same', data_format = 'channels_first')(reshape2 + deconv1)\n",
    "deconv2_res = Conv2DTranspose(32, 3, strides = 1, activation = \"relu\", padding = 'same', data_format = 'channels_first')(deconv2)\n",
    "deconv2_res = Conv2DTranspose(32, 3, strides = 1, activation = None, padding = 'same', data_format = 'channels_first')(deconv2_res)\n",
    "deconv2 = Add()([deconv2, deconv2_res])\n",
    "deconv2 = Activation('relu')(deconv2)\n",
    "\n",
    "deconv3 = Conv2DTranspose(5, 3, strides = 2, activation = \"relu\", padding = 'same', data_format = 'channels_first')(reshape3 + deconv2)\n",
    "outputs = Reshape(IMAGE_SHAPE)(deconv3)\n",
    "\n",
    "decoder = Model(zc, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e036f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = encoder([images, redshifts])\n",
    "zc = tf.keras.layers.Concatenate()([z, redshifts])  # Assuming you want to concat the output of encoder and redshifts\n",
    "decoder_output = decoder(zc)\n",
    "\n",
    "model = Model(inputs = [images, redshifts], outputs = decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c25fe180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 64, 64)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 32)   1472        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 16, 16)   18496       ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 16, 16)   36928       ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 16, 16)   36928       ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 64, 16, 16)   0           ['conv2d_1[0][0]',               \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 64, 16, 16)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 128, 16, 16)  32896       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 128, 16, 16)  65664       ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 128, 16, 16)  65664       ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 128, 16, 16)  0           ['conv2d_4[0][0]',               \n",
      "                                                                  'conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 128, 16, 16)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 32768)        0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 16384)        0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 32768)        0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 81921)        0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          41944064    ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_attention (DenseAttentio  (None, 512)         1050624     ['dense[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 512)          262656      ['dense_attention[0][0]']        \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 8384)         4300992     ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " multivariate_normal_tri_l (Mul  ((None, 128),       0           ['dense_6[0][0]']                \n",
      " tivariateNormalTriL)            (None, 128))                                                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 47,816,384\n",
      "Trainable params: 47,816,384\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 129)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 512)          66560       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_attention_1 (DenseAttent  (None, 512)         1050624     ['dense_7[0][0]']                \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 512)          262656      ['dense_attention_1[0][0]']      \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 81920)        42024960    ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " tf.split (TFOpLambda)          [(None, 32768),      0           ['dense_13[0][0]']               \n",
      "                                 (None, 16384),                                                   \n",
      "                                 (None, 32768)]                                                   \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 128, 16, 16)  0           ['tf.split[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 64, 16, 16)  32832       ['reshape[0][0]']                \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 64, 16, 16)  16448       ['conv2d_transpose[0][0]']       \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 64, 16, 16)  16448       ['conv2d_transpose_1[0][0]']     \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 64, 16, 16)   0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'conv2d_transpose_2[0][0]']     \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 64, 16, 16)   0           ['tf.split[0][1]']               \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 64, 16, 16)   0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 64, 16, 16)  0           ['reshape_1[0][0]',              \n",
      " da)                                                              'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 32, 32, 32)  18464       ['tf.__operators__.add[0][0]']   \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 32, 32, 32)  9248        ['conv2d_transpose_3[0][0]']     \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 32, 32, 32)  9248        ['conv2d_transpose_4[0][0]']     \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 32, 32, 32)   0           ['conv2d_transpose_3[0][0]',     \n",
      "                                                                  'conv2d_transpose_5[0][0]']     \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 32, 32, 32)   0           ['tf.split[0][2]']               \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 32, 32, 32)   0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 32, 32, 32)  0           ['reshape_2[0][0]',              \n",
      " mbda)                                                            'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 5, 64, 64)   1445        ['tf.__operators__.add_1[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 5, 64, 64)    0           ['conv2d_transpose_6[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 43,508,933\n",
      "Trainable params: 43,508,933\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 64, 64)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 128)          47816384    ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 129)          0           ['model[0][0]',                  \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 5, 64, 64)    43508933    ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 91,325,317\n",
      "Trainable params: 91,325,317\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()\n",
    "decoder.summary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d463c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer = optimizer, loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcbb9c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_917521/203229614.py:1: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
      "  run = neptune.init_run(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/astro-data-lab/VAE/e/VAE-229\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    name = \"CVAE\",\n",
    "    project = \"astro-data-lab/VAE\",\n",
    "    api_token = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGFlZGMxOC04MWU5LTQ2NDctYjlhZS05NGE2NGQ0NmIzMmEifQ==\",\n",
    ")  # your credentials\n",
    "\n",
    "model_name = 'cvae_residual_relu'\n",
    "\n",
    "weights_path = os.path.join('/data3/Billy/models/', model_name) + '/weights'\n",
    "\n",
    "neptune_callback = NeptuneCallback(run = run)\n",
    "\n",
    "LR_callback = ReduceLROnPlateau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a667a1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 10:19:00.347795: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-10-06 10:19:05.437634: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-10-06 10:19:06.372129: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-10-06 10:19:06.862769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-06 10:19:08.286466: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fc9f249c220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-06 10:19:08.286493: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-10-06 10:19:08.302368: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-06 10:19:08.421634: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-10-06 10:19:08.479663: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - ETA: 0s - loss: 4.0344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 10:22:28.621182: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 248s 617ms/step - loss: 4.0344 - val_loss: 2.2764 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 45s 118ms/step - loss: 2.4505 - val_loss: 2.2793 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 42s 111ms/step - loss: 2.5032 - val_loss: 2.1808 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 41s 107ms/step - loss: 2.3726 - val_loss: 2.0996 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 37s 96ms/step - loss: 2.2986 - val_loss: 2.1033 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 55s 144ms/step - loss: 2.2175 - val_loss: 1.9685 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 38s 100ms/step - loss: 2.1232 - val_loss: 1.8013 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 47s 123ms/step - loss: 1.9547 - val_loss: 1.6915 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 42s 111ms/step - loss: 1.8468 - val_loss: 1.6554 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 47s 123ms/step - loss: 1.8269 - val_loss: 1.6386 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      " 52/380 [===>..........................] - ETA: 30s - loss: 1.6898"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen, epochs = 100, callbacks = [neptune_callback, LR_callback], validation_data = val_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6736025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = 3\n",
    "index = 466\n",
    "z = test_gen[lib][0][1][index]\n",
    "z_shifted = 2\n",
    "band = 0\n",
    "print(f'z = {z}')\n",
    "str = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str = np.concatenate((str, np.array([z])))\n",
    "str = str.reshape(1, LATENT_DIM + 1)\n",
    "str_shifted = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str_shifted = np.concatenate((str_shifted, np.array([z_shifted])))\n",
    "str_shifted = str_shifted.reshape(1, LATENT_DIM + 1)\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (10, 5))\n",
    "axes[0].imshow(test_gen[lib][0][0][index][band], cmap = 'afmhot')\n",
    "axes[1].imshow(decoder([str])[0][band], cmap = 'afmhot')\n",
    "axes[2].imshow(decoder([str_shifted])[0][band], cmap = 'afmhot')\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "axes[2].axis('off')\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[1].set_title(\"Regenerated\")\n",
    "axes[2].set_title(\"Regenerated Far\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2840186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = 5\n",
    "index = 273\n",
    "z = test_gen[lib][0][1][index]\n",
    "z_shifted = 0.1\n",
    "band = 0\n",
    "print(f'z = {z}')\n",
    "str = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str = np.concatenate((str, np.array([z])))\n",
    "str = str.reshape(1, LATENT_DIM + 1)\n",
    "str_shifted = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str_shifted = np.concatenate((str_shifted, np.array([z_shifted])))\n",
    "str_shifted = str_shifted.reshape(1, LATENT_DIM + 1)\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (10, 5))\n",
    "axes[0].imshow(test_gen[lib][0][0][index][band], cmap = 'afmhot')\n",
    "axes[1].imshow(decoder([str])[0][band], cmap = 'afmhot')\n",
    "axes[2].imshow(decoder([str_shifted])[0][band], cmap = 'afmhot')\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "axes[2].axis('off')\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[1].set_title(\"Regenerated\")\n",
    "axes[2].set_title(\"Regenerated Close\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534af846",
   "metadata": {},
   "outputs": [],
   "source": [
    "band = 0\n",
    "str = prior.sample(1)[0]\n",
    "strlo = np.concatenate((str, np.array([0.1])))\n",
    "strlo = strlo.reshape(1, LATENT_DIM + 1)\n",
    "strhi = np.concatenate((str, np.array([2])))\n",
    "strhi = strhi.reshape(1, LATENT_DIM + 1)\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 5))\n",
    "axes[0].imshow(decoder([strlo])[0][band], cmap = 'afmhot')\n",
    "axes[1].imshow(decoder([strhi])[0][band], cmap = 'afmhot')\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "axes[0].set_title(\"Low z\")\n",
    "axes[1].set_title(\"High z\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e3dd1",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 5))\n",
    "x_array = np.arange(5)\n",
    "lo_array = np.array([])\n",
    "hi_array = np.array([])\n",
    "for j in range(0, 5):\n",
    "    lo_array = np.append(lo_array, decoder([strlo])[0][j][63][63])\n",
    "    hi_array = np.append(hi_array, decoder([strhi])[0][j][63][63])\n",
    "axes[0].scatter(x_array, lo_array, c = 'blue', label = 'Low')\n",
    "axes[1].scatter(x_array, hi_array, c = 'red', label = 'High')\n",
    "axes[0].set_xlabel(\"Bands\")\n",
    "axes[0].set_ylabel(\"Central Pixel Value\")\n",
    "axes[0].legend()\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (5, 5))\n",
    "x_array = np.arange(5)\n",
    "lo_array = np.array([])\n",
    "hi_array = np.array([])\n",
    "for j in range(0, 5):\n",
    "    lo_array = np.append(lo_array, np.amax(np.transpose(np.asarray(decoder([strlo])[0][j][60:67]))[60:67].flatten()))\n",
    "    hi_array = np.append(hi_array, np.amax(np.transpose(np.asarray(decoder([strhi])[0][j][60:67]))[60:67].flatten()))\n",
    "axes.scatter(x_array, lo_array, c = 'blue', label = 'Low')\n",
    "axes.scatter(x_array, hi_array, c = 'red', label = 'High')\n",
    "axes.set_xlabel(\"Bands\")\n",
    "axes.set_ylabel(\"Max Pixel Value Near Center\")\n",
    "axes.legend()\n",
    "axes.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9b6f1-5c04-43c2-be92-e73c12ec603b",
   "metadata": {},
   "source": [
    "for j in range(3, 80):\n",
    "    for i in range(0, 512):\n",
    "        if test_gen[j][0][1][i] <= 0.1:\n",
    "            print(j)\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166f1bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3, 80):\n",
    "    for i in range(0, 512):\n",
    "        if test_gen[j][0][1][i] >= 3.5:\n",
    "            print(j)\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9448c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 84):\n",
    "    l = 512\n",
    "    if i == 83:\n",
    "        l = 464\n",
    "    for j in range(0, l):\n",
    "        index = i * BATCH_SIZE + j + 1\n",
    "        stdout.write(\"\\rChecking %d samples of \" % (index) + \"42960\")\n",
    "        z = test_gen[i][0][1][j]\n",
    "        str = np.asarray(encoder([np.array([test_gen[i][0][0][j]]), np.array([test_gen[i][0][1][j]])])[0])\n",
    "        str = np.concatenate((str, np.array([z])))\n",
    "        str = str.reshape(1, LATENT_DIM + 1)\n",
    "        hdul = fits.PrimaryHDU(data = test_gen[i][0][0][j])\n",
    "        string = f\"/data/CVAE Generated/Full/Original Galaxy #{index}.fits\"\n",
    "        hdul.writeto(string, overwrite = True)\n",
    "        hdul = fits.PrimaryHDU(data = decoder([str])[0])\n",
    "        string = f\"/data/CVAE Generated/Full/Reconstructed Galaxy #{index}.fits\"\n",
    "        hdul.writeto(string, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8092e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_bands_max_near_center(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.amax(np.array([test_gen[0][0][0][i][j]])))\n",
    "            pred_array = np.append(pred_array, np.amax(np.transpose(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j][60:67]))[60:67].flatten()))\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(f\"Maximum normalized pixel value z = {np.array([test_gen[0][0][1][i]])[0]}\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "\n",
    "def scatter_bands_max(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.amax(np.array([test_gen[0][0][0][i][j]])))\n",
    "            pred_array = np.append(pred_array, np.amax(np.array([model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]])))\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(\"Maximum normalized pixel value\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "        \n",
    "def scatter_bands_center(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.array([test_gen[0][0][0][i][j]])[0][63][63])\n",
    "            pred_array = np.append(pred_array, model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j][63][63])\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(f\"Central pixel value z = {np.array([test_gen[0][0][1][i]])}\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "        \n",
    "def scatter_bands_center_shift(lib = 3, i = 37, z = 1):\n",
    "    print(z)\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (5, 5))\n",
    "    x_array = np.arange(5)\n",
    "    true_array = np.array([])\n",
    "    pred_array = np.array([])\n",
    "    for j in range(0, 5):\n",
    "        true_array = np.append(true_array, np.array([test_gen[lib][0][0][i][j]])[0][63][63])\n",
    "        pred_array = np.append(pred_array, model([np.array([test_gen[lib][0][0][i]]), np.array([z])])[0][j][63][63])\n",
    "    axes.scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "    axes.scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "    axes.set_xlabel(\"Bands\")\n",
    "    axes.set_ylabel(\"Central pixel value\")\n",
    "    axes.legend()\n",
    "    \n",
    "def scatter_bands_max_shift(lib = 3, i = 37, z = 1):\n",
    "    print(z)\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (5, 5))\n",
    "    x_array = np.arange(5)\n",
    "    true_array = np.array([])\n",
    "    pred_array = np.array([])\n",
    "    for j in range(0, 5):\n",
    "        true_array = np.append(true_array, np.amax(np.array([test_gen[lib][0][0][i][j]])))\n",
    "        pred_array = np.append(pred_array, np.amax(np.array([model([np.array([test_gen[lib][0][0][i]]), np.array([z])])[0][j]])))\n",
    "    axes.scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "    axes.scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "    axes.set_xlabel(\"Bands\")\n",
    "    axes.set_ylabel(\"Central pixel value\")\n",
    "    axes.legend()\n",
    "\n",
    "def scatter_bands_percentile(percentile = 90, num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show /  5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_90 = np.percentile(np.array([test_gen[0][0][0][i][j]]).flatten(), percentile)\n",
    "            pred_90 = np.percentile(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]).flatten(), percentile)\n",
    "            true_array = np.append(true_array, true_90)\n",
    "            pred_array = np.append(pred_array, pred_90)\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel('Bands')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(f'{percentile}th percentile normalized pixel value')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "\n",
    "def scatter_bands_mean(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_mean = np.mean(np.array([test_gen[0][0][0][i][j]]).flatten())\n",
    "            pred_mean = np.mean(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]).flatten())\n",
    "            true_array = np.append(true_array, true_mean)\n",
    "            pred_array = np.append(pred_array, pred_mean)\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel('Bands')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel('Mean normalized pixel value')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "\n",
    "def display_histograms(num_to_show = 2, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = num_to_show, ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        for j in range(0, 5):\n",
    "            true_arr = sorted(np.array([test_gen[0][0][0][i][j]]).flatten())\n",
    "            pred_arr = sorted(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]).flatten())\n",
    "            true_arr = true_arr[0 : int(len(true_arr) * .99)]\n",
    "            pred_arr = pred_arr[0 : int(len(pred_arr) * .99)]\n",
    "            axes[i][j].hist(true_arr, 100, color = 'blue', label = 'True', alpha = 0.5)\n",
    "            axes[i][j].hist(pred_arr, 100, color = 'red', label = 'Predicted', alpha = 0.5)\n",
    "            axes[i][j].set_xlabel(\"Pixel Values\")\n",
    "            axes[i][j].set_ylabel(\"Count\")\n",
    "            axes[i][j].legend()\n",
    "    fig.suptitle('Histograms of Predicted vs. True Image, Horizontal are Bands')\n",
    "    \n",
    "def display_5_bands(index):\n",
    "    fig, axes = plt.subplots(nrows = 2, ncols = 5, figsize = (20, 10))\n",
    "    loss = round(model.evaluate([np.array([test_gen[0][0][0][index]]), np.array([test_gen[0][0][1][index]])], np.array([test_gen[0][0][0][index]]), verbose = 0), 2)\n",
    "    for i in range(0, 5):\n",
    "        axes[0][i].imshow(np.array([test_gen[0][0][0][index]])[0][i], cmap = 'afmhot')\n",
    "        max_pixel_true = round(np.amax(np.array([test_gen[0][0][0][index]])[0][i]), 2)\n",
    "        # axes[0][i].set_title(f'True band {i} max = {max_pixel_true}')\n",
    "        pred = model([np.array([test_gen[0][0][0][index]]), np.array([test_gen[0][0][1][index]])])[0][i]\n",
    "        axes[1][i].imshow(pred, cmap = 'afmhot')\n",
    "        max_pixel_pred = round(np.amax(pred), 2)\n",
    "        axes[1][i].set_title(f'\\n loss = {loss}') # f'Pred band {i} max = {max_pixel_pred}' + \n",
    "        \n",
    "def display_high_loss(num_to_show, min_loss):\n",
    "    fig, axes = plt.subplots(nrows = num_to_show, ncols = 5, figsize = (20, 5 * num_to_show))\n",
    "    r = 0\n",
    "    for i in range(BATCH_SIZE):\n",
    "        loss = round(model.evaluate([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])], np.array([test_gen[0][0][0][i]]), verbose = 0), 2)\n",
    "        if loss >= min_loss:\n",
    "            print(i)\n",
    "            for j in range(0, 5):\n",
    "                axes[r][j].imshow(np.array([test_gen[0][0][0][i]])[0][j], cmap = 'afmhot')\n",
    "                axes[r][j].set_title(f'Loss = {loss}')\n",
    "            r += 1\n",
    "        if r >= num_to_show:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77067c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max_near_center(num_to_show = 10, index = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c4266",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array = np.array([])\n",
    "y_array = np.array([])\n",
    "l = len(test_gen[0][0][0])\n",
    "print(l)\n",
    "for i in range(0, l):\n",
    "    x_array = np.append(x_array, np.amax(np.array([test_gen[0][0][0][i][4]])))\n",
    "    y_array = np.append(y_array, np.array([test_gen[0][0][1][i]])[0])\n",
    "    print(i)\n",
    "plt.scatter(y_array, x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81015273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "xy = np.asarray(np.vstack([y_array, x_array])).astype('float32')\n",
    "z = gaussian_kde(xy)(xy)\n",
    "plt.scatter(y_array, x_array, s = 5, c = z)\n",
    "plt.xlim(0,4)\n",
    "plt.ylim(0, 80)\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"Maximum Pixel Value near the Center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac674f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_center_shift(lib = 3, i = 267, z = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dcc7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max_shift(lib = 3, i = 37, z = test_gen[3][0][1][37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa5bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max_shift(lib = 3, i = 37, z = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2457f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_center()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_mean(10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c48efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_percentile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3369ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eeb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_5_bands(38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_high_loss(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d688ff7-5416-4f2d-8c46-f9d20a2fb1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e207b9cd-6a04-443f-b56f-8ba3b3bf56ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('/data3/Billy/64x64_cvae_generated_16.hdf5', 'a')\n",
    "str = prior.sample(1)[0]\n",
    "str = np.concatenate((str, np.array([0.1])))\n",
    "str = str.reshape(1, LATENT_DIM + 1)\n",
    "image_g = decoder([str])[0][0]\n",
    "image_r = decoder([str])[0][1]\n",
    "image_i = decoder([str])[0][2]\n",
    "image_z = decoder([str])[0][3]\n",
    "image_y = decoder([str])[0][4]\n",
    "five_band_image = []\n",
    "five_band_image.append(image_g)\n",
    "five_band_image.append(image_r)\n",
    "five_band_image.append(image_i)\n",
    "five_band_image.append(image_z)\n",
    "five_band_image.append(image_y)\n",
    "five_band_image_reshape = np.reshape(np.array(five_band_image), [1, 5, 64, 64])\n",
    "hf.create_dataset('image', data = five_band_image_reshape, chunks = True, maxshape = (None, 5, 64, 64))\n",
    "hf.create_dataset('specz_redshift', data = [0.1], chunks = True, maxshape = (None, ))\n",
    "for i in tqdm(range(1999)):\n",
    "    z = random.uniform(0, 2)\n",
    "    str = prior.sample(1)[0]\n",
    "    str = np.concatenate((str, np.array([z])))\n",
    "    str = str.reshape(1, LATENT_DIM + 1)\n",
    "    image_g = decoder([str])[0][0]\n",
    "    image_r = decoder([str])[0][1]\n",
    "    image_i = decoder([str])[0][2]\n",
    "    image_z = decoder([str])[0][3]\n",
    "    image_y = decoder([str])[0][4]\n",
    "    five_band_image = []\n",
    "    five_band_image.append(image_g)\n",
    "    five_band_image.append(image_r)\n",
    "    five_band_image.append(image_i)\n",
    "    five_band_image.append(image_z)\n",
    "    five_band_image.append(image_y)\n",
    "    five_band_image_reshape = np.reshape(np.array(five_band_image), [1, 5, 64, 64])\n",
    "    hf['specz_redshift'].resize((hf['specz_redshift'].shape[0] + 1), axis = 0)\n",
    "    hf['specz_redshift'][hf['specz_redshift'].shape[0] - 1] = [z]\n",
    "    hf['image'].resize((hf['image'].shape[0] + 1), axis = 0)\n",
    "    hf['image'][hf['image'].shape[0] - 1, :, :, :] = five_band_image\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diffusion",
   "language": "python",
   "name": "diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d23f862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import random\n",
    "import neptune\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow_probability import layers as tfpl\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, RepeatVector, MaxPooling2D, Conv2D, Concatenate, UpSampling2D, Conv2DTranspose, Flatten, Dropout, Dense, BatchNormalization, Activation, Reshape, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_probability.python.distributions import kl_divergence\n",
    "from neptune.integrations.tensorflow_keras import NeptuneCallback\n",
    "from DataMakerPlus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e0800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 16\n",
    "BASE_DEPTH = 8\n",
    "CHANNELS = 5\n",
    "IMAGE_SHAPE = (CHANNELS, 64, 64)\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 250\n",
    "CHECKPOINTS_TO_SAVE = 4\n",
    "KL_WEIGHT = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a44e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU');\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 20000)]);\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU');\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbc0eecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 5, 64, 64)\n",
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = f'/data/tuando/data/HSC/HSC_v6/step3A/64x64/5x64x64_training_z_less_than_2.hdf5'\n",
    "TEST_PATH = f'/data/tuando/data/HSC/HSC_v6/step3A/64x64/5x64x64_testing_z_less_than_2.hdf5'\n",
    "\n",
    "gen_args = {\n",
    "    'image_key': 'image',\n",
    "    'numerical_keys': None,\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'shuffle': False}\n",
    "train_gen = HDF5DataGenerator(TRAIN_PATH, mode = 'train', **gen_args)\n",
    "test_gen = HDF5DataGenerator(TEST_PATH, mode = 'train', **gen_args)\n",
    "print(train_gen[0][0].shape) # a batch of images\n",
    "print(train_gen[0][1].shape) # a batch of corresponding redshifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf416fd-e625-4f31-9a7d-1ccde69b7591",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_count = 0\n",
    "def next_batch():\n",
    "    global batch_count\n",
    "    x_train = np.asarray(train_gen[batch_count][0])\n",
    "    y_train = np.asarray(train_gen[batch_count][1]).reshape((BATCH_SIZE, 1))\n",
    "    batch_count = batch_count + 1\n",
    "    if batch_count == len(train_gen) - 1:\n",
    "        batch_count = 0\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3446dc25-6d3c-4f10-80f3-a308c6265422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(LATENT_DIM):\n",
    "    noise = Input(shape = (LATENT_DIM,))\n",
    "    label = Input(shape = (1,), dtype = 'float32')\n",
    "    label_embedding = Dense(LATENT_DIM)(label)\n",
    "    model_input = Concatenate()([noise, label_embedding])\n",
    "    \n",
    "    x = Dense(1024, activation = \"relu\")(model_input)\n",
    "    x = Dense(1024, activation = \"relu\")(x) # Size of the dense layer changed\n",
    "    x = Dense(256 * 16 * 16, activation = \"relu\")(x) # Size of the dense layer changed\n",
    "    x = Reshape((256, 16, 16))(x) # Reshape size changed\n",
    "    x = Conv2DTranspose(128, 2, strides = 1, activation = \"relu\", padding = 'same', data_format = 'channels_first')(x)\n",
    "    x = Conv2DTranspose(64, 2, strides = 1, activation = \"relu\", padding = 'same', data_format = 'channels_first')(x)\n",
    "    x = Conv2DTranspose(32, 3, strides = 2, activation = \"relu\", padding = 'same', data_format = 'channels_first')(x)\n",
    "    x = Conv2DTranspose(CHANNELS, 3, strides = 2, activation = \"relu\", padding = 'same', data_format = 'channels_first')(x)\n",
    "    outputs = Reshape(IMAGE_SHAPE)(x)\n",
    "    \n",
    "    model = Model([noise, label], outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d19e8c-1ff2-4dba-8ac8-d92d09a948dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(IMAGE_SHAPE):\n",
    "    img = Input(shape = IMAGE_SHAPE)\n",
    "    label = Input(shape = (1,), dtype = 'float32')\n",
    "\n",
    "    label_embedding = Dense(np.prod(IMAGE_SHAPE))(label)\n",
    "    label_embedding = Reshape(IMAGE_SHAPE)(label_embedding)\n",
    "    \n",
    "    merged_input = Concatenate(axis = 1)([img, label_embedding]) # Concatenate along channels\n",
    "\n",
    "    x = Conv2D(32, kernel_size = (3, 3), strides = 1, padding='same', data_format = 'channels_first')(merged_input)\n",
    "    x = LeakyReLU(alpha = 0.01)(x)\n",
    "    x = MaxPooling2D(2, 2, data_format = 'channels_first')(x)\n",
    "    x = Conv2D(64, kernel_size = (3, 3), strides = 1, padding = 'same', data_format = 'channels_first')(x)\n",
    "    x = LeakyReLU(alpha = 0.01)(x)\n",
    "    x = MaxPooling2D(2, 2, data_format = 'channels_first')(x)\n",
    "    x = Conv2D(128, kernel_size = (3, 3), strides = 1, padding = 'same', data_format = 'channels_first')(x)\n",
    "    x = LeakyReLU(alpha = 0.01)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = Dense(128)(x)\n",
    "    outputs = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "    model = Model([img, label], outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac0656b3-3405-4c91-a58a-20072034b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    \n",
    "    discriminator.compile(optimizer = Adam(learning_rate = 0.001), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    noise = Input(shape = (LATENT_DIM,))\n",
    "    label = Input(shape = (1,))\n",
    "    img = generator([noise, label])\n",
    "    fake_pred = discriminator([img, label])\n",
    "\n",
    "    combined_model = Model([noise, label], fake_pred)\n",
    "    combined_model.compile(optimizer = Adam(learning_rate = 0.001), loss = 'binary_crossentropy')\n",
    "    return combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "612784c9-bb37-4e44-acd0-ec361412827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator(LATENT_DIM)\n",
    "discriminator = build_discriminator(IMAGE_SHAPE)\n",
    "gan = build_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98160f52-98a9-47c7-9bc1-dd9f3ff429e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           32          ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1024)         33792       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1024)         1049600     ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 65536)        67174400    ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 256, 16, 16)  0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 128, 16, 16)  131200     ['reshape[0][0]']                \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 64, 16, 16)  32832       ['conv2d_transpose[0][0]']       \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 32, 32, 32)  18464       ['conv2d_transpose_1[0][0]']     \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 5, 64, 64)   1445        ['conv2d_transpose_2[0][0]']     \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 5, 64, 64)    0           ['conv2d_transpose_3[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 68,441,765\n",
      "Trainable params: 68,441,765\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 20480)        40960       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 5, 64, 64)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 5, 64, 64)    0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 10, 64, 64)   0           ['input_3[0][0]',                \n",
      "                                                                  'reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 64, 64)   2912        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 32, 64, 64)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 32, 32, 32)   0           ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 32, 32)   18496       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 64, 32, 32)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 16, 16)  0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 16, 16)  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 128, 16, 16)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 32768)        0           ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          4194432     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 128)          16512       ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            129         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,347,297\n",
      "Trainable params: 0\n",
      "Non-trainable params: 4,347,297\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4582b2fc-e9c5-4001-9548-115149643da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyFile(object):\n",
    "    def write(self, x): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed85a5c-bcbb-4721-8df2-20e3e4182388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x1553f9534f70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yli21/.conda/envs/photoz/lib/python3.10/site-packages/tqdm/std.py\", line 1145, in __del__\n",
      "    self.close()\n",
      "  File \"/home/yli21/.conda/envs/photoz/lib/python3.10/site-packages/tqdm/notebook.py\", line 283, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    }
   ],
   "source": [
    "# Save the original standard output\n",
    "original_stdout = sys.stdout\n",
    "\n",
    "# Redirect standard output to the dummy file\n",
    "sys.stdout = DummyFile()\n",
    "\n",
    "# Training code\n",
    "epochs = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Train Discriminator\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n",
    "    fake_redshift = np.random.uniform(0, 2, (BATCH_SIZE, 1))\n",
    "    fake_labels = np.zeros((BATCH_SIZE, 1))\n",
    "    fake_images = generator.predict([noise, fake_redshift])\n",
    "    \n",
    "    real_images, real_redshift = next_batch() # Get a batch of real images\n",
    "    real_labels = np.ones((BATCH_SIZE, 1))\n",
    "    \n",
    "    labels = np.vstack([real_labels, fake_labels])\n",
    "    redshifts = np.vstack([real_redshift, fake_redshift])\n",
    "    images = np.vstack([real_images, fake_images])\n",
    "\n",
    "    d_loss = discriminator.train_on_batch([images, redshifts], labels);\n",
    "\n",
    "    # Train Generator\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n",
    "    fake_redshift = np.random.uniform(0, 2, (BATCH_SIZE, 1)) # a vector of fake redshift to input the generator\n",
    "    g_loss = gan.train_on_batch([noise, fake_redshift], real_labels); # train the generator\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        # Restore original standard output for printing\n",
    "        sys.stdout = original_stdout\n",
    "        print(f\"Epoch {epoch}, Discriminator Loss: {d_loss}, Generator Loss: {g_loss}\")\n",
    "        # Redirect standard output back to the dummy file\n",
    "        sys.stdout = DummyFile()\n",
    "\n",
    "# Restore original standard output after training\n",
    "sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (photoz)",
   "language": "python",
   "name": "photoz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

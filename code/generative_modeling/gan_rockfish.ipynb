{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d23f862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import random\n",
    "import neptune\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow_probability import layers as tfpl\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, RepeatVector, MaxPooling2D, Conv2D, Concatenate, UpSampling2D, Conv2DTranspose, Flatten, Dropout, Dense, BatchNormalization, Activation, Reshape, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_probability.python.distributions import kl_divergence\n",
    "from neptune.integrations.tensorflow_keras import NeptuneCallback\n",
    "from DataMakerPlus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e0800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 16\n",
    "BASE_DEPTH = 8\n",
    "CHANNELS = 5\n",
    "IMAGE_SHAPE = (CHANNELS, 64, 64)\n",
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 250\n",
    "CHECKPOINTS_TO_SAVE = 4\n",
    "KL_WEIGHT = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a44e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU');\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 40511)]);\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU');\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc0eecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 5, 64, 64)\n",
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = f'/data/tuando/data/HSC/HSC_v6/step3A/64x64/5x64x64_training_z_less_than_2.hdf5'\n",
    "TEST_PATH = f'/data/tuando/data/HSC/HSC_v6/step3A/64x64/5x64x64_testing_z_less_than_2.hdf5'\n",
    "\n",
    "gen_args = {\n",
    "    'image_key': 'image',\n",
    "    'numerical_keys': None,\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'shuffle': False}\n",
    "train_gen = HDF5DataGenerator(TRAIN_PATH, mode = 'train', **gen_args)\n",
    "test_gen = HDF5DataGenerator(TEST_PATH, mode = 'train', **gen_args)\n",
    "print(train_gen[0][0].shape) # a batch of images\n",
    "print(train_gen[0][1].shape) # a batch of corresponding redshifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf416fd-e625-4f31-9a7d-1ccde69b7591",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_count = 0\n",
    "def next_batch():\n",
    "    global batch_count\n",
    "    x_train = np.asarray(train_gen[batch_count][0])\n",
    "    y_train = np.asarray(train_gen[batch_count][1]).reshape((BATCH_SIZE, 1))\n",
    "    batch_count = batch_count + 1\n",
    "    if batch_count == len(train_gen) - 1:\n",
    "        batch_count = 0\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3446dc25-6d3c-4f10-80f3-a308c6265422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(LATENT_DIM):\n",
    "    noise = Input(shape = (LATENT_DIM,))\n",
    "    label = Input(shape = (1,), dtype = 'float32')\n",
    "    label_embedding = Dense(LATENT_DIM)(label)\n",
    "    model_input = Concatenate()([noise, label_embedding])\n",
    "    \n",
    "    x = Dense(1024, activation = \"relu\")(model_input)\n",
    "    x = Dense(1024, activation = \"relu\")(x) # Size of the dense layer changed\n",
    "    x = Dense(256 * 16 * 16, activation = \"relu\")(x) # Size of the dense layer changed\n",
    "    x = Reshape((256, 16, 16))(x) # Reshape size changed\n",
    "    x = Conv2DTranspose(128, 2, strides = 1, activation = \"relu\", padding = 'same', data_format = 'channels_first')(x)\n",
    "    x = Conv2DTranspose(64, 2, strides = 1, activation = \"relu\", padding = 'same', data_format = 'channels_first')(x)\n",
    "    x = Conv2DTranspose(32, 3, strides = 2, activation = \"relu\", padding = 'same', data_format = 'channels_first')(x)\n",
    "    x = Conv2DTranspose(CHANNELS, 3, strides = 2, activation = \"relu\", padding = 'same', data_format = 'channels_first')(x)\n",
    "    outputs = Reshape(IMAGE_SHAPE)(x)\n",
    "    \n",
    "    model = Model([noise, label], outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3d19e8c-1ff2-4dba-8ac8-d92d09a948dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(IMAGE_SHAPE):\n",
    "    img = Input(shape = IMAGE_SHAPE)\n",
    "    label = Input(shape = (1,), dtype = 'float32')\n",
    "\n",
    "    label_embedding = Dense(np.prod(IMAGE_SHAPE))(label)\n",
    "    label_embedding = Reshape(IMAGE_SHAPE)(label_embedding)\n",
    "    \n",
    "    merged_input = Concatenate(axis = 1)([img, label_embedding]) # Concatenate along channels\n",
    "\n",
    "    x = Conv2D(32, kernel_size = (3, 3), strides = 1, padding = 'same', data_format = 'channels_first')(merged_input)\n",
    "    x = LeakyReLU(alpha = 0.01)(x)\n",
    "    x = MaxPooling2D(2, 2, data_format = 'channels_first')(x)\n",
    "    x = Conv2D(64, kernel_size = (3, 3), strides = 1, padding = 'same', data_format = 'channels_first')(x)\n",
    "    x = LeakyReLU(alpha = 0.01)(x)\n",
    "    x = MaxPooling2D(2, 2, data_format = 'channels_first')(x)\n",
    "    x = Conv2D(128, kernel_size = (3, 3), strides = 1, padding = 'same', data_format = 'channels_first')(x)\n",
    "    x = LeakyReLU(alpha = 0.01)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = Dense(128)(x)\n",
    "    outputs = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "    model = Model([img, label], outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac0656b3-3405-4c91-a58a-20072034b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    \n",
    "    discriminator.compile(optimizer = Adam(learning_rate = 0.0002), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    noise = Input(shape = (LATENT_DIM,))\n",
    "    label = Input(shape = (1,))\n",
    "    img = generator([noise, label])\n",
    "    fake_pred = discriminator([img, label])\n",
    "\n",
    "    combined_model = Model([noise, label], fake_pred)\n",
    "    combined_model.compile(optimizer = Adam(learning_rate = 0.0001), loss = 'binary_crossentropy')\n",
    "    return combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "612784c9-bb37-4e44-acd0-ec361412827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator(LATENT_DIM)\n",
    "discriminator = build_discriminator(IMAGE_SHAPE)\n",
    "gan = build_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98160f52-98a9-47c7-9bc1-dd9f3ff429e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           32          ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1024)         33792       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1024)         1049600     ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 65536)        67174400    ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 256, 16, 16)  0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 128, 16, 16)  131200     ['reshape[0][0]']                \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 64, 16, 16)  32832       ['conv2d_transpose[0][0]']       \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 32, 32, 32)  18464       ['conv2d_transpose_1[0][0]']     \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 5, 64, 64)   1445        ['conv2d_transpose_2[0][0]']     \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 5, 64, 64)    0           ['conv2d_transpose_3[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 68,441,765\n",
      "Trainable params: 68,441,765\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 20480)        40960       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 5, 64, 64)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 5, 64, 64)    0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 10, 64, 64)   0           ['input_3[0][0]',                \n",
      "                                                                  'reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 64, 64)   2912        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 32, 64, 64)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 32, 32, 32)   0           ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 32, 32)   18496       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 64, 32, 32)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 16, 16)  0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 16, 16)  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 128, 16, 16)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 32768)        0           ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          4194432     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 128)          16512       ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            129         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,347,297\n",
      "Trainable params: 0\n",
      "Non-trainable params: 4,347,297\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13b1f3-1942-429c-b713-344c7f304b6b",
   "metadata": {},
   "source": [
    "class DummyFile(object):\n",
    "    def write(self, x): pass\n",
    "\n",
    "# Save the original standard output\n",
    "original_stdout = sys.stdout\n",
    "\n",
    "# Redirect standard output to the dummy file\n",
    "sys.stdout = DummyFile()\n",
    "\n",
    "sys.stdout = original_stdout\n",
    "print(\"1\")\n",
    "# Redirect standard output back to the dummy file\n",
    "sys.stdout = DummyFile()\n",
    "\n",
    "# Training code\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Train Discriminator\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n",
    "    fake_redshift = np.random.uniform(0, 2, (BATCH_SIZE, 1))\n",
    "    fake_labels = np.zeros((BATCH_SIZE, 1))\n",
    "    \n",
    "    sys.stdout = original_stdout\n",
    "    print(\"1\")\n",
    "    # Redirect standard output back to the dummy file\n",
    "    sys.stdout = DummyFile()\n",
    "    \n",
    "    fake_images = generator.predict([noise, fake_redshift])\n",
    "    \n",
    "    sys.stdout = original_stdout\n",
    "    print(\"1\")\n",
    "    # Redirect standard output back to the dummy file\n",
    "    sys.stdout = DummyFile()\n",
    "    \n",
    "    real_images, real_redshift = next_batch() # Get a batch of real images\n",
    "    real_labels = np.ones((BATCH_SIZE, 1))\n",
    "    \n",
    "    labels = np.vstack([real_labels, fake_labels])\n",
    "    redshifts = np.vstack([real_redshift, fake_redshift])\n",
    "    images = np.vstack([real_images, fake_images])\n",
    "    \n",
    "    sys.stdout = original_stdout\n",
    "    print(\"1\")\n",
    "    # Redirect standard output back to the dummy file\n",
    "    sys.stdout = DummyFile()\n",
    "\n",
    "    d_loss = discriminator.train_on_batch([images, redshifts], labels);\n",
    "    \n",
    "    sys.stdout = original_stdout\n",
    "    print(\"1\")\n",
    "    # Redirect standard output back to the dummy file\n",
    "    sys.stdout = DummyFile()\n",
    "    \n",
    "    # Train Generator\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n",
    "    fake_redshift = np.random.uniform(0, 2, (BATCH_SIZE, 1)) # a vector of fake redshift to input the generator\n",
    "    g_loss = gan.train_on_batch([noise, fake_redshift], real_labels); # train the generator\n",
    "    \n",
    "    if True: # epoch % 5 == 0:\n",
    "        # Restore original standard output for printing\n",
    "        sys.stdout = original_stdout\n",
    "        print(f\"Epoch {epoch}, Discriminator Loss: {d_loss}, Generator Loss: {g_loss}\")\n",
    "        # Redirect standard output back to the dummy file\n",
    "        sys.stdout = DummyFile()\n",
    "\n",
    "# Restore original standard output after training\n",
    "sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1be3ce1-0783-4f66-bcc0-f2869edb34cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 0, Discriminator Loss: [0.006479423958808184, 1.0], Generator Loss: 4.755455017089844\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 5, Discriminator Loss: [0.008182164281606674, 0.9979248046875], Generator Loss: 5.272846698760986\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 10, Discriminator Loss: [0.003223307430744171, 1.0], Generator Loss: 5.354257583618164\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 15, Discriminator Loss: [0.009222758933901787, 0.9984130859375], Generator Loss: 5.239963531494141\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 20, Discriminator Loss: [0.05542264133691788, 0.9969482421875], Generator Loss: 3.311141014099121\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 25, Discriminator Loss: [0.0011006512213498354, 1.0], Generator Loss: 7.390136241912842\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 30, Discriminator Loss: [0.010133123956620693, 0.9974365234375], Generator Loss: 9.408670425415039\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 35, Discriminator Loss: [0.0023775072768330574, 0.99951171875], Generator Loss: 7.604196071624756\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 40, Discriminator Loss: [0.001999247120693326, 0.9998779296875], Generator Loss: 5.622066497802734\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 45, Discriminator Loss: [0.00757805909961462, 1.0], Generator Loss: 4.926531791687012\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 50, Discriminator Loss: [0.0029654435347765684, 1.0], Generator Loss: 6.235752582550049\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 55, Discriminator Loss: [0.004650214686989784, 0.9989013671875], Generator Loss: 6.6284027099609375\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 60, Discriminator Loss: [0.08051568269729614, 0.984130859375], Generator Loss: 4.185427665710449\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 65, Discriminator Loss: [0.059700027108192444, 0.9891357421875], Generator Loss: 7.787030220031738\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 70, Discriminator Loss: [0.01345043908804655, 1.0], Generator Loss: 5.701261043548584\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 75, Discriminator Loss: [0.03380553051829338, 0.99169921875], Generator Loss: 6.405216217041016\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 80, Discriminator Loss: [0.0041403635405004025, 0.999755859375], Generator Loss: 7.273499011993408\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 85, Discriminator Loss: [0.0002632357645779848, 1.0], Generator Loss: 9.272658348083496\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 90, Discriminator Loss: [0.07505635172128677, 0.9765625], Generator Loss: 4.42531156539917\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "Epoch 95, Discriminator Loss: [0.018565012142062187, 0.9951171875], Generator Loss: 20.254335403442383\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n",
      "128/128 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15524589d8d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Train Discriminator\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n",
    "    \n",
    "    fake_redshift = np.random.uniform(0, 2, (BATCH_SIZE, 1))\n",
    "    fake_labels = np.zeros((BATCH_SIZE, 1))\n",
    "    fake_images = generator.predict([noise, fake_redshift])\n",
    "    \n",
    "    real_images, real_redshift = next_batch() # Get a batch of real images\n",
    "    real_labels = np.ones((BATCH_SIZE, 1))\n",
    "    \n",
    "    labels = np.vstack([real_labels, fake_labels])\n",
    "    redshifts = np.vstack([real_redshift, fake_redshift])\n",
    "    images = np.vstack([real_images, fake_images])\n",
    "    \n",
    "    d_loss = discriminator.train_on_batch([images, redshifts], labels);\n",
    "    \n",
    "    # Train Generator\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n",
    "    fake_redshift = np.random.uniform(0, 2, (BATCH_SIZE, 1)) # a vector of fake redshift to input the generator\n",
    "    g_loss = gan.train_on_batch([noise, fake_redshift], real_labels); # train the generator\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch}, Discriminator Loss: {d_loss}, Generator Loss: {g_loss}\")\n",
    "        \n",
    "plt.imshow(fake_images[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f023d8e6-c115-4c3f-af88-bdf27ac4e5a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4067800170.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    stop here\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e46853-2145-4bb2-8aea-6c4f0a0f6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('/data/tuando/data/GAN/GAN_v1/step1/64x64/5x64x64_gan_generated_1.hdf5', 'a')\n",
    "str = prior.sample(1)[0]\n",
    "str = np.concatenate((str, np.array([0.1])))\n",
    "str = str.reshape(1, LATENT_DIM + 1)\n",
    "image_g = decoder([str])[0][0]\n",
    "image_r = decoder([str])[0][1]\n",
    "image_i = decoder([str])[0][2]\n",
    "image_z = decoder([str])[0][3]\n",
    "image_y = decoder([str])[0][4]\n",
    "five_band_image = []\n",
    "five_band_image.append(image_g)\n",
    "five_band_image.append(image_r)\n",
    "five_band_image.append(image_i)\n",
    "five_band_image.append(image_z)\n",
    "five_band_image.append(image_y)\n",
    "five_band_image_reshape = np.reshape(np.array(five_band_image), [1, 5, 64, 64])\n",
    "hf.create_dataset('image', data = five_band_image_reshape, chunks = True, maxshape = (None, 5, 64, 64))\n",
    "hf.create_dataset('specz_redshift', data = [0.1], chunks = True, maxshape = (None, ))\n",
    "for i in tqdm(range(1999)):\n",
    "    z = random.uniform(0, 2)\n",
    "    str = prior.sample(1)[0]\n",
    "    str = np.concatenate((str, np.array([z])))\n",
    "    str = str.reshape(1, LATENT_DIM + 1)\n",
    "    image_g = decoder([str])[0][0]\n",
    "    image_r = decoder([str])[0][1]\n",
    "    image_i = decoder([str])[0][2]\n",
    "    image_z = decoder([str])[0][3]\n",
    "    image_y = decoder([str])[0][4]\n",
    "    five_band_image = []\n",
    "    five_band_image.append(image_g)\n",
    "    five_band_image.append(image_r)\n",
    "    five_band_image.append(image_i)\n",
    "    five_band_image.append(image_z)\n",
    "    five_band_image.append(image_y)\n",
    "    five_band_image_reshape = np.reshape(np.array(five_band_image), [1, 5, 64, 64])\n",
    "    hf['specz_redshift'].resize((hf['specz_redshift'].shape[0] + 1), axis = 0)\n",
    "    hf['specz_redshift'][hf['specz_redshift'].shape[0] - 1] = [z]\n",
    "    hf['image'].resize((hf['image'].shape[0] + 1), axis = 0)\n",
    "    hf['image'][hf['image'].shape[0] - 1, :, :, :] = five_band_image\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128a138e-d8f8-46ec-91a5-7f66b8a64795",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_redshift = np.random.uniform(0, 2, (BATCH_SIZE, 1))\n",
    "fake_labels = np.zeros((BATCH_SIZE, 1))\n",
    "fake_images = generator.predict([noise, fake_redshift])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeff52f-cda7-4ae6-9832-b339d9422ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fake_images[197][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380068a1-f396-47f7-9ee1-11b20fdb21ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(generator, to_file='generator_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb11c0ba-3770-448c-b90d-c6b368d7e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(discriminator, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa699ab-8e4b-43eb-a8d4-d532776a3c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665cc85-365d-4100-b1f8-f903d1700585",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gan'\n",
    "\n",
    "weights_path = os.path.join('/data/tuando/models/', model_name) + '/weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a660ffa-3a95-4939-8d1a-6d1f5fc6566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc0b28f-846a-434d-9ec0-8cf03f1baa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63042c4d-6123-4f21-b4f7-52ef8c2fb98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'discriminator'\n",
    "\n",
    "weights_path = os.path.join('/data/tuando/models/', model_name) + '/weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbfd77f-e729-4f66-8d74-48139ffe2828",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96062427-c157-4b89-9d7f-d2d8c93e5e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (photoz)",
   "language": "python",
   "name": "photoz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

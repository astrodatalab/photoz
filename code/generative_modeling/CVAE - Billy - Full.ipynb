{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f923d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "write = True # log this version as new\n",
    "MODEL_DESCRIPTION = \"Correct Full CVAE New KL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d23f862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import stdout\n",
    "from datetime import datetime\n",
    "import neptune.new as neptune\n",
    "from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
    "from astropy.io import fits\n",
    "import random\n",
    "from DataMaker import HDF5ImageGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2032fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import Cropping2D, ZeroPadding2D, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Reshape\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import layers as tfpl\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow.nn import leaky_relu\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e0800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 256\n",
    "BASE_DEPTH = 8\n",
    "IMAGE_SHAPE = (5, 127, 127)\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 250\n",
    "CHECKPOINTS_TO_SAVE = 4\n",
    "KL_WEIGHT = 1e-10\n",
    "# Good value: 1e-6\n",
    "# With KL 0 val_loss = 0.4763\n",
    "# With KL 1e-6 val loss = 0.6252\n",
    "# With KL 1e-8 val loss = 0.5257\n",
    "# With KL 1e-10 val loss = 0.4466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a44e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 02:06:16.996201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 02:06:17.002371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 02:06:17.003654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 02:06:17.039548: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-11 02:06:17.041098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 02:06:17.043432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 02:06:17.045753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 02:06:17.413035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 02:06:17.414251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 02:06:17.415411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 02:06:17.416554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20000 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU');\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 20000)]);\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU');\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb7cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "DATASET_NAME = \"HSC_v6\"\n",
    "MODEL_TYPE = \"CVAE\"\n",
    "MODEL_VERSION = \"v1.0\"\n",
    "MODEL_SUBVERSION = \"v1.0.\" + now.strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "\n",
    "model_id = '_'.join([DATASET_NAME, MODEL_TYPE, MODEL_VERSION])\n",
    "model_path = os.path.join('/models', model_id, MODEL_SUBVERSION, 'model')\n",
    "checkpoints_path = os.path.join('/models', model_id, MODEL_SUBVERSION, 'checkpoints')\n",
    "logs_path = os.path.join('/logs', model_id, MODEL_SUBVERSION)\n",
    "predictions_path = os.path.join('/predictions', model_id, MODEL_SUBVERSION)\n",
    "weights_path = model_path + '/weights.h5'\n",
    "\n",
    "os.makedirs(model_path, exist_ok = True)\n",
    "os.makedirs(checkpoints_path, exist_ok = True)\n",
    "os.makedirs(logs_path, exist_ok = True)\n",
    "os.makedirs(predictions_path, exist_ok = True)\n",
    "\n",
    "if write == True:\n",
    "    with open(\"/models/README.md\", \"a\") as myfile:\n",
    "        myfile.write(MODEL_TYPE + \" \" + MODEL_SUBVERSION + \" - \" + MODEL_DESCRIPTION + \" - B. Li\" + \"\\n\")\n",
    "else:\n",
    "    with open(\"/models/README.md\", \"a\") as myfile:\n",
    "        myfile.write(MODEL_TYPE + \" \" + MODEL_SUBVERSION + \" - ... \"+ \" - B. Li\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc0eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_gen = {'X_key': 'image',\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': False}\n",
    "\n",
    "train_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/127x127/5x127x127_training.hdf5', **args_gen)\n",
    "val_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/127x127/5x127x127_validation.hdf5', **args_gen)\n",
    "test_gen = HDF5ImageGenerator(src = '/data/HSC/HSC_v6/step2A/127x127/5x127x127_testing.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "588c99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = BATCH_SIZE\n",
    "l = len(train_gen._indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d31d75f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(LATENT_DIM), scale = 0.1), reinterpreted_batch_ndims = 1)\n",
    "\n",
    "images = Input(shape = IMAGE_SHAPE)\n",
    "redshifts = Input(shape = 1,)\n",
    "conv1 = Conv2D(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "            padding = 'same', data_format = 'channels_first')(images)\n",
    "conv2 = Conv2D(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "            padding = 'same', data_format = 'channels_first')(conv1)\n",
    "flatten = Flatten()(conv2)\n",
    "dense1 = Dense(1024, activation = None)(flatten)\n",
    "dense2 = tf.keras.layers.Dense(32, activation = \"relu\")(redshifts)\n",
    "dense3 = tf.keras.layers.Dense(32, activation = \"relu\")(dense2)\n",
    "concat = tf.keras.layers.Concatenate()([dense1, dense3])\n",
    "dense4 = Dense(tfpl.MultivariateNormalTriL.params_size(LATENT_DIM), activation = None)(concat)\n",
    "z = tfpl.MultivariateNormalTriL(LATENT_DIM,\n",
    "            activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight = KL_WEIGHT))(dense4)\n",
    "encoder = Model([images, redshifts], z)\n",
    "\n",
    "zc = tf.keras.layers.Concatenate()([z, redshifts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b25f1d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense5 = Dense(8 * LATENT_DIM * 32 * 32, activation = None)\n",
    "reshape = Reshape((8 * LATENT_DIM, 32, 32))\n",
    "conv3 = Conv2DTranspose(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "                    padding = 'same', data_format = 'channels_first')\n",
    "conv4 = Conv2DTranspose(BASE_DEPTH, 3, strides = 2, activation = leaky_relu,\n",
    "                    padding = 'same', data_format = 'channels_first')\n",
    "conv5 = Conv2DTranspose(BASE_DEPTH, 3, strides = 1, activation = leaky_relu, \n",
    "                    padding = 'same', data_format = 'channels_first')\n",
    "conv6 = Conv2D(IMAGE_SHAPE[0], 3, strides = 1, activation = None, \n",
    "           padding = 'same', data_format = 'channels_first')\n",
    "cropping = Cropping2D(cropping=((0, 1), (0, 1)), data_format = 'channels_first')\n",
    "outputs = Reshape(IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcac6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense5_model = dense5(zc)\n",
    "reshape_model = reshape(dense5_model)\n",
    "conv3_model = conv3(reshape_model)\n",
    "conv4_model = conv4(conv3_model)\n",
    "conv5_model = conv5(conv4_model)\n",
    "conv6_model = conv6(conv5_model)\n",
    "cropping_model = cropping(conv6_model)\n",
    "outputs_model = outputs(cropping_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c11d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = [images, redshifts], outputs = [outputs_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e036f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = Input(shape = (LATENT_DIM + 1, ))\n",
    "dense5_decoder = dense5(latents)\n",
    "reshape_decoder = reshape(dense5_decoder)\n",
    "conv3_decoder = conv3(reshape_decoder)\n",
    "conv4_decoder = conv4(conv3_decoder)\n",
    "conv5_decoder = conv5(conv4_decoder)\n",
    "conv6_decoder = conv6(conv5_decoder)\n",
    "cropping_decoder = cropping(conv6_decoder)\n",
    "outputs_decoder = outputs(cropping_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17a65d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Model(latents, outputs_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c25fe180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 127, 127  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 8, 64, 64)    368         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 32, 32)    584         ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8192)         0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           64          ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         8389632     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           1056        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1056)         0           ['dense[0][0]',                  \n",
      "                                                                  'dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 33152)        35041664    ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " multivariate_normal_tri_l (Mul  ((None, 256),       0           ['dense_3[0][0]']                \n",
      " tivariateNormalTriL)            (None, 256))                                                     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 257)          0           ['multivariate_normal_tri_l[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 2097152)      541065216   ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 2048, 32, 32  0           ['dense_4[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 8, 64, 64)   147464      ['reshape[0][0]']                \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 8, 128, 128)  584        ['conv2d_transpose[0][0]']       \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 8, 128, 128)  584        ['conv2d_transpose_1[0][0]']     \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 5, 128, 128)  365         ['conv2d_transpose_2[0][0]']     \n",
      "                                                                                                  \n",
      " cropping2d (Cropping2D)        (None, 5, 127, 127)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 5, 127, 127)  0           ['cropping2d[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 584,647,581\n",
      "Trainable params: 584,647,581\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d463c7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/billyli/miniconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr = 0.0001)\n",
    "model.compile(optimizer = optimizer, loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcbb9c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/astro-data-lab/VAE/e/VAE-114\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    name = MODEL_SUBVERSION,\n",
    "    project = \"astro-data-lab/VAE\",\n",
    "    api_token = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGFlZGMxOC04MWU5LTQ2NDctYjlhZS05NGE2NGQ0NmIzMmEifQ==\",\n",
    ")  # your credentials\n",
    "\n",
    "# logs_callback = TensorBoard(log_dir = logs_path)\n",
    "\n",
    "weights_callback = ModelCheckpoint(filepath = os.path.join(checkpoints_path, 'weights_epoch{epoch}.hdf5'), save_freq = int(EPOCHS/CHECKPOINTS_TO_SAVE), save_weights_only = True)\n",
    "\n",
    "LR_callback = ReduceLROnPlateau()\n",
    "\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs_path, histogram_freq = 1)\n",
    "\n",
    "neptune_callback = NeptuneCallback(run = run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f61a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 02:06:23.816745: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-02-11 02:08:16.091298: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n",
      "2023-02-11 02:11:04.770065: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-11 02:13:06.493954: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-02-11 02:13:06.493979: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61/392 [===>..........................] - ETA: 6:27 - loss: 4.3275"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 02:14:18.259119: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2155872256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/392 [========>.....................] - ETA: 4:57 - loss: 4.0156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 02:15:23.044266: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2155872256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/392 [=============>................] - ETA: 4:00 - loss: 3.5919"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 02:16:42.461512: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2155872256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/392 [=================>............] - ETA: 2:57 - loss: 3.3104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 02:18:09.499069: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2155872256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/392 [======================>.......] - ETA: 1:47 - loss: 3.1087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 02:19:46.846561: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2155872256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 1037s 2s/step - loss: 3.0025 - val_loss: 2.2420 - lr: 1.0000e-04\n",
      "Epoch 2/250\n",
      "392/392 [==============================] - 549s 1s/step - loss: 2.2072 - val_loss: 2.0429 - lr: 1.0000e-04\n",
      "Epoch 3/250\n",
      "392/392 [==============================] - 581s 1s/step - loss: 2.0611 - val_loss: 1.9266 - lr: 1.0000e-04\n",
      "Epoch 4/250\n",
      "392/392 [==============================] - 560s 1s/step - loss: 1.9377 - val_loss: 1.9725 - lr: 1.0000e-04\n",
      "Epoch 5/250\n",
      "392/392 [==============================] - 516s 1s/step - loss: 1.7872 - val_loss: 1.6816 - lr: 1.0000e-04\n",
      "Epoch 6/250\n",
      "392/392 [==============================] - 511s 1s/step - loss: 1.6390 - val_loss: 1.5150 - lr: 1.0000e-04\n",
      "Epoch 7/250\n",
      "392/392 [==============================] - 511s 1s/step - loss: 1.4968 - val_loss: 1.4046 - lr: 1.0000e-04\n",
      "Epoch 8/250\n",
      "392/392 [==============================] - 488s 1s/step - loss: 1.3574 - val_loss: 1.2640 - lr: 1.0000e-04\n",
      "Epoch 9/250\n",
      "392/392 [==============================] - 483s 1s/step - loss: 1.2381 - val_loss: 1.1687 - lr: 1.0000e-04\n",
      "Epoch 10/250\n",
      "392/392 [==============================] - 483s 1s/step - loss: 1.1306 - val_loss: 1.0709 - lr: 1.0000e-04\n",
      "Epoch 11/250\n",
      "392/392 [==============================] - 487s 1s/step - loss: 1.0484 - val_loss: 0.9977 - lr: 1.0000e-04\n",
      "Epoch 12/250\n",
      "392/392 [==============================] - 479s 1s/step - loss: 0.9815 - val_loss: 0.9459 - lr: 1.0000e-04\n",
      "Epoch 13/250\n",
      "392/392 [==============================] - 497s 1s/step - loss: 0.9247 - val_loss: 0.9243 - lr: 1.0000e-04\n",
      "Epoch 14/250\n",
      "392/392 [==============================] - 485s 1s/step - loss: 0.8759 - val_loss: 0.8701 - lr: 1.0000e-04\n",
      "Epoch 15/250\n",
      "392/392 [==============================] - 484s 1s/step - loss: 0.8393 - val_loss: 0.8358 - lr: 1.0000e-04\n",
      "Epoch 16/250\n",
      "392/392 [==============================] - 505s 1s/step - loss: 0.8015 - val_loss: 0.8009 - lr: 1.0000e-04\n",
      "Epoch 17/250\n",
      "392/392 [==============================] - 482s 1s/step - loss: 0.7673 - val_loss: 0.7769 - lr: 1.0000e-04\n",
      "Epoch 18/250\n",
      "392/392 [==============================] - 480s 1s/step - loss: 0.7416 - val_loss: 0.7645 - lr: 1.0000e-04\n",
      "Epoch 19/250\n",
      "392/392 [==============================] - 505s 1s/step - loss: 0.7262 - val_loss: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 20/250\n",
      "392/392 [==============================] - 485s 1s/step - loss: 0.7012 - val_loss: 0.7245 - lr: 1.0000e-04\n",
      "Epoch 21/250\n",
      "392/392 [==============================] - 467s 1s/step - loss: 0.6856 - val_loss: 0.7165 - lr: 1.0000e-04\n",
      "Epoch 22/250\n",
      "392/392 [==============================] - 496s 1s/step - loss: 0.6649 - val_loss: 0.7071 - lr: 1.0000e-04\n",
      "Epoch 23/250\n",
      "392/392 [==============================] - 482s 1s/step - loss: 0.6491 - val_loss: 0.6923 - lr: 1.0000e-04\n",
      "Epoch 24/250\n",
      "392/392 [==============================] - 479s 1s/step - loss: 0.6440 - val_loss: 0.6782 - lr: 1.0000e-04\n",
      "Epoch 25/250\n",
      "392/392 [==============================] - 505s 1s/step - loss: 0.6204 - val_loss: 0.6773 - lr: 1.0000e-04\n",
      "Epoch 26/250\n",
      "392/392 [==============================] - 479s 1s/step - loss: 0.6127 - val_loss: 0.7270 - lr: 1.0000e-04\n",
      "Epoch 27/250\n",
      "392/392 [==============================] - 473s 1s/step - loss: 0.6059 - val_loss: 0.6682 - lr: 1.0000e-04\n",
      "Epoch 28/250\n",
      "392/392 [==============================] - 492s 1s/step - loss: 0.5889 - val_loss: 0.6521 - lr: 1.0000e-04\n",
      "Epoch 29/250\n",
      "392/392 [==============================] - 479s 1s/step - loss: 0.5866 - val_loss: 0.6417 - lr: 1.0000e-04\n",
      "Epoch 30/250\n",
      "392/392 [==============================] - 498s 1s/step - loss: 0.5672 - val_loss: 0.6422 - lr: 1.0000e-04\n",
      "Epoch 31/250\n",
      "392/392 [==============================] - 517s 1s/step - loss: 0.5640 - val_loss: 0.6384 - lr: 1.0000e-04\n",
      "Epoch 32/250\n",
      "392/392 [==============================] - 473s 1s/step - loss: 0.5564 - val_loss: 0.6432 - lr: 1.0000e-04\n",
      "Epoch 33/250\n",
      "392/392 [==============================] - 474s 1s/step - loss: 0.5378 - val_loss: 0.6118 - lr: 1.0000e-04\n",
      "Epoch 34/250\n",
      "392/392 [==============================] - 475s 1s/step - loss: 0.5361 - val_loss: 0.6126 - lr: 1.0000e-04\n",
      "Epoch 35/250\n",
      "392/392 [==============================] - 487s 1s/step - loss: 0.5272 - val_loss: 0.5976 - lr: 1.0000e-04\n",
      "Epoch 36/250\n",
      "392/392 [==============================] - 473s 1s/step - loss: 0.5124 - val_loss: 0.6169 - lr: 1.0000e-04\n",
      "Epoch 37/250\n",
      "392/392 [==============================] - 502s 1s/step - loss: 0.5082 - val_loss: 0.5929 - lr: 1.0000e-04\n",
      "Epoch 38/250\n",
      "392/392 [==============================] - 492s 1s/step - loss: 0.5309 - val_loss: 0.6183 - lr: 1.0000e-04\n",
      "Epoch 39/250\n",
      "392/392 [==============================] - 460s 1s/step - loss: 0.5043 - val_loss: 0.5897 - lr: 1.0000e-04\n",
      "Epoch 40/250\n",
      "392/392 [==============================] - 517s 1s/step - loss: 0.4884 - val_loss: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 41/250\n",
      "392/392 [==============================] - 581s 1s/step - loss: 0.4733 - val_loss: 0.5787 - lr: 1.0000e-04\n",
      "Epoch 42/250\n",
      "392/392 [==============================] - 567s 1s/step - loss: 0.4733 - val_loss: 0.5771 - lr: 1.0000e-04\n",
      "Epoch 43/250\n",
      "392/392 [==============================] - 492s 1s/step - loss: 0.5262 - val_loss: 0.5775 - lr: 1.0000e-04\n",
      "Epoch 44/250\n",
      "392/392 [==============================] - 518s 1s/step - loss: 0.4666 - val_loss: 0.5683 - lr: 1.0000e-04\n",
      "Epoch 45/250\n",
      "392/392 [==============================] - 490s 1s/step - loss: 0.4626 - val_loss: 0.5583 - lr: 1.0000e-04\n",
      "Epoch 46/250\n",
      "392/392 [==============================] - 495s 1s/step - loss: 0.4489 - val_loss: 0.5560 - lr: 1.0000e-04\n",
      "Epoch 47/250\n",
      "392/392 [==============================] - 517s 1s/step - loss: 0.4463 - val_loss: 0.5531 - lr: 1.0000e-04\n",
      "Epoch 48/250\n",
      "392/392 [==============================] - 498s 1s/step - loss: 0.4427 - val_loss: 0.5479 - lr: 1.0000e-04\n",
      "Epoch 49/250\n",
      "392/392 [==============================] - 502s 1s/step - loss: 0.4558 - val_loss: 0.5577 - lr: 1.0000e-04\n",
      "Epoch 50/250\n",
      "392/392 [==============================] - 496s 1s/step - loss: 0.4411 - val_loss: 0.5497 - lr: 1.0000e-04\n",
      "Epoch 51/250\n",
      "392/392 [==============================] - 482s 1s/step - loss: 0.4257 - val_loss: 0.5472 - lr: 1.0000e-04\n",
      "Epoch 52/250\n",
      "392/392 [==============================] - 481s 1s/step - loss: 0.4288 - val_loss: 0.5399 - lr: 1.0000e-04\n",
      "Epoch 53/250\n",
      "392/392 [==============================] - 555s 1s/step - loss: 0.4202 - val_loss: 0.5387 - lr: 1.0000e-04\n",
      "Epoch 54/250\n",
      "392/392 [==============================] - 480s 1s/step - loss: 0.4123 - val_loss: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 55/250\n",
      "392/392 [==============================] - 474s 1s/step - loss: 0.4132 - val_loss: 0.5364 - lr: 1.0000e-04\n",
      "Epoch 56/250\n",
      "392/392 [==============================] - 493s 1s/step - loss: 0.4153 - val_loss: 0.5495 - lr: 1.0000e-04\n",
      "Epoch 57/250\n",
      "392/392 [==============================] - 486s 1s/step - loss: 0.4154 - val_loss: 0.5667 - lr: 1.0000e-04\n",
      "Epoch 58/250\n",
      "392/392 [==============================] - 505s 1s/step - loss: 0.4076 - val_loss: 0.5351 - lr: 1.0000e-04\n",
      "Epoch 59/250\n",
      "392/392 [==============================] - 493s 1s/step - loss: 0.4023 - val_loss: 0.5365 - lr: 1.0000e-04\n",
      "Epoch 60/250\n",
      "392/392 [==============================] - 505s 1s/step - loss: 0.3914 - val_loss: 0.5297 - lr: 1.0000e-04\n",
      "Epoch 61/250\n",
      "392/392 [==============================] - 499s 1s/step - loss: 0.4116 - val_loss: 0.5308 - lr: 1.0000e-04\n",
      "Epoch 62/250\n",
      "392/392 [==============================] - 510s 1s/step - loss: 0.3909 - val_loss: 0.5330 - lr: 1.0000e-04\n",
      "Epoch 63/250\n",
      "392/392 [==============================] - 486s 1s/step - loss: 0.3817 - val_loss: 0.5288 - lr: 1.0000e-04\n",
      "Epoch 64/250\n",
      "392/392 [==============================] - 484s 1s/step - loss: 0.4202 - val_loss: 0.5394 - lr: 1.0000e-04\n",
      "Epoch 65/250\n",
      "392/392 [==============================] - 491s 1s/step - loss: 0.3851 - val_loss: 0.5240 - lr: 1.0000e-04\n",
      "Epoch 66/250\n",
      "392/392 [==============================] - 501s 1s/step - loss: 0.4154 - val_loss: 0.5124 - lr: 1.0000e-04\n",
      "Epoch 67/250\n",
      "392/392 [==============================] - 494s 1s/step - loss: 0.3885 - val_loss: 0.5163 - lr: 1.0000e-04\n",
      "Epoch 68/250\n",
      "392/392 [==============================] - 474s 1s/step - loss: 0.3671 - val_loss: 0.5126 - lr: 1.0000e-04\n",
      "Epoch 69/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 488s 1s/step - loss: 0.3590 - val_loss: 0.5121 - lr: 1.0000e-04\n",
      "Epoch 70/250\n",
      "392/392 [==============================] - 481s 1s/step - loss: 0.3641 - val_loss: 0.5195 - lr: 1.0000e-04\n",
      "Epoch 71/250\n",
      "392/392 [==============================] - 475s 1s/step - loss: 0.3610 - val_loss: 0.5012 - lr: 1.0000e-04\n",
      "Epoch 72/250\n",
      "392/392 [==============================] - 489s 1s/step - loss: 0.3613 - val_loss: 0.5120 - lr: 1.0000e-04\n",
      "Epoch 73/250\n",
      "392/392 [==============================] - 482s 1s/step - loss: 0.3605 - val_loss: 0.5085 - lr: 1.0000e-04\n",
      "Epoch 74/250\n",
      "392/392 [==============================] - 490s 1s/step - loss: 0.3998 - val_loss: 0.5408 - lr: 1.0000e-04\n",
      "Epoch 75/250\n",
      "392/392 [==============================] - 505s 1s/step - loss: 0.3613 - val_loss: 0.5049 - lr: 1.0000e-04\n",
      "Epoch 76/250\n",
      "392/392 [==============================] - 500s 1s/step - loss: 0.3511 - val_loss: 0.4953 - lr: 1.0000e-04\n",
      "Epoch 77/250\n",
      "392/392 [==============================] - 481s 1s/step - loss: 0.3382 - val_loss: 0.4954 - lr: 1.0000e-04\n",
      "Epoch 78/250\n",
      "392/392 [==============================] - 498s 1s/step - loss: 0.3426 - val_loss: 0.4953 - lr: 1.0000e-04\n",
      "Epoch 79/250\n",
      "392/392 [==============================] - 482s 1s/step - loss: 0.3440 - val_loss: 0.5025 - lr: 1.0000e-04\n",
      "Epoch 80/250\n",
      "392/392 [==============================] - 486s 1s/step - loss: 0.3459 - val_loss: 0.4930 - lr: 1.0000e-04\n",
      "Epoch 81/250\n",
      "392/392 [==============================] - 492s 1s/step - loss: 0.3394 - val_loss: 0.4965 - lr: 1.0000e-04\n",
      "Epoch 82/250\n",
      "392/392 [==============================] - 498s 1s/step - loss: 0.3274 - val_loss: 0.4909 - lr: 1.0000e-04\n",
      "Epoch 83/250\n",
      "392/392 [==============================] - 496s 1s/step - loss: 0.3218 - val_loss: 0.4984 - lr: 1.0000e-04\n",
      "Epoch 84/250\n",
      "392/392 [==============================] - 486s 1s/step - loss: 0.3256 - val_loss: 0.5043 - lr: 1.0000e-04\n",
      "Epoch 85/250\n",
      "392/392 [==============================] - 484s 1s/step - loss: 0.3447 - val_loss: 0.5012 - lr: 1.0000e-04\n",
      "Epoch 86/250\n",
      "392/392 [==============================] - 478s 1s/step - loss: 0.3302 - val_loss: 0.4947 - lr: 1.0000e-04\n",
      "Epoch 87/250\n",
      "392/392 [==============================] - 500s 1s/step - loss: 0.3280 - val_loss: 0.4924 - lr: 1.0000e-04\n",
      "Epoch 88/250\n",
      "392/392 [==============================] - 474s 1s/step - loss: 0.3199 - val_loss: 0.4894 - lr: 1.0000e-04\n",
      "Epoch 89/250\n",
      "392/392 [==============================] - 473s 1s/step - loss: 0.3275 - val_loss: 0.4905 - lr: 1.0000e-04\n",
      "Epoch 90/250\n",
      "392/392 [==============================] - 492s 1s/step - loss: 0.3115 - val_loss: 0.4925 - lr: 1.0000e-04\n",
      "Epoch 91/250\n",
      "392/392 [==============================] - 483s 1s/step - loss: 0.3083 - val_loss: 0.4853 - lr: 1.0000e-04\n",
      "Epoch 92/250\n",
      "392/392 [==============================] - 477s 1s/step - loss: 0.3072 - val_loss: 0.5013 - lr: 1.0000e-04\n",
      "Epoch 93/250\n",
      "392/392 [==============================] - 491s 1s/step - loss: 0.3149 - val_loss: 0.4949 - lr: 1.0000e-04\n",
      "Epoch 94/250\n",
      "392/392 [==============================] - 478s 1s/step - loss: 0.3258 - val_loss: 0.4814 - lr: 1.0000e-04\n",
      "Epoch 95/250\n",
      "392/392 [==============================] - 484s 1s/step - loss: 0.3166 - val_loss: 0.4974 - lr: 1.0000e-04\n",
      "Epoch 96/250\n",
      "392/392 [==============================] - 482s 1s/step - loss: 0.3124 - val_loss: 0.4881 - lr: 1.0000e-04\n",
      "Epoch 97/250\n",
      "392/392 [==============================] - 494s 1s/step - loss: 0.3243 - val_loss: 0.4870 - lr: 1.0000e-04\n",
      "Epoch 98/250\n",
      "392/392 [==============================] - 475s 1s/step - loss: 0.3216 - val_loss: 0.4889 - lr: 1.0000e-04\n",
      "Epoch 99/250\n",
      "392/392 [==============================] - 478s 1s/step - loss: 0.2995 - val_loss: 0.4762 - lr: 1.0000e-04\n",
      "Epoch 100/250\n",
      "392/392 [==============================] - 496s 1s/step - loss: 0.2948 - val_loss: 0.4762 - lr: 1.0000e-04\n",
      "Epoch 101/250\n",
      "286/392 [====================>.........] - ETA: 1:47 - loss: 0.3142"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen, epochs = EPOCHS, callbacks = [weights_callback, neptune_callback, LR_callback], validation_data = val_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76973515",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = 2\n",
    "index = 6\n",
    "z = 100 # test_gen[lib][0][1][index]\n",
    "band = 0\n",
    "print(f'z = {z}')\n",
    "str = np.asarray(encoder([np.array([test_gen[lib][0][0][index]]), np.array([test_gen[lib][0][1][index]])])[0])\n",
    "str = np.concatenate((str, np.array([z])))\n",
    "str = str.reshape(1, LATENT_DIM + 1)\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 5))\n",
    "axes[0].imshow(test_gen[lib][0][0][index][band], cmap = 'afmhot')\n",
    "axes[1].imshow(decoder([str])[0][band], cmap = 'afmhot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f31360",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3, 80):\n",
    "    for i in range(0, 512):\n",
    "        if test_gen[j][0][1][i] <= 0.1:\n",
    "            print(j)\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd8b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3, 80):\n",
    "    for i in range(0, 512):\n",
    "        if test_gen[j][0][1][i] >= 4:\n",
    "            print(j)\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166f1bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3, 80):\n",
    "    for i in range(0, 512):\n",
    "        if test_gen[j][0][1][i] >= 3.5:\n",
    "            print(j)\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9448c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 84):\n",
    "    l = 512\n",
    "    if i == 83:\n",
    "        l = 464\n",
    "    for j in range(0, l):\n",
    "        index = i * BATCH_SIZE + j + 1\n",
    "        stdout.write(\"\\rChecking %d samples of \" % (index) + \"42960\")\n",
    "        z = test_gen[i][0][1][j]\n",
    "        str = np.asarray(encoder([np.array([test_gen[i][0][0][j]]), np.array([test_gen[i][0][1][j]])])[0])\n",
    "        str = np.concatenate((str, np.array([z])))\n",
    "        str = str.reshape(1, LATENT_DIM + 1)\n",
    "        hdul = fits.PrimaryHDU(data = test_gen[i][0][0][j])\n",
    "        string = f\"/data/CVAE Generated/Full/Original Galaxy #{index}.fits\"\n",
    "        hdul.writeto(string, overwrite = True)\n",
    "        hdul = fits.PrimaryHDU(data = decoder([str])[0])\n",
    "        string = f\"/data/CVAE Generated/Full/Reconstructed Galaxy #{index}.fits\"\n",
    "        hdul.writeto(string, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8092e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_bands_max(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.amax(np.array([test_gen[0][0][0][i][j]])))\n",
    "            pred_array = np.append(pred_array, np.amax(np.array([model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]])))\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(\"Maximum normalized pixel value\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "        \n",
    "def scatter_bands_center(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_array = np.append(true_array, np.array([test_gen[0][0][0][i][j]])[0][63][63])\n",
    "            pred_array = np.append(pred_array, model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j][63][63])\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel(\"Bands\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(\"Central pixel value\")\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "\n",
    "def scatter_bands_percentile(percentile = 90, num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show /  5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_90 = np.percentile(np.array([test_gen[0][0][0][i][j]]).flatten(), percentile)\n",
    "            pred_90 = np.percentile(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]).flatten(), percentile)\n",
    "            true_array = np.append(true_array, true_90)\n",
    "            pred_array = np.append(pred_array, pred_90)\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel('Bands')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel(f'{percentile}th percentile normalized pixel value')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "\n",
    "def scatter_bands_mean(num_to_show = 10, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = int(num_to_show / 5), ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        true_array = np.array([])\n",
    "        pred_array = np.array([])\n",
    "        for j in range(0, 5):\n",
    "            true_mean = np.mean(np.array([test_gen[0][0][0][i][j]]).flatten())\n",
    "            pred_mean = np.mean(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]).flatten())\n",
    "            true_array = np.append(true_array, true_mean)\n",
    "            pred_array = np.append(pred_array, pred_mean)\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, true_array, c = 'blue', label = 'True')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].scatter(x_array, pred_array, c = 'red', label = 'Predicted')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_xlabel('Bands')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].set_ylabel('Mean normalized pixel value')\n",
    "        axes[int((i - index) / 5)][int((i - index) % 5)].legend()\n",
    "\n",
    "def display_histograms(num_to_show = 2, index = 0):\n",
    "    fig, axes = plt.subplots(nrows = num_to_show, ncols = 5, figsize = (20, int(num_to_show)))\n",
    "    for i in range(index, index + num_to_show):\n",
    "        x_array = np.arange(5)\n",
    "        for j in range(0, 5):\n",
    "            true_arr = sorted(np.array([test_gen[0][0][0][i][j]]).flatten())\n",
    "            pred_arr = sorted(np.asarray(model([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])])[0][j]).flatten())\n",
    "            true_arr = true_arr[0 : int(len(true_arr) * .99)]\n",
    "            pred_arr = pred_arr[0 : int(len(pred_arr) * .99)]\n",
    "            axes[i][j].hist(true_arr, 100, color = 'blue', label = 'True', alpha = 0.5)\n",
    "            axes[i][j].hist(pred_arr, 100, color = 'red', label = 'Predicted', alpha = 0.5)\n",
    "            axes[i][j].set_xlabel(\"Pixel Values\")\n",
    "            axes[i][j].set_ylabel(\"Count\")\n",
    "            axes[i][j].legend()\n",
    "    fig.suptitle('Histograms of Predicted vs. True Image, Horizontal are Bands')\n",
    "    \n",
    "def display_5_bands(index):\n",
    "    fig, axes = plt.subplots(nrows = 2, ncols = 5, figsize = (20, 10))\n",
    "    loss = round(model.evaluate([np.array([test_gen[0][0][0][index]]), np.array([test_gen[0][0][1][index]])], np.array([test_gen[0][0][0][index]]), verbose = 0), 2)\n",
    "    for i in range(0, 5):\n",
    "        axes[0][i].imshow(np.array([test_gen[0][0][0][index]])[0][i], cmap = 'afmhot')\n",
    "        max_pixel_true = round(np.amax(np.array([test_gen[0][0][0][index]])[0][i]), 2)\n",
    "        # axes[0][i].set_title(f'True band {i} max = {max_pixel_true}')\n",
    "        pred = model([np.array([test_gen[0][0][0][index]]), np.array([test_gen[0][0][1][index]])])[0][i]\n",
    "        axes[1][i].imshow(pred, cmap = 'afmhot')\n",
    "        max_pixel_pred = round(np.amax(pred), 2)\n",
    "        axes[1][i].set_title(f'\\n loss = {loss}') # f'Pred band {i} max = {max_pixel_pred}' + \n",
    "        \n",
    "def display_high_loss(num_to_show, min_loss):\n",
    "    fig, axes = plt.subplots(nrows = num_to_show, ncols = 5, figsize = (20, 5 * num_to_show))\n",
    "    r = 0\n",
    "    for i in range(BATCH_SIZE):\n",
    "        loss = round(model.evaluate([np.array([test_gen[0][0][0][i]]), np.array([test_gen[0][0][1][i]])], np.array([test_gen[0][0][0][i]]), verbose = 0), 2)\n",
    "        if loss >= min_loss:\n",
    "            print(i)\n",
    "            for j in range(0, 5):\n",
    "                axes[r][j].imshow(np.array([test_gen[0][0][0][i]])[0][j], cmap = 'afmhot')\n",
    "                axes[r][j].set_title(f'Loss = {loss}')\n",
    "            r += 1\n",
    "        if r >= num_to_show:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2457f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_center()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_mean(10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c48efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_bands_percentile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3369ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eeb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_5_bands(38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_high_loss(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn",
   "language": "python",
   "name": "bnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3633e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from astropy.io import fits\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from DataMaker import *\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import keras\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Input, Concatenate\n",
    "\n",
    "from photoz_utils import *\n",
    "from DataMaker import *\n",
    "from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
    "import neptune.new as neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75753d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 10GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e0a333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: albumentations in ./.local/lib/python3.8/site-packages (1.2.1)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in ./.local/lib/python3.8/site-packages (from albumentations) (4.6.0.66)\n",
      "Requirement already satisfied: qudida>=0.0.4 in ./.local/lib/python3.8/site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.11.1 in ./.local/lib/python3.8/site-packages (from albumentations) (1.19.5)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from albumentations) (1.6.2)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations) (3.7.4.3)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations) (0.24.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (2.21.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (2.8.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (2022.8.8)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from typing import Tuple, Union, Optional\n",
    "\n",
    "import h5py as h5\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "!pip install albumentations\n",
    "from albumentations import Compose\n",
    "import numpy as np\n",
    "\n",
    "available_modes = {\"train\", \"test\"}\n",
    "available_labels_encoding = {\"hot\", \"smooth\", False}\n",
    "\n",
    "\n",
    "class HDF5ImageGenerator(Sequence):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        src,\n",
    "        #X_key=\"images\",\n",
    "        y_key=\"labels\",\n",
    "        classes_key=None,\n",
    "        batch_size=200,\n",
    "        shuffle=True,\n",
    "        scaler=True,\n",
    "        num_classes=None,\n",
    "        labels_encoding=\"hot\",\n",
    "        smooth_factor=0.1,\n",
    "        augmenter=False,\n",
    "        mode=\"train\",\n",
    "    ):\n",
    "\n",
    "        if mode not in available_modes:\n",
    "            raise ValueError('`mode` should be `train` '\n",
    "                             '(fit_generator() and evaluate_generator()) or '\n",
    "                             '`test` (predict_generator(). '\n",
    "                             'Received: %s' % mode)\n",
    "        self.mode = mode\n",
    "\n",
    "        if labels_encoding not in available_labels_encoding:\n",
    "            raise ValueError('`labels_encoding` should be `hot` '\n",
    "                             '(classic binary matrix) or '\n",
    "                             '`smooth` (smooth encoding) or '\n",
    "                             'False (no labels encoding). '\n",
    "                             'Received: %s' % labels_encoding)\n",
    "        self.labels_encoding = labels_encoding\n",
    "\n",
    "        if (self.labels_encoding == \"smooth\") and not (0 < smooth_factor <= 1):\n",
    "            raise ValueError('`smooth` labels encoding '\n",
    "                             'must use a `smooth_factor` '\n",
    "                             '< 0 smooth_factor <= 1')\n",
    "\n",
    "        if augmenter and not isinstance(augmenter, Compose):\n",
    "            raise ValueError('`augmenter` argument '\n",
    "                             'must be an instance of albumentations '\n",
    "                             '`Compose` class. '\n",
    "                             'Received type: %s' % type(augmenter))\n",
    "        self.augmenter = augmenter\n",
    "\n",
    "        self.src: str = src\n",
    "        #self.X_key: str = X_key\n",
    "        self.y_key: str = y_key\n",
    "        self.classes_key: str = classes_key\n",
    "        self.batch_size: int = batch_size\n",
    "        self.shuffle: bool = shuffle\n",
    "        self.scaler: bool = scaler\n",
    "        self.num_classes: int = num_classes\n",
    "        self.smooth_factor: float = smooth_factor\n",
    "\n",
    "        self._indices = np.arange(self.__get_dataset_shape(self.y_key, 0))\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Representation of the class.\"\"\"\n",
    "        return f\"{self.__class__.__name__}({self.__dict__!r})\"\n",
    "\n",
    "    def __get_dataset_shape(self, dataset: str, index: int) -> Tuple[int, ...]:\n",
    "        \"\"\"Get an h5py dataset shape.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        dataset : str\n",
    "            The dataset key.\n",
    "        index : int\n",
    "            The dataset index.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ints\n",
    "            A tuple of array dimensions.\n",
    "        \"\"\"\n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            return file[dataset].shape[index]\n",
    "\n",
    "    def __get_dataset_items(\n",
    "        self,\n",
    "        indices: np.ndarray,\n",
    "        dataset: Optional[str] = None\n",
    "    ) -> Union[np.ndarray, Tuple[np.ndarray]]:\n",
    "        \"\"\"Get an HDF5 dataset items.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        indices : ndarray, \n",
    "            The list of current batch indices.\n",
    "        dataset : (optional) str\n",
    "            The dataset key. If None, returns\n",
    "            a batch of (image tensors, labels).\n",
    "            Defaults to None.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray or a tuple of ndarrays\n",
    "            A batch of samples.\n",
    "        \"\"\"\n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            if dataset is not None:\n",
    "                return np.asarray(file[dataset][indices]).astype('float32')\n",
    "            else:\n",
    "                return np.asarray(file[self.y_key][indices]).astype('float32')\n",
    "            \n",
    "    \n",
    "    @property\n",
    "    def num_items(self) -> int:\n",
    "        \"\"\"Grab the total number of examples\n",
    "         from the dataset.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The total number of examples.\n",
    "        \"\"\"\n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            return file[self.y_key].shape[0]\n",
    "    \n",
    "    @property \n",
    "    def classes(self) -> list:\n",
    "        \"\"\"Grab \"human\" classes from the dataset.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of the raw classes.\n",
    "        \"\"\"\n",
    "        if self.classes_key is None:\n",
    "            raise ValueError('Canceled. parameter `classes_key` '\n",
    "                             'is set to None.')\n",
    "        \n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            return file[self.classes_key][:]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The number of batches per epochs.\n",
    "        \"\"\"\n",
    "        return int(\n",
    "            np.ceil(\n",
    "                self.__get_dataset_shape(self.y_key, 0) /\n",
    "                float(self.batch_size)))\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_labels_smoothing(batch_y: np.ndarray,\n",
    "                               factor: float) -> np.ndarray:\n",
    "        \"\"\"Applies labels smoothing to the original\n",
    "         labels binary matrix.\n",
    "         \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_y : np.ndarray\n",
    "            Current batch integer labels.\n",
    "        factor : float\n",
    "            Smoothing factor.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A binary class matrix.\n",
    "        \"\"\"\n",
    "        batch_y *= 1 - factor\n",
    "        batch_y += factor / batch_y.shape[1]\n",
    "\n",
    "        return batch_y\n",
    "\n",
    "    def apply_labels_encoding(\n",
    "            self,\n",
    "            batch_y: np.ndarray,\n",
    "            smooth_factor: Optional[float] = None) -> np.ndarray:\n",
    "        \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "         See Keras to_categorical utils function.\n",
    "         \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_y : np.ndarray\n",
    "            Current batch integer labels.\n",
    "        smooth_factor : (optional) Float\n",
    "            Smooth factor.\n",
    "            Defaults to None.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A binary class matrix.\n",
    "        \"\"\"\n",
    "        batch_y = to_categorical(batch_y, num_classes=self.num_classes)\n",
    "\n",
    "        if smooth_factor is not None:\n",
    "            batch_y = self.apply_labels_smoothing(batch_y,\n",
    "                                                  factor=smooth_factor)\n",
    "\n",
    "        return batch_y\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_normalization(batch_X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalize the pixel intensities. \n",
    "        \n",
    "        Normalize the pixel intensities to the range [0, 1].\n",
    "         \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_X : np.ndarray\n",
    "            Batch of image tensors to be normalized.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A batch of normalized image tensors.\n",
    "        \"\"\"\n",
    "        return batch_X.astype(\"float32\") / 4.0\n",
    "\n",
    "\n",
    "\n",
    "    def __next_batch(self,\n",
    "                     indices: np.ndarray) -> Tuple[np.ndarray]:\n",
    "        \"\"\"Generates a batch of train/val data for the given indices.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        index : int\n",
    "            The index for the batch.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ndarrays\n",
    "            A tuple containing a batch of image tensors\n",
    "            and their associated labels.\n",
    "        \"\"\"\n",
    "        # Grab samples (tensors, labels) HDF5 source file.\n",
    "        (batch_y) = np.asarray(self.__get_dataset_items(indices))\n",
    "\n",
    "\n",
    "        if self.labels_encoding:\n",
    "            batch_y = self.apply_labels_encoding(\n",
    "                batch_y,\n",
    "                smooth_factor=self.smooth_factor\n",
    "                if self.labels_encoding == \"smooth\" else None,\n",
    "            )\n",
    "\n",
    "        return (batch_y)\n",
    "\n",
    "    def __getitem__(\n",
    "            self,\n",
    "            index: int) -> Union[np.ndarray, Tuple[np.ndarray]]:\n",
    "        \"\"\"Generates a batch of data for the given index.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        index : int\n",
    "            The index for the current batch.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ndarrays or ndarray\n",
    "            A tuple containing a batch of image tensors\n",
    "            and their associated labels (train) or\n",
    "            a tuple of image tensors (predict).\n",
    "        \"\"\"\n",
    "        # Indices for the current batch.\n",
    "        indices = np.sort(self._indices[index * self.batch_size:(index + 1) *\n",
    "                                        self.batch_size])\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            return self.__next_batch(indices)\n",
    "        else:\n",
    "            return self.__next_batch_test(indices)\n",
    "\n",
    "    def __shuffle_indices(self):\n",
    "        \"\"\"If the shuffle parameter is set to True,\n",
    "         dataset will be shuffled (in-place).\n",
    "         (not available in test 'mode').\n",
    "        \"\"\"\n",
    "        if (self.mode == \"train\") and self.shuffle:\n",
    "            np.random.shuffle(self._indices)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Triggered once at the very beginning as well as \n",
    "         at the end of each epoch.\n",
    "        \"\"\"\n",
    "        self.__shuffle_indices()\n",
    "        \n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "IMAGE_SHAPE = (5, 127, 127)\n",
    "BATCH_SIZE = 200\n",
    "EPOCHS = 5\n",
    "GB_LIMIT = 5\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "args_gen = {'y_key': 'specz_redshift',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': False}\n",
    "\n",
    "TRAIN_PATH  = '/data/HSC/HSC_v6/step2A/127x127/divisible_training/five_band_image127x127_with_metadata_corrected_training_divisible.hdf5'\n",
    "VAL_PATH = '/data/HSC/HSC_v6/step2A/127x127/divisible_training/five_band_image127x127_with_metadata_corrected_validation_divisible.hdf5'\n",
    "TEST_PATH = '/data/HSC/HSC_v6/step2A/127x127/divisible_training/five_band_image127x127_with_metadata_corrected_testing_divisible.hdf5'\n",
    "\n",
    "\n",
    "train_gen_label = HDF5ImageGenerator(src=TRAIN_PATH, **args_gen)\n",
    "val_gen_label = HDF5ImageGenerator(src=VAL_PATH, **args_gen)\n",
    "test_gen_label = HDF5ImageGenerator(src=TEST_PATH, **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed6bc381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: albumentations in ./.local/lib/python3.8/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in ./.local/lib/python3.8/site-packages (from albumentations) (1.19.5)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in ./.local/lib/python3.8/site-packages (from albumentations) (4.6.0.66)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from albumentations) (1.6.2)\n",
      "Requirement already satisfied: qudida>=0.0.4 in ./.local/lib/python3.8/site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations) (3.7.4.3)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations) (0.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (20.9)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (2022.8.8)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (2.8.5)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (2.21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from typing import Tuple, Union, Optional\n",
    "\n",
    "import h5py as h5\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "!pip install albumentations\n",
    "from albumentations import Compose\n",
    "import numpy as np\n",
    "\n",
    "available_modes = {\"train\", \"test\"}\n",
    "available_labels_encoding = {\"hot\", \"smooth\", False}\n",
    "\n",
    "\n",
    "class HDF5ImageGenerator(Sequence):\n",
    "    \"\"\"Just a simple custom Keras HDF5 ImageDataGenerator.\n",
    "    \n",
    "    Custom Keras ImageDataGenerator that generates\n",
    "    batches of tensor images from HDF5 files with (optional) real-time\n",
    "    data augmentation.\n",
    "     \n",
    "    Arguments\n",
    "    ---------\n",
    "    src : str\n",
    "        Path of the hdf5 source file.\n",
    "    X_key : str\n",
    "        Key of the h5 file image tensors dataset.\n",
    "        Default is \"images\".\n",
    "    y_key : str\n",
    "        Key of the h5 file labels dataset.\n",
    "        Default is \"labels\".\n",
    "    classes_key : str\n",
    "        Key of the h5 file dataset containing\n",
    "        the raw classes.\n",
    "        Default is None.\n",
    "    batch_size : int\n",
    "        Size of each batch, must be a power of two.\n",
    "        (16, 32, 64, 128, 256, ...)\n",
    "        Default is 32.\n",
    "    shuffle : bool\n",
    "        Shuffle images at the end of each epoch.\n",
    "        Default is True.\n",
    "    scaler : \"std\", \"norm\" or False\n",
    "        \"std\" mode means standardization to range [-1, 1]\n",
    "        with 0 mean and unit variance.\n",
    "        \"norm\" mode means normalization to range [0, 1].\n",
    "        Default is \"std\".\n",
    "    num_classes : None or int\n",
    "        Specifies the total number of classes\n",
    "        for labels encoding.\n",
    "        Default is None.\n",
    "    labels_encoding : \"hot\", \"smooth\" or False\n",
    "        \"hot\" mode means classic one hot encoding.\n",
    "        \"smooth\" mode means smooth hot encoding.\n",
    "        Default is \"hot\".\n",
    "    smooth_factor : int or float\n",
    "        smooth factor used by smooth\n",
    "        labels encoding.\n",
    "        Default is 0.1.\n",
    "    augmenter : albumentations Compose([]) Pipeline or False\n",
    "        An albumentations transformations pipeline\n",
    "        to apply to each sample.\n",
    "        Default is False.\n",
    "    mode : str \"train\" or \"test\"\n",
    "        Model generator type. \"train\" is used for\n",
    "        fit_generator() and evaluate_generator.\n",
    "        \"test\" is used for predict_generator().\n",
    "        Default is \"train\".\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Turn off scaler (scaler=False) if using the\n",
    "    ToFloat(max_value=255) transformation from\n",
    "    albumentations.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    Example of usage:\n",
    "    ```python\n",
    "    my_augmenter = Compose([\n",
    "        HorizontalFlip(p=0.5),\n",
    "        RandomContrast(limit=0.2, p=0.5),\n",
    "        RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
    "        RandomBrightness(limit=0.2, p=0.5),\n",
    "        Resize(227, 227, cv2.INTER_AREA)\n",
    "    ])\n",
    "\n",
    "    # Create the generator.\n",
    "    train_gen = HDF5ImageGenerator(\n",
    "        'path/to/my/file.h5',\n",
    "         augmenter=my_augmenter)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        src,\n",
    "        #X_key=\"images\",\n",
    "        y_key=\"labels\",\n",
    "        classes_key=None,\n",
    "        batch_size=200,\n",
    "        shuffle=True,\n",
    "        scaler=True,\n",
    "        num_classes=None,\n",
    "        labels_encoding=\"hot\",\n",
    "        smooth_factor=0.1,\n",
    "        augmenter=False,\n",
    "        mode=\"train\",\n",
    "    ):\n",
    "\n",
    "        if mode not in available_modes:\n",
    "            raise ValueError('`mode` should be `train` '\n",
    "                             '(fit_generator() and evaluate_generator()) or '\n",
    "                             '`test` (predict_generator(). '\n",
    "                             'Received: %s' % mode)\n",
    "        self.mode = mode\n",
    "\n",
    "        if labels_encoding not in available_labels_encoding:\n",
    "            raise ValueError('`labels_encoding` should be `hot` '\n",
    "                             '(classic binary matrix) or '\n",
    "                             '`smooth` (smooth encoding) or '\n",
    "                             'False (no labels encoding). '\n",
    "                             'Received: %s' % labels_encoding)\n",
    "        self.labels_encoding = labels_encoding\n",
    "\n",
    "        if (self.labels_encoding == \"smooth\") and not (0 < smooth_factor <= 1):\n",
    "            raise ValueError('`smooth` labels encoding '\n",
    "                             'must use a `smooth_factor` '\n",
    "                             '< 0 smooth_factor <= 1')\n",
    "\n",
    "        if augmenter and not isinstance(augmenter, Compose):\n",
    "            raise ValueError('`augmenter` argument '\n",
    "                             'must be an instance of albumentations '\n",
    "                             '`Compose` class. '\n",
    "                             'Received type: %s' % type(augmenter))\n",
    "        self.augmenter = augmenter\n",
    "\n",
    "        self.src: str = src\n",
    "        #self.X_key: str = X_key\n",
    "        self.y_key: str = y_key\n",
    "        self.classes_key: str = classes_key\n",
    "        self.batch_size: int = batch_size\n",
    "        self.shuffle: bool = shuffle\n",
    "        self.scaler: bool = scaler\n",
    "        self.num_classes: int = num_classes\n",
    "        self.smooth_factor: float = smooth_factor\n",
    "\n",
    "        self._indices = np.arange(self.__get_dataset_shape(self.y_key, 0))\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Representation of the class.\"\"\"\n",
    "        return f\"{self.__class__.__name__}({self.__dict__!r})\"\n",
    "\n",
    "    def __get_dataset_shape(self, dataset: str, index: int) -> Tuple[int, ...]:\n",
    "        \"\"\"Get an h5py dataset shape.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        dataset : str\n",
    "            The dataset key.\n",
    "        index : int\n",
    "            The dataset index.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ints\n",
    "            A tuple of array dimensions.\n",
    "        \"\"\"\n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            return file[dataset].shape[index]\n",
    "\n",
    "    def __get_dataset_items(\n",
    "        self,\n",
    "        indices: np.ndarray,\n",
    "        dataset: Optional[str] = None\n",
    "    ) -> Union[np.ndarray, Tuple[np.ndarray]]:\n",
    "        \"\"\"Get an HDF5 dataset items.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        indices : ndarray, \n",
    "            The list of current batch indices.\n",
    "        dataset : (optional) str\n",
    "            The dataset key. If None, returns\n",
    "            a batch of (image tensors, labels).\n",
    "            Defaults to None.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray or a tuple of ndarrays\n",
    "            A batch of samples.\n",
    "        \"\"\"\n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            if dataset is not None:\n",
    "                return np.asarray(file[dataset][indices]).astype('float32')\n",
    "            else:\n",
    "                return np.asarray(file[self.y_key][indices]).astype('float32')\n",
    "    \n",
    "    @property\n",
    "    def num_items(self) -> int:\n",
    "        \"\"\"Grab the total number of examples\n",
    "         from the dataset.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The total number of examples.\n",
    "        \"\"\"\n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            return file[self.y_key].shape[0]\n",
    "    \n",
    "    @property \n",
    "    def classes(self) -> list:\n",
    "        \"\"\"Grab \"human\" classes from the dataset.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of the raw classes.\n",
    "        \"\"\"\n",
    "        if self.classes_key is None:\n",
    "            raise ValueError('Canceled. parameter `classes_key` '\n",
    "                             'is set to None.')\n",
    "        \n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            return file[self.classes_key][:]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The number of batches per epochs.\n",
    "        \"\"\"\n",
    "        return int(\n",
    "            np.ceil(\n",
    "                self.__get_dataset_shape(self.y_key, 0) /\n",
    "                float(self.batch_size)))\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_labels_smoothing(batch_y: np.ndarray,\n",
    "                               factor: float) -> np.ndarray:\n",
    "        \"\"\"Applies labels smoothing to the original\n",
    "         labels binary matrix.\n",
    "         \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_y : np.ndarray\n",
    "            Current batch integer labels.\n",
    "        factor : float\n",
    "            Smoothing factor.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A binary class matrix.\n",
    "        \"\"\"\n",
    "        batch_y *= 1 - factor\n",
    "        batch_y += factor / batch_y.shape[1]\n",
    "\n",
    "        return batch_y\n",
    "\n",
    "    def apply_labels_encoding(\n",
    "            self,\n",
    "            batch_y: np.ndarray,\n",
    "            smooth_factor: Optional[float] = None) -> np.ndarray:\n",
    "        \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "         See Keras to_categorical utils function.\n",
    "         \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_y : np.ndarray\n",
    "            Current batch integer labels.\n",
    "        smooth_factor : (optional) Float\n",
    "            Smooth factor.\n",
    "            Defaults to None.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A binary class matrix.\n",
    "        \"\"\"\n",
    "        batch_y = to_categorical(batch_y, num_classes=self.num_classes)\n",
    "\n",
    "        if smooth_factor is not None:\n",
    "            batch_y = self.apply_labels_smoothing(batch_y,\n",
    "                                                  factor=smooth_factor)\n",
    "\n",
    "        return batch_y\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_normalization(batch_X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalize the pixel intensities. \n",
    "        \n",
    "        Normalize the pixel intensities to the range [0, 1].\n",
    "         \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_X : np.ndarray\n",
    "            Batch of image tensors to be normalized.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A batch of normalized image tensors.\n",
    "        \"\"\"\n",
    "        return batch_X.astype(\"float32\") / 4.0\n",
    "\n",
    "\n",
    "\n",
    "    def __next_batch(self,\n",
    "                     indices: np.ndarray) -> Tuple[np.ndarray]:\n",
    "        \"\"\"Generates a batch of train/val data for the given indices.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        index : int\n",
    "            The index for the batch.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ndarrays\n",
    "            A tuple containing a batch of image tensors\n",
    "            and their associated labels.\n",
    "        \"\"\"\n",
    "        # Grab samples (tensors, labels) HDF5 source file.\n",
    "        (batch_y) = np.asarray(self.__get_dataset_items(indices))\n",
    "\n",
    "\n",
    "        if self.labels_encoding:\n",
    "            batch_y = self.apply_labels_encoding(\n",
    "                batch_y,\n",
    "                smooth_factor=self.smooth_factor\n",
    "                if self.labels_encoding == \"smooth\" else None,\n",
    "            )\n",
    "\n",
    "        return (batch_y)\n",
    "\n",
    "    def __getitem__(\n",
    "            self,\n",
    "            index: int) -> Union[np.ndarray, Tuple[np.ndarray]]:\n",
    "        \"\"\"Generates a batch of data for the given index.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        index : int\n",
    "            The index for the current batch.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ndarrays or ndarray\n",
    "            A tuple containing a batch of image tensors\n",
    "            and their associated labels (train) or\n",
    "            a tuple of image tensors (predict).\n",
    "        \"\"\"\n",
    "        # Indices for the current batch.\n",
    "        indices = np.sort(self._indices[index * self.batch_size:(index + 1) *\n",
    "                                        self.batch_size])\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            return self.__next_batch(indices)\n",
    "        else:\n",
    "            return self.__next_batch_test(indices)\n",
    "\n",
    "    def __shuffle_indices(self):\n",
    "        \"\"\"If the shuffle parameter is set to True,\n",
    "         dataset will be shuffled (in-place).\n",
    "         (not available in test 'mode').\n",
    "        \"\"\"\n",
    "        if (self.mode == \"train\") and self.shuffle:\n",
    "            np.random.shuffle(self._indices)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Triggered once at the very beginning as well as \n",
    "         at the end of each epoch.\n",
    "        \"\"\"\n",
    "        self.__shuffle_indices()\n",
    "        \n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "IMAGE_SHAPE = (5, 127, 127)\n",
    "BATCH_SIZE = 200\n",
    "EPOCHS = 5\n",
    "GB_LIMIT = 5\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "args_gen = {'y_key': 'g_cmodel_mag',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': False}\n",
    "\n",
    "\n",
    "\n",
    "train_gen_gmag = HDF5ImageGenerator(src=TRAIN_PATH, **args_gen)\n",
    "val_gen_gmag = HDF5ImageGenerator(src=VAL_PATH, **args_gen)\n",
    "test_gen_gmag = HDF5ImageGenerator(src=TEST_PATH, **args_gen)\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "args_gen = {'y_key': 'r_cmodel_mag',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': False}\n",
    "\n",
    "\n",
    "train_gen_rmag = HDF5ImageGenerator(src=TRAIN_PATH, **args_gen)\n",
    "val_gen_rmag= HDF5ImageGenerator(src=VAL_PATH, **args_gen)\n",
    "test_gen_rmag = HDF5ImageGenerator(src=TEST_PATH, **args_gen)\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "args_gen = {'y_key': 'i_cmodel_mag',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': False}\n",
    "\n",
    "\n",
    "train_gen_imag = HDF5ImageGenerator(src=TRAIN_PATH, **args_gen)\n",
    "val_gen_imag= HDF5ImageGenerator(src=VAL_PATH, **args_gen)\n",
    "test_gen_imag = HDF5ImageGenerator(src=TEST_PATH, **args_gen)\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "args_gen = {'y_key': 'z_cmodel_mag',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': False}\n",
    "\n",
    "\n",
    "train_gen_zmag = HDF5ImageGenerator(src=TRAIN_PATH, **args_gen)\n",
    "val_gen_zmag= HDF5ImageGenerator(src=VAL_PATH, **args_gen)\n",
    "test_gen_zmag = HDF5ImageGenerator(src=TEST_PATH, **args_gen)\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "args_gen = {'y_key': 'y_cmodel_mag',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': False}\n",
    "\n",
    "\n",
    "train_gen_ymag = HDF5ImageGenerator(src=TRAIN_PATH, **args_gen)\n",
    "val_gen_ymag= HDF5ImageGenerator(src=VAL_PATH, **args_gen)\n",
    "test_gen_ymag = HDF5ImageGenerator(src=TEST_PATH, **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5066d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feb209da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: albumentations in ./.local/lib/python3.8/site-packages (1.2.1)\n",
      "Requirement already satisfied: qudida>=0.0.4 in ./.local/lib/python3.8/site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in ./.local/lib/python3.8/site-packages (from albumentations) (4.6.0.66)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: numpy>=1.11.1 in ./.local/lib/python3.8/site-packages (from albumentations) (1.19.5)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from albumentations) (1.6.2)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations) (0.24.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations) (3.7.4.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (2.21.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (2022.8.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (2.8.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from typing import Tuple, Union, Optional\n",
    "\n",
    "import h5py as h5\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "!pip install albumentations\n",
    "from albumentations import Compose\n",
    "import numpy as np\n",
    "\n",
    "available_modes = {\"train\", \"test\"}\n",
    "available_labels_encoding = {\"hot\", \"smooth\", False}\n",
    "\n",
    "\n",
    "class HDF5ImageGenerator(Sequence):\n",
    "    \"\"\"Just a simple custom Keras HDF5 ImageDataGenerator.\n",
    "    \n",
    "    Custom Keras ImageDataGenerator that generates\n",
    "    batches of tensor images from HDF5 files with (optional) real-time\n",
    "    data augmentation.\n",
    "     \n",
    "    Arguments\n",
    "    ---------\n",
    "    src : str\n",
    "        Path of the hdf5 source file.\n",
    "    X_key : str\n",
    "        Key of the h5 file image tensors dataset.\n",
    "        Default is \"images\".\n",
    "    y_key : str\n",
    "        Key of the h5 file labels dataset.\n",
    "        Default is \"labels\".\n",
    "    classes_key : str\n",
    "        Key of the h5 file dataset containing\n",
    "        the raw classes.\n",
    "        Default is None.\n",
    "    batch_size : int\n",
    "        Size of each batch, must be a power of two.\n",
    "        (16, 32, 64, 128, 256, ...)\n",
    "        Default is 32.\n",
    "    shuffle : bool\n",
    "        Shuffle images at the end of each epoch.\n",
    "        Default is True.\n",
    "    scaler : \"std\", \"norm\" or False\n",
    "        \"std\" mode means standardization to range [-1, 1]\n",
    "        with 0 mean and unit variance.\n",
    "        \"norm\" mode means normalization to range [0, 1].\n",
    "        Default is \"std\".\n",
    "    num_classes : None or int\n",
    "        Specifies the total number of classes\n",
    "        for labels encoding.\n",
    "        Default is None.\n",
    "    labels_encoding : \"hot\", \"smooth\" or False\n",
    "        \"hot\" mode means classic one hot encoding.\n",
    "        \"smooth\" mode means smooth hot encoding.\n",
    "        Default is \"hot\".\n",
    "    smooth_factor : int or float\n",
    "        smooth factor used by smooth\n",
    "        labels encoding.\n",
    "        Default is 0.1.\n",
    "    augmenter : albumentations Compose([]) Pipeline or False\n",
    "        An albumentations transformations pipeline\n",
    "        to apply to each sample.\n",
    "        Default is False.\n",
    "    mode : str \"train\" or \"test\"\n",
    "        Model generator type. \"train\" is used for\n",
    "        fit_generator() and evaluate_generator.\n",
    "        \"test\" is used for predict_generator().\n",
    "        Default is \"train\".\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Turn off scaler (scaler=False) if using the\n",
    "    ToFloat(max_value=255) transformation from\n",
    "    albumentations.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    Example of usage:\n",
    "    ```python\n",
    "    my_augmenter = Compose([\n",
    "        HorizontalFlip(p=0.5),\n",
    "        RandomContrast(limit=0.2, p=0.5),\n",
    "        RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
    "        RandomBrightness(limit=0.2, p=0.5),\n",
    "        Resize(227, 227, cv2.INTER_AREA)\n",
    "    ])\n",
    "\n",
    "    # Create the generator.\n",
    "    train_gen = HDF5ImageGenerator(\n",
    "        'path/to/my/file.h5',\n",
    "         augmenter=my_augmenter)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        src,\n",
    "        #X_key=\"images\",\n",
    "        y_key=\"labels\",\n",
    "        classes_key=None,\n",
    "        batch_size=200,\n",
    "        shuffle=True,\n",
    "        scaler=True,\n",
    "        num_classes=None,\n",
    "        labels_encoding=\"hot\",\n",
    "        smooth_factor=0.1,\n",
    "        augmenter=False,\n",
    "        mode=\"train\",\n",
    "    ):\n",
    "\n",
    "        if mode not in available_modes:\n",
    "            raise ValueError('`mode` should be `train` '\n",
    "                             '(fit_generator() and evaluate_generator()) or '\n",
    "                             '`test` (predict_generator(). '\n",
    "                             'Received: %s' % mode)\n",
    "        self.mode = mode\n",
    "\n",
    "        if labels_encoding not in available_labels_encoding:\n",
    "            raise ValueError('`labels_encoding` should be `hot` '\n",
    "                             '(classic binary matrix) or '\n",
    "                             '`smooth` (smooth encoding) or '\n",
    "                             'False (no labels encoding). '\n",
    "                             'Received: %s' % labels_encoding)\n",
    "        self.labels_encoding = labels_encoding\n",
    "\n",
    "        if (self.labels_encoding == \"smooth\") and not (0 < smooth_factor <= 1):\n",
    "            raise ValueError('`smooth` labels encoding '\n",
    "                             'must use a `smooth_factor` '\n",
    "                             '< 0 smooth_factor <= 1')\n",
    "\n",
    "        if augmenter and not isinstance(augmenter, Compose):\n",
    "            raise ValueError('`augmenter` argument '\n",
    "                             'must be an instance of albumentations '\n",
    "                             '`Compose` class. '\n",
    "                             'Received type: %s' % type(augmenter))\n",
    "        self.augmenter = augmenter\n",
    "\n",
    "        self.src: str = src\n",
    "        #self.X_key: str = X_key\n",
    "        self.y_key: str = y_key\n",
    "        self.classes_key: str = classes_key\n",
    "        self.batch_size: int = batch_size\n",
    "        self.shuffle: bool = shuffle\n",
    "        self.scaler: bool = scaler\n",
    "        self.num_classes: int = num_classes\n",
    "        self.smooth_factor: float = smooth_factor\n",
    "\n",
    "        self._indices = np.arange(self.__get_dataset_shape(self.y_key, 0))\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Representation of the class.\"\"\"\n",
    "        return f\"{self.__class__.__name__}({self.__dict__!r})\"\n",
    "\n",
    "    def __get_dataset_shape(self, dataset: str, index: int) -> Tuple[int, ...]:\n",
    "        \"\"\"Get an h5py dataset shape.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        dataset : str\n",
    "            The dataset key.\n",
    "        index : int\n",
    "            The dataset index.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ints\n",
    "            A tuple of array dimensions.\n",
    "        \"\"\"\n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            return file[dataset].shape[index]\n",
    "\n",
    "    def __get_dataset_items(\n",
    "        self,\n",
    "        indices: np.ndarray,\n",
    "        dataset: Optional[str] = None\n",
    "    ) -> Union[np.ndarray, Tuple[np.ndarray]]:\n",
    "        \"\"\"Get an HDF5 dataset items.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        indices : ndarray, \n",
    "            The list of current batch indices.\n",
    "        dataset : (optional) str\n",
    "            The dataset key. If None, returns\n",
    "            a batch of (image tensors, labels).\n",
    "            Defaults to None.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray or a tuple of ndarrays\n",
    "            A batch of samples.\n",
    "        \"\"\"\n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            if dataset is not None:\n",
    "                return np.asarray(file[dataset][indices]).astype('float32')\n",
    "            else:\n",
    "                return np.asarray(file[self.y_key][indices]).astype('float32')\n",
    "    \n",
    "    @property\n",
    "    def num_items(self) -> int:\n",
    "        \"\"\"Grab the total number of examples\n",
    "         from the dataset.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The total number of examples.\n",
    "        \"\"\"\n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            return file[self.y_key].shape[0]\n",
    "    \n",
    "    @property \n",
    "    def classes(self) -> list:\n",
    "        \"\"\"Grab \"human\" classes from the dataset.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of the raw classes.\n",
    "        \"\"\"\n",
    "        if self.classes_key is None:\n",
    "            raise ValueError('Canceled. parameter `classes_key` '\n",
    "                             'is set to None.')\n",
    "        \n",
    "        with h5.File(self.src, \"r\") as file:\n",
    "            return file[self.classes_key][:]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch.\n",
    "         \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The number of batches per epochs.\n",
    "        \"\"\"\n",
    "        return int(\n",
    "            np.ceil(\n",
    "                self.__get_dataset_shape(self.y_key, 0) /\n",
    "                float(self.batch_size)))\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_labels_smoothing(batch_y: np.ndarray,\n",
    "                               factor: float) -> np.ndarray:\n",
    "        \"\"\"Applies labels smoothing to the original\n",
    "         labels binary matrix.\n",
    "         \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_y : np.ndarray\n",
    "            Current batch integer labels.\n",
    "        factor : float\n",
    "            Smoothing factor.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A binary class matrix.\n",
    "        \"\"\"\n",
    "        batch_y *= 1 - factor\n",
    "        batch_y += factor / batch_y.shape[1]\n",
    "\n",
    "        return batch_y\n",
    "\n",
    "    def apply_labels_encoding(\n",
    "            self,\n",
    "            batch_y: np.ndarray,\n",
    "            smooth_factor: Optional[float] = None) -> np.ndarray:\n",
    "        \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "         See Keras to_categorical utils function.\n",
    "         \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_y : np.ndarray\n",
    "            Current batch integer labels.\n",
    "        smooth_factor : (optional) Float\n",
    "            Smooth factor.\n",
    "            Defaults to None.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A binary class matrix.\n",
    "        \"\"\"\n",
    "        batch_y = to_categorical(batch_y, num_classes=self.num_classes)\n",
    "\n",
    "        if smooth_factor is not None:\n",
    "            batch_y = self.apply_labels_smoothing(batch_y,\n",
    "                                                  factor=smooth_factor)\n",
    "\n",
    "        return batch_y\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_normalization(batch_X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalize the pixel intensities. \n",
    "        \n",
    "        Normalize the pixel intensities to the range [0, 1].\n",
    "         \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_X : np.ndarray\n",
    "            Batch of image tensors to be normalized.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A batch of normalized image tensors.\n",
    "        \"\"\"\n",
    "        return batch_X.astype(\"float32\") / 4.0\n",
    "\n",
    "    def __next_batch(self,\n",
    "                     indices: np.ndarray) -> Tuple[np.ndarray]:\n",
    "        \"\"\"Generates a batch of train/val data for the given indices.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        index : int\n",
    "            The index for the batch.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ndarrays\n",
    "            A tuple containing a batch of image tensors\n",
    "            and their associated labels.\n",
    "        \"\"\"\n",
    "        # Grab samples (tensors, labels) HDF5 source file.\n",
    "        (batch_y) = np.asarray(self.__get_dataset_items(indices))\n",
    "\n",
    "\n",
    "        # Shall we apply labels encoding?\n",
    "        if self.labels_encoding:\n",
    "            batch_y = self.apply_labels_encoding(\n",
    "                batch_y,\n",
    "                smooth_factor=self.smooth_factor\n",
    "                if self.labels_encoding == \"smooth\" else None,\n",
    "            )\n",
    "\n",
    "        return (batch_y)\n",
    "\n",
    "    def __getitem__(\n",
    "            self,\n",
    "            index: int) -> Union[np.ndarray, Tuple[np.ndarray]]:\n",
    "        \"\"\"Generates a batch of data for the given index.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        index : int\n",
    "            The index for the current batch.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of ndarrays or ndarray\n",
    "            A tuple containing a batch of image tensors\n",
    "            and their associated labels (train) or\n",
    "            a tuple of image tensors (predict).\n",
    "        \"\"\"\n",
    "        # Indices for the current batch.\n",
    "        indices = np.sort(self._indices[index * self.batch_size:(index + 1) *\n",
    "                                        self.batch_size])\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            return self.__next_batch(indices)\n",
    "        else:\n",
    "            return self.__next_batch_test(indices)\n",
    "\n",
    "    def __shuffle_indices(self):\n",
    "        \"\"\"If the shuffle parameter is set to True,\n",
    "         dataset will be shuffled (in-place).\n",
    "         (not available in test 'mode').\n",
    "        \"\"\"\n",
    "        if (self.mode == \"train\") and self.shuffle:\n",
    "            np.random.shuffle(self._indices)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Triggered once at the very beginning as well as \n",
    "         at the end of each epoch.\n",
    "        \"\"\"\n",
    "        self.__shuffle_indices()\n",
    "        \n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "IMAGE_SHAPE = (5, 127, 127)\n",
    "BATCH_SIZE = 200\n",
    "EPOCHS = 5\n",
    "GB_LIMIT = 5\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "args_gen = {'y_key': 'image',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': False}\n",
    "\n",
    "\n",
    "train_gen_image = HDF5ImageGenerator(src=TRAIN_PATH, **args_gen)\n",
    "val_gen_image = HDF5ImageGenerator(src=VAL_PATH, **args_gen)\n",
    "test_gen_image = HDF5ImageGenerator(src=TEST_PATH, **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1bb0edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42960\n"
     ]
    }
   ],
   "source": [
    "photozdata = h5py.File('../../data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_validation.hdf5', 'r')\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "spectro_z = np.asarray(photozdata[\"specz_redshift\"])\n",
    "col1 = np.asarray(photozdata[\"g_cmodel_mag\"])\n",
    "col2 = np.asarray(photozdata[\"r_cmodel_mag\"])\n",
    "col3 = np.asarray(photozdata[\"i_cmodel_mag\"])\n",
    "col4 =np.asarray(photozdata[\"z_cmodel_mag\"])\n",
    "col5 = np.asarray(photozdata[\"y_cmodel_mag\"])\n",
    "specz_err = np.asarray(photozdata[\"specz_redshift_err\"])\n",
    "gmag_err = np.asarray(photozdata[\"g_cmodel_magsigma\"])\n",
    "ymag_err = np.asarray(photozdata[\"y_cmodel_magsigma\"])\n",
    "\n",
    "photodata = {'col1':col1,\n",
    "             'col2':col2,\n",
    "             'col3':col3,\n",
    "             'col4':col4,\n",
    "             'col5':col5,\n",
    "             'specz_err': specz_err,\n",
    "             'gmag_err':gmag_err,\n",
    "             'ymag_err':ymag_err,\n",
    "             'specz':spectro_z\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(photodata)\n",
    "photodata = df\n",
    "\n",
    "photodata.replace(-99., np.nan, inplace=True)\n",
    "photodata.replace(-99.9, np.nan, inplace=True)\n",
    "photodata.replace(np.inf, np.nan, inplace=True)\n",
    "photodata= photodata.dropna(how='any')\n",
    "specz_err = photodata['specz_err']\n",
    "spectro_z = photodata['specz']\n",
    "gmag_err = photodata['gmag_err']\n",
    "ymag_err = photodata['ymag_err']\n",
    "photodata = photodata.drop(\"specz\", axis=1)\n",
    "photodata = photodata.drop(\"specz_err\", axis =1)\n",
    "photodata = photodata.drop(\"gmag_err\", axis =1)\n",
    "photodata = photodata.drop(\"ymag_err\", axis =1)\n",
    "\n",
    "print(len(photodata))\n",
    "photodata1 = np.array(photodata)\n",
    "#normalize\n",
    "photodata = min_max_scaler.fit_transform(photodata)\n",
    "photozdata.close()\n",
    "x_train_mags_scaled = photodata\n",
    "#x_train_mags_scaled ,x_test_mags_scaled,y_train2,y_test2 = train_test_split(photodata,random_state=42,test_size=0.0)\n",
    "y_train = spectro_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a320e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200481"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43d8e4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 5, 127, 127) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 127, 127) 1472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 63, 63)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 63, 63)   4128        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 31, 31)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 31, 31)   4128        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 31, 31)   4128        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 200)          1200        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 30752)        0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200)          40200       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_variational (DenseVariati (None, 400)          36903600    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 200)          40200       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_variational_1 (DenseVaria (None, 200)          240600      dense_variational[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 200)          40200       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 400)          0           dense_variational_1[0][0]        \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            802         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "independent_normal (Independent multiple             0           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 37,280,658\n",
      "Trainable params: 37,280,658\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "def posterior_mean_field(kernel_size: int, bias_size: int, dtype: any) -> tf.keras.Model:\n",
    "    \"\"\"Specify the surrogate posterior over `keras.layers.Dense` `kernel` and `bias`.\"\"\"\n",
    "    n = kernel_size + bias_size\n",
    "    c = np.log(np.expm1(1.))\n",
    "\n",
    "    return tf.keras.Sequential([\n",
    "        tfp.layers.VariableLayer(2 * n, dtype=dtype, initializer=lambda shape, dtype: random_gaussian_initializer(shape, dtype), trainable=True),\n",
    "        tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "            tfd.Normal(loc=t[..., :n],\n",
    "                       scale= + 10e-4*tf.nn.softplus(c + t[..., n:])),\n",
    "            reinterpreted_batch_ndims=1)),\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "def prior_trainable(kernel_size: int, bias_size: int, dtype: any) -> tf.keras.Model:\n",
    "    \"\"\"Specify the prior over `keras.layers.Dense` `kernel` and `bias`.\"\"\"\n",
    "    n = kernel_size + bias_size\n",
    "\n",
    "    return tf.keras.Sequential([\n",
    "        tfp.layers.VariableLayer(n, dtype=dtype),  # Returns a trainable variable of shape n, regardless of input\n",
    "        tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "            tfd.Normal(loc=t, scale=1),\n",
    "            reinterpreted_batch_ndims=1)),\n",
    "    ])\n",
    "#USE SKIP CONNECTION:\n",
    "def random_gaussian_initializer(shape, dtype):\n",
    "    n = int(shape / 2)\n",
    "    loc_norm = tf.random_normal_initializer(mean=0., stddev=0.1)\n",
    "    loc = tf.Variable(\n",
    "        initial_value=loc_norm(shape=(n,), dtype=dtype)\n",
    "    )\n",
    "    scale_norm = tf.random_normal_initializer(mean=-3., stddev=0.1)\n",
    "    scale = tf.Variable(\n",
    "        initial_value=scale_norm(shape=(n,), dtype=dtype)\n",
    "    )\n",
    "    return tf.concat([loc, scale], 0)\n",
    "\n",
    "def negative_loglikelihood(targets, estimated_distribution):\n",
    "    return -estimated_distribution.log_prob(targets)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "input1_ = tf.keras.layers.Input(shape=(5,127,127))\n",
    "input2_ = tf.keras.layers.Input(shape=(5,))\n",
    "\n",
    "\n",
    "#CNN\n",
    "conv1 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3),activation='tanh', padding='same', data_format='channels_first')(input1_)\n",
    "pooling1 = tf.keras.layers.MaxPooling2D(pool_size = (2,2),data_format='channels_first')(conv1)\n",
    "conv2 =tf.keras.layers.Conv2D(32, kernel_size=(2, 2),activation='tanh', padding='same', data_format='channels_first')(pooling1)\n",
    "pooling2 = tf.keras.layers.MaxPooling2D(pool_size = (2,2),data_format='channels_first')(conv2)\n",
    "\n",
    "conv3 = tf.keras.layers.Conv2D(32, kernel_size=(2, 2),activation='relu', padding='same', data_format='channels_first')(pooling2)\n",
    "conv4 = tf.keras.layers.Conv2D(32, kernel_size=(2,2 ),activation='relu', padding='same', data_format='channels_first')(conv3)\n",
    "flatten = tf.keras.layers.Flatten()(conv4)\n",
    "\n",
    "dense1 = tfp.layers.DenseVariational(400, activation=\"tanh\",make_posterior_fn=posterior_mean_field,\n",
    "                                      make_prior_fn=prior_trainable,\n",
    "                                      kl_weight=1 / len(y_train))(flatten)\n",
    "dense2 = tfp.layers.DenseVariational(200, activation=\"tanh\",make_posterior_fn=posterior_mean_field,\n",
    "                                      make_prior_fn=prior_trainable,\n",
    "                                      kl_weight=1 / len(y_train))(dense1)\n",
    "\n",
    "#NN regression:\n",
    "\n",
    "hidden1 = tf.keras.layers.Dense(200, activation=\"relu\")(input2_)\n",
    "hidden2 = tf.keras.layers.Dense(200, activation=\"relu\")(hidden1)\n",
    "hidden3 = tf.keras.layers.Dense(200, activation=\"relu\")(hidden2)\n",
    "hidden4 = tf.keras.layers.Dense(200, activation=\"relu\")(hidden3)\n",
    "\n",
    "\n",
    "#combine both outputs\n",
    "concat = tf.keras.layers.Concatenate()([dense2, hidden4])\n",
    "distribution_params = tf.keras.layers.Dense(units=2)(concat)\n",
    "output = tfp.layers.IndependentNormal(1)(distribution_params)\n",
    "\n",
    "#output = tf.keras.layers.Dense(1)(concat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input1_,input2_],outputs = [output])\n",
    "\n",
    "\n",
    "model.summary()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669aa256",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoinedMags(tf.keras.utils.Sequence):\n",
    "    def __init__(self, input_gen1, input_gen2, input_gen3,input_gen4,input_gen5):\n",
    "        self.gen1 = input_gen1\n",
    "        self.gen2 = input_gen2\n",
    "        self.gen3 = input_gen3\n",
    "        self.gen4 = input_gen4        \n",
    "        self.gen5 = input_gen5\n",
    "\n",
    "        #assert len(input_gen1) == len(input_gen2) == len(target_gen)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gen1)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x1 = self.gen1[i]\n",
    "        x2 = self.gen2[i]\n",
    "        x3 = self.gen3[i]\n",
    "        x4 = self.gen4[i]\n",
    "        x5 = self.gen5[i]\n",
    "\n",
    "        return np.column_stack([x1, x2, x3, x4, x5])\n",
    "    def on_epoch_end(self):\n",
    "        self.gen1.on_epoch_end()\n",
    "        self.gen2.on_epoch_end()\n",
    "        self.gen3.on_epoch_end()\n",
    "        self.gen4.on_epoch_end()\n",
    "        self.gen5.on_epoch_end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "538c9fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class JoinedGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, input_gen1, input_gen2, target_gen):\n",
    "        self.gen1 = input_gen1\n",
    "        self.gen2 = input_gen2\n",
    "        self.gen3 = target_gen\n",
    "\n",
    "        #assert len(input_gen1) == len(input_gen2) == len(target_gen)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gen1)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x1 = self.gen1[i]\n",
    "        x2 = self.gen2[i]\n",
    "        y = self.gen3[i]\n",
    "\n",
    "        return [x1, x2], y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.gen1.on_epoch_end()\n",
    "        self.gen2.on_epoch_end()\n",
    "        self.gen3.on_epoch_end()\n",
    "\n",
    "val_mags2 = JoinedMags(val_gen_gmag,val_gen_rmag,val_gen_imag,val_gen_zmag,val_gen_ymag)\n",
    "val_my_gen = JoinedGen(val_gen_image, val_mags2, val_gen_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bee455f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/astro-data-lab/BCNN/e/BCNN-8\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "#for neptune ai\n",
    "\n",
    "# params = {\"lr\": 0.0001, \"epochs\": 1000}\n",
    "\n",
    "# run = neptune.init(\n",
    "#     project=\"astro-data-lab/BCNN\",\n",
    "#     api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4NDU0YjdhYy01NjM4LTQwMDQtOGQxMC02YTQ2MDkyMzQ5MmUifQ==\",\n",
    "# )  # your credentials\n",
    "# run[\"parameters\"] = params\n",
    "# neptune_cbk = NeptuneCallback(run=run, base_namespace=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68e31e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from photoz_utils import *\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=params[\"lr\"])\n",
    "model.compile(optimizer=optimizer, loss=negative_loglikelihood,metrics=[tf.keras.metrics.RootMeanSquaredError()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13e2c3f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/astro-data-lab/Bayesian-CNN/e/BAY-22\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer DenseVariational has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1045.8564 - root_mean_squared_error: 0.0647\n",
      "Epoch 00001: loss improved from inf to 1045.85645, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 432s 431ms/step - loss: 1045.8564 - root_mean_squared_error: 0.0647 - val_loss: 1060.1315 - val_root_mean_squared_error: 0.2394\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1044.3706 - root_mean_squared_error: 0.0706\n",
      "Epoch 00002: loss improved from 1045.85645 to 1044.37061, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 501s 501ms/step - loss: 1044.3706 - root_mean_squared_error: 0.0706 - val_loss: 1092.3418 - val_root_mean_squared_error: 0.2378\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1042.7769 - root_mean_squared_error: 0.0632\n",
      "Epoch 00003: loss improved from 1044.37061 to 1042.77686, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 495s 495ms/step - loss: 1042.7769 - root_mean_squared_error: 0.0632 - val_loss: 1079.9331 - val_root_mean_squared_error: 0.2377\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1041.2565 - root_mean_squared_error: 0.0648\n",
      "Epoch 00004: loss improved from 1042.77686 to 1041.25647, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 455s 455ms/step - loss: 1041.2565 - root_mean_squared_error: 0.0648 - val_loss: 1093.8000 - val_root_mean_squared_error: 0.2396\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1039.8000 - root_mean_squared_error: 0.0614\n",
      "Epoch 00005: loss improved from 1041.25647 to 1039.80005, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 452s 452ms/step - loss: 1039.8000 - root_mean_squared_error: 0.0614 - val_loss: 1088.1738 - val_root_mean_squared_error: 0.2378\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1038.2489 - root_mean_squared_error: 0.0641\n",
      "Epoch 00006: loss improved from 1039.80005 to 1038.24890, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 466s 466ms/step - loss: 1038.2489 - root_mean_squared_error: 0.0641 - val_loss: 1083.3743 - val_root_mean_squared_error: 0.2380\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1036.7963 - root_mean_squared_error: 0.0627\n",
      "Epoch 00007: loss improved from 1038.24890 to 1036.79626, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 456s 456ms/step - loss: 1036.7963 - root_mean_squared_error: 0.0627 - val_loss: 1070.2456 - val_root_mean_squared_error: 0.2388\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1035.2710 - root_mean_squared_error: 0.0632\n",
      "Epoch 00008: loss improved from 1036.79626 to 1035.27100, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 482s 482ms/step - loss: 1035.2710 - root_mean_squared_error: 0.0632 - val_loss: 1068.6840 - val_root_mean_squared_error: 0.2377\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1033.8768 - root_mean_squared_error: 0.0636\n",
      "Epoch 00009: loss improved from 1035.27100 to 1033.87683, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 463s 463ms/step - loss: 1033.8768 - root_mean_squared_error: 0.0636 - val_loss: 1059.2078 - val_root_mean_squared_error: 0.2385\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1032.4062 - root_mean_squared_error: 0.0642\n",
      "Epoch 00010: loss improved from 1033.87683 to 1032.40625, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 479s 479ms/step - loss: 1032.4062 - root_mean_squared_error: 0.0642 - val_loss: 1074.3219 - val_root_mean_squared_error: 0.2377\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1030.8879 - root_mean_squared_error: 0.0617\n",
      "Epoch 00011: loss improved from 1032.40625 to 1030.88794, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 467s 467ms/step - loss: 1030.8879 - root_mean_squared_error: 0.0617 - val_loss: 1079.9213 - val_root_mean_squared_error: 0.2392\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1029.5175 - root_mean_squared_error: 0.0622\n",
      "Epoch 00012: loss improved from 1030.88794 to 1029.51746, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 472s 472ms/step - loss: 1029.5175 - root_mean_squared_error: 0.0622 - val_loss: 1070.5894 - val_root_mean_squared_error: 0.2390\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1028.0168 - root_mean_squared_error: 0.0606\n",
      "Epoch 00013: loss improved from 1029.51746 to 1028.01685, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 469s 469ms/step - loss: 1028.0168 - root_mean_squared_error: 0.0606 - val_loss: 1067.3860 - val_root_mean_squared_error: 0.2390\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1026.5682 - root_mean_squared_error: 0.0602\n",
      "Epoch 00014: loss improved from 1028.01685 to 1026.56824, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 470s 470ms/step - loss: 1026.5682 - root_mean_squared_error: 0.0602 - val_loss: 1062.5853 - val_root_mean_squared_error: 0.2377\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1025.1505 - root_mean_squared_error: 0.0596\n",
      "Epoch 00015: loss improved from 1026.56824 to 1025.15051, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 472s 472ms/step - loss: 1025.1505 - root_mean_squared_error: 0.0596 - val_loss: 1042.5129 - val_root_mean_squared_error: 0.2387\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1023.7473 - root_mean_squared_error: 0.0617\n",
      "Epoch 00016: loss improved from 1025.15051 to 1023.74725, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 468s 468ms/step - loss: 1023.7473 - root_mean_squared_error: 0.0617 - val_loss: 1055.6748 - val_root_mean_squared_error: 0.2380\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1022.3425 - root_mean_squared_error: 0.0624\n",
      "Epoch 00017: loss improved from 1023.74725 to 1022.34247, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 471s 471ms/step - loss: 1022.3425 - root_mean_squared_error: 0.0624 - val_loss: 1075.9434 - val_root_mean_squared_error: 0.2362\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1020.9276 - root_mean_squared_error: 0.0588\n",
      "Epoch 00018: loss improved from 1022.34247 to 1020.92761, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 465s 465ms/step - loss: 1020.9276 - root_mean_squared_error: 0.0588 - val_loss: 1074.3723 - val_root_mean_squared_error: 0.2367\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1019.5991 - root_mean_squared_error: 0.0609\n",
      "Epoch 00019: loss improved from 1020.92761 to 1019.59912, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 463s 463ms/step - loss: 1019.5991 - root_mean_squared_error: 0.0609 - val_loss: 1050.8680 - val_root_mean_squared_error: 0.2378\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1018.1872 - root_mean_squared_error: 0.0598\n",
      "Epoch 00020: loss improved from 1019.59912 to 1018.18719, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 474s 474ms/step - loss: 1018.1872 - root_mean_squared_error: 0.0598 - val_loss: 1044.0121 - val_root_mean_squared_error: 0.2386\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1016.7964 - root_mean_squared_error: 0.0579\n",
      "Epoch 00021: loss improved from 1018.18719 to 1016.79639, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 465s 465ms/step - loss: 1016.7964 - root_mean_squared_error: 0.0579 - val_loss: 1051.4579 - val_root_mean_squared_error: 0.2368\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1015.4781 - root_mean_squared_error: 0.0564\n",
      "Epoch 00022: loss improved from 1016.79639 to 1015.47809, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 460s 460ms/step - loss: 1015.4781 - root_mean_squared_error: 0.0564 - val_loss: 1053.5916 - val_root_mean_squared_error: 0.2377\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1014.0453 - root_mean_squared_error: 0.0571\n",
      "Epoch 00023: loss improved from 1015.47809 to 1014.04535, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 461s 461ms/step - loss: 1014.0453 - root_mean_squared_error: 0.0571 - val_loss: 1054.0082 - val_root_mean_squared_error: 0.2367\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1012.7526 - root_mean_squared_error: 0.0580\n",
      "Epoch 00024: loss improved from 1014.04535 to 1012.75262, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 465s 465ms/step - loss: 1012.7526 - root_mean_squared_error: 0.0580 - val_loss: 1054.2531 - val_root_mean_squared_error: 0.2379\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1011.4159 - root_mean_squared_error: 0.0580\n",
      "Epoch 00025: loss improved from 1012.75262 to 1011.41589, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 1011.4159 - root_mean_squared_error: 0.0580 - val_loss: 1032.7351 - val_root_mean_squared_error: 0.2388\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1010.0633 - root_mean_squared_error: 0.0576\n",
      "Epoch 00026: loss improved from 1011.41589 to 1010.06329, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 1010.0633 - root_mean_squared_error: 0.0576 - val_loss: 1056.0851 - val_root_mean_squared_error: 0.2381\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1008.7325 - root_mean_squared_error: 0.0590\n",
      "Epoch 00027: loss improved from 1010.06329 to 1008.73248, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 461s 461ms/step - loss: 1008.7325 - root_mean_squared_error: 0.0590 - val_loss: 1060.6127 - val_root_mean_squared_error: 0.2370\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1007.4119 - root_mean_squared_error: 0.0575\n",
      "Epoch 00028: loss improved from 1008.73248 to 1007.41187, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 460s 460ms/step - loss: 1007.4119 - root_mean_squared_error: 0.0575 - val_loss: 1036.2485 - val_root_mean_squared_error: 0.2392\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1006.1105 - root_mean_squared_error: 0.0552\n",
      "Epoch 00029: loss improved from 1007.41187 to 1006.11047, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 1006.1105 - root_mean_squared_error: 0.0552 - val_loss: 1050.0205 - val_root_mean_squared_error: 0.2383\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1004.7155 - root_mean_squared_error: 0.0556\n",
      "Epoch 00030: loss improved from 1006.11047 to 1004.71552, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 461s 461ms/step - loss: 1004.7155 - root_mean_squared_error: 0.0556 - val_loss: 1059.3019 - val_root_mean_squared_error: 0.2370\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1003.4338 - root_mean_squared_error: 0.0568\n",
      "Epoch 00031: loss improved from 1004.71552 to 1003.43378, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 452s 452ms/step - loss: 1003.4338 - root_mean_squared_error: 0.0568 - val_loss: 1045.6158 - val_root_mean_squared_error: 0.2377\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1002.2006 - root_mean_squared_error: 0.0569\n",
      "Epoch 00032: loss improved from 1003.43378 to 1002.20056, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 461s 460ms/step - loss: 1002.2006 - root_mean_squared_error: 0.0569 - val_loss: 1035.5116 - val_root_mean_squared_error: 0.2380\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1000.8167 - root_mean_squared_error: 0.0547\n",
      "Epoch 00033: loss improved from 1002.20056 to 1000.81665, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 460s 460ms/step - loss: 1000.8167 - root_mean_squared_error: 0.0547 - val_loss: 1049.4403 - val_root_mean_squared_error: 0.2370\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 999.5827 - root_mean_squared_error: 0.0545\n",
      "Epoch 00034: loss improved from 1000.81665 to 999.58270, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 450s 449ms/step - loss: 999.5827 - root_mean_squared_error: 0.0545 - val_loss: 1039.4167 - val_root_mean_squared_error: 0.2369\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 998.2958 - root_mean_squared_error: 0.0534\n",
      "Epoch 00035: loss improved from 999.58270 to 998.29578, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 449s 449ms/step - loss: 998.2958 - root_mean_squared_error: 0.0534 - val_loss: 1035.8519 - val_root_mean_squared_error: 0.2363\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 997.0644 - root_mean_squared_error: 0.0544\n",
      "Epoch 00036: loss improved from 998.29578 to 997.06439, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 447s 447ms/step - loss: 997.0644 - root_mean_squared_error: 0.0544 - val_loss: 1053.2133 - val_root_mean_squared_error: 0.2369\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 995.7887 - root_mean_squared_error: 0.0525\n",
      "Epoch 00037: loss improved from 997.06439 to 995.78870, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 496s 496ms/step - loss: 995.7887 - root_mean_squared_error: 0.0525 - val_loss: 1039.8983 - val_root_mean_squared_error: 0.2370\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 994.5394 - root_mean_squared_error: 0.0546\n",
      "Epoch 00038: loss improved from 995.78870 to 994.53937, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 468s 468ms/step - loss: 994.5394 - root_mean_squared_error: 0.0546 - val_loss: 1044.3741 - val_root_mean_squared_error: 0.2370\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 993.2877 - root_mean_squared_error: 0.0562\n",
      "Epoch 00039: loss improved from 994.53937 to 993.28766, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 465s 465ms/step - loss: 993.2877 - root_mean_squared_error: 0.0562 - val_loss: 1033.9302 - val_root_mean_squared_error: 0.2372\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 992.0308 - root_mean_squared_error: 0.0552\n",
      "Epoch 00040: loss improved from 993.28766 to 992.03082, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 484s 484ms/step - loss: 992.0308 - root_mean_squared_error: 0.0552 - val_loss: 1036.4971 - val_root_mean_squared_error: 0.2364\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 990.8090 - root_mean_squared_error: 0.0556\n",
      "Epoch 00041: loss improved from 992.03082 to 990.80896, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 990.8090 - root_mean_squared_error: 0.0556 - val_loss: 1019.0185 - val_root_mean_squared_error: 0.2367\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 989.5206 - root_mean_squared_error: 0.0515\n",
      "Epoch 00042: loss improved from 990.80896 to 989.52057, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 482s 482ms/step - loss: 989.5206 - root_mean_squared_error: 0.0515 - val_loss: 1015.1703 - val_root_mean_squared_error: 0.2391\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 988.2907 - root_mean_squared_error: 0.0537\n",
      "Epoch 00043: loss improved from 989.52057 to 988.29071, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 471s 471ms/step - loss: 988.2907 - root_mean_squared_error: 0.0537 - val_loss: 1027.0697 - val_root_mean_squared_error: 0.2372\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 987.1006 - root_mean_squared_error: 0.0522\n",
      "Epoch 00044: loss improved from 988.29071 to 987.10065, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 458s 458ms/step - loss: 987.1006 - root_mean_squared_error: 0.0522 - val_loss: 1016.2891 - val_root_mean_squared_error: 0.2370\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 985.9199 - root_mean_squared_error: 0.0539\n",
      "Epoch 00045: loss improved from 987.10065 to 985.91986, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 472s 472ms/step - loss: 985.9199 - root_mean_squared_error: 0.0539 - val_loss: 1026.8501 - val_root_mean_squared_error: 0.2376\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 984.6784 - root_mean_squared_error: 0.0511\n",
      "Epoch 00046: loss improved from 985.91986 to 984.67841, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 457s 457ms/step - loss: 984.6784 - root_mean_squared_error: 0.0511 - val_loss: 1011.7955 - val_root_mean_squared_error: 0.2372\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 983.4076 - root_mean_squared_error: 0.0543\n",
      "Epoch 00047: loss improved from 984.67841 to 983.40759, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 469s 469ms/step - loss: 983.4076 - root_mean_squared_error: 0.0543 - val_loss: 1015.2686 - val_root_mean_squared_error: 0.2363\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 982.2562 - root_mean_squared_error: 0.0501\n",
      "Epoch 00048: loss improved from 983.40759 to 982.25623, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 464s 464ms/step - loss: 982.2562 - root_mean_squared_error: 0.0501 - val_loss: 1023.5733 - val_root_mean_squared_error: 0.2350\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 981.0291 - root_mean_squared_error: 0.0526\n",
      "Epoch 00049: loss improved from 982.25623 to 981.02905, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 469s 469ms/step - loss: 981.0291 - root_mean_squared_error: 0.0526 - val_loss: 1033.8279 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 979.8743 - root_mean_squared_error: 0.0523\n",
      "Epoch 00050: loss improved from 981.02905 to 979.87433, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 465s 465ms/step - loss: 979.8743 - root_mean_squared_error: 0.0523 - val_loss: 1008.5816 - val_root_mean_squared_error: 0.2360\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 978.7052 - root_mean_squared_error: 0.0517\n",
      "Epoch 00051: loss improved from 979.87433 to 978.70520, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 467s 466ms/step - loss: 978.7052 - root_mean_squared_error: 0.0517 - val_loss: 1033.0396 - val_root_mean_squared_error: 0.2361\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 977.4917 - root_mean_squared_error: 0.0510\n",
      "Epoch 00052: loss improved from 978.70520 to 977.49170, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 464s 464ms/step - loss: 977.4917 - root_mean_squared_error: 0.0510 - val_loss: 1024.1976 - val_root_mean_squared_error: 0.2356\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 976.2910 - root_mean_squared_error: 0.0502\n",
      "Epoch 00053: loss improved from 977.49170 to 976.29102, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 469s 469ms/step - loss: 976.2910 - root_mean_squared_error: 0.0502 - val_loss: 1029.2802 - val_root_mean_squared_error: 0.2370\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 975.1265 - root_mean_squared_error: 0.0515\n",
      "Epoch 00054: loss improved from 976.29102 to 975.12646, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 471s 471ms/step - loss: 975.1265 - root_mean_squared_error: 0.0515 - val_loss: 1031.4399 - val_root_mean_squared_error: 0.2369\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 973.9814 - root_mean_squared_error: 0.0506\n",
      "Epoch 00055: loss improved from 975.12646 to 973.98138, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 471s 471ms/step - loss: 973.9814 - root_mean_squared_error: 0.0506 - val_loss: 1027.0844 - val_root_mean_squared_error: 0.2360\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 972.8104 - root_mean_squared_error: 0.0496\n",
      "Epoch 00056: loss improved from 973.98138 to 972.81042, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 476s 476ms/step - loss: 972.8104 - root_mean_squared_error: 0.0496 - val_loss: 1022.5745 - val_root_mean_squared_error: 0.2363\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 971.6835 - root_mean_squared_error: 0.0491\n",
      "Epoch 00057: loss improved from 972.81042 to 971.68353, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 464s 464ms/step - loss: 971.6835 - root_mean_squared_error: 0.0491 - val_loss: 1021.3010 - val_root_mean_squared_error: 0.2364\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 970.5252 - root_mean_squared_error: 0.0480\n",
      "Epoch 00058: loss improved from 971.68353 to 970.52521, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 467s 467ms/step - loss: 970.5252 - root_mean_squared_error: 0.0480 - val_loss: 1031.0295 - val_root_mean_squared_error: 0.2361\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 969.3973 - root_mean_squared_error: 0.0490\n",
      "Epoch 00059: loss improved from 970.52521 to 969.39734, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 465s 465ms/step - loss: 969.3973 - root_mean_squared_error: 0.0490 - val_loss: 1017.5275 - val_root_mean_squared_error: 0.2363\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 968.2568 - root_mean_squared_error: 0.0482\n",
      "Epoch 00060: loss improved from 969.39734 to 968.25677, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 470s 470ms/step - loss: 968.2568 - root_mean_squared_error: 0.0482 - val_loss: 1009.3065 - val_root_mean_squared_error: 0.2370\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 967.2208 - root_mean_squared_error: 0.0479\n",
      "Epoch 00061: loss improved from 968.25677 to 967.22083, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 473s 473ms/step - loss: 967.2208 - root_mean_squared_error: 0.0479 - val_loss: 1007.0939 - val_root_mean_squared_error: 0.2359\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 966.0378 - root_mean_squared_error: 0.0475\n",
      "Epoch 00062: loss improved from 967.22083 to 966.03778, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 472s 472ms/step - loss: 966.0378 - root_mean_squared_error: 0.0475 - val_loss: 1016.3423 - val_root_mean_squared_error: 0.2362\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 964.9017 - root_mean_squared_error: 0.0474\n",
      "Epoch 00063: loss improved from 966.03778 to 964.90167, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 463s 463ms/step - loss: 964.9017 - root_mean_squared_error: 0.0474 - val_loss: 1019.9305 - val_root_mean_squared_error: 0.2364\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 963.8146 - root_mean_squared_error: 0.0493\n",
      "Epoch 00064: loss improved from 964.90167 to 963.81458, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 463s 463ms/step - loss: 963.8146 - root_mean_squared_error: 0.0493 - val_loss: 1011.2589 - val_root_mean_squared_error: 0.2366\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 962.7382 - root_mean_squared_error: 0.0484\n",
      "Epoch 00065: loss improved from 963.81458 to 962.73822, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 467s 467ms/step - loss: 962.7382 - root_mean_squared_error: 0.0484 - val_loss: 1009.0408 - val_root_mean_squared_error: 0.2357\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 961.6342 - root_mean_squared_error: 0.0457\n",
      "Epoch 00066: loss improved from 962.73822 to 961.63416, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 468s 467ms/step - loss: 961.6342 - root_mean_squared_error: 0.0457 - val_loss: 1002.8649 - val_root_mean_squared_error: 0.2373\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 960.5446 - root_mean_squared_error: 0.0496\n",
      "Epoch 00067: loss improved from 961.63416 to 960.54456, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 474s 474ms/step - loss: 960.5446 - root_mean_squared_error: 0.0496 - val_loss: 1010.1374 - val_root_mean_squared_error: 0.2358\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 959.4457 - root_mean_squared_error: 0.0495\n",
      "Epoch 00068: loss improved from 960.54456 to 959.44568, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 460s 460ms/step - loss: 959.4457 - root_mean_squared_error: 0.0495 - val_loss: 981.3907 - val_root_mean_squared_error: 0.2362\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 958.3398 - root_mean_squared_error: 0.0481\n",
      "Epoch 00069: loss improved from 959.44568 to 958.33978, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 474s 474ms/step - loss: 958.3398 - root_mean_squared_error: 0.0481 - val_loss: 1004.0671 - val_root_mean_squared_error: 0.2365\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 957.2624 - root_mean_squared_error: 0.0474\n",
      "Epoch 00070: loss improved from 958.33978 to 957.26239, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 461s 461ms/step - loss: 957.2624 - root_mean_squared_error: 0.0474 - val_loss: 1003.9899 - val_root_mean_squared_error: 0.2358\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 956.1678 - root_mean_squared_error: 0.0482\n",
      "Epoch 00071: loss improved from 957.26239 to 956.16779, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 466s 466ms/step - loss: 956.1678 - root_mean_squared_error: 0.0482 - val_loss: 974.3323 - val_root_mean_squared_error: 0.2380\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 955.0630 - root_mean_squared_error: 0.0463\n",
      "Epoch 00072: loss improved from 956.16779 to 955.06305, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 460s 460ms/step - loss: 955.0630 - root_mean_squared_error: 0.0463 - val_loss: 1005.3889 - val_root_mean_squared_error: 0.2352\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 954.0488 - root_mean_squared_error: 0.0458\n",
      "Epoch 00073: loss improved from 955.06305 to 954.04883, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 954.0488 - root_mean_squared_error: 0.0458 - val_loss: 980.9503 - val_root_mean_squared_error: 0.2368\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 952.9818 - root_mean_squared_error: 0.0441\n",
      "Epoch 00074: loss improved from 954.04883 to 952.98181, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 470s 470ms/step - loss: 952.9818 - root_mean_squared_error: 0.0441 - val_loss: 1013.9280 - val_root_mean_squared_error: 0.2365\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 951.8800 - root_mean_squared_error: 0.0470\n",
      "Epoch 00075: loss improved from 952.98181 to 951.88000, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 471s 471ms/step - loss: 951.8800 - root_mean_squared_error: 0.0470 - val_loss: 1007.6051 - val_root_mean_squared_error: 0.2359\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 950.8665 - root_mean_squared_error: 0.0475\n",
      "Epoch 00076: loss improved from 951.88000 to 950.86646, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 950.8665 - root_mean_squared_error: 0.0475 - val_loss: 969.2306 - val_root_mean_squared_error: 0.2361\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 949.7925 - root_mean_squared_error: 0.0439\n",
      "Epoch 00077: loss improved from 950.86646 to 949.79254, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 480s 480ms/step - loss: 949.7925 - root_mean_squared_error: 0.0439 - val_loss: 997.4871 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 948.7605 - root_mean_squared_error: 0.0464\n",
      "Epoch 00078: loss improved from 949.79254 to 948.76050, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 462s 462ms/step - loss: 948.7605 - root_mean_squared_error: 0.0464 - val_loss: 994.6094 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 947.6684 - root_mean_squared_error: 0.0468\n",
      "Epoch 00079: loss improved from 948.76050 to 947.66840, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 473s 473ms/step - loss: 947.6684 - root_mean_squared_error: 0.0468 - val_loss: 958.1045 - val_root_mean_squared_error: 0.2396\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 946.5820 - root_mean_squared_error: 0.0450\n",
      "Epoch 00080: loss improved from 947.66840 to 946.58197, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 469s 469ms/step - loss: 946.5820 - root_mean_squared_error: 0.0450 - val_loss: 997.0616 - val_root_mean_squared_error: 0.2369\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 945.6059 - root_mean_squared_error: 0.0445\n",
      "Epoch 00081: loss improved from 946.58197 to 945.60590, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 463s 463ms/step - loss: 945.6059 - root_mean_squared_error: 0.0445 - val_loss: 1005.0730 - val_root_mean_squared_error: 0.2372\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 944.5926 - root_mean_squared_error: 0.0432\n",
      "Epoch 00082: loss improved from 945.60590 to 944.59259, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 462s 462ms/step - loss: 944.5926 - root_mean_squared_error: 0.0432 - val_loss: 966.6058 - val_root_mean_squared_error: 0.2376\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 943.5668 - root_mean_squared_error: 0.0445\n",
      "Epoch 00083: loss improved from 944.59259 to 943.56677, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 482s 482ms/step - loss: 943.5668 - root_mean_squared_error: 0.0445 - val_loss: 981.6170 - val_root_mean_squared_error: 0.2359\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 942.5007 - root_mean_squared_error: 0.0474\n",
      "Epoch 00084: loss improved from 943.56677 to 942.50073, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 478s 478ms/step - loss: 942.5007 - root_mean_squared_error: 0.0474 - val_loss: 1009.0093 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 941.5355 - root_mean_squared_error: 0.0451\n",
      "Epoch 00085: loss improved from 942.50073 to 941.53546, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 470s 469ms/step - loss: 941.5355 - root_mean_squared_error: 0.0451 - val_loss: 1004.3002 - val_root_mean_squared_error: 0.2372\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 940.5338 - root_mean_squared_error: 0.0452\n",
      "Epoch 00086: loss improved from 941.53546 to 940.53381, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 464s 464ms/step - loss: 940.5338 - root_mean_squared_error: 0.0452 - val_loss: 972.8028 - val_root_mean_squared_error: 0.2375\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 939.4423 - root_mean_squared_error: 0.0429\n",
      "Epoch 00087: loss improved from 940.53381 to 939.44232, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 460s 460ms/step - loss: 939.4423 - root_mean_squared_error: 0.0429 - val_loss: 992.1537 - val_root_mean_squared_error: 0.2365\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 938.5265 - root_mean_squared_error: 0.0465\n",
      "Epoch 00088: loss improved from 939.44232 to 938.52649, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 463s 463ms/step - loss: 938.5265 - root_mean_squared_error: 0.0465 - val_loss: 996.9123 - val_root_mean_squared_error: 0.2351\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 937.4996 - root_mean_squared_error: 0.0427\n",
      "Epoch 00089: loss improved from 938.52649 to 937.49957, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 466s 466ms/step - loss: 937.4996 - root_mean_squared_error: 0.0427 - val_loss: 959.9843 - val_root_mean_squared_error: 0.2389\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 936.4738 - root_mean_squared_error: 0.0432\n",
      "Epoch 00090: loss improved from 937.49957 to 936.47375, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 474s 474ms/step - loss: 936.4738 - root_mean_squared_error: 0.0432 - val_loss: 989.7412 - val_root_mean_squared_error: 0.2360\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 935.4600 - root_mean_squared_error: 0.0431\n",
      "Epoch 00091: loss improved from 936.47375 to 935.46002, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 465s 465ms/step - loss: 935.4600 - root_mean_squared_error: 0.0431 - val_loss: 970.8935 - val_root_mean_squared_error: 0.2366\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 934.4990 - root_mean_squared_error: 0.0431\n",
      "Epoch 00092: loss improved from 935.46002 to 934.49896, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 465s 465ms/step - loss: 934.4990 - root_mean_squared_error: 0.0431 - val_loss: 977.2249 - val_root_mean_squared_error: 0.2360\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 933.5273 - root_mean_squared_error: 0.0435\n",
      "Epoch 00093: loss improved from 934.49896 to 933.52734, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 467s 467ms/step - loss: 933.5273 - root_mean_squared_error: 0.0435 - val_loss: 964.9478 - val_root_mean_squared_error: 0.2367\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 932.5242 - root_mean_squared_error: 0.0437\n",
      "Epoch 00094: loss improved from 933.52734 to 932.52423, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 476s 476ms/step - loss: 932.5242 - root_mean_squared_error: 0.0437 - val_loss: 996.5057 - val_root_mean_squared_error: 0.2350\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 931.5646 - root_mean_squared_error: 0.0417\n",
      "Epoch 00095: loss improved from 932.52423 to 931.56458, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 474s 474ms/step - loss: 931.5646 - root_mean_squared_error: 0.0417 - val_loss: 989.1913 - val_root_mean_squared_error: 0.2356\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 930.5742 - root_mean_squared_error: 0.0420\n",
      "Epoch 00096: loss improved from 931.56458 to 930.57422, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 465s 464ms/step - loss: 930.5742 - root_mean_squared_error: 0.0420 - val_loss: 1002.9968 - val_root_mean_squared_error: 0.2351\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 929.6000 - root_mean_squared_error: 0.0432\n",
      "Epoch 00097: loss improved from 930.57422 to 929.59998, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 473s 473ms/step - loss: 929.6000 - root_mean_squared_error: 0.0432 - val_loss: 984.4998 - val_root_mean_squared_error: 0.2356\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 928.6658 - root_mean_squared_error: 0.0424\n",
      "Epoch 00098: loss improved from 929.59998 to 928.66583, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 468s 468ms/step - loss: 928.6658 - root_mean_squared_error: 0.0424 - val_loss: 986.8530 - val_root_mean_squared_error: 0.2357\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 927.6663 - root_mean_squared_error: 0.0412\n",
      "Epoch 00099: loss improved from 928.66583 to 927.66626, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 460s 460ms/step - loss: 927.6663 - root_mean_squared_error: 0.0412 - val_loss: 988.9587 - val_root_mean_squared_error: 0.2362\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 926.7170 - root_mean_squared_error: 0.0420\n",
      "Epoch 00100: loss improved from 927.66626 to 926.71698, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 475s 475ms/step - loss: 926.7170 - root_mean_squared_error: 0.0420 - val_loss: 979.0756 - val_root_mean_squared_error: 0.2356\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "import tensorflow.keras as keras\n",
    "checkpoint_path = 'evan_checkpoints/cp5.ckpt'\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='loss',\n",
    "                                                 verbose=1,\n",
    "                                                 save_freq = 1000,\n",
    "                                                 save_best_only=True)\n",
    "mags = np.column_stack([train_gen_gmag,train_gen_rmag,train_gen_imag,train_gen_zmag,train_gen_ymag])\n",
    "\n",
    "mags2 = zip(train_gen_gmag,train_gen_rmag,train_gen_imag,train_gen_zmag,train_gen_ymag)\n",
    "class JoinedGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, input_gen1, input_gen2, target_gen):\n",
    "        self.gen1 = input_gen1\n",
    "        self.gen2 = input_gen2\n",
    "        self.gen3 = target_gen\n",
    "\n",
    "        #assert len(input_gen1) == len(input_gen2) == len(target_gen)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gen1)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x1 = self.gen1[i]\n",
    "        x2 = self.gen2[i]\n",
    "        y = self.gen3[i]\n",
    "\n",
    "        return [x1, x2], y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.gen1.on_epoch_end()\n",
    "        self.gen2.on_epoch_end()\n",
    "        self.gen3.on_epoch_end()\n",
    "log_dir = os.path.join(\"tf_logs/\")\n",
    "mags2 = JoinedMags(train_gen_gmag,train_gen_rmag,train_gen_imag,train_gen_zmag,train_gen_ymag)\n",
    "my_gen = JoinedGen(train_gen_image, mags2, train_gen_label)\n",
    "params = {\"lr\": 0.001, \"epochs\": 100}\n",
    "\n",
    "run = neptune.init(\n",
    "    project=\"astro-data-lab/Bayesian-CNN\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4NDU0YjdhYy01NjM4LTQwMDQtOGQxMC02YTQ2MDkyMzQ5MmUifQ==\",\n",
    ")  # your credentials\n",
    "run[\"parameters\"] = params\n",
    "neptune_cbk = NeptuneCallback(run=run, base_namespace=\"training\")\n",
    "\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "history = model.fit(my_gen,epochs=100,shuffle= True,verbose=1, validation_data = val_my_gen, callbacks = [tensorboard_callback, cp_callback])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'],loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(history.history['root_mean_squared_error'])\n",
    "plt.plot(history.history['val_root_mean_squared_error'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('RMS error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','val'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac54387c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/astro-data-lab/Bayesian-CNN/e/BAY-23\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer DenseVariational has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 925.7492 - root_mean_squared_error: 0.0451\n",
      "Epoch 00001: loss improved from inf to 925.74921, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 491s 490ms/step - loss: 925.7492 - root_mean_squared_error: 0.0451 - val_loss: 988.9055 - val_root_mean_squared_error: 0.2360\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 924.8826 - root_mean_squared_error: 0.0438\n",
      "Epoch 00002: loss improved from 925.74921 to 924.88263, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 924.8826 - root_mean_squared_error: 0.0438 - val_loss: 960.9711 - val_root_mean_squared_error: 0.2357\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 923.8519 - root_mean_squared_error: 0.0444\n",
      "Epoch 00003: loss improved from 924.88263 to 923.85193, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 923.8519 - root_mean_squared_error: 0.0444 - val_loss: 966.0777 - val_root_mean_squared_error: 0.2344\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 922.9062 - root_mean_squared_error: 0.0416\n",
      "Epoch 00004: loss improved from 923.85193 to 922.90619, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 492s 492ms/step - loss: 922.9062 - root_mean_squared_error: 0.0416 - val_loss: 991.1556 - val_root_mean_squared_error: 0.2354\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 921.9594 - root_mean_squared_error: 0.0428\n",
      "Epoch 00005: loss improved from 922.90619 to 921.95941, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 498s 498ms/step - loss: 921.9594 - root_mean_squared_error: 0.0428 - val_loss: 973.1381 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 921.0280 - root_mean_squared_error: 0.0410\n",
      "Epoch 00006: loss improved from 921.95941 to 921.02802, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 471s 471ms/step - loss: 921.0280 - root_mean_squared_error: 0.0410 - val_loss: 953.5822 - val_root_mean_squared_error: 0.2364\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 920.0839 - root_mean_squared_error: 0.0412\n",
      "Epoch 00007: loss improved from 921.02802 to 920.08386, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 491s 491ms/step - loss: 920.0839 - root_mean_squared_error: 0.0412 - val_loss: 976.5937 - val_root_mean_squared_error: 0.2351\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 919.1838 - root_mean_squared_error: 0.0433\n",
      "Epoch 00008: loss improved from 920.08386 to 919.18384, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 516s 516ms/step - loss: 919.1838 - root_mean_squared_error: 0.0433 - val_loss: 968.1428 - val_root_mean_squared_error: 0.2359\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 918.2199 - root_mean_squared_error: 0.0408\n",
      "Epoch 00009: loss improved from 919.18384 to 918.21991, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 918.2199 - root_mean_squared_error: 0.0408 - val_loss: 967.6907 - val_root_mean_squared_error: 0.2365\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 917.2716 - root_mean_squared_error: 0.0405\n",
      "Epoch 00010: loss improved from 918.21991 to 917.27161, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 499s 499ms/step - loss: 917.2716 - root_mean_squared_error: 0.0405 - val_loss: 945.4277 - val_root_mean_squared_error: 0.2351\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 916.4084 - root_mean_squared_error: 0.0404\n",
      "Epoch 00011: loss improved from 917.27161 to 916.40839, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 500s 500ms/step - loss: 916.4084 - root_mean_squared_error: 0.0404 - val_loss: 970.8015 - val_root_mean_squared_error: 0.2353\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 915.5005 - root_mean_squared_error: 0.0403\n",
      "Epoch 00012: loss improved from 916.40839 to 915.50055, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 496s 496ms/step - loss: 915.5005 - root_mean_squared_error: 0.0403 - val_loss: 965.8457 - val_root_mean_squared_error: 0.2349\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 914.5394 - root_mean_squared_error: 0.0402\n",
      "Epoch 00013: loss improved from 915.50055 to 914.53943, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 516s 516ms/step - loss: 914.5394 - root_mean_squared_error: 0.0402 - val_loss: 973.2900 - val_root_mean_squared_error: 0.2354\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 913.5894 - root_mean_squared_error: 0.0382\n",
      "Epoch 00014: loss improved from 914.53943 to 913.58942, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 508s 508ms/step - loss: 913.5894 - root_mean_squared_error: 0.0382 - val_loss: 955.1184 - val_root_mean_squared_error: 0.2346\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 912.7180 - root_mean_squared_error: 0.0397\n",
      "Epoch 00015: loss improved from 913.58942 to 912.71802, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 516s 516ms/step - loss: 912.7180 - root_mean_squared_error: 0.0397 - val_loss: 967.4233 - val_root_mean_squared_error: 0.2352\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 911.8184 - root_mean_squared_error: 0.0408\n",
      "Epoch 00016: loss improved from 912.71802 to 911.81842, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 495s 495ms/step - loss: 911.8184 - root_mean_squared_error: 0.0408 - val_loss: 973.0261 - val_root_mean_squared_error: 0.2356\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 910.9047 - root_mean_squared_error: 0.0404\n",
      "Epoch 00017: loss improved from 911.81842 to 910.90466, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 470s 470ms/step - loss: 910.9047 - root_mean_squared_error: 0.0404 - val_loss: 962.1586 - val_root_mean_squared_error: 0.2396\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 910.0159 - root_mean_squared_error: 0.0388\n",
      "Epoch 00018: loss improved from 910.90466 to 910.01593, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 472s 472ms/step - loss: 910.0159 - root_mean_squared_error: 0.0388 - val_loss: 969.5466 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 909.1523 - root_mean_squared_error: 0.0410\n",
      "Epoch 00019: loss improved from 910.01593 to 909.15234, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 466s 466ms/step - loss: 909.1523 - root_mean_squared_error: 0.0410 - val_loss: 970.9123 - val_root_mean_squared_error: 0.2362\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 908.2176 - root_mean_squared_error: 0.0377\n",
      "Epoch 00020: loss improved from 909.15234 to 908.21759, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 483s 483ms/step - loss: 908.2176 - root_mean_squared_error: 0.0377 - val_loss: 974.8900 - val_root_mean_squared_error: 0.2348\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 907.3723 - root_mean_squared_error: 0.0365\n",
      "Epoch 00021: loss improved from 908.21759 to 907.37225, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 476s 476ms/step - loss: 907.3723 - root_mean_squared_error: 0.0365 - val_loss: 936.9004 - val_root_mean_squared_error: 0.2365\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 906.5016 - root_mean_squared_error: 0.0408\n",
      "Epoch 00022: loss improved from 907.37225 to 906.50159, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 906.5016 - root_mean_squared_error: 0.0408 - val_loss: 947.2427 - val_root_mean_squared_error: 0.2360\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 905.6161 - root_mean_squared_error: 0.0409\n",
      "Epoch 00023: loss improved from 906.50159 to 905.61609, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 508s 508ms/step - loss: 905.6161 - root_mean_squared_error: 0.0409 - val_loss: 941.4250 - val_root_mean_squared_error: 0.2357\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 904.7333 - root_mean_squared_error: 0.0398\n",
      "Epoch 00024: loss improved from 905.61609 to 904.73334, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 496s 496ms/step - loss: 904.7333 - root_mean_squared_error: 0.0398 - val_loss: 930.6685 - val_root_mean_squared_error: 0.2366\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 903.8719 - root_mean_squared_error: 0.0396\n",
      "Epoch 00025: loss improved from 904.73334 to 903.87195, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 475s 475ms/step - loss: 903.8719 - root_mean_squared_error: 0.0396 - val_loss: 940.2586 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 902.9503 - root_mean_squared_error: 0.0390\n",
      "Epoch 00026: loss improved from 903.87195 to 902.95026, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 456s 456ms/step - loss: 902.9503 - root_mean_squared_error: 0.0390 - val_loss: 958.2833 - val_root_mean_squared_error: 0.2349\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 902.1038 - root_mean_squared_error: 0.0393\n",
      "Epoch 00027: loss improved from 902.95026 to 902.10382, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 471s 472ms/step - loss: 902.1038 - root_mean_squared_error: 0.0393 - val_loss: 971.9620 - val_root_mean_squared_error: 0.2350\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 901.2736 - root_mean_squared_error: 0.0399\n",
      "Epoch 00028: loss improved from 902.10382 to 901.27362, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 477s 476ms/step - loss: 901.2736 - root_mean_squared_error: 0.0399 - val_loss: 919.1489 - val_root_mean_squared_error: 0.2359\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 900.3965 - root_mean_squared_error: 0.0387\n",
      "Epoch 00029: loss improved from 901.27362 to 900.39655, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 476s 476ms/step - loss: 900.3965 - root_mean_squared_error: 0.0387 - val_loss: 934.8353 - val_root_mean_squared_error: 0.2368\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 899.5593 - root_mean_squared_error: 0.0387\n",
      "Epoch 00030: loss improved from 900.39655 to 899.55927, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 469s 469ms/step - loss: 899.5593 - root_mean_squared_error: 0.0387 - val_loss: 975.9182 - val_root_mean_squared_error: 0.2354\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 898.6695 - root_mean_squared_error: 0.0394\n",
      "Epoch 00031: loss improved from 899.55927 to 898.66949, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 481s 481ms/step - loss: 898.6695 - root_mean_squared_error: 0.0394 - val_loss: 956.9014 - val_root_mean_squared_error: 0.2354\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 897.8372 - root_mean_squared_error: 0.0394\n",
      "Epoch 00032: loss improved from 898.66949 to 897.83722, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 455s 455ms/step - loss: 897.8372 - root_mean_squared_error: 0.0394 - val_loss: 954.0729 - val_root_mean_squared_error: 0.2347\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 896.9991 - root_mean_squared_error: 0.0381\n",
      "Epoch 00033: loss improved from 897.83722 to 896.99915, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 483s 483ms/step - loss: 896.9991 - root_mean_squared_error: 0.0381 - val_loss: 976.6545 - val_root_mean_squared_error: 0.2363\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 896.1243 - root_mean_squared_error: 0.0378\n",
      "Epoch 00034: loss improved from 896.99915 to 896.12427, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 474s 474ms/step - loss: 896.1243 - root_mean_squared_error: 0.0378 - val_loss: 942.2968 - val_root_mean_squared_error: 0.2359\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 895.2117 - root_mean_squared_error: 0.0368\n",
      "Epoch 00035: loss improved from 896.12427 to 895.21167, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 474s 474ms/step - loss: 895.2117 - root_mean_squared_error: 0.0368 - val_loss: 958.2878 - val_root_mean_squared_error: 0.2357\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 894.3790 - root_mean_squared_error: 0.0386\n",
      "Epoch 00036: loss improved from 895.21167 to 894.37897, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 474s 474ms/step - loss: 894.3790 - root_mean_squared_error: 0.0386 - val_loss: 949.7235 - val_root_mean_squared_error: 0.2354\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 893.5991 - root_mean_squared_error: 0.0368\n",
      "Epoch 00037: loss improved from 894.37897 to 893.59906, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 465s 465ms/step - loss: 893.5991 - root_mean_squared_error: 0.0368 - val_loss: 953.5866 - val_root_mean_squared_error: 0.2353\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 892.7081 - root_mean_squared_error: 0.0372\n",
      "Epoch 00038: loss improved from 893.59906 to 892.70813, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 892.7081 - root_mean_squared_error: 0.0372 - val_loss: 947.0436 - val_root_mean_squared_error: 0.2357\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 891.8726 - root_mean_squared_error: 0.0372\n",
      "Epoch 00039: loss improved from 892.70813 to 891.87262, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 481s 481ms/step - loss: 891.8726 - root_mean_squared_error: 0.0372 - val_loss: 949.3185 - val_root_mean_squared_error: 0.2354\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 891.1066 - root_mean_squared_error: 0.0377\n",
      "Epoch 00040: loss improved from 891.87262 to 891.10663, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 466s 466ms/step - loss: 891.1066 - root_mean_squared_error: 0.0377 - val_loss: 928.9669 - val_root_mean_squared_error: 0.2347\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 890.2691 - root_mean_squared_error: 0.0384\n",
      "Epoch 00041: loss improved from 891.10663 to 890.26910, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 466s 466ms/step - loss: 890.2691 - root_mean_squared_error: 0.0384 - val_loss: 956.4250 - val_root_mean_squared_error: 0.2348\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 889.4284 - root_mean_squared_error: 0.0356\n",
      "Epoch 00042: loss improved from 890.26910 to 889.42841, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 464s 464ms/step - loss: 889.4284 - root_mean_squared_error: 0.0356 - val_loss: 933.6475 - val_root_mean_squared_error: 0.2359\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 888.5909 - root_mean_squared_error: 0.0367\n",
      "Epoch 00043: loss improved from 889.42841 to 888.59094, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 454s 454ms/step - loss: 888.5909 - root_mean_squared_error: 0.0367 - val_loss: 937.9364 - val_root_mean_squared_error: 0.2367\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 887.7730 - root_mean_squared_error: 0.0358\n",
      "Epoch 00044: loss improved from 888.59094 to 887.77301, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 466s 466ms/step - loss: 887.7730 - root_mean_squared_error: 0.0358 - val_loss: 961.4533 - val_root_mean_squared_error: 0.2358\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 886.9745 - root_mean_squared_error: 0.0361\n",
      "Epoch 00045: loss improved from 887.77301 to 886.97449, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 468s 468ms/step - loss: 886.9745 - root_mean_squared_error: 0.0361 - val_loss: 917.5656 - val_root_mean_squared_error: 0.2364\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 886.2029 - root_mean_squared_error: 0.0353\n",
      "Epoch 00046: loss improved from 886.97449 to 886.20288, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 454s 454ms/step - loss: 886.2029 - root_mean_squared_error: 0.0353 - val_loss: 924.9833 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 885.3899 - root_mean_squared_error: 0.0360\n",
      "Epoch 00047: loss improved from 886.20288 to 885.38989, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 475s 475ms/step - loss: 885.3899 - root_mean_squared_error: 0.0360 - val_loss: 927.4299 - val_root_mean_squared_error: 0.2341\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 884.5255 - root_mean_squared_error: 0.0356\n",
      "Epoch 00048: loss improved from 885.38989 to 884.52551, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 469s 469ms/step - loss: 884.5255 - root_mean_squared_error: 0.0356 - val_loss: 945.1113 - val_root_mean_squared_error: 0.2350\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 883.7661 - root_mean_squared_error: 0.0391\n",
      "Epoch 00049: loss improved from 884.52551 to 883.76605, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 461s 461ms/step - loss: 883.7661 - root_mean_squared_error: 0.0391 - val_loss: 936.0055 - val_root_mean_squared_error: 0.2353\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 882.9114 - root_mean_squared_error: 0.0372\n",
      "Epoch 00050: loss improved from 883.76605 to 882.91144, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 467s 467ms/step - loss: 882.9114 - root_mean_squared_error: 0.0372 - val_loss: 964.3937 - val_root_mean_squared_error: 0.2352\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 882.1390 - root_mean_squared_error: 0.0387\n",
      "Epoch 00051: loss improved from 882.91144 to 882.13904, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 466s 466ms/step - loss: 882.1390 - root_mean_squared_error: 0.0387 - val_loss: 946.9766 - val_root_mean_squared_error: 0.2358\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 881.3500 - root_mean_squared_error: 0.0353\n",
      "Epoch 00052: loss improved from 882.13904 to 881.34998, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 450s 450ms/step - loss: 881.3500 - root_mean_squared_error: 0.0353 - val_loss: 956.2794 - val_root_mean_squared_error: 0.2356\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 880.5583 - root_mean_squared_error: 0.0355\n",
      "Epoch 00053: loss improved from 881.34998 to 880.55835, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 475s 475ms/step - loss: 880.5583 - root_mean_squared_error: 0.0355 - val_loss: 951.7888 - val_root_mean_squared_error: 0.2352\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 879.7446 - root_mean_squared_error: 0.0352\n",
      "Epoch 00054: loss improved from 880.55835 to 879.74457, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 483s 483ms/step - loss: 879.7446 - root_mean_squared_error: 0.0352 - val_loss: 940.8848 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 879.0480 - root_mean_squared_error: 0.0353\n",
      "Epoch 00055: loss improved from 879.74457 to 879.04797, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 455s 455ms/step - loss: 879.0480 - root_mean_squared_error: 0.0353 - val_loss: 922.5291 - val_root_mean_squared_error: 0.2351\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 878.1617 - root_mean_squared_error: 0.0353\n",
      "Epoch 00056: loss improved from 879.04797 to 878.16174, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 463s 464ms/step - loss: 878.1617 - root_mean_squared_error: 0.0353 - val_loss: 930.7620 - val_root_mean_squared_error: 0.2349\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 877.3947 - root_mean_squared_error: 0.0361\n",
      "Epoch 00057: loss improved from 878.16174 to 877.39465, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 477s 477ms/step - loss: 877.3947 - root_mean_squared_error: 0.0361 - val_loss: 968.2581 - val_root_mean_squared_error: 0.2350\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 876.6091 - root_mean_squared_error: 0.0349\n",
      "Epoch 00058: loss improved from 877.39465 to 876.60913, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 471s 471ms/step - loss: 876.6091 - root_mean_squared_error: 0.0349 - val_loss: 947.2208 - val_root_mean_squared_error: 0.2346\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 875.7894 - root_mean_squared_error: 0.0358\n",
      "Epoch 00059: loss improved from 876.60913 to 875.78937, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 481s 480ms/step - loss: 875.7894 - root_mean_squared_error: 0.0358 - val_loss: 925.8387 - val_root_mean_squared_error: 0.2363\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 875.0654 - root_mean_squared_error: 0.0359\n",
      "Epoch 00060: loss improved from 875.78937 to 875.06537, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 474s 474ms/step - loss: 875.0654 - root_mean_squared_error: 0.0359 - val_loss: 932.2318 - val_root_mean_squared_error: 0.2346\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 874.2921 - root_mean_squared_error: 0.0364\n",
      "Epoch 00061: loss improved from 875.06537 to 874.29205, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 470s 470ms/step - loss: 874.2921 - root_mean_squared_error: 0.0364 - val_loss: 937.7258 - val_root_mean_squared_error: 0.2358\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 873.4972 - root_mean_squared_error: 0.0345\n",
      "Epoch 00062: loss improved from 874.29205 to 873.49719, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 461s 461ms/step - loss: 873.4972 - root_mean_squared_error: 0.0345 - val_loss: 926.7869 - val_root_mean_squared_error: 0.2341\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 872.6985 - root_mean_squared_error: 0.0354\n",
      "Epoch 00063: loss improved from 873.49719 to 872.69849, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 482s 482ms/step - loss: 872.6985 - root_mean_squared_error: 0.0354 - val_loss: 950.0399 - val_root_mean_squared_error: 0.2349\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 871.9583 - root_mean_squared_error: 0.0335\n",
      "Epoch 00064: loss improved from 872.69849 to 871.95825, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 448s 448ms/step - loss: 871.9583 - root_mean_squared_error: 0.0335 - val_loss: 947.5720 - val_root_mean_squared_error: 0.2352\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 871.1832 - root_mean_squared_error: 0.0322\n",
      "Epoch 00065: loss improved from 871.95825 to 871.18323, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 474s 474ms/step - loss: 871.1832 - root_mean_squared_error: 0.0322 - val_loss: 963.4581 - val_root_mean_squared_error: 0.2357\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 870.4153 - root_mean_squared_error: 0.0348\n",
      "Epoch 00066: loss improved from 871.18323 to 870.41528, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 477s 477ms/step - loss: 870.4153 - root_mean_squared_error: 0.0348 - val_loss: 909.9818 - val_root_mean_squared_error: 0.2365\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 869.6635 - root_mean_squared_error: 0.0356\n",
      "Epoch 00067: loss improved from 870.41528 to 869.66351, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 479s 479ms/step - loss: 869.6635 - root_mean_squared_error: 0.0356 - val_loss: 957.2792 - val_root_mean_squared_error: 0.2353\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 868.9078 - root_mean_squared_error: 0.0344\n",
      "Epoch 00068: loss improved from 869.66351 to 868.90778, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 467s 467ms/step - loss: 868.9078 - root_mean_squared_error: 0.0344 - val_loss: 919.8658 - val_root_mean_squared_error: 0.2356\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 868.1841 - root_mean_squared_error: 0.0347\n",
      "Epoch 00069: loss improved from 868.90778 to 868.18408, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 472s 472ms/step - loss: 868.1841 - root_mean_squared_error: 0.0347 - val_loss: 944.5869 - val_root_mean_squared_error: 0.2349\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 867.4382 - root_mean_squared_error: 0.0338\n",
      "Epoch 00070: loss improved from 868.18408 to 867.43817, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 468s 468ms/step - loss: 867.4382 - root_mean_squared_error: 0.0338 - val_loss: 955.6965 - val_root_mean_squared_error: 0.2349\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 866.6641 - root_mean_squared_error: 0.0356\n",
      "Epoch 00071: loss improved from 867.43817 to 866.66406, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 472s 472ms/step - loss: 866.6641 - root_mean_squared_error: 0.0356 - val_loss: 925.1500 - val_root_mean_squared_error: 0.2360\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 865.8973 - root_mean_squared_error: 0.0341\n",
      "Epoch 00072: loss improved from 866.66406 to 865.89734, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 463s 463ms/step - loss: 865.8973 - root_mean_squared_error: 0.0341 - val_loss: 926.5932 - val_root_mean_squared_error: 0.2354\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 865.1717 - root_mean_squared_error: 0.0332\n",
      "Epoch 00073: loss improved from 865.89734 to 865.17169, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 470s 470ms/step - loss: 865.1717 - root_mean_squared_error: 0.0332 - val_loss: 944.2847 - val_root_mean_squared_error: 0.2353\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 864.4396 - root_mean_squared_error: 0.0349\n",
      "Epoch 00074: loss improved from 865.17169 to 864.43958, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 474s 474ms/step - loss: 864.4396 - root_mean_squared_error: 0.0349 - val_loss: 922.5201 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 863.6450 - root_mean_squared_error: 0.0339\n",
      "Epoch 00075: loss improved from 864.43958 to 863.64502, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 471s 471ms/step - loss: 863.6450 - root_mean_squared_error: 0.0339 - val_loss: 929.8596 - val_root_mean_squared_error: 0.2353\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 862.9758 - root_mean_squared_error: 0.0358\n",
      "Epoch 00076: loss improved from 863.64502 to 862.97577, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 484s 484ms/step - loss: 862.9758 - root_mean_squared_error: 0.0358 - val_loss: 934.7034 - val_root_mean_squared_error: 0.2353\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 862.1371 - root_mean_squared_error: 0.0348\n",
      "Epoch 00077: loss improved from 862.97577 to 862.13715, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 478s 478ms/step - loss: 862.1371 - root_mean_squared_error: 0.0348 - val_loss: 932.0364 - val_root_mean_squared_error: 0.2361\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 861.4792 - root_mean_squared_error: 0.0350\n",
      "Epoch 00078: loss improved from 862.13715 to 861.47919, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 465s 465ms/step - loss: 861.4792 - root_mean_squared_error: 0.0350 - val_loss: 922.2032 - val_root_mean_squared_error: 0.2359\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 860.6990 - root_mean_squared_error: 0.0328\n",
      "Epoch 00079: loss improved from 861.47919 to 860.69897, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 478s 478ms/step - loss: 860.6990 - root_mean_squared_error: 0.0328 - val_loss: 934.1870 - val_root_mean_squared_error: 0.2358\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 860.0096 - root_mean_squared_error: 0.0339\n",
      "Epoch 00080: loss improved from 860.69897 to 860.00958, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 466s 466ms/step - loss: 860.0096 - root_mean_squared_error: 0.0339 - val_loss: 914.3795 - val_root_mean_squared_error: 0.2353\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 859.2830 - root_mean_squared_error: 0.0336\n",
      "Epoch 00081: loss improved from 860.00958 to 859.28302, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 468s 468ms/step - loss: 859.2830 - root_mean_squared_error: 0.0336 - val_loss: 924.3523 - val_root_mean_squared_error: 0.2358\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 858.5266 - root_mean_squared_error: 0.0320\n",
      "Epoch 00082: loss improved from 859.28302 to 858.52661, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 457s 457ms/step - loss: 858.5266 - root_mean_squared_error: 0.0320 - val_loss: 937.6609 - val_root_mean_squared_error: 0.2354\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 857.8401 - root_mean_squared_error: 0.0343\n",
      "Epoch 00083: loss improved from 858.52661 to 857.84009, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 469s 469ms/step - loss: 857.8401 - root_mean_squared_error: 0.0343 - val_loss: 904.0797 - val_root_mean_squared_error: 0.2366\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 857.0991 - root_mean_squared_error: 0.0324\n",
      "Epoch 00084: loss improved from 857.84009 to 857.09912, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 463s 463ms/step - loss: 857.0991 - root_mean_squared_error: 0.0324 - val_loss: 927.8802 - val_root_mean_squared_error: 0.2361\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 856.3427 - root_mean_squared_error: 0.0324\n",
      "Epoch 00085: loss improved from 857.09912 to 856.34265, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 462s 462ms/step - loss: 856.3427 - root_mean_squared_error: 0.0324 - val_loss: 933.2855 - val_root_mean_squared_error: 0.2350\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 855.7083 - root_mean_squared_error: 0.0359\n",
      "Epoch 00086: loss improved from 856.34265 to 855.70825, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 455s 455ms/step - loss: 855.7083 - root_mean_squared_error: 0.0359 - val_loss: 902.7069 - val_root_mean_squared_error: 0.2352\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 854.9448 - root_mean_squared_error: 0.0327\n",
      "Epoch 00087: loss improved from 855.70825 to 854.94482, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 470s 470ms/step - loss: 854.9448 - root_mean_squared_error: 0.0327 - val_loss: 901.9455 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 854.2457 - root_mean_squared_error: 0.0318\n",
      "Epoch 00088: loss improved from 854.94482 to 854.24567, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 466s 467ms/step - loss: 854.2457 - root_mean_squared_error: 0.0318 - val_loss: 905.2653 - val_root_mean_squared_error: 0.2358\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 853.4797 - root_mean_squared_error: 0.0323\n",
      "Epoch 00089: loss improved from 854.24567 to 853.47968, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 471s 471ms/step - loss: 853.4797 - root_mean_squared_error: 0.0323 - val_loss: 925.6811 - val_root_mean_squared_error: 0.2354\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 852.8059 - root_mean_squared_error: 0.0344\n",
      "Epoch 00090: loss improved from 853.47968 to 852.80591, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 469s 469ms/step - loss: 852.8059 - root_mean_squared_error: 0.0344 - val_loss: 936.8077 - val_root_mean_squared_error: 0.2343\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 852.0967 - root_mean_squared_error: 0.0329\n",
      "Epoch 00091: loss improved from 852.80591 to 852.09674, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 462s 462ms/step - loss: 852.0967 - root_mean_squared_error: 0.0329 - val_loss: 905.5201 - val_root_mean_squared_error: 0.2357\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 851.3626 - root_mean_squared_error: 0.0341\n",
      "Epoch 00092: loss improved from 852.09674 to 851.36261, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 462s 462ms/step - loss: 851.3626 - root_mean_squared_error: 0.0341 - val_loss: 919.7341 - val_root_mean_squared_error: 0.2350\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 850.7034 - root_mean_squared_error: 0.0317\n",
      "Epoch 00093: loss improved from 851.36261 to 850.70337, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 452s 452ms/step - loss: 850.7034 - root_mean_squared_error: 0.0317 - val_loss: 923.4594 - val_root_mean_squared_error: 0.2337\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 849.9994 - root_mean_squared_error: 0.0321\n",
      "Epoch 00094: loss improved from 850.70337 to 849.99939, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 468s 468ms/step - loss: 849.9994 - root_mean_squared_error: 0.0321 - val_loss: 910.2442 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 849.3022 - root_mean_squared_error: 0.0348\n",
      "Epoch 00095: loss improved from 849.99939 to 849.30225, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 469s 469ms/step - loss: 849.3022 - root_mean_squared_error: 0.0348 - val_loss: 898.7043 - val_root_mean_squared_error: 0.2354\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 848.5621 - root_mean_squared_error: 0.0318\n",
      "Epoch 00096: loss improved from 849.30225 to 848.56207, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 469s 469ms/step - loss: 848.5621 - root_mean_squared_error: 0.0318 - val_loss: 929.0025 - val_root_mean_squared_error: 0.2355\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 847.9230 - root_mean_squared_error: 0.0330\n",
      "Epoch 00097: loss improved from 848.56207 to 847.92297, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 459s 459ms/step - loss: 847.9230 - root_mean_squared_error: 0.0330 - val_loss: 898.2603 - val_root_mean_squared_error: 0.2346\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 847.2043 - root_mean_squared_error: 0.0325\n",
      "Epoch 00098: loss improved from 847.92297 to 847.20435, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 481s 481ms/step - loss: 847.2043 - root_mean_squared_error: 0.0325 - val_loss: 948.8218 - val_root_mean_squared_error: 0.2363\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 846.5308 - root_mean_squared_error: 0.0314\n",
      "Epoch 00099: loss improved from 847.20435 to 846.53082, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 456s 456ms/step - loss: 846.5308 - root_mean_squared_error: 0.0314 - val_loss: 941.1899 - val_root_mean_squared_error: 0.2365\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 845.7980 - root_mean_squared_error: 0.0318\n",
      "Epoch 00100: loss improved from 846.53082 to 845.79797, saving model to evan_checkpoints/cp5.ckpt\n",
      "1000/1000 [==============================] - 458s 458ms/step - loss: 845.7980 - root_mean_squared_error: 0.0318 - val_loss: 933.4903 - val_root_mean_squared_error: 0.2359\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "import tensorflow.keras as keras\n",
    "checkpoint_path = 'evan_checkpoints/cp5.ckpt'\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='loss',\n",
    "                                                 verbose=1,\n",
    "                                                 save_freq = 1000,\n",
    "                                                 save_best_only=True)\n",
    "mags = np.column_stack([train_gen_gmag,train_gen_rmag,train_gen_imag,train_gen_zmag,train_gen_ymag])\n",
    "\n",
    "mags2 = zip(train_gen_gmag,train_gen_rmag,train_gen_imag,train_gen_zmag,train_gen_ymag)\n",
    "class JoinedGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, input_gen1, input_gen2, target_gen):\n",
    "        self.gen1 = input_gen1\n",
    "        self.gen2 = input_gen2\n",
    "        self.gen3 = target_gen\n",
    "\n",
    "        #assert len(input_gen1) == len(input_gen2) == len(target_gen)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gen1)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x1 = self.gen1[i]\n",
    "        x2 = self.gen2[i]\n",
    "        y = self.gen3[i]\n",
    "\n",
    "        return [x1, x2], y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.gen1.on_epoch_end()\n",
    "        self.gen2.on_epoch_end()\n",
    "        self.gen3.on_epoch_end()\n",
    "log_dir = os.path.join(\"tf_logs/\")\n",
    "mags2 = JoinedMags(train_gen_gmag,train_gen_rmag,train_gen_imag,train_gen_zmag,train_gen_ymag)\n",
    "my_gen = JoinedGen(train_gen_image, mags2, train_gen_label)\n",
    "params = {\"lr\": 0.001, \"epochs\": 100}\n",
    "\n",
    "run = neptune.init(\n",
    "    project=\"astro-data-lab/Bayesian-CNN\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4NDU0YjdhYy01NjM4LTQwMDQtOGQxMC02YTQ2MDkyMzQ5MmUifQ==\",\n",
    ")  # your credentials\n",
    "run[\"parameters\"] = params\n",
    "neptune_cbk = NeptuneCallback(run=run, base_namespace=\"training\")\n",
    "\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "history = model.fit(my_gen,epochs=100,shuffle= True,verbose=1, validation_data = val_my_gen, callbacks = [tensorboard_callback, cp_callback])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'],loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(history.history['root_mean_squared_error'])\n",
    "plt.plot(history.history['val_root_mean_squared_error'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('RMS error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','val'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7352fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model here:\n",
    "\n",
    "model.load_weights('evan_checkpoints/cp5.ckpt')\n",
    "\n",
    "photoz_arr = []\n",
    "std_arr = []\n",
    "sample_arr = []\n",
    "for i in range(len(test_gen_label)):\n",
    "    mags = np.column_stack([test_gen_gmag[i],test_gen_rmag[i],test_gen_imag[i],test_gen_zmag[i],test_gen_ymag[i]])\n",
    "    evaluated_model_i = model([test_gen_image[i], mags])\n",
    "    predict_i = model.predict([test_gen_image[i], mags])\n",
    "    prediction_mean_i = (evaluated_model_i.mean()).numpy().tolist()\n",
    "\n",
    "    prediction_stdv_i = (evaluated_model_i.stddev()).numpy()\n",
    "    sample_arr.append(np.ravel(predict_i))\n",
    "    photoz_arr.append(np.ravel(prediction_mean_i))\n",
    "    std_arr.append(np.ravel(prediction_stdv_i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3bec3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7feb38717df0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['root_mean_squared_error'])\n",
    "plt.plot(history.history['val_root_mean_squared_error'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('RMS error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','val'],loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a40f044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zspec_bin</th>\n",
       "      <th>count</th>\n",
       "      <th>L</th>\n",
       "      <th>bias_bw</th>\n",
       "      <th>bias_conv</th>\n",
       "      <th>scatter_bw</th>\n",
       "      <th>scatter_conv</th>\n",
       "      <th>outlier_bw</th>\n",
       "      <th>outlier_conv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 4.0]</td>\n",
       "      <td>43000</td>\n",
       "      <td>0.104205</td>\n",
       "      <td>-0.013181</td>\n",
       "      <td>-0.012612</td>\n",
       "      <td>0.035045</td>\n",
       "      <td>0.030702</td>\n",
       "      <td>0.142372</td>\n",
       "      <td>0.065977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    zspec_bin  count         L   bias_bw  bias_conv  scatter_bw  scatter_conv  \\\n",
       "0  (0.0, 4.0]  43000  0.104205 -0.013181  -0.012612    0.035045      0.030702   \n",
       "\n",
       "   outlier_bw  outlier_conv  \n",
       "0    0.142372      0.065977  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from photoz_utils import *\n",
    "y_test_new = pd.Series(np.ravel(y_test))\n",
    "photoz = pd.Series(np.ravel(photoz_arr))\n",
    "get_point_metrics(photoz,y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a458d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/bcnn_with_mags_optimal_model_old_loss_10_4_22')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1091fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import h5py\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from DataMaker import HDF5ImageGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc18d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import photoz_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50b6b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfpl = tfp.layers\n",
    "tf1 = tf.compat.v1\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d2c3541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_probability.python.distributions import kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d8bd5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 10GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3da0b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 16\n",
    "IMAGE_SHAPE = (5, 127, 127)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 90\n",
    "GB_LIMIT = 30\n",
    "CHECKPOINTS_TO_SAVE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ee842a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_gen = {'X_key': 'image',\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': True,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': True}\n",
    "\n",
    "train_gen = HDF5ImageGenerator(src='/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_training.hdf5', **args_gen)\n",
    "val_gen = HDF5ImageGenerator(src='/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_validation.hdf5', **args_gen)\n",
    "test_gen = HDF5ImageGenerator(src='/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_testing.hdf5', **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "928372fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(train_gen._indices)\n",
    "t = len(test_gen._indices)\n",
    "v = len(val_gen._indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f187c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_mean_field(kernel_size: int, bias_size: int, dtype: any) -> tf.keras.Model:\n",
    "    \"\"\"Specify the surrogate posterior over `keras.layers.Dense` `kernel` and `bias`.\"\"\"\n",
    "    n = kernel_size + bias_size\n",
    "    c = np.log(np.expm1(1.))\n",
    "\n",
    "    return tf.keras.Sequential([\n",
    "        tfp.layers.VariableLayer(2 * n, dtype = dtype, initializer = lambda shape, dtype: random_gaussian_initializer(shape, dtype), trainable = True),\n",
    "        tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "            tfd.Normal(loc = t[ ..., : n],\n",
    "                       scale = 0 + tf.nn.softplus(c + t[..., n:])),\n",
    "            reinterpreted_batch_ndims = 1)),\n",
    "    ])\n",
    "\n",
    "def prior_trainable(kernel_size: int, bias_size: int, dtype: any) -> tf.keras.Model:\n",
    "    \"\"\"Specify the prior over `keras.layers.Dense` `kernel` and `bias`.\"\"\"\n",
    "    n = kernel_size + bias_size\n",
    "\n",
    "    return tf.keras.Sequential([\n",
    "        tfp.layers.VariableLayer(n, dtype = dtype),  # Returns a trainable variable of shape n, regardless of input\n",
    "        tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "            tfd.Normal(loc = t, scale = 0.1),\n",
    "            reinterpreted_batch_ndims = 1)),\n",
    "    ])\n",
    "\n",
    "def random_gaussian_initializer(shape, dtype):\n",
    "    n = int(shape / 2)\n",
    "    loc_norm = tf.random_normal_initializer(mean = 0., stddev = 0.1)\n",
    "    loc = tf.Variable(\n",
    "        initial_value = loc_norm(shape = (n, ), dtype = dtype)\n",
    "    )\n",
    "    scale_norm = tf.random_normal_initializer(mean = -3., stddev = 0.1)\n",
    "    scale = tf.Variable(\n",
    "        initial_value = scale_norm(shape = (n, ), dtype = dtype)\n",
    "    )\n",
    "    return tf.concat([loc, scale], 0)\n",
    "\n",
    "kl_divergence_function = lambda q, p, _: kl_divergence(q, p) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69ccd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, InputLayer, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2beada9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_flipout_1 (Conv2DFli  (None, 32, 126, 126)     1312      \n",
      " pout)                                                           \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 32, 63, 63)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 62, 62)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 32, 31, 31)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 30, 30)        4128      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 29, 29)        4128      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 26912)             0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 26912)             0         \n",
      "                                                                 \n",
      " dense_variational_2 (DenseV  (None, 512)              41338368  \n",
      " ariational)                                                     \n",
      "                                                                 \n",
      " dense_variational_3 (DenseV  (None, 128)              196992    \n",
      " ariational)                                                     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      " independent_normal_1 (Indep  ((None, 1),              0         \n",
      " endentNormal)                (None, 1))                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,549,314\n",
      "Trainable params: 41,549,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_variational = Sequential([\n",
    "    InputLayer(input_shape = (5, 127, 127)),\n",
    "    tfpl.Convolution2DFlipout(32, kernel_size=(2, 2), activation = 'tanh', kernel_divergence_fn = kl_divergence_function, data_format = 'channels_first'),\n",
    "    MaxPooling2D(2, 2, data_format = 'channels_first'),\n",
    "    Conv2D(32, kernel_size = (2, 2), activation = 'tanh', data_format = 'channels_first'),\n",
    "    MaxPooling2D(2, 2, data_format = 'channels_first'),\n",
    "    Conv2D(32, kernel_size = (2, 2), activation = 'relu', data_format = 'channels_first'),\n",
    "    Conv2D(32, kernel_size = (2, 2), activation = 'relu', data_format = 'channels_first'),\n",
    "    Flatten(),\n",
    "    Dropout(0.2),\n",
    "    tfpl.DenseVariational(512, \n",
    "                                      make_posterior_fn = posterior_mean_field,\n",
    "                                      make_prior_fn = prior_trainable,\n",
    "                                      kl_weight = 1 / n),\n",
    "    tfpl.DenseVariational(128, \n",
    "                                      make_posterior_fn = posterior_mean_field,\n",
    "                                      make_prior_fn = prior_trainable,\n",
    "                                      kl_weight = 1 / n),\n",
    "    Dense(tfpl.IndependentNormal.params_size(1)),\n",
    "    tfpl.IndependentNormal(1)\n",
    "])\n",
    "\n",
    "model_variational.build((n, 5, 127, 127))\n",
    "\n",
    "model_variational.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de5fcf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(targets, estimated_distribution):\n",
    "    return - estimated_distribution.log_prob(targets) / (1 + targets)\n",
    "\n",
    "model_variational.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = loss_function, metrics = [keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42841133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "model_name = 'HSC_v6_BCNN_full'\n",
    "\n",
    "checkpoint_filepath = os.path.join('/models/', model_name)\n",
    "\n",
    "weights_path = os.path.join('/models/', model_name) + '_weights'\n",
    "\n",
    "log_directory = os.path.join('/logs/', model_name)\n",
    "\n",
    "logs_callback = TensorBoard(log_dir = log_directory)\n",
    "\n",
    "weights_callback = ModelCheckpoint(filepath = os.path.join(checkpoint_filepath, 'weights_epoch{epoch}.hdf5'),\n",
    "                                   save_freq = int(EPOCHS / CHECKPOINTS_TO_SAVE) * int(n / BATCH_SIZE),\n",
    "                                   save_weights_only = True, save_best_only=True)\n",
    "\n",
    "LR_callback = ReduceLROnPlateau()\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_directory, histogram_freq = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed21918a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Layer DenseVariational has arguments ['self', 'units', 'make_posterior_fn', 'make_prior_fn', 'kl_weight', 'kl_use_exact', 'activation', 'use_bias', 'activity_regularizer']\n",
      "in `__init__` and therefore must override `get_config()`.\n",
      "\n",
      "Example:\n",
      "\n",
      "class CustomLayer(keras.layers.Layer):\n",
      "    def __init__(self, arg1, arg2):\n",
      "        super().__init__()\n",
      "        self.arg1 = arg1\n",
      "        self.arg2 = arg2\n",
      "\n",
      "    def get_config(self):\n",
      "        config = super().get_config()\n",
      "        config.update({\n",
      "            \"arg1\": self.arg1,\n",
      "            \"arg2\": self.arg2,\n",
      "        })\n",
      "        return config\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Layer DenseVariational has arguments ['self', 'units', 'make_posterior_fn', 'make_prior_fn', 'kl_weight', 'kl_use_exact', 'activation', 'use_bias', 'activity_regularizer']\n",
      "in `__init__` and therefore must override `get_config()`.\n",
      "\n",
      "Example:\n",
      "\n",
      "class CustomLayer(keras.layers.Layer):\n",
      "    def __init__(self, arg1, arg2):\n",
      "        super().__init__()\n",
      "        self.arg1 = arg1\n",
      "        self.arg2 = arg2\n",
      "\n",
      "    def get_config(self):\n",
      "        config = super().get_config()\n",
      "        config.update({\n",
      "            \"arg1\": self.arg1,\n",
      "            \"arg2\": self.arg2,\n",
      "        })\n",
      "        return config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 00:01:03.726403: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-09-13 00:01:03.726456: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n",
      "2022-09-13 00:01:03.817188: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-09-13 00:01:03.817219: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_1/conv2d_flipout_1/Conv2D' defined at (most recent call last):\n    File \"/home/billyli/miniconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/billyli/miniconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3771805/3415848660.py\", line 1, in <cell line: 1>\n      model_variational.fit(train_gen, epochs = 1, shuffle = True, verbose = 1, validation_data = val_gen, callbacks = [tensorboard_callback, logs_callback, LR_callback, weights_callback])\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/tensorflow_probability/python/layers/conv_variational.py\", line 231, in call\n      outputs = self._apply_variational_kernel(inputs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/tensorflow_probability/python/layers/conv_variational.py\", line 1076, in _apply_variational_kernel\n      outputs = self._convolution_op(\nNode: 'sequential_1/conv2d_flipout_1/Conv2D'\nDNN library is not found.\n\t [[{{node sequential_1/conv2d_flipout_1/Conv2D}}]] [Op:__inference_train_function_4914]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_variational\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLR_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_1/conv2d_flipout_1/Conv2D' defined at (most recent call last):\n    File \"/home/billyli/miniconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/billyli/miniconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3771805/3415848660.py\", line 1, in <cell line: 1>\n      model_variational.fit(train_gen, epochs = 1, shuffle = True, verbose = 1, validation_data = val_gen, callbacks = [tensorboard_callback, logs_callback, LR_callback, weights_callback])\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/tensorflow_probability/python/layers/conv_variational.py\", line 231, in call\n      outputs = self._apply_variational_kernel(inputs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/tensorflow_probability/python/layers/conv_variational.py\", line 1076, in _apply_variational_kernel\n      outputs = self._convolution_op(\nNode: 'sequential_1/conv2d_flipout_1/Conv2D'\nDNN library is not found.\n\t [[{{node sequential_1/conv2d_flipout_1/Conv2D}}]] [Op:__inference_train_function_4914]"
     ]
    }
   ],
   "source": [
    "model_variational.fit(train_gen, epochs = 1, shuffle = True, verbose = 1, validation_data = val_gen, callbacks = [tensorboard_callback, logs_callback, LR_callback, weights_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3617d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variational.save_weights(weights_path.format(epoch = 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e6a645b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f09166d7a90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_variational.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "deefc7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_train = h5py.File('/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_training.hdf5', 'r')\n",
    "y_train = np.asarray(hf_train['specz_redshift'][0:])[..., None]\n",
    "object_id_train = np.asarray(hf_train['object_id'][0:])\n",
    "hf_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ec563ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_test = h5py.File('/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_testing.hdf5', 'r')\n",
    "x_test = np.asarray(np.transpose(hf_test['image'][0:],(0,1,2,3)))\n",
    "y_test = np.asarray(hf_test['specz_redshift'][0:])[..., None]\n",
    "object_id = np.asarray(hf_test['object_id'][0:])\n",
    "hf_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e091d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_validation = h5py.File('/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_validation.hdf5', 'r')\n",
    "y_validation = np.asarray(hf_validation['specz_redshift'][0:])[..., None]\n",
    "object_id_validation = np.asarray(hf_validation['object_id'][0:])\n",
    "hf_validation.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c0995a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "t = 2000\n",
    "v = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f257cf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 23:23:30.195754: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-09-12 23:23:30.195821: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Exception encountered when calling layer \"conv2d_flipout\" (type Conv2DFlipout).\n\nDNN library is not found. [Op:Conv2D]\n\nCall arguments received by layer \"conv2d_flipout\" (type Conv2DFlipout):\n  • inputs=tf.Tensor(shape=(1, 5, 127, 127), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_variational\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow_probability/python/layers/conv_variational.py:231\u001b[0m, in \u001b[0;36m_ConvVariational.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m    229\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(value\u001b[38;5;241m=\u001b[39minputs, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 231\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_variational_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_variational_bias(outputs)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow_probability/python/layers/conv_variational.py:1076\u001b[0m, in \u001b[0;36m_ConvFlipout._apply_variational_kernel\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_posterior_affine_tensor \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1073\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_posterior_tensor_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_posterior_affine))\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_posterior_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1076\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convolution_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_posterior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1079\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(inputs)\n\u001b[1;32m   1080\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(input_shape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Exception encountered when calling layer \"conv2d_flipout\" (type Conv2DFlipout).\n\nDNN library is not found. [Op:Conv2D]\n\nCall arguments received by layer \"conv2d_flipout\" (type Conv2DFlipout):\n  • inputs=tf.Tensor(shape=(1, 5, 127, 127), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model_variational(np.expand_dims(x_test[0], axis = 0)).mean()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67536dda",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 5, 127, 127), found shape=(5, 127, 127)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m photoz \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(t):\n\u001b[0;32m----> 4\u001b[0m     photoz\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel_variational\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      6\u001b[0m photoz \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(photoz)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/engine/input_spec.py:264\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    265\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    266\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    267\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 5, 127, 127), found shape=(5, 127, 127)"
     ]
    }
   ],
   "source": [
    "photoz = []\n",
    "\n",
    "for i in range(t):\n",
    "    photoz.append(model_variational(np.expand_dims(x_test[i], axis = 0)).mean()[0][0])\n",
    "\n",
    "photoz = np.asarray(photoz).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f5b1434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 23:19:12.804195: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-09-12 23:19:12.804266: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Exception encountered when calling layer \"conv2d_flipout\" (type Conv2DFlipout).\n\nDNN library is not found. [Op:Conv2D]\n\nCall arguments received by layer \"conv2d_flipout\" (type Conv2DFlipout):\n  • inputs=tf.Tensor(shape=(1, 5, 127, 127), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m photoz \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(t):\n\u001b[0;32m----> 4\u001b[0m     photoz\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel_variational\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_gen\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      6\u001b[0m photoz \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(photoz)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow_probability/python/layers/conv_variational.py:231\u001b[0m, in \u001b[0;36m_ConvVariational.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m    229\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(value\u001b[38;5;241m=\u001b[39minputs, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 231\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_variational_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_variational_bias(outputs)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow_probability/python/layers/conv_variational.py:1076\u001b[0m, in \u001b[0;36m_ConvFlipout._apply_variational_kernel\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_posterior_affine_tensor \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1073\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_posterior_tensor_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_posterior_affine))\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_posterior_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1076\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convolution_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_posterior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1079\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(inputs)\n\u001b[1;32m   1080\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(input_shape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Exception encountered when calling layer \"conv2d_flipout\" (type Conv2DFlipout).\n\nDNN library is not found. [Op:Conv2D]\n\nCall arguments received by layer \"conv2d_flipout\" (type Conv2DFlipout):\n  • inputs=tf.Tensor(shape=(1, 5, 127, 127), dtype=float32)"
     ]
    }
   ],
   "source": [
    "photoz = []\n",
    "\n",
    "for i in range(t):\n",
    "    photoz.append(model_variational(np.array([test_gen[int(i/BATCH_SIZE)][0][int(i%BATCH_SIZE)]])).mean()[0][0])\n",
    "\n",
    "photoz = np.asarray(photoz).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd9113",
   "metadata": {},
   "source": [
    "photoz_train = []\n",
    "\n",
    "for i in range(n):\n",
    "    photoz_train.append(model_variational(np.array([train_gen[int(i/BATCH_SIZE)][0][int(i%BATCH_SIZE)]])).mean()[0][0])\n",
    "\n",
    "photoz_train = np.asarray(photoz_train).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016e9ea9",
   "metadata": {},
   "source": [
    "photoz_validation = []\n",
    "\n",
    "for i in range(v):\n",
    "    photoz_validation.append(model_variational(np.array([val_gen[int(i/BATCH_SIZE)][0][int(i%BATCH_SIZE)]])).mean()[0][0])\n",
    "\n",
    "photoz_validation = np.asarray(photoz_validation).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaca9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "specz = np.asarray(y_test)[:,0][:t]\n",
    "# specz_train = np.asarray(y_train)[:,0][:n]\n",
    "# specz_validation = np.asarray(y_validation)[:,0][:v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "photoz_err = []\n",
    "\n",
    "for i in range(t):\n",
    "    photoz_err.append(model_variational(np.array([test_gen[int(i/BATCH_SIZE)][0][int(i%BATCH_SIZE)]])).stddev()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7072dbc",
   "metadata": {},
   "source": [
    "photoz_err_train = []\n",
    "\n",
    "for i in range(n):\n",
    "    photoz_err_train.append(model_variational(np.array([train_gen[int(i/BATCH_SIZE)][0][int(i%BATCH_SIZE)]])).stddev()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8429a8",
   "metadata": {},
   "source": [
    "photoz_err_validation = []\n",
    "\n",
    "for i in range(v):\n",
    "    photoz_err_validation.append(model_variational(np.array([val_gen[int(i/BATCH_SIZE)][0][int(i%BATCH_SIZE)]])).stddev()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca0c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "xy = np.asarray(np.vstack([specz, photoz])).astype('float32')\n",
    "z = gaussian_kde(xy)(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d080369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "z_max = 4\n",
    "sns.set(rc={'figure.figsize': (10, 10), 'lines.markersize': 20})\n",
    "plt.rcParams.update({'font.size': 40})\n",
    "fig, ax = plt.subplots()\n",
    "scatter_plot = ax.scatter(specz, photoz, c = z, s = 1, edgecolor = None)\n",
    "plt.colorbar(scatter_plot, label = 'Density')\n",
    "plt.title('Prediction')\n",
    "plt.xlabel('spectroscopic redshift')\n",
    "plt.ylabel('photo z')\n",
    "plt.plot([0, z_max], [0, z_max],color = 'black')\n",
    "plt.xlim([0, z_max])\n",
    "plt.ylim([0, z_max])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258bc2ea",
   "metadata": {},
   "source": [
    "sns.set(rc={'figure.figsize':(10, 10), 'lines.markersize':20})\n",
    "plt.rcParams.update({'font.size': 100})\n",
    "sns.set(font_scale=3)\n",
    "\n",
    "data = {'BCNN':10.7, 'BNN':19.7, 'Mizuki':27.4,\n",
    "        'DEmP':25}\n",
    "models_list = list(data.keys())\n",
    "outlier_rates = list(data.values())\n",
    "\n",
    "plt.bar(models_list, outlier_rates, color=('blue', 'red', 'red', 'red'))\n",
    "plt.plot([-.5, 3.5], [15, 15], color = 'black', linestyle = 'dashed')\n",
    "plt.title(\"Outlier Rates\")\n",
    "plt.ylabel(\"% Outlier Rate\")\n",
    "plt.xlabel(\"Model Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b34aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_variational = 0\n",
    "overlap_array_variational = []\n",
    "for i in range(0,t):\n",
    "    if np.abs(specz[i]-photoz[i])<=photoz_err[i]:\n",
    "        overlap_variational += 1\n",
    "        overlap_array_variational.append(1)\n",
    "    else:\n",
    "        overlap_array_variational.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4218c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "display_size = 1000\n",
    "scatter_plot = ax.scatter(specz[:display_size], photoz[:display_size], c = z[:display_size], s = 4, edgecolor = None, zorder = 2)\n",
    "error_plot = ax.errorbar(specz[:display_size], photoz[:display_size], yerr = photoz_err[:display_size], fmt = \"o\", markersize = 0, color = 'blue', elinewidth = 1, zorder = 1)\n",
    "plt.title('Prediction with error, Bayesian')\n",
    "plt.xlabel('spectroscopic redshift')\n",
    "plt.ylabel('photo z')\n",
    "plt.plot([0, z_max], [0, z_max], color = 'black')\n",
    "plt.xlim([0, z_max])\n",
    "plt.ylim([0, z_max])\n",
    "print(\"Coverage: \"+str(overlap_variational/t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5eee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_array_variational = np.transpose(np.vstack((specz, photoz, photoz_err, overlap_array_variational))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb236386",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_combined_array_variational = sorted(combined_array_variational, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebecb5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_variational = int(z_max*5)\n",
    "splitted_sorted_combined_array_variational = np.array_split(sorted_combined_array_variational, bins_variational)\n",
    "coverage_variational = []\n",
    "for i in range(0, bins_variational):\n",
    "    bins_count_variational = 0\n",
    "    for j in range(0,len(splitted_sorted_combined_array_variational[i])):\n",
    "        if splitted_sorted_combined_array_variational[i][j][3] == 1:\n",
    "            bins_count_variational += 1\n",
    "    coverage_variational.append(bins_count_variational/len(splitted_sorted_combined_array_variational[i])/0.6827)\n",
    "x_array = np.arange(0, z_max, z_max/bins_variational)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06c57bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x_array, coverage_variational, c = 'red')\n",
    "plt.title('Coverage, Bayesian')\n",
    "plt.xlabel('spectroscopic redshift')\n",
    "plt.ylabel('coverage')\n",
    "plt.ylim([0, 1.5])\n",
    "plt.plot([0, 4], [1, 1], color = 'black', linestyle = 'dashed')\n",
    "print(\"Coverage: \"+str(overlap_variational/t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7375ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_array = []\n",
    "for i in range(0, bins_variational):\n",
    "    total = 0\n",
    "    for j in range(0, len(splitted_sorted_combined_array_variational[i])):\n",
    "        bias = (splitted_sorted_combined_array_variational[i][j][1]-splitted_sorted_combined_array_variational[i][j][0])\n",
    "        total += bias/(1 + splitted_sorted_combined_array_variational[i][j][0])\n",
    "    mean_array.append(total/len(splitted_sorted_combined_array_variational[i]))\n",
    "x_array = np.arange(0, z_max, z_max/bins_variational)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_array = []\n",
    "for i in range(0,bins_variational):\n",
    "    error_total = 0\n",
    "    for j in range(0,len(splitted_sorted_combined_array_variational[i])):\n",
    "        error_total += splitted_sorted_combined_array_variational[i][j][2]\n",
    "    error_array.append(error_total/len(splitted_sorted_combined_array_variational[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8652e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(5, 5), 'lines.markersize':40})\n",
    "plt.rcParams.update({'font.size': 40})\n",
    "plt.errorbar(x_array, mean_array, yerr = error_array, fmt = \"o\", color = 'blue', markersize = 4, elinewidth = 2)\n",
    "plt.title('Bias Plot for Probabilistic Model')\n",
    "plt.xlabel('True Redshift')\n",
    "plt.ylabel('Bias (Predicted - True)')\n",
    "plt.plot([0, z_max], [0, 0], color = 'black')\n",
    "plt.plot([0, z_max], [0.02, 0.02], color = 'black', linestyle = 'dashed')\n",
    "plt.plot([0, z_max], [-0.02, -0.02], color = 'black', linestyle = 'dashed')\n",
    "plt.ylim([-0.5, 0.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee12a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_outlier_array = np.transpose(np.vstack((specz,np.subtract(photoz, specz))))\n",
    "sorted_combined_outlier_array = sorted(combined_outlier_array, key=lambda x: x[0])\n",
    "bins_outlier = int(z_max*10)\n",
    "splitted_sorted_combined_outlier_array = np.array_split(sorted_combined_outlier_array,bins_outlier)\n",
    "outlier_array = []\n",
    "outlier_count_total = 0\n",
    "for i in range(0,bins_outlier):\n",
    "    outlier_count = 0\n",
    "    for j in range(0,len(splitted_sorted_combined_outlier_array[i])):\n",
    "        if np.abs(splitted_sorted_combined_outlier_array[i][j][1]/(splitted_sorted_combined_outlier_array[i][j][0] + 1)) >= .15:\n",
    "            outlier_count += 1\n",
    "            outlier_count_total += 1\n",
    "    outlier_array.append(outlier_count/len(specz)*bins_outlier)\n",
    "x_array_outlier = np.arange(0,z_max,z_max/bins_outlier)\n",
    "plt.plot(x_array_outlier, outlier_array, c = 'blue')\n",
    "plt.title('Outlier Rate')\n",
    "plt.xlabel('spec z')\n",
    "plt.ylabel('outlier rate')\n",
    "plt.xlim([0,z_max])\n",
    "plt.ylim([0,1/2])\n",
    "plt.show()\n",
    "\n",
    "print(\"Outlier Rate: \"+str(outlier_count_total/len(specz)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938faefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "photoz_utils.save_with_oid_std(model_name, object_id, specz, photoz, photoz_err)\n",
    "# photoz_utils.save_train_with_oid_std(model_name, object_id_train, specz_train, photoz_train, photoz_err_train)\n",
    "# photoz_utils.save_validation_with_oid_std(model_name, object_id_validation, specz_validation, photoz_validation, photoz_err_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae84b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertains = []\n",
    "for i in range(0, len(photoz_err)):\n",
    "    if photoz_err[i].numpy() >= 1:\n",
    "        uncertains.append(i)\n",
    "        print(\"Object ID: \" + str(object_id[i]) + \", Spectro_z: \" + str(specz[i]) + \", Photo_z: \" + str(photoz[i]) + \", Photo_z_err: \" + str(photoz_err[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c89c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = 2\n",
    "current = uncertains[check]\n",
    "print(\"Object ID: \" + str(object_id[current]) + \", Spectro_z: \" + str(specz[current]) + \", Photo_z: \" + str(photoz[current]) + \", Photo_z_err: \" + str(photoz_err[current].numpy()))\n",
    "plt.imshow(x_test[current][:,:,0])\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54921336",
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = []\n",
    "for i in range(0, len(photoz)):\n",
    "    if np.abs(photoz[i]-specz[i]) >= 1 and photoz_err[i].numpy() <= 0.5:\n",
    "        biases.append(i)\n",
    "        print(\"Object ID: \" + str(object_id[i]) + \", Spectro_z: \" + str(specz[i]) + \", Photo_z: \" + str(photoz[i]) + \", Photo_z_err: \" + str(photoz_err[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d860045",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_bias = 3\n",
    "current_bias = biases[check_bias]\n",
    "print(\"Object ID: \" + str(object_id[current_bias]) + \", Spectro_z: \" + str(specz[current_bias]) + \", Photo_z: \" + str(photoz[current_bias]) + \", Photo_z_err: \" + str(photoz_err[current_bias].numpy()))\n",
    "plt.imshow(x_test[current_bias][:,:,0])\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec169d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn",
   "language": "python",
   "name": "bnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

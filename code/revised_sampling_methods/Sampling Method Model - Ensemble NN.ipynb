{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9825dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import pandas as pd\n",
    "import random\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import clear_output\n",
    "from scipy.interpolate import interp1d\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "tfd = tfp.distributions\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "from photoz_utils import *\n",
    "from photoz_plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34252c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24abff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_max = 2.5\n",
    "\n",
    "train_array = pd.read_csv('/data/HSC/HSC_v6/3_model_comparison/training_'+str(z_max)+'z_.csv') # zmax = 2.5\n",
    "train_array = np.asarray(train_array)\n",
    "\n",
    "test_array = pd.read_csv('/data/HSC/HSC_v6/3_model_comparison/testing_'+str(z_max)+'z_.csv')\n",
    "test_array = np.asarray(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298056a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "OID_test = test_array[:,0]\n",
    "X_test = test_array[:,[12,13,14,15,16]]\n",
    "y_test = test_array[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "286c8b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_array = \"[1, 1, 1, 1]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2daf62b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnetwork = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54689ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_total = list(train_array[:,[12,13,14,15,16]])\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af432415",
   "metadata": {},
   "outputs": [],
   "source": [
    "nensemble = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "619d4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "sampling_method = 'oversampled'\n",
    "\n",
    "for i in range(1, nnetwork + 1):\n",
    "    if sampling_method == 'control':\n",
    "        training_array_bin = pd.read_csv('/data/HSC/HSC_v6/3_model_comparison/'+str(sampling_method)+'_training_set_'+str(z_max)+'z#1.csv')\n",
    "    else:\n",
    "        training_array_bin = pd.read_csv('/data/HSC/HSC_v6/3_model_comparison/'+str(sampling_method)+'_training_set_'+str(z_max)+'z_'+str(sample_array)+'#'+str(i)+'.csv')\n",
    "    training_array_bin = np.asarray(training_array_bin)\n",
    "    X_bin = list(training_array_bin[:,[12,13,14,15,16]])\n",
    "    X_bin = scaler.transform(X_bin)\n",
    "    y_bin = list(training_array_bin[:,2])\n",
    "    X.append(X_bin)\n",
    "    y.append(y_bin)\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bce2b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for i in range(0,nensemble):\n",
    "    input_ = tf.keras.layers.Input(shape=X[0].shape[1:])\n",
    "    hidden1 = tf.keras.layers.Dense(200, activation=\"tanh\")(input_)\n",
    "    hidden2 = tf.keras.layers.Dense(200, activation=\"tanh\")(hidden1)\n",
    "    hidden3 = tf.keras.layers.Dense(200, activation=\"tanh\")(hidden2)\n",
    "    hidden4 = tf.keras.layers.Dense(200, activation=\"relu\")(hidden3)\n",
    "    concat = tf.keras.layers.Concatenate()([input_, hidden4])\n",
    "    output = tf.keras.layers.Dense(1)(concat)\n",
    "    model = tf.keras.Model(inputs=[input_], outputs=[output])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\",metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb28378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19686/19686 [==============================] - 33s 2ms/step - loss: 1.3319 - mean_absolute_error: 0.2403\n",
      "Epoch 2/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.3190 - mean_absolute_error: 0.1936\n",
      "Epoch 3/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2648 - mean_absolute_error: 0.1772\n",
      "Epoch 4/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2742 - mean_absolute_error: 0.1696\n",
      "Epoch 5/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2470 - mean_absolute_error: 0.1636\n",
      "Epoch 6/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2271 - mean_absolute_error: 0.1586\n",
      "Epoch 7/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2501 - mean_absolute_error: 0.1552\n",
      "Epoch 8/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2345 - mean_absolute_error: 0.1509\n",
      "Epoch 9/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2532 - mean_absolute_error: 0.1479\n",
      "Epoch 10/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2441 - mean_absolute_error: 0.1449\n",
      "Epoch 11/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2340 - mean_absolute_error: 0.1426\n",
      "Epoch 12/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2573 - mean_absolute_error: 0.1406\n",
      "Epoch 13/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2387 - mean_absolute_error: 0.1382\n",
      "Epoch 14/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2308 - mean_absolute_error: 0.1360\n",
      "Epoch 15/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2326 - mean_absolute_error: 0.1339\n",
      "Epoch 16/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2321 - mean_absolute_error: 0.1321\n",
      "Epoch 17/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2112 - mean_absolute_error: 0.1302\n",
      "Epoch 18/500\n",
      "19686/19686 [==============================] - 32s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.1286\n",
      "Epoch 19/500\n",
      " 1507/19686 [=>............................] - ETA: 29s - loss: 0.1365 - mean_absolute_error: 0.1250"
     ]
    }
   ],
   "source": [
    "for i in range(0, nensemble):\n",
    "    models[i].fit(X[i],y[i],epochs=500,shuffle = True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "for i in range(0, nensemble):\n",
    "    y_predict_single = models[i].predict(X_test)\n",
    "    y_predict.append(np.transpose(y_predict_single)[0])\n",
    "\n",
    "y_predict = np.transpose(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21474d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_array = []\n",
    "std_array = []\n",
    "for i in range(0,len(X_test)):\n",
    "    mean = np.mean(y_predict[i])\n",
    "    std = np.std(y_predict[i])\n",
    "    mean_array.append(mean)\n",
    "    std_array.append(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72debab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(mean_array, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3dcfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_array_string = \"\"\n",
    "for i in sample_array:\n",
    "    sample_array_string += str(i)\n",
    "    sample_array_string += \"_\"\n",
    "\n",
    "ensemble_prediction = np.transpose(np.vstack((OID_test, y_test, mean_array, std_array)))\n",
    "\n",
    "df = pd.DataFrame(ensemble_prediction, columns=['object_id', 'specz_redshift', 'photoz_redshift',\n",
    "       'photoz_uncertainty'])\n",
    "model_name = 'ensemble_nn_v1'\n",
    "metrics = get_point_metrics(pd.Series(mean_array), pd.Series(y_test), 2.5, binned=False)\n",
    "\n",
    "if os.path.exists(f'/predictions/HSC_v6_sampling_method_models/{model_name}') == False:\n",
    "    os.makedirs(f'/predictions/HSC_v6_sampling_method_models/{model_name}')\n",
    "if sampling_method == 'control':\n",
    "    df.to_csv(f'/predictions/HSC_v6_sampling_method_models/{model_name}/{sampling_method}_{z_max}z_predictions.csv', index=False)\n",
    "    metrics.to_csv(f'/predictions/HSC_v6_sampling_method_models/{model_name}/{sampling_method}_{z_max}z_metrics.csv', index=False)\n",
    "else:\n",
    "    df.to_csv(f'/predictions/HSC_v6_sampling_method_models/{model_name}/{sampling_method}_{z_max}z_predictions_{sample_array}.csv', index=False)\n",
    "    metrics.to_csv(f'/predictions/HSC_v6_sampling_method_models/{model_name}/{sampling_method}_{z_max}z_metrics_{sample_array}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e422952",
   "metadata": {},
   "source": [
    "# VAE - Galaxy Images\n",
    "\n",
    "2022-08-03\n",
    "\n",
    "Zooey Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5194ac",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d23f862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from DataMaker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e0800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 16\n",
    "BASE_DEPTH = 32\n",
    "IMAGE_SHAPE = (5, 127, 127)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "GB_LIMIT = 10\n",
    "CHECKPOINTS_TO_SAVE = 4\n",
    "KL_WEIGHT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb7cabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/models/HSC_v6_small_VAE_v7/model/weights.h5\n",
      "/models/HSC_v6_small_VAE_v7/model\n",
      "/models/HSC_v6_small_VAE_v7/checkpoints\n",
      "/logs/HSC_v6_small_VAE_v7\n",
      "/predictions/HSC_v6_small_VAE_v7\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"HSC_v6_small\"\n",
    "MODEL_TYPE = \"VAE\"\n",
    "MODEL_VERSION = \"v7\"\n",
    "\n",
    "model_id = '_'.join([DATASET_NAME, MODEL_TYPE, MODEL_VERSION])\n",
    "dir_model = os.path.join('/models', model_id, 'model')\n",
    "dir_checkpoints = os.path.join('/models', model_id, 'checkpoints')\n",
    "dir_logs = os.path.join('/logs', model_id)\n",
    "dir_predictions = os.path.join('/predictions', model_id)\n",
    "weights_file = dir_model + '/weights.h5'\n",
    "\n",
    "print(weights_file)\n",
    "print(dir_model)\n",
    "print(dir_checkpoints)\n",
    "print(dir_logs)\n",
    "print(dir_predictions)\n",
    "\n",
    "os.makedirs(dir_model, exist_ok=True)\n",
    "os.makedirs(dir_checkpoints, exist_ok=True)\n",
    "os.makedirs(dir_logs, exist_ok=True)\n",
    "os.makedirs(dir_predictions, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feddde7",
   "metadata": {},
   "source": [
    "## Allocate GPU\n",
    "\n",
    "Make sure to check others' current usage on Aurora in terminal using `watch nvidia-smi`. Set your `GB_LIMIT` accordingly, in gigabytes. Aurora has 50GB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a44e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 21:18:22.291221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-21 21:18:22.299609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-21 21:18:22.300812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-21 21:18:22.302637: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-21 21:18:22.304191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-21 21:18:22.304868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-21 21:18:22.305524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-21 21:18:22.663852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-21 21:18:22.664578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-21 21:18:22.665242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-21 21:18:22.665879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 200000 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=GB_LIMIT* 20000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e37b0",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Create the shuffled and batched data generators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711b24b8",
   "metadata": {},
   "source": [
    "from albumentations import Compose\n",
    "from albumentations.augmentations.transforms import ToFloat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb70b66",
   "metadata": {},
   "source": [
    "my_augmenter = Compose([ToFloat(max_value=4.16)])\n",
    "batch_args_gen = {'X_key': 'image', 'y_key': 'image', 'labels_encoding': False, 'scaler': False,\n",
    "                  'batch_size': BATCH_SIZE, 'mode': 'train', 'shuffle': True}\n",
    "args_gen = {'X_key': 'image', 'y_key': 'image', 'labels_encoding': False, 'scaler': False,\n",
    "            'batch_size': 1, 'mode': 'test', 'shuffle': False}\n",
    "start_path = \"/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_\"\n",
    "TRAIN_PATH = start_path + \"training_small.hdf5\"\n",
    "VAL_PATH = start_path + \"validation_small.hdf5\"\n",
    "TEST_PATH = start_path + \"testing_small.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e747b930",
   "metadata": {},
   "source": [
    "train_gen = HDF5ImageGenerator(src=TRAIN_PATH, **batch_args_gen)\n",
    "val_gen = HDF5ImageGenerator(src=VAL_PATH, **batch_args_gen)\n",
    "test_gen = HDF5ImageGenerator(src=TEST_PATH, **args_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c90a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_train = h5py.File('/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_training_small.hdf5', 'r')\n",
    "hf_test = h5py.File('/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_testing_small.hdf5', 'r')\n",
    "hf_validation = h5py.File('/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_validation_small.hdf5', 'r')\n",
    "x_train = np.asarray(hf_train['image'][0:])\n",
    "x_test = np.asarray(hf_test['image'][0:])\n",
    "x_validation = np.asarray(hf_validation['image'][0:])\n",
    "max_value = 4.16\n",
    "x_train = np.true_divide(x_train, max_value)\n",
    "x_test = np.true_divide(x_test, max_value)\n",
    "x_validation = np.true_divide(x_validation, max_value)\n",
    "y_train = np.asarray(hf_train['specz_redshift'][0:])[..., None]\n",
    "y_test = np.asarray(hf_test['specz_redshift'][0:])[..., None]\n",
    "y_validation = np.asarray(hf_validation['specz_redshift'][0:])[..., None]\n",
    "# object_id_train = np.asarray(hf_train['object_id'][0:])\n",
    "# object_id = np.asarray(hf_test['object_id'][0:])\n",
    "# object_id_validation = np.asarray(hf_validation['object_id'][0:])\n",
    "hf_train.close()\n",
    "hf_test.close()\n",
    "hf_validation.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143100de",
   "metadata": {},
   "source": [
    "for i in range(0,10000):\n",
    "    if y_train[i]>=0.1:\n",
    "        np.delete(x_train, i)\n",
    "        np.delete(y_train, i)\n",
    "for i in range(0,2000):\n",
    "    if y_test[i]>=0.1:\n",
    "        np.delete(x_test, i)\n",
    "        np.delete(y_test, i)\n",
    "for i in range(0,2000):\n",
    "    if y_validation[i]>=0.1:\n",
    "        np.delete(x_validation, i)\n",
    "        np.delete(y_validation, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47469b",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "\n",
    "What we'd like to save during training.\n",
    "\n",
    "- Metrics logs per epoch to visualise in TensorBoard.\n",
    "- Model weights per epoch.\n",
    "- Predictions and corresponding metrics per prediction per epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d700b6c6",
   "metadata": {},
   "source": [
    "An alternative to ReduceLROnPlateau is LearningRateScheduler to decrease step size after a fixed number of epochs, but I think we'd prefer to do it by metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcbb9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "logs_callback = TensorBoard(log_dir=dir_logs)\n",
    "weights_callback = ModelCheckpoint(filepath=os.path.join(dir_checkpoints, 'weights_epoch{epoch}.hdf5'),\n",
    "                                   save_freq=int(EPOCHS/CHECKPOINTS_TO_SAVE),\n",
    "                                   save_weights_only=True\n",
    "                                  )\n",
    "LR_callback = ReduceLROnPlateau()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6800e2",
   "metadata": {},
   "source": [
    "## VAE Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328caff3",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e33b930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 21:18:24.177842: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 195.31G (209715200000 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.180269: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 175.78G (188743680000 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.182653: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 158.20G (169869312000 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.185045: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 142.38G (152882380800 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.187424: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 128.14G (137594142720 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.189793: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 115.33G (123834728448 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.192181: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 103.80G (111451250688 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.194548: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 93.42G (100306124800 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.196908: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 84.08G (90275512320 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.199290: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 75.67G (81247961088 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.201642: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 68.10G (73123160064 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.203997: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 61.29G (65810841600 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.206350: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 55.16G (59229757440 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.208704: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 49.65G (53306781696 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.211170: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 44.68G (47976103936 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.213766: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 40.21G (43178491904 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.216150: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 36.19G (38860640256 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.218537: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 32.57G (34974576640 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.221016: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 29.31G (31477118976 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.223575: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 26.38G (28329406464 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-10-21 21:18:24.225942: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 23.75G (25496465408 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Cropping2D, ZeroPadding2D, UpSampling2D, MaxPool2D\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Reshape\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import layers as tfpl\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow.nn import leaky_relu\n",
    "\n",
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(LATENT_DIM), scale=0.1), reinterpreted_batch_ndims=1)\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        images = Input(shape=IMAGE_SHAPE)\n",
    "        x = Conv2D(BASE_DEPTH, 3, strides=1, activation=leaky_relu,\n",
    "                   padding='same', data_format='channels_first')(images)\n",
    "        x = MaxPool2D(pool_size=(2, 2), data_format = 'channels_first')(x)\n",
    "        x = Conv2D(2*BASE_DEPTH, 3, strides=2, activation=leaky_relu,\n",
    "                   padding='same', data_format='channels_first')(x)\n",
    "        x = MaxPool2D(pool_size=(2, 2), data_format = 'channels_first')(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(tfpl.MultivariateNormalTriL.params_size(LATENT_DIM), activation=None)(x)\n",
    "        z = tfpl.MultivariateNormalTriL(LATENT_DIM,\n",
    "                  activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight=KL_WEIGHT))(x)\n",
    "        self.encoder = Model(images, z, name='encoder')\n",
    "\n",
    "        latents = Input(shape=LATENT_DIM)\n",
    "        x = Dense(4*LATENT_DIM*16*16, activation=None)(latents)\n",
    "        x = Reshape((4*LATENT_DIM,16,16))(x)\n",
    "        x = UpSampling2D(size=(2, 2), data_format='channels_first', interpolation='nearest')(x)\n",
    "        x = Conv2DTranspose(2*BASE_DEPTH, 3, strides=1, activation=leaky_relu,\n",
    "                            padding='same', data_format='channels_first')(x)\n",
    "        x = UpSampling2D(size=(2, 2), data_format='channels_first', interpolation='nearest')(x)\n",
    "        x = Conv2DTranspose(2*BASE_DEPTH, 3, strides=2, activation=leaky_relu,\n",
    "                            padding='same', data_format='channels_first')(x)\n",
    "        x = Conv2DTranspose(BASE_DEPTH, 3, strides=1, activation=leaky_relu,\n",
    "                            padding='same', data_format='channels_first')(x)\n",
    "        x = Conv2D(IMAGE_SHAPE[0], 3, strides=1, activation=None, \n",
    "                   padding='same', data_format='channels_first')(x)\n",
    "        outputs = Cropping2D(cropping=((0,1),(0,1)), data_format='channels_first')(x)\n",
    "        self.decoder = Model(latents, outputs, name='decoder')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def summary(self):\n",
    "        print(self.encoder.summary())\n",
    "        print(self.decoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55ce4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e56e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b45ea229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5, 127, 127)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 127, 127)      1472      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 32, 63, 63)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 32, 32)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 16, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 560)               9175600   \n",
      "                                                                 \n",
      " multivariate_normal_tri_l (  ((None, 32),             0         \n",
      " MultivariateNormalTriL)      (None, 32))                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,195,568\n",
      "Trainable params: 9,195,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32768)             1081344   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 128, 16, 16)       0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 128, 32, 32)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 64, 32, 32)       73792     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 64, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 64, 128, 128)     36928     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 128, 128)     18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 5, 128, 128)       1445      \n",
      "                                                                 \n",
      " cropping2d (Cropping2D)     (None, 5, 127, 127)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,211,973\n",
      "Trainable params: 1,211,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9a7d5e",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c65f61a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 21:18:24.794078: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3225800000 exceeds 10% of free system memory.\n",
      "2022-10-21 21:18:25.981848: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3225800000 exceeds 10% of free system memory.\n",
      "2022-10-21 21:18:27.179894: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3225800000 exceeds 10% of free system memory.\n",
      "2022-10-21 21:18:28.083286: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3225800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 21:20:33.797063: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n",
      "2022-10-21 21:23:19.033082: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-21 21:23:19.112286: E tensorflow/stream_executor/cuda/cuda_blas.cc:232] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2022-10-21 21:23:19.112317: E tensorflow/stream_executor/cuda/cuda_blas.cc:234] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-10-21 21:23:19.202306: E tensorflow/stream_executor/cuda/cuda_blas.cc:232] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2022-10-21 21:23:19.202329: E tensorflow/stream_executor/cuda/cuda_blas.cc:234] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-10-21 21:23:19.207015: E tensorflow/stream_executor/cuda/cuda_blas.cc:232] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2022-10-21 21:23:19.207030: E tensorflow/stream_executor/cuda/cuda_blas.cc:234] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-10-21 21:23:19.207040: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:438 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'vae/encoder/dense/MatMul' defined at (most recent call last):\n    File \"/home/billyli/miniconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/billyli/miniconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3053593/961623859.py\", line 1, in <cell line: 1>\n      history = model.fit(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/tmp/ipykernel_3053593/498051639.py\", line 47, in call\n      x = self.encoder(x)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/layers/core/dense.py\", line 221, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'vae/encoder/dense/MatMul'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node vae/encoder/dense/MatMul}}]] [Op:__inference_train_function_3733]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# callbacks=[logs_callback, weights_callback],\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_validation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'vae/encoder/dense/MatMul' defined at (most recent call last):\n    File \"/home/billyli/miniconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/billyli/miniconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/billyli/miniconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3053593/961623859.py\", line 1, in <cell line: 1>\n      history = model.fit(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/tmp/ipykernel_3053593/498051639.py\", line 47, in call\n      x = self.encoder(x)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billyli/miniconda3/lib/python3.9/site-packages/keras/layers/core/dense.py\", line 221, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'vae/encoder/dense/MatMul'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node vae/encoder/dense/MatMul}}]] [Op:__inference_train_function_3733]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = x_train,\n",
    "    y = x_train,\n",
    "    epochs=10,\n",
    "    # callbacks=[logs_callback, weights_callback],\n",
    "    validation_data = (x_validation, x_validation),\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6cf499",
   "metadata": {},
   "source": [
    "### Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights(weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb606637",
   "metadata": {},
   "source": [
    "## Save final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stdout\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a9162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preds(dataset='train', num_to_save=None):\n",
    "    if dataset == 'train':\n",
    "        datagen = HDF5ImageGenerator(src=TRAIN_PATH, **args_gen)\n",
    "    elif dataset == 'val':\n",
    "        datagen = HDF5ImageGenerator(src=VAL_PATH, **args_gen)\n",
    "    else:\n",
    "        dataset = 'test'\n",
    "        datagen = test_gen\n",
    "    preds_path = os.path.join(dir_predictions, dataset + \"_preds.hdf5\")\n",
    "    print(\"Saving predictions for\", dataset, \"dataset in\", preds_path)\n",
    "    \n",
    "    if num_to_save is None:\n",
    "        size = len(datagen._indices)\n",
    "    else:\n",
    "        size = num_to_save\n",
    "\n",
    "    with h5py.File(preds_path, 'w') as f:\n",
    "        f.create_dataset('true', (size, ) + IMAGE_SHAPE)\n",
    "        f.create_dataset('pred', (size, ) + IMAGE_SHAPE)\n",
    "        f.create_dataset('loss', size)\n",
    "        it = iter(datagen)\n",
    "        for i in range(size):\n",
    "            x = next(it)\n",
    "            f['true'][i] = x\n",
    "            f['pred'][i] = model.predict(x, verbose=0)\n",
    "            f['loss'][i] = model.evaluate(x, x, verbose=0)\n",
    "            stdout.write(\"\\rSaved %d samples of \" % i + str(size))\n",
    "            stdout.flush()\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0619570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_preds('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c6bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_preds('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc44cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_preds('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe17730",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4cac47",
   "metadata": {},
   "source": [
    "### Example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb5501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_preds(dataset='train', num_to_show=10):\n",
    "    preds_path = os.path.join(dir_predictions, dataset + \"_preds.hdf5\")    \n",
    "    with h5py.File(preds_path, 'r') as f:\n",
    "        fig, axes = plt.subplots(nrows=num_to_show, ncols=2, figsize=(10,5*num_to_show))\n",
    "        for i in range(num_to_show):\n",
    "            axes[i][0].imshow(f['true'][i][4])\n",
    "            axes[i][0].set_title('True')\n",
    "            axes[i][1].imshow(f['pred'][i][4])\n",
    "            axes[i][1].set_title(\"Pred, loss %.2f\" % f['loss'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b45d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_preds('train', num_to_show=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa0d34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_preds('val', num_to_show=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40047af2",
   "metadata": {},
   "source": [
    "### Example generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c64cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6d4793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_example_galaxies(num_to_generate=10):\n",
    "    z = prior.sample(num_to_generate)\n",
    "    xhat = model.decoder(z)\n",
    "    cols = 3\n",
    "    rows = int(math.ceil(num_to_generate / cols))\n",
    "    gs = gridspec.GridSpec(rows, cols)\n",
    "    fig = plt.figure(figsize=(15, 5*rows))\n",
    "    for i in range(num_to_generate):\n",
    "        ax = fig.add_subplot(gs[i])\n",
    "        ax.imshow(xhat[i][0])\n",
    "        ax.set_title(f'Generated image {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798196b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generate_example_galaxies(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4495eedf",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3]",
   "language": "python",
   "name": "conda-env-miniconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

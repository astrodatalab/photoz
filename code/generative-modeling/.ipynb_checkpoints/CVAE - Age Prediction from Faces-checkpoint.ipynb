{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e38f09b",
   "metadata": {},
   "source": [
    "# CVAE - Age Prediction from Faces\n",
    "\n",
    "2022-07-15\n",
    "\n",
    "Zooey Nguyen\n",
    "\n",
    "Autoencoder with variational layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddfb8f1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6698743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aad0ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/data/UTKFace/data\"\n",
    "MODEL_PATH = \"/data/UTKFace/models\"\n",
    "MODEL_NAME = \"CVAE\"\n",
    "MODEL_VERSION = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1111d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 16\n",
    "IMAGE_SHAPE = (256,256,3)\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 1\n",
    "GB_LIMIT = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce73c2d",
   "metadata": {},
   "source": [
    "## Allocate GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b81cd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=GB_LIMIT*1000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a7595d",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "Create a shuffled and batched dataset with age labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfb94919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import basename\n",
    "from os import listdir\n",
    "import h5py\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc81f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = []\n",
    "for filename in listdir(DATA_PATH):\n",
    "    age_str = basename(filename).split('_')[0]\n",
    "    ages.append(int(age_str))\n",
    "ages = tf.data.Dataset.from_tensor_slices(ages).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da444131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23708 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "df = image_dataset_from_directory(DATA_PATH, labels=None, batch_size=BATCH_SIZE)\n",
    "df = df.map(lambda x: (x, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e255cf2",
   "metadata": {},
   "source": [
    "## Conditional variational autoencoder model\n",
    "\n",
    "https://keras.io/examples/generative/vae/\n",
    "\n",
    "https://agustinus.kristia.de/techblog/2016/12/17/conditional-vae/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad0345b",
   "metadata": {},
   "source": [
    "### Define CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "469b5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class Sampling(Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7e2b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D\n",
    "from tensorflow.keras.layers import Input, InputLayer, Flatten, Dense, Reshape\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # concatenate image inputs with conditions\n",
    "        images = Input(shape=(IMAGE_SHAPE))\n",
    "        conditions = Input(shape=(1,))\n",
    "        inputs = merge([X, cond], mode='concat', concat_axis=1)\n",
    "        \n",
    "        # encoder\n",
    "        x = Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
    "        x = Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "        x = Flatten()(x)\n",
    "        mean = Dense(LATENT_DIM)(x)\n",
    "        logvar = Dense(LATENT_DIM)(x)\n",
    "        latents = Sampling()([mean, logvar])\n",
    "        self.encoder = Model(inputs, latents)\n",
    "\n",
    "        # concatenate conditions with latent dimensions\n",
    "        z = merge([latents, cond], mode='concat', concat_axis=1)\n",
    "        x = Dense(units=np.prod(IMAGE_SHAPE), activation='relu')(z)\n",
    "        x = Reshape(target_shape=IMAGE_SHAPE)(x)\n",
    "        x = Conv2DTranspose(32, (3,3), activation='relu', padding='same')(x)\n",
    "        x = Conv2DTranspose(32, (3,3), activation='relu', padding='same')(x)\n",
    "        x = Conv2DTranspose(3, (3,3), padding='same')(x)\n",
    "        x = Reshape(target_shape=IMAGE_SHAPE)(x)\n",
    "        self.decoder = Model(latents, outputs)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07fa9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(y_true, y_pred):\n",
    "    \"\"\" Calculate loss = reconstruction loss + KL loss for each data in minibatch \"\"\"\n",
    "    # E[log P(X|z,y)]\n",
    "    recon = K.sum(K.binary_crossentropy(y_pred, y_true), axis=1)\n",
    "    # D_KL(Q(z|X,y) || P(z|X)); calculate in closed form as both dist. are Gaussian\n",
    "    kl = 0.5 * K.sum(K.exp(log_sigma) + K.square(mu) - 1. - log_sigma, axis=1)\n",
    "\n",
    "    return recon + kl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b567a496",
   "metadata": {},
   "source": [
    "### Create VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5a121e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "384f653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448e9374",
   "metadata": {},
   "source": [
    "### Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e7484564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 547s 546ms/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f06982876d0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(df, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be76f936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/UTKFace/models/VAE_v1_batch128_epoch1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d77b77367fa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'_epoch'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_file = MODEL_PATH + '/' + MODEL_NAME +\\\n",
    "    '_v' + MODEL_VERSION +\\\n",
    "    '_batch' + str(BATCH_SIZE) +\\\n",
    "    '_epoch' + str(EPOCHS)\n",
    "print(model_file)\n",
    "model.save(model, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88eaeac",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9d65cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

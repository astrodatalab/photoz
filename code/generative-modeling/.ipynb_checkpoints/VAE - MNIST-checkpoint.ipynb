{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e38f09b",
   "metadata": {},
   "source": [
    "# VAE - MNIST\n",
    "\n",
    "2022-08-05\n",
    "\n",
    "Zooey Nguyen\n",
    "\n",
    "- v1: just the Conv2Ds (plus the middle layers ofc)\n",
    "- v2:  add MaxPooling2D\n",
    "- v3: UpSampling2D+Conv2D to replace Conv2DTranspose with corresponding input decoder changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddfb8f1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6698743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad0ffcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/models/MNIST_VAE_v3/model\n",
      "/models/MNIST_VAE_v3/checkpoints\n",
      "/logs/MNIST_VAE_v3\n",
      "/predictions/MNIST_VAE_v3\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"MNIST\"\n",
    "MODEL_TYPE = \"VAE\"\n",
    "MODEL_VERSION = \"v3\"\n",
    "\n",
    "model_id = '_'.join([DATASET_NAME, MODEL_TYPE, MODEL_VERSION])\n",
    "dir_model = os.path.join('/models', model_id, 'model')\n",
    "dir_checkpoints = os.path.join('/models', model_id, 'checkpoints')\n",
    "dir_logs = os.path.join('/logs', model_id)\n",
    "dir_predictions = os.path.join('/predictions', model_id)\n",
    "\n",
    "print(dir_model)\n",
    "print(dir_checkpoints)\n",
    "print(dir_logs)\n",
    "print(dir_predictions)\n",
    "\n",
    "os.makedirs(dir_model, exist_ok=True)\n",
    "os.makedirs(dir_checkpoints, exist_ok=True)\n",
    "os.makedirs(dir_logs, exist_ok=True)\n",
    "os.makedirs(dir_predictions, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1111d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 16\n",
    "IMAGE_SHAPE = (28, 28, 1)\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 40\n",
    "GB_LIMIT = 5\n",
    "CHECKPOINTS_TO_SAVE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce73c2d",
   "metadata": {},
   "source": [
    "## Allocate GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b81cd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=GB_LIMIT*1000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a7595d",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "Create a shuffled and batched dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb94919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import basename\n",
    "from os import listdir\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da444131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((None, 28, 28), (None, 28, 28)), types: (tf.uint8, tf.uint8)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "\n",
    "train_df, test_df = load_data()\n",
    "train_images, train_labels = train_df\n",
    "train_gen = tf.data.Dataset.from_tensor_slices(train_images).batch(BATCH_SIZE)\n",
    "train_gen = train_gen.map(lambda x: (x,x))\n",
    "train_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543a1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "logs_callback = TensorBoard(log_dir=dir_logs)\n",
    "weights_callback = ModelCheckpoint(filepath=os.path.join(dir_checkpoints, 'weights_epoch{epoch}.hdf5'),\n",
    "                                   save_freq=int(EPOCHS/CHECKPOINTS_TO_SAVE),\n",
    "                                   save_weights_only=True\n",
    "                                  )\n",
    "LR_callback = ReduceLROnPlateau()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd4a907",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e255cf2",
   "metadata": {},
   "source": [
    "## Variational autoencoder model\n",
    "\n",
    "https://keras.io/examples/generative/vae/\n",
    "\n",
    "https://agustinus.kristia.de/techblog/2016/12/17/conditional-vae/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad0345b",
   "metadata": {},
   "source": [
    "### Define VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "469b5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class Sampling(Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7e2b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Reshape\n",
    "from tensorflow.keras.initializers import Zeros\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        images = Input(shape=IMAGE_SHAPE)\n",
    "        x = Conv2D(32, (3,3), activation='relu', padding='same')(images)\n",
    "        x = MaxPooling2D((2,2), padding='same')(x)\n",
    "        x = Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D((2,2), padding='same')(x)\n",
    "        x = Flatten()(x)\n",
    "        mean = Dense(LATENT_DIM, activation='relu')(x)\n",
    "        logvar = Dense(LATENT_DIM, activation='relu', kernel_initializer='zeros')(x)\n",
    "        samples = Sampling()([mean, logvar])\n",
    "        self.encoder = Model(images, samples)\n",
    "\n",
    "        latents = Input(shape=(LATENT_DIM,))\n",
    "        x = Dense(7*7)(latents)\n",
    "        x = Reshape(target_shape=(7,7,1))(x)\n",
    "        x = Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "        x = UpSampling2D((2,2))(x)\n",
    "        x = Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "        x = UpSampling2D((2,2))(x)\n",
    "        x = Conv2D(1, (3,3), activation='sigmoid', padding='same')(x)\n",
    "        outputs = Reshape(target_shape=IMAGE_SHAPE)(x)\n",
    "        self.decoder = Model(latents, outputs)\n",
    " \n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b567a496",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5a121e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "384f653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448e9374",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7484564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[logs_callback, weights_callback],\n",
    "                    verbose=1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8413ba",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bac037",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(dir_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88eaeac",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bbb041",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_gen.take(1):\n",
    "    images, labels = sample\n",
    "    predictions = model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff52b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[0].imshow(images[i])\n",
    "    ax[1].imshow(predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a0d0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a15be90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e422952",
   "metadata": {},
   "source": [
    "# VAE - Galaxy Images\n",
    "\n",
    "2022-08-03\n",
    "\n",
    "Zooey Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5194ac",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d23f862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from DataMaker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e0800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 16\n",
    "IMAGE_SHAPE = (5, 127, 127)\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "GB_LIMIT = 10\n",
    "CHECKPOINTS_TO_SAVE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb7cabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/models/HSC_v6_small_VAE_v1/model\n",
      "/models/HSC_v6_small_VAE_v1/checkpoints\n",
      "/logs/HSC_v6_small_VAE_v1\n",
      "/predictions/HSC_v6_small_VAE_v1\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"HSC_v6_small\"\n",
    "MODEL_TYPE = \"VAE\"\n",
    "MODEL_VERSION = \"v1\"\n",
    "\n",
    "model_id = '_'.join([DATASET_NAME, MODEL_TYPE, MODEL_VERSION])\n",
    "dir_model = os.path.join('/models', model_id, 'model')\n",
    "dir_checkpoints = os.path.join('/models', model_id, 'checkpoints')\n",
    "dir_logs = os.path.join('/logs', model_id)\n",
    "dir_predictions = os.path.join('/predictions', model_id)\n",
    "\n",
    "print(dir_model)\n",
    "print(dir_checkpoints)\n",
    "print(dir_logs)\n",
    "print(dir_predictions)\n",
    "\n",
    "os.makedirs(dir_model, exist_ok=True)\n",
    "os.makedirs(dir_checkpoints, exist_ok=True)\n",
    "os.makedirs(dir_logs, exist_ok=True)\n",
    "os.makedirs(dir_predictions, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feddde7",
   "metadata": {},
   "source": [
    "## Allocate GPU\n",
    "\n",
    "Make sure to check others' current usage on Aurora in terminal using `watch nvidia-smi`. Set your `GB_LIMIT` accordingly, in gigabytes. Aurora has 50GB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a44e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=GB_LIMIT*1000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e37b0",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Create the shuffled and batched data generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f974bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_gen = {'X_key': 'image',\n",
    "    'y_key': 'specz_redshift',\n",
    "    'scaler': False,\n",
    "    'labels_encoding': False,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mode': 'train',\n",
    "    'shuffle': True}\n",
    "\n",
    "start_path = \"/data/HSC/HSC_v6/step2A/127x127/five_band_image127x127_with_metadata_corrected_\"\n",
    "end_path = \"_small.hdf5\"\n",
    "TRAIN_PATH = start_path + \"training\" + end_path\n",
    "VAL_PATH = start_path + \"validation\" + end_path\n",
    "TEST_PATH = start_path + \"testing\" + end_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5796575d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coord', 'dec', 'g_cmodel_mag', 'g_cmodel_magsigma', 'i_cmodel_mag', 'i_cmodel_magsigma', 'image', 'object_id', 'r_cmodel_mag', 'r_cmodel_magsigma', 'ra', 'skymap_id', 'specz_dec', 'specz_flag_homogeneous', 'specz_mag_i', 'specz_name', 'specz_ra', 'specz_redshift', 'specz_redshift_err', 'y_cmodel_mag', 'y_cmodel_magsigma', 'z_cmodel_mag', 'z_cmodel_magsigma']\n",
      "(10000, 5, 127, 127)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(TRAIN_PATH) as train_hf:\n",
    "    print(list(train_hf.keys()))\n",
    "    print(train_hf['image'].shape)\n",
    "    TRAIN_SIZE = train_hf['image'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c1c87d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = HDF5ImageGenerator(src=TRAIN_PATH, **args_gen)\n",
    "val_gen = HDF5ImageGenerator(src=VAL_PATH, **args_gen)\n",
    "test_gen = HDF5ImageGenerator(src=TEST_PATH, **args_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f445be",
   "metadata": {},
   "source": [
    "## Choose losses and metrics\n",
    "\n",
    "We need these for callbacks and training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40030216",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "METRICS = [\n",
    "    tf.keras.metrics.MeanAbsoluteError()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47469b",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "\n",
    "What we'd like to save during training.\n",
    "\n",
    "- Metrics logs per epoch to visualise in TensorBoard.\n",
    "- Model weights per epoch.\n",
    "- Predictions and corresponding metrics per prediction per epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d700b6c6",
   "metadata": {},
   "source": [
    "An alternative to ReduceLROnPlateau is LearningRateScheduler to decrease step size after a fixed number of epochs, but I think we'd prefer to do it by metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcbb9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "logs_callback = TensorBoard(log_dir=dir_logs)\n",
    "weights_callback = ModelCheckpoint(filepath=os.path.join(dir_checkpoints, 'weights_epoch{epoch}.hdf5'),\n",
    "                                   save_freq=int(EPOCHS/CHECKPOINTS_TO_SAVE),\n",
    "                                   save_weights_only=True\n",
    "                                  )\n",
    "LR_callback = ReduceLROnPlateau()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6800e2",
   "metadata": {},
   "source": [
    "## CVAE Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328caff3",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da123a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class Sampling(Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e33b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Reshape\n",
    "from tensorflow.keras.initializers import Zeros\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        images = Input(shape=(IMAGE_SHAPE))\n",
    "        x = Conv2D(32, (3,3), activation='relu', padding='same', data_format='channels_first')(images)\n",
    "        x = Conv2D(32, (3,3), activation='relu', padding='same', data_format='channels_first')(x)\n",
    "        x = Flatten()(x)\n",
    "        mean = Dense(LATENT_DIM)(x)\n",
    "        logvar = Dense(LATENT_DIM, kernel_initializer=Zeros)(x)\n",
    "        samples = Sampling()([mean, logvar])\n",
    "        self.encoder = Model(images, samples)\n",
    "\n",
    "        latents = Input(shape=(LATENT_DIM,))\n",
    "        x = Dense(units=np.prod(IMAGE_SHAPE), activation='relu')(latents)\n",
    "        x = Reshape(target_shape=IMAGE_SHAPE)(x)\n",
    "        x = Conv2DTranspose(32, (3,3), activation='relu', padding='same', data_format='channels_first')(x)\n",
    "        x = Conv2DTranspose(32, (3,3), activation='relu', padding='same', data_format='channels_first')(x)\n",
    "        x = Conv2DTranspose(5, (3,3), activation='sigmoid', padding='same', data_format='channels_first')(x)\n",
    "        outputs = Reshape(target_shape=IMAGE_SHAPE)(x)\n",
    "        self.decoder = Model(latents, outputs)\n",
    " \n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb196697",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55ce4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4e56e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9a7d5e",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c65f61a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Incompatible shapes: [128,1] vs. [128,5,127,127]\n\t [[node mean_squared_error/SquaredDifference (defined at <ipython-input-14-6eecdda167c0>:1) ]] [Op:__inference_train_function_1448]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node mean_squared_error/SquaredDifference:\n vae/model_1/reshape_1/Reshape (defined at <ipython-input-11-95c1c38ff78b>:30)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6eecdda167c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogs_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [128,1] vs. [128,5,127,127]\n\t [[node mean_squared_error/SquaredDifference (defined at <ipython-input-14-6eecdda167c0>:1) ]] [Op:__inference_train_function_1448]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node mean_squared_error/SquaredDifference:\n vae/model_1/reshape_1/Reshape (defined at <ipython-input-11-95c1c38ff78b>:30)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[logs_callback, weights_callback],\n",
    "    validation_data=val_gen,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6cf499",
   "metadata": {},
   "source": [
    "### Save final model and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(dir_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb606637",
   "metadata": {},
   "source": [
    "Save training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fbc5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = model.predict(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a4209",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds_path = os.path.join(dir_predictions, \"train_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(train_preds_path, train_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb204f",
   "metadata": {},
   "source": [
    "Save validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d25220",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f4fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_path = os.path.join(dir_predictions, \"val_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e9d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(val_preds_path, val_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922cad5b",
   "metadata": {},
   "source": [
    "Save test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cef1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d3cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_path = os.path.join(dir_predictions, \"test_preds.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(test_preds_path, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1170a08b",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a0c22",
   "metadata": {},
   "source": [
    "Reload previously saved model or saved results if you'd like to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836cccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedmodel = tf.keras.models.load_model(dir_model, compile=False)\n",
    "savedmodel.compile(optimizer='adam', loss='mse', metrics=[data_callback.collector])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40047af2",
   "metadata": {},
   "source": [
    "### Example results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fef73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4495eedf",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55dfc1a1-ea2a-41a6-b551-4327c88a0907",
   "metadata": {},
   "source": [
    "This is an example of running code on Rockfish. You need to do the setup first, which I have a tutorial written in \"Getting started with the lab\". - Billy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1091fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import h5py\n",
    "import random\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import Sequential\n",
    "import sys,os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b6b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfpl = tfp.layers\n",
    "tf1 = tf.compat.v1\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d2c3541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_probability.python.distributions import kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eabda23-62aa-4403-a4b7-74a6e75a827f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 10:13:35.315958: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 10GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 10000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da0b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "t = 2000\n",
    "v = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa248053",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_train = h5py.File('/data/tuando/data/HSC/HSC_v6/step3A/64x64/64x64_training_z_less_than_2_small.hdf5', 'r')\n",
    "hf_test = h5py.File('/data/tuando/data/HSC/HSC_v6/step3A/64x64/64x64_testing_z_less_than_2_small.hdf5', 'r')\n",
    "hf_validation = h5py.File('/data/tuando/data/HSC/HSC_v6/step3A/64x64/64x64_validation_z_less_than_2_small.hdf5', 'r')\n",
    "x_train = np.asarray(np.transpose(hf_train['image'][0:],(0,2,3,1)))\n",
    "x_test = np.asarray(np.transpose(hf_test['image'][0:],(0,2,3,1)))\n",
    "x_validation = np.asarray(np.transpose(hf_validation['image'][0:],(0,2,3,1)))\n",
    "n = 10000\n",
    "t = 2000\n",
    "v = 2000\n",
    "max_value = 4.16\n",
    "x_train = np.true_divide(x_train, max_value)\n",
    "x_test = np.true_divide(x_test, max_value)\n",
    "x_validation = np.true_divide(x_validation, max_value)\n",
    "y_train = np.asarray(hf_train['specz_redshift'][0:])[..., None]\n",
    "y_test = np.asarray(hf_test['specz_redshift'][0:])[..., None]\n",
    "y_validation = np.asarray(hf_validation['specz_redshift'][0:])[..., None]\n",
    "hf_train.close()\n",
    "hf_test.close()\n",
    "hf_validation.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f187c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_mean_field(kernel_size: int, bias_size: int, dtype: any) -> tf.keras.Model:\n",
    "    \"\"\"Specify the surrogate posterior over `keras.layers.Dense` `kernel` and `bias`.\"\"\"\n",
    "    n = kernel_size + bias_size\n",
    "    c = np.log(np.expm1(1.))\n",
    "\n",
    "    return tf.keras.Sequential([\n",
    "        tfp.layers.VariableLayer(2 * n, dtype = dtype, initializer = lambda shape, dtype: random_gaussian_initializer(shape, dtype), trainable = True),\n",
    "        tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "            tfd.Normal(loc = t[ ..., : n],\n",
    "                       scale = tf.nn.softplus(c + t[..., n:])),\n",
    "            reinterpreted_batch_ndims = 1)),\n",
    "    ])\n",
    "\n",
    "def prior_trainable(kernel_size: int, bias_size: int, dtype: any) -> tf.keras.Model:\n",
    "    \"\"\"Specify the prior over `keras.layers.Dense` `kernel` and `bias`.\"\"\"\n",
    "    n = kernel_size + bias_size\n",
    "\n",
    "    return tf.keras.Sequential([\n",
    "        tfp.layers.VariableLayer(n, dtype = dtype),  # Returns a trainable variable of shape n, regardless of input\n",
    "        tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "            tfd.Normal(loc = t, scale = 0.01),\n",
    "            reinterpreted_batch_ndims = 1)),\n",
    "    ])\n",
    "\n",
    "def random_gaussian_initializer(shape, dtype):\n",
    "    n = int(shape / 2)\n",
    "    loc_norm = tf.random_normal_initializer(mean = 0., stddev = 0.03)\n",
    "    loc = tf.Variable(\n",
    "        initial_value = loc_norm(shape = (n, ), dtype = dtype)\n",
    "    )\n",
    "    scale_norm = tf.random_normal_initializer(mean = -3., stddev = 0.1)\n",
    "    scale = tf.Variable(\n",
    "        initial_value = scale_norm(shape = (n, ), dtype = dtype)\n",
    "    )\n",
    "    return tf.concat([loc, scale], 0)\n",
    "\n",
    "kl_divergence_function = lambda q, p, _: kl_divergence(q, p) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69ccd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import InputLayer, MaxPooling2D, Conv2D, Flatten, Dropout, Dense, BatchNormalization, Activation\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2beada9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_flipout_2 (Conv2DFl  (None, 62, 62, 16)        1456      \n",
      " ipout)                                                          \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 62, 62, 16)        64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 62, 62, 16)        0         \n",
      "                                                                 \n",
      " conv2d_flipout_3 (Conv2DFl  (None, 60, 60, 32)        9248      \n",
      " ipout)                                                          \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 60, 60, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 60, 60, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 28, 28, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 26, 26, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 26, 26, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 13, 13, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 21632)             0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 21632)             0         \n",
      "                                                                 \n",
      " dense_variational_1 (Dense  (None, 64)                4153536   \n",
      " Variational)                                                    \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      " independent_normal_1 (Inde  ((None, 1),               0         \n",
      " pendentNormal)               (None, 1))                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4257938 (16.24 MB)\n",
      "Trainable params: 4257330 (16.24 MB)\n",
      "Non-trainable params: 608 (2.38 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_337686/4228447022.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  n = int(shape / 2)\n"
     ]
    }
   ],
   "source": [
    "model_variational = Sequential([\n",
    "    InputLayer(input_shape=(64, 64, 5)),\n",
    "    \n",
    "    # First Conv block\n",
    "    tfpl.Convolution2DFlipout(16, kernel_size=(3, 3), activation=None, kernel_divergence_fn=kl_divergence_function),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    tfpl.Convolution2DFlipout(32, kernel_size=(3, 3), activation=None, kernel_divergence_fn=kl_divergence_function),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    # Second Conv block\n",
    "    Conv2D(64, kernel_size=(3, 3), activation=None),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Conv2D(128, kernel_size=(3, 3), activation=None),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Dense Variational layer\n",
    "    tfpl.DenseVariational(64, \n",
    "                          make_posterior_fn=posterior_mean_field,\n",
    "                          make_prior_fn=prior_trainable,\n",
    "                          kl_weight=1/n),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Output layer\n",
    "    Dense(tfpl.IndependentNormal.params_size(1)),\n",
    "    tfpl.IndependentNormal(1)\n",
    "])\n",
    "\n",
    "model_variational.build((10000, 64, 64, 5))\n",
    "\n",
    "model_variational.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de5fcf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(targets, estimated_distribution):\n",
    "    return - estimated_distribution.log_prob(targets)\n",
    "\n",
    "model_variational.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = loss_function, metrics = [tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42841133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "\n",
    "model_name = 'HSC_v6_BCNN_v5'\n",
    "\n",
    "checkpoint_filepath = os.path.join('/models/', model_name) + '/' + model_name\n",
    "\n",
    "weights_path = os.path.join('/models/', model_name) + '/weights'\n",
    "\n",
    "log_dir = os.path.join('/logs/', model_name)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_filepath, save_weights_only = True, verbose = 1, save_freq = 150*250)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq = 1)\n",
    "\n",
    "LR_callback = ReduceLROnPlateau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed21918a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "313/313 [==============================] - 15s 41ms/step - loss: 3816.2795 - root_mean_squared_error: 2.2170 - val_loss: 3189.1941 - val_root_mean_squared_error: 2.4206 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 2755.9170 - root_mean_squared_error: 2.2012 - val_loss: 2372.0996 - val_root_mean_squared_error: 2.1116 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 2077.6509 - root_mean_squared_error: 1.7266 - val_loss: 1813.0962 - val_root_mean_squared_error: 1.6053 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "139/313 [============>.................] - ETA: 6s - loss: 1714.7527 - root_mean_squared_error: 1.4680"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_variational\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_validation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mLR_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/photoz/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/photoz/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.conda/envs/photoz/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/photoz/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/photoz/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.conda/envs/photoz/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/photoz/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/photoz/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/.conda/envs/photoz/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/.conda/envs/photoz/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_variational.fit(x = x_train, y = y_train, epochs = 60, shuffle = True, verbose = 1, validation_data = (x_validation, y_validation), callbacks = [LR_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b1434",
   "metadata": {},
   "outputs": [],
   "source": [
    "photoz = []\n",
    "\n",
    "for i in range(t):\n",
    "    photoz.append(model_variational(np.array([x_test[i]])).mean()[0][0])\n",
    "\n",
    "photoz = np.asarray(photoz).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaca9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "specz = np.asarray(y_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "photoz_err = []\n",
    "\n",
    "for i in range(t):\n",
    "    photoz_err.append(model_variational(np.array([x_test[i]])).stddev()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca0c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "xy = np.asarray(np.vstack([specz, photoz])).astype('float32')\n",
    "z = gaussian_kde(xy)(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d080369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "z_max = 4\n",
    "sns.set(rc={'figure.figsize': (10, 10), 'lines.markersize': 20})\n",
    "plt.rcParams.update({'font.size': 40})\n",
    "fig, ax = plt.subplots()\n",
    "scatter_plot = ax.scatter(specz, photoz, c = z, s = 1, edgecolor = None)\n",
    "plt.colorbar(scatter_plot, label = 'Density')\n",
    "plt.title('Prediction')\n",
    "plt.xlabel('spectroscopic redshift')\n",
    "plt.ylabel('photo z')\n",
    "plt.plot([0, z_max], [0, z_max],color = 'black')\n",
    "plt.xlim([0, z_max])\n",
    "plt.ylim([0, z_max])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b34aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_variational = 0\n",
    "overlap_array_variational = []\n",
    "for i in range(0,t):\n",
    "    if np.abs(specz[i]-photoz[i])<=photoz_err[i]:\n",
    "        overlap_variational += 1\n",
    "        overlap_array_variational.append(1)\n",
    "    else:\n",
    "        overlap_array_variational.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4218c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(5, 5), 'lines.markersize':40})\n",
    "plt.rcParams.update({'font.size': 40})\n",
    "fig, ax = plt.subplots()\n",
    "display_size = 1000\n",
    "scatter_plot = ax.scatter(specz[:display_size], photoz[:display_size], c = z[:display_size], s = 4, edgecolor = None, zorder = 2)\n",
    "error_plot = ax.errorbar(specz[:display_size], photoz[:display_size], yerr = photoz_err[:display_size], fmt = \"o\", markersize = 0, color = 'blue', elinewidth = 1, zorder = 1)\n",
    "plt.title('Prediction With Error')\n",
    "plt.xlabel('Spectroscopic Redshift')\n",
    "plt.ylabel('Photometric Redshift')\n",
    "plt.plot([0, z_max], [0, z_max], color = 'black')\n",
    "plt.xlim([0, z_max])\n",
    "plt.ylim([0, z_max])\n",
    "print(\"Coverage: \"+str(overlap_variational/t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5eee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_array_variational = np.transpose(np.vstack((specz, photoz, photoz_err, overlap_array_variational))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb236386",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_combined_array_variational = sorted(combined_array_variational, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebecb5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_variational = int(z_max*5)\n",
    "splitted_sorted_combined_array_variational = np.array_split(sorted_combined_array_variational, bins_variational)\n",
    "coverage_variational = []\n",
    "for i in range(0, bins_variational):\n",
    "    bins_count_variational = 0\n",
    "    for j in range(0,len(splitted_sorted_combined_array_variational[i])):\n",
    "        if splitted_sorted_combined_array_variational[i][j][3] == 1:\n",
    "            bins_count_variational += 1\n",
    "    coverage_variational.append(bins_count_variational/len(splitted_sorted_combined_array_variational[i])/0.6827)\n",
    "x_array = np.arange(0, z_max, z_max/bins_variational)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06c57bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x_array, coverage_variational, c = 'red')\n",
    "plt.title('Coverage')\n",
    "plt.xlabel('Spectroscopic Redshift')\n",
    "plt.ylabel('Coverage')\n",
    "plt.ylim([0, 1.5])\n",
    "plt.plot([0, 4], [1, 1], color = 'black', linestyle = 'dashed')\n",
    "plt.annotate(\"Underconfident\", xy = (0, 1.06), color = 'black', size = 12)\n",
    "plt.annotate(\"Overconfident\", xy = (0, 0.9), color = 'black', size = 12)\n",
    "print(\"Coverage: \"+str(overlap_variational/t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7375ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_array = []\n",
    "for i in range(0, bins_variational):\n",
    "    total = 0\n",
    "    for j in range(0, len(splitted_sorted_combined_array_variational[i])):\n",
    "        bias = (splitted_sorted_combined_array_variational[i][j][1]-splitted_sorted_combined_array_variational[i][j][0])/(1 + splitted_sorted_combined_array_variational[i][j][0])\n",
    "        total += bias/(1 + splitted_sorted_combined_array_variational[i][j][0])\n",
    "    mean_array.append(total/len(splitted_sorted_combined_array_variational[i]))\n",
    "x_array = np.arange(0, z_max, z_max/bins_variational)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_array = []\n",
    "for i in range(0, bins_variational):\n",
    "    error_total = 0\n",
    "    for j in range(0,len(splitted_sorted_combined_array_variational[i])):\n",
    "        error_total += splitted_sorted_combined_array_variational[i][j][2]\n",
    "    error_array.append(error_total/len(splitted_sorted_combined_array_variational[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8652e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(5, 5), 'lines.markersize':40})\n",
    "plt.rcParams.update({'font.size': 40})\n",
    "plt.scatter(x_array, mean_array, marker='o', color = 'blue', s = 4)\n",
    "# plt.errorbar(x_array, mean_array, yerr = error_array, fmt = \"o\", color = 'blue', markersize = 4, elinewidth = 2)\n",
    "plt.title('Bias Plot for Probabilistic Model')\n",
    "plt.xlabel('True Redshift')\n",
    "plt.ylabel('Bias: (Predicted - True)/(1 + True)')\n",
    "plt.plot([0, z_max], [0, 0], color = 'black')\n",
    "plt.plot([0, z_max], [0.003, 0.003], color = 'black', linestyle = 'dashed')\n",
    "plt.plot([0, z_max], [-0.003, -0.003], color = 'black', linestyle = 'dashed')\n",
    "plt.ylim([-0.1, 0.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_outlier_array = np.transpose(np.vstack((specz, photoz, photoz_err)))\n",
    "sorted_combined_outlier_array = sorted(combined_outlier_array, key=lambda x: x[0])\n",
    "bins_outlier = int(z_max*20)\n",
    "splitted_sorted_combined_outlier_array = np.array_split(sorted_combined_outlier_array,bins_outlier)\n",
    "outlier_array = []\n",
    "outlier_count_total = 0\n",
    "for i in range(0,bins_outlier):\n",
    "    outlier_count = 0\n",
    "    for j in range(0,len(splitted_sorted_combined_outlier_array[i])):\n",
    "        if np.abs(splitted_sorted_combined_outlier_array[i][j][1] - splitted_sorted_combined_outlier_array[i][j][0]) >= 3 * splitted_sorted_combined_outlier_array[i][j][2]:\n",
    "            outlier_count += 1\n",
    "            outlier_count_total += 1\n",
    "    outlier_array.append(outlier_count/len(specz)*bins_outlier)\n",
    "x_array_outlier = np.arange(0,z_max,z_max/bins_outlier)\n",
    "plt.plot(x_array_outlier, outlier_array, c = 'blue')\n",
    "plt.title('Outlier Rate')\n",
    "plt.xlabel('spec z')\n",
    "plt.ylabel('outlier rate')\n",
    "plt.xlim([0,z_max])\n",
    "plt.ylim([0,1/2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee12a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_outlier_array = np.transpose(np.vstack((specz,np.subtract(photoz, specz))))\n",
    "sorted_combined_outlier_array = sorted(combined_outlier_array, key=lambda x: x[0])\n",
    "bins_outlier = int(z_max*10)\n",
    "splitted_sorted_combined_outlier_array = np.array_split(sorted_combined_outlier_array,bins_outlier)\n",
    "outlier_array = []\n",
    "outlier_count_total = 0\n",
    "for i in range(0,bins_outlier):\n",
    "    outlier_count = 0\n",
    "    for j in range(0,len(splitted_sorted_combined_outlier_array[i])):\n",
    "        if np.abs(splitted_sorted_combined_outlier_array[i][j][1]/(splitted_sorted_combined_outlier_array[i][j][0] + 1)) >= .15:\n",
    "            outlier_count += 1\n",
    "            outlier_count_total += 1\n",
    "    outlier_array.append(outlier_count/len(specz)*bins_outlier)\n",
    "x_array_outlier = np.arange(0,z_max,z_max/bins_outlier)\n",
    "plt.plot(x_array_outlier, outlier_array, c = 'blue')\n",
    "plt.title('Outlier Rate')\n",
    "plt.xlabel('spec z')\n",
    "plt.ylabel('outlier rate')\n",
    "plt.xlim([0,z_max])\n",
    "plt.ylim([0,1])\n",
    "plt.show()\n",
    "\n",
    "# print(\"Outlier Rate: \"+str(outlier_count_total/len(specz)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec169d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (photoz)",
   "language": "python",
   "name": "photoz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b68f2741",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdbd2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from astropy.io import fits\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4952fa08",
   "metadata": {},
   "source": [
    "Setting up GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f408052e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 10GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cfabed",
   "metadata": {},
   "source": [
    "Setting up AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc28605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a078811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 21, 21, 96)        17376     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 21, 21, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 10, 10, 256)       393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 384)         590208    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 256)         393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 20,123,233\n",
      "Trainable params: 20,120,481\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(6,6), strides=(6,6), activation='relu', input_shape=(127,127,5)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(4,4), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(2,2), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(2,2), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='Adam', loss=\"mse\",metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c3cd7a",
   "metadata": {},
   "source": [
    "GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "573b6b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\", line 163, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/training.py\", line 1158, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 933, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 763, in _initialize\n",
      "    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3050, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3444, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3279, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 999, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 672, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/training.py:830 train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/training.py:813 run_step  *\n",
      "        outputs = model.train_step(data)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/training.py:770 train_step  *\n",
      "        y_pred = self(x, training=True)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/base_layer.py:1006 __call__  *\n",
      "        outputs = call_fn(inputs, *args, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/sequential.py:389 call  *\n",
      "        outputs = layer(inputs, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/base_layer.py:1006 __call__  *\n",
      "        outputs = call_fn(inputs, *args, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/functional.py:1442 call  *\n",
      "        return getattr(self._module, self._method_name)(*args, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__  **\n",
      "        outputs = call_fn(inputs, *args, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/keras/layers/pooling.py:358 call\n",
      "        outputs = self.pool_function(\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
      "        return target(*args, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:4653 max_pool\n",
      "        return gen_nn_ops.max_pool(\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py:5341 max_pool\n",
      "        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n",
      "        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n",
      "        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3557 _create_op_internal\n",
      "        ret = Operation(\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n",
      "        self._c_op = _create_c_op(self._graph, node_def, inputs,\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n",
      "        raise ValueError(str(e))\n",
      "\n",
      "    ValueError: Negative dimension size caused by subtracting 3 from 2 for '{{node sequential_47/module_wrapper_867/max_pooling2d_137/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 3, 3, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](sequential_47/module_wrapper_866/batch_normalization_229/FusedBatchNormV3)' with input shapes: [?,2,2,256].\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\", line 163, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/training.py\", line 1158, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 933, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 763, in _initialize\n",
      "    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3050, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3444, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3279, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 999, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 672, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/training.py:830 train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/training.py:813 run_step  *\n",
      "        outputs = model.train_step(data)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/training.py:770 train_step  *\n",
      "        y_pred = self(x, training=True)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/base_layer.py:1006 __call__  *\n",
      "        outputs = call_fn(inputs, *args, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/sequential.py:389 call  *\n",
      "        outputs = layer(inputs, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/base_layer.py:1006 __call__  *\n",
      "        outputs = call_fn(inputs, *args, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/functional.py:1442 call  *\n",
      "        return getattr(self._module, self._method_name)(*args, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__  **\n",
      "        outputs = call_fn(inputs, *args, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/keras/layers/pooling.py:358 call\n",
      "        outputs = self.pool_function(\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
      "        return target(*args, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:4653 max_pool\n",
      "        return gen_nn_ops.max_pool(\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py:5341 max_pool\n",
      "        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n",
      "        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n",
      "        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3557 _create_op_internal\n",
      "        ret = Operation(\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n",
      "        self._c_op = _create_c_op(self._graph, node_def, inputs,\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n",
      "        raise ValueError(str(e))\n",
      "\n",
      "    ValueError: Negative dimension size caused by subtracting 3 from 2 for '{{node sequential_48/module_wrapper_886/max_pooling2d_140/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 3, 3, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](sequential_48/module_wrapper_885/batch_normalization_234/FusedBatchNormV3)' with input shapes: [?,2,2,256].\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\", line 163, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/training.py\", line 1158, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 933, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 763, in _initialize\n",
      "    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3050, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3444, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3279, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 999, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 672, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/training.py:830 train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/training.py:813 run_step  *\n",
      "        outputs = model.train_step(data)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/training.py:770 train_step  *\n",
      "        y_pred = self(x, training=True)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/base_layer.py:1006 __call__  *\n",
      "        outputs = call_fn(inputs, *args, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/sequential.py:389 call  *\n",
      "        outputs = layer(inputs, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/base_layer.py:1006 __call__  *\n",
      "        outputs = call_fn(inputs, *args, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/functional.py:1442 call  *\n",
      "        return getattr(self._module, self._method_name)(*args, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__  **\n",
      "        outputs = call_fn(inputs, *args, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/keras/layers/pooling.py:358 call\n",
      "        outputs = self.pool_function(\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
      "        return target(*args, **kwargs)\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:4653 max_pool\n",
      "        return gen_nn_ops.max_pool(\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py:5341 max_pool\n",
      "        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n",
      "        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n",
      "        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3557 _create_op_internal\n",
      "        ret = Operation(\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n",
      "        self._c_op = _create_c_op(self._graph, node_def, inputs,\n",
      "    /opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n",
      "        raise ValueError(str(e))\n",
      "\n",
      "    ValueError: Negative dimension size caused by subtracting 3 from 2 for '{{node sequential_49/module_wrapper_905/max_pooling2d_143/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 3, 3, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](sequential_49/module_wrapper_904/batch_normalization_239/FusedBatchNormV3)' with input shapes: [?,2,2,256].\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-48efa048a0a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstride_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstride_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpool_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_CV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"neg_mean_absolute_error\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/jupyterhub/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def create_model(pool_sizes = 3,stride_size = 2):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(filters=96, kernel_size=(6,6), strides=(6,6), activation='relu', input_shape=(127,127,5)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(pool_sizes,pool_sizes), strides=(stride_size,stride_size)))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=(2,2), strides=(1,1), activation='relu', padding=\"same\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(2,2), strides=(1,1), activation='relu', padding=\"same\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='Adam', loss=\"mse\",metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_CV = tf.keras.wrappers.scikit_learn.KerasRegressor(build_fn=create_model,epochs = 100, shuffle = True, verbose = 0)\n",
    "\n",
    "stride_size = [1,2,3,4]\n",
    "pool_sizes = [1,2,3,4]\n",
    "param_grid = dict(stride_size = stride_size,pool_sizes = pool_sizes)\n",
    "grid = GridSearchCV(estimator=model_CV,param_grid = param_grid, scoring = \"neg_mean_absolute_error\",cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fccd918e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.256676 using {'stride_size': 6}\n",
      "-0.267129 (0.013140) with: {'stride_size': 5}\n",
      "-0.256676 (0.019207) with: {'stride_size': 6}\n",
      "-0.264485 (0.002286) with: {'stride_size': 7}\n",
      "-0.268365 (0.004802) with: {'stride_size': 8}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e38b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('../../data/HSC/HSC_v6/five_band_image127x127.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e9ad005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "32/32 [==============================] - 2s 8ms/step - loss: 117.4397 - mean_absolute_error: 8.0001\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.3067 - mean_absolute_error: 2.1894\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2005 - mean_absolute_error: 1.3498\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2173 - mean_absolute_error: 1.0242\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2290 - mean_absolute_error: 0.8540\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1952 - mean_absolute_error: 0.7444\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1572 - mean_absolute_error: 0.6689\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1811 - mean_absolute_error: 0.6149\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1413 - mean_absolute_error: 0.5708\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1533 - mean_absolute_error: 0.5349\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1714 - mean_absolute_error: 0.5067\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2205 - mean_absolute_error: 0.4845\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2075 - mean_absolute_error: 0.4652\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1638 - mean_absolute_error: 0.4480\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1236 - mean_absolute_error: 0.4327\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1407 - mean_absolute_error: 0.4192\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1701 - mean_absolute_error: 0.4077\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1599 - mean_absolute_error: 0.3965\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1417 - mean_absolute_error: 0.3877\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1519 - mean_absolute_error: 0.3792\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1498 - mean_absolute_error: 0.3717\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1390 - mean_absolute_error: 0.3644\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1579 - mean_absolute_error: 0.3576\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1454 - mean_absolute_error: 0.3518\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1510 - mean_absolute_error: 0.3460\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1276 - mean_absolute_error: 0.3408\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1449 - mean_absolute_error: 0.3356\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1216 - mean_absolute_error: 0.3308\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1271 - mean_absolute_error: 0.3270\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1363 - mean_absolute_error: 0.3229\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1240 - mean_absolute_error: 0.3192\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1133 - mean_absolute_error: 0.3154\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1109 - mean_absolute_error: 0.3120\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1068 - mean_absolute_error: 0.3086\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1142 - mean_absolute_error: 0.3055\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1211 - mean_absolute_error: 0.3026\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1438 - mean_absolute_error: 0.3003\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1357 - mean_absolute_error: 0.2980\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1072 - mean_absolute_error: 0.2952\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1074 - mean_absolute_error: 0.2925\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1591 - mean_absolute_error: 0.2902\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1452 - mean_absolute_error: 0.2885\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1493 - mean_absolute_error: 0.2867\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1757 - mean_absolute_error: 0.2854\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1373 - mean_absolute_error: 0.2839\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1369 - mean_absolute_error: 0.2823\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1474 - mean_absolute_error: 0.2807\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1243 - mean_absolute_error: 0.2792\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1368 - mean_absolute_error: 0.2776\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1349 - mean_absolute_error: 0.2761\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1192 - mean_absolute_error: 0.2746\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1152 - mean_absolute_error: 0.2731\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1243 - mean_absolute_error: 0.2715\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1141 - mean_absolute_error: 0.2702\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1036 - mean_absolute_error: 0.2687\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1100 - mean_absolute_error: 0.2673\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1180 - mean_absolute_error: 0.2659\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1066 - mean_absolute_error: 0.2646\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1034 - mean_absolute_error: 0.2633\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0863 - mean_absolute_error: 0.2619\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1467 - mean_absolute_error: 0.2607\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1227 - mean_absolute_error: 0.2600\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0951 - mean_absolute_error: 0.2587\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1056 - mean_absolute_error: 0.2576\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0925 - mean_absolute_error: 0.2563\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1244 - mean_absolute_error: 0.2550\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1112 - mean_absolute_error: 0.2543\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0894 - mean_absolute_error: 0.2531\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0801 - mean_absolute_error: 0.2519\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0907 - mean_absolute_error: 0.2508\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0832 - mean_absolute_error: 0.2496\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0696 - mean_absolute_error: 0.2484\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1138 - mean_absolute_error: 0.2474\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0910 - mean_absolute_error: 0.2464\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1011 - mean_absolute_error: 0.2454\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0724 - mean_absolute_error: 0.2444\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0691 - mean_absolute_error: 0.2432\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0809 - mean_absolute_error: 0.2421\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0849 - mean_absolute_error: 0.2412\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0668 - mean_absolute_error: 0.2401\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1770 - mean_absolute_error: 0.2394\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1542 - mean_absolute_error: 0.2393\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1509 - mean_absolute_error: 0.2390\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1543 - mean_absolute_error: 0.2388\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1421 - mean_absolute_error: 0.2385\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1470 - mean_absolute_error: 0.2383\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1665 - mean_absolute_error: 0.2380\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1599 - mean_absolute_error: 0.2378\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1277 - mean_absolute_error: 0.2375\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1150 - mean_absolute_error: 0.2370\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1225 - mean_absolute_error: 0.2366\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1228 - mean_absolute_error: 0.2360\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1374 - mean_absolute_error: 0.2356\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1649 - mean_absolute_error: 0.2354\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1257 - mean_absolute_error: 0.2349\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1268 - mean_absolute_error: 0.2345\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1024 - mean_absolute_error: 0.2341\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1130 - mean_absolute_error: 0.2335\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1275 - mean_absolute_error: 0.2331\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1108 - mean_absolute_error: 0.2326\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1062 - mean_absolute_error: 0.2321\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1321 - mean_absolute_error: 0.2317\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0970 - mean_absolute_error: 0.2312\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1387 - mean_absolute_error: 0.2309\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1137 - mean_absolute_error: 0.2306\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0934 - mean_absolute_error: 0.2301\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1118 - mean_absolute_error: 0.2296\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0952 - mean_absolute_error: 0.2291\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0879 - mean_absolute_error: 0.2286\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1134 - mean_absolute_error: 0.2281\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1104 - mean_absolute_error: 0.2277\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0846 - mean_absolute_error: 0.2271\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1130 - mean_absolute_error: 0.2267\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1019 - mean_absolute_error: 0.2264\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0739 - mean_absolute_error: 0.2259\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0922 - mean_absolute_error: 0.2252\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0776 - mean_absolute_error: 0.2247\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0638 - mean_absolute_error: 0.2242\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0753 - mean_absolute_error: 0.2236\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0741 - mean_absolute_error: 0.2231\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1974 - mean_absolute_error: 0.2229\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1779 - mean_absolute_error: 0.2231\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1754 - mean_absolute_error: 0.2232\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1765 - mean_absolute_error: 0.2233\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1698 - mean_absolute_error: 0.2234\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1405 - mean_absolute_error: 0.2234\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1216 - mean_absolute_error: 0.2232\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1234 - mean_absolute_error: 0.2230\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1265 - mean_absolute_error: 0.2228\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1347 - mean_absolute_error: 0.2226\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1258 - mean_absolute_error: 0.2224\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1373 - mean_absolute_error: 0.2223\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1251 - mean_absolute_error: 0.2221\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1078 - mean_absolute_error: 0.2219\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1040 - mean_absolute_error: 0.2216\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1078 - mean_absolute_error: 0.2213\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0978 - mean_absolute_error: 0.2210\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1172 - mean_absolute_error: 0.2207\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1079 - mean_absolute_error: 0.2205\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0909 - mean_absolute_error: 0.2202\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1187 - mean_absolute_error: 0.2199\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1245 - mean_absolute_error: 0.2198\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0983 - mean_absolute_error: 0.2195\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1047 - mean_absolute_error: 0.2192\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0996 - mean_absolute_error: 0.2189\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0948 - mean_absolute_error: 0.2186\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0974 - mean_absolute_error: 0.2183\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1026 - mean_absolute_error: 0.2180\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0904 - mean_absolute_error: 0.2177\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0837 - mean_absolute_error: 0.2174\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0952 - mean_absolute_error: 0.2171\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0922 - mean_absolute_error: 0.2167\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0902 - mean_absolute_error: 0.2164\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0880 - mean_absolute_error: 0.2161\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0782 - mean_absolute_error: 0.2157\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0959 - mean_absolute_error: 0.2155\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0734 - mean_absolute_error: 0.2151\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0787 - mean_absolute_error: 0.2148\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0776 - mean_absolute_error: 0.2144\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0716 - mean_absolute_error: 0.2140\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1381 - mean_absolute_error: 0.2138\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1273 - mean_absolute_error: 0.2137\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1141 - mean_absolute_error: 0.2136\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1196 - mean_absolute_error: 0.2135\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0894 - mean_absolute_error: 0.2133\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0951 - mean_absolute_error: 0.2130\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1093 - mean_absolute_error: 0.2128\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0732 - mean_absolute_error: 0.2126\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0950 - mean_absolute_error: 0.2123\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0909 - mean_absolute_error: 0.2120\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0771 - mean_absolute_error: 0.2118\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0856 - mean_absolute_error: 0.2115\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0763 - mean_absolute_error: 0.2112\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0720 - mean_absolute_error: 0.2109\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0807 - mean_absolute_error: 0.2106\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0815 - mean_absolute_error: 0.2104\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0642 - mean_absolute_error: 0.2100\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0825 - mean_absolute_error: 0.2097\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0577 - mean_absolute_error: 0.2094\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0769 - mean_absolute_error: 0.2090\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0550 - mean_absolute_error: 0.2087\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0409 - mean_absolute_error: 0.2083\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0369 - mean_absolute_error: 0.2078\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0363 - mean_absolute_error: 0.2073\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0497 - mean_absolute_error: 0.2069\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0373 - mean_absolute_error: 0.2064\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0571 - mean_absolute_error: 0.2060\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0524 - mean_absolute_error: 0.2056\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0475 - mean_absolute_error: 0.2052\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0376 - mean_absolute_error: 0.2048\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0345 - mean_absolute_error: 0.2043\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0443 - mean_absolute_error: 0.2039\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0652 - mean_absolute_error: 0.2035\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0465 - mean_absolute_error: 0.2032\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0412 - mean_absolute_error: 0.2028\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0406 - mean_absolute_error: 0.2024\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0406 - mean_absolute_error: 0.2020\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0330 - mean_absolute_error: 0.2015\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0341 - mean_absolute_error: 0.2011\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0304 - mean_absolute_error: 0.2006\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1819 - mean_absolute_error: 0.2005\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1689 - mean_absolute_error: 0.2007\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1332 - mean_absolute_error: 0.2007\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1283 - mean_absolute_error: 0.2007\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1511 - mean_absolute_error: 0.2007\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1326 - mean_absolute_error: 0.2007\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1336 - mean_absolute_error: 0.2007\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0955 - mean_absolute_error: 0.2007\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1061 - mean_absolute_error: 0.2006\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0998 - mean_absolute_error: 0.2005\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0976 - mean_absolute_error: 0.2004\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0852 - mean_absolute_error: 0.2003\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1188 - mean_absolute_error: 0.2002\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0931 - mean_absolute_error: 0.2001\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0732 - mean_absolute_error: 0.1999\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0883 - mean_absolute_error: 0.1998\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0736 - mean_absolute_error: 0.1996\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0631 - mean_absolute_error: 0.1994\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0887 - mean_absolute_error: 0.1992\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0708 - mean_absolute_error: 0.1990\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1061 - mean_absolute_error: 0.1989\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0934 - mean_absolute_error: 0.1988\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1018 - mean_absolute_error: 0.1987\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0983 - mean_absolute_error: 0.1987\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0855 - mean_absolute_error: 0.1986\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0632 - mean_absolute_error: 0.1984\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0633 - mean_absolute_error: 0.1982\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0597 - mean_absolute_error: 0.1980\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0914 - mean_absolute_error: 0.1978\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0631 - mean_absolute_error: 0.1977\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0918 - mean_absolute_error: 0.1976\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1136 - mean_absolute_error: 0.1975\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1006 - mean_absolute_error: 0.1974\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1466 - mean_absolute_error: 0.1974\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1241 - mean_absolute_error: 0.1974\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1424 - mean_absolute_error: 0.1975\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1004 - mean_absolute_error: 0.1974\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0854 - mean_absolute_error: 0.1973\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0674 - mean_absolute_error: 0.1972\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0713 - mean_absolute_error: 0.1970\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1628 - mean_absolute_error: 0.1970\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1288 - mean_absolute_error: 0.1970\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1297 - mean_absolute_error: 0.1970\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1365 - mean_absolute_error: 0.1970\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1254 - mean_absolute_error: 0.1970\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1268 - mean_absolute_error: 0.1970\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1236 - mean_absolute_error: 0.1970\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1013 - mean_absolute_error: 0.1969\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1064 - mean_absolute_error: 0.1969\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1127 - mean_absolute_error: 0.1968\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1334 - mean_absolute_error: 0.1968\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1629 - mean_absolute_error: 0.1968\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1317 - mean_absolute_error: 0.1969\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1223 - mean_absolute_error: 0.1970\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1376 - mean_absolute_error: 0.1970\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2060 - mean_absolute_error: 0.1971\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1454 - mean_absolute_error: 0.1974\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1592 - mean_absolute_error: 0.1975\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1605 - mean_absolute_error: 0.1976\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1309 - mean_absolute_error: 0.1976\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1121 - mean_absolute_error: 0.1977\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0932 - mean_absolute_error: 0.1976\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1019 - mean_absolute_error: 0.1976\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1079 - mean_absolute_error: 0.1976\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0941 - mean_absolute_error: 0.1975\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0928 - mean_absolute_error: 0.1974\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0908 - mean_absolute_error: 0.1974\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0787 - mean_absolute_error: 0.1973\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0727 - mean_absolute_error: 0.1972\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0713 - mean_absolute_error: 0.1970\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0669 - mean_absolute_error: 0.1969\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0778 - mean_absolute_error: 0.1967\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0714 - mean_absolute_error: 0.1966\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0704 - mean_absolute_error: 0.1964\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0737 - mean_absolute_error: 0.1963\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0902 - mean_absolute_error: 0.1962\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0649 - mean_absolute_error: 0.1961\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0567 - mean_absolute_error: 0.1959\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0673 - mean_absolute_error: 0.1957\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0519 - mean_absolute_error: 0.1955\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1652 - mean_absolute_error: 0.1955\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1407 - mean_absolute_error: 0.1956\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1276 - mean_absolute_error: 0.1957\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1241 - mean_absolute_error: 0.1957\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1281 - mean_absolute_error: 0.1958\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0956 - mean_absolute_error: 0.1958\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0868 - mean_absolute_error: 0.1958\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0947 - mean_absolute_error: 0.1957\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1196 - mean_absolute_error: 0.1957\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1016 - mean_absolute_error: 0.1957\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0923 - mean_absolute_error: 0.1957\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0878 - mean_absolute_error: 0.1956\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0786 - mean_absolute_error: 0.1955\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0823 - mean_absolute_error: 0.1954\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0688 - mean_absolute_error: 0.1953\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0795 - mean_absolute_error: 0.1952\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0961 - mean_absolute_error: 0.1952\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0663 - mean_absolute_error: 0.1951\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0675 - mean_absolute_error: 0.1950\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0840 - mean_absolute_error: 0.1949\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0719 - mean_absolute_error: 0.1949\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0696 - mean_absolute_error: 0.1948\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0647 - mean_absolute_error: 0.1947\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0721 - mean_absolute_error: 0.1945\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0728 - mean_absolute_error: 0.1944\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0640 - mean_absolute_error: 0.1943\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0551 - mean_absolute_error: 0.1942\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0546 - mean_absolute_error: 0.1940\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0554 - mean_absolute_error: 0.1938\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0493 - mean_absolute_error: 0.1937\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0483 - mean_absolute_error: 0.1935\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0420 - mean_absolute_error: 0.1933\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0456 - mean_absolute_error: 0.1931\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0364 - mean_absolute_error: 0.1929\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0460 - mean_absolute_error: 0.1927\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0393 - mean_absolute_error: 0.1925\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0521 - mean_absolute_error: 0.1923\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0492 - mean_absolute_error: 0.1921\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0398 - mean_absolute_error: 0.1919\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0425 - mean_absolute_error: 0.1917\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1351 - mean_absolute_error: 0.1916\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1265 - mean_absolute_error: 0.1917\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1203 - mean_absolute_error: 0.1917\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1077 - mean_absolute_error: 0.1917\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0995 - mean_absolute_error: 0.1916\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1016 - mean_absolute_error: 0.1916\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0902 - mean_absolute_error: 0.1915\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0866 - mean_absolute_error: 0.1915\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0729 - mean_absolute_error: 0.1914\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0893 - mean_absolute_error: 0.1913\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0774 - mean_absolute_error: 0.1912\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0599 - mean_absolute_error: 0.1911\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0761 - mean_absolute_error: 0.1910\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0632 - mean_absolute_error: 0.1909\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0537 - mean_absolute_error: 0.1908\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0566 - mean_absolute_error: 0.1906\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0622 - mean_absolute_error: 0.1905\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0618 - mean_absolute_error: 0.1903\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0754 - mean_absolute_error: 0.1902\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0835 - mean_absolute_error: 0.1901\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0681 - mean_absolute_error: 0.1901\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0483 - mean_absolute_error: 0.1899\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0486 - mean_absolute_error: 0.1897\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0430 - mean_absolute_error: 0.1896\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0521 - mean_absolute_error: 0.1894\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0523 - mean_absolute_error: 0.1892\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0477 - mean_absolute_error: 0.1891\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0490 - mean_absolute_error: 0.1889\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0654 - mean_absolute_error: 0.1887\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0431 - mean_absolute_error: 0.1886\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0414 - mean_absolute_error: 0.1884\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0505 - mean_absolute_error: 0.1882\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0377 - mean_absolute_error: 0.1881\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0373 - mean_absolute_error: 0.1879\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0416 - mean_absolute_error: 0.1877\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0693 - mean_absolute_error: 0.1876\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0679 - mean_absolute_error: 0.1875\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0519 - mean_absolute_error: 0.1874\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0513 - mean_absolute_error: 0.1872\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0331 - mean_absolute_error: 0.1871\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1582 - mean_absolute_error: 0.1870\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1395 - mean_absolute_error: 0.1871\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1316 - mean_absolute_error: 0.1872\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1433 - mean_absolute_error: 0.1873\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1565 - mean_absolute_error: 0.1874\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1321 - mean_absolute_error: 0.1875\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1236 - mean_absolute_error: 0.1876\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1167 - mean_absolute_error: 0.1876\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1174 - mean_absolute_error: 0.1877\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1165 - mean_absolute_error: 0.1877\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1402 - mean_absolute_error: 0.1878\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1576 - mean_absolute_error: 0.1879\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1476 - mean_absolute_error: 0.1880\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1322 - mean_absolute_error: 0.1881\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1176 - mean_absolute_error: 0.1882\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1178 - mean_absolute_error: 0.1883\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1224 - mean_absolute_error: 0.1883\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0967 - mean_absolute_error: 0.1883\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1016 - mean_absolute_error: 0.1884\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1028 - mean_absolute_error: 0.1884\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1039 - mean_absolute_error: 0.1884\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1156 - mean_absolute_error: 0.1884\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0823 - mean_absolute_error: 0.1884\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1240 - mean_absolute_error: 0.1884\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1176 - mean_absolute_error: 0.1885\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0850 - mean_absolute_error: 0.1885\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0884 - mean_absolute_error: 0.1885\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1001 - mean_absolute_error: 0.1885\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1034 - mean_absolute_error: 0.1885\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1004 - mean_absolute_error: 0.1886\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0990 - mean_absolute_error: 0.1886\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0859 - mean_absolute_error: 0.1885\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0860 - mean_absolute_error: 0.1885\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0800 - mean_absolute_error: 0.1885\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0693 - mean_absolute_error: 0.1884\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0725 - mean_absolute_error: 0.1884\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0646 - mean_absolute_error: 0.1883\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0622 - mean_absolute_error: 0.1882\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0532 - mean_absolute_error: 0.1881\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0727 - mean_absolute_error: 0.1881\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1830 - mean_absolute_error: 0.1881\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1521 - mean_absolute_error: 0.1882\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1379 - mean_absolute_error: 0.1883\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1389 - mean_absolute_error: 0.1884\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1236 - mean_absolute_error: 0.1885\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1124 - mean_absolute_error: 0.1885\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1097 - mean_absolute_error: 0.1886\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1142 - mean_absolute_error: 0.1886\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1158 - mean_absolute_error: 0.1887\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1243 - mean_absolute_error: 0.1887\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1058 - mean_absolute_error: 0.1887\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0949 - mean_absolute_error: 0.1888\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0837 - mean_absolute_error: 0.1888\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0814 - mean_absolute_error: 0.1887\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0762 - mean_absolute_error: 0.1887\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0895 - mean_absolute_error: 0.1886\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1205 - mean_absolute_error: 0.1887\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1185 - mean_absolute_error: 0.1887\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1246 - mean_absolute_error: 0.1888\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1030 - mean_absolute_error: 0.1888\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0825 - mean_absolute_error: 0.1888\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0703 - mean_absolute_error: 0.1887\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0671 - mean_absolute_error: 0.1887\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0803 - mean_absolute_error: 0.1887\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0841 - mean_absolute_error: 0.1886\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0658 - mean_absolute_error: 0.1886\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0617 - mean_absolute_error: 0.1885\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0584 - mean_absolute_error: 0.1884\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0690 - mean_absolute_error: 0.1883\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0673 - mean_absolute_error: 0.1883\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0675 - mean_absolute_error: 0.1882\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0592 - mean_absolute_error: 0.1881\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0482 - mean_absolute_error: 0.1881\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0510 - mean_absolute_error: 0.1880\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0508 - mean_absolute_error: 0.1879\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0419 - mean_absolute_error: 0.1878\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0436 - mean_absolute_error: 0.1876\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0423 - mean_absolute_error: 0.1875\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0508 - mean_absolute_error: 0.1874\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0456 - mean_absolute_error: 0.1873\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1623 - mean_absolute_error: 0.1873\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1337 - mean_absolute_error: 0.1874\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1235 - mean_absolute_error: 0.1874\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1178 - mean_absolute_error: 0.1875\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1021 - mean_absolute_error: 0.1875\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1026 - mean_absolute_error: 0.1875\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0911 - mean_absolute_error: 0.1875\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0821 - mean_absolute_error: 0.1875\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0755 - mean_absolute_error: 0.1875\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0769 - mean_absolute_error: 0.1874\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0713 - mean_absolute_error: 0.1874\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0868 - mean_absolute_error: 0.1873\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0746 - mean_absolute_error: 0.1873\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0623 - mean_absolute_error: 0.1873\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0699 - mean_absolute_error: 0.1872\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0656 - mean_absolute_error: 0.1872\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0627 - mean_absolute_error: 0.1871\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0614 - mean_absolute_error: 0.1870\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0614 - mean_absolute_error: 0.1870\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0472 - mean_absolute_error: 0.1869\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0554 - mean_absolute_error: 0.1868\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0580 - mean_absolute_error: 0.1867\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0595 - mean_absolute_error: 0.1867\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0439 - mean_absolute_error: 0.1866\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0444 - mean_absolute_error: 0.1865\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0456 - mean_absolute_error: 0.1864\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0454 - mean_absolute_error: 0.1863\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0423 - mean_absolute_error: 0.1861\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0406 - mean_absolute_error: 0.1860\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0339 - mean_absolute_error: 0.1859\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0330 - mean_absolute_error: 0.1858\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0361 - mean_absolute_error: 0.1856\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0382 - mean_absolute_error: 0.1855\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0465 - mean_absolute_error: 0.1854\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0515 - mean_absolute_error: 0.1853\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0331 - mean_absolute_error: 0.1852\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0384 - mean_absolute_error: 0.1851\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0421 - mean_absolute_error: 0.1850\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0376 - mean_absolute_error: 0.1849\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0414 - mean_absolute_error: 0.1848\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1826 - mean_absolute_error: 0.1848\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1607 - mean_absolute_error: 0.1849\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1321 - mean_absolute_error: 0.1850\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1230 - mean_absolute_error: 0.1851\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1178 - mean_absolute_error: 0.1851\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1605 - mean_absolute_error: 0.1852\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1235 - mean_absolute_error: 0.1853\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1096 - mean_absolute_error: 0.1853\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1272 - mean_absolute_error: 0.1853\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0940 - mean_absolute_error: 0.1853\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0889 - mean_absolute_error: 0.1853\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0900 - mean_absolute_error: 0.1853\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0756 - mean_absolute_error: 0.1853\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0721 - mean_absolute_error: 0.1852\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0789 - mean_absolute_error: 0.1852\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0837 - mean_absolute_error: 0.1852\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0725 - mean_absolute_error: 0.1851\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0600 - mean_absolute_error: 0.1851\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0675 - mean_absolute_error: 0.1850\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0671 - mean_absolute_error: 0.1849\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0696 - mean_absolute_error: 0.1849\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0859 - mean_absolute_error: 0.1848\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0746 - mean_absolute_error: 0.1848\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0616 - mean_absolute_error: 0.1847\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0564 - mean_absolute_error: 0.1847\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0637 - mean_absolute_error: 0.1846\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0592 - mean_absolute_error: 0.1845\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0669 - mean_absolute_error: 0.1845\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0505 - mean_absolute_error: 0.1844\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0375 - mean_absolute_error: 0.1843\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0358 - mean_absolute_error: 0.1842\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0420 - mean_absolute_error: 0.1840\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0373 - mean_absolute_error: 0.1839\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0348 - mean_absolute_error: 0.1838\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0367 - mean_absolute_error: 0.1837\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0343 - mean_absolute_error: 0.1835\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0304 - mean_absolute_error: 0.1834\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0296 - mean_absolute_error: 0.1833\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0280 - mean_absolute_error: 0.1831\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0271 - mean_absolute_error: 0.1830\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1658 - mean_absolute_error: 0.1830\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1296 - mean_absolute_error: 0.1830\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1128 - mean_absolute_error: 0.1831\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1177 - mean_absolute_error: 0.1831\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1198 - mean_absolute_error: 0.1831\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1102 - mean_absolute_error: 0.1831\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0803 - mean_absolute_error: 0.1831\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0839 - mean_absolute_error: 0.1831\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0782 - mean_absolute_error: 0.1831\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0898 - mean_absolute_error: 0.1831\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1078 - mean_absolute_error: 0.1830\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0863 - mean_absolute_error: 0.1831\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0811 - mean_absolute_error: 0.1830\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0611 - mean_absolute_error: 0.1830\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0746 - mean_absolute_error: 0.1830\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0693 - mean_absolute_error: 0.1829\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0680 - mean_absolute_error: 0.1829\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0643 - mean_absolute_error: 0.1828\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0588 - mean_absolute_error: 0.1827\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0501 - mean_absolute_error: 0.1827\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0432 - mean_absolute_error: 0.1826\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0623 - mean_absolute_error: 0.1825\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0482 - mean_absolute_error: 0.1824\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0435 - mean_absolute_error: 0.1823\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0469 - mean_absolute_error: 0.1823\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0347 - mean_absolute_error: 0.1822\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0335 - mean_absolute_error: 0.1821\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0459 - mean_absolute_error: 0.1819\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0353 - mean_absolute_error: 0.1819\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0291 - mean_absolute_error: 0.1817\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0255 - mean_absolute_error: 0.1816\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0293 - mean_absolute_error: 0.1815\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0247 - mean_absolute_error: 0.1813\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0277 - mean_absolute_error: 0.1812\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0257 - mean_absolute_error: 0.1811\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0244 - mean_absolute_error: 0.1809\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0228 - mean_absolute_error: 0.1808\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0221 - mean_absolute_error: 0.1806\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0269 - mean_absolute_error: 0.1805\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0293 - mean_absolute_error: 0.1803\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1543 - mean_absolute_error: 0.1803\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1324 - mean_absolute_error: 0.1804\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1064 - mean_absolute_error: 0.1804\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1205 - mean_absolute_error: 0.1804\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1064 - mean_absolute_error: 0.1804\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1012 - mean_absolute_error: 0.1804\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0789 - mean_absolute_error: 0.1804\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0982 - mean_absolute_error: 0.1804\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0728 - mean_absolute_error: 0.1804\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0791 - mean_absolute_error: 0.1803\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0683 - mean_absolute_error: 0.1803\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0891 - mean_absolute_error: 0.1803\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0702 - mean_absolute_error: 0.1802\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0653 - mean_absolute_error: 0.1802\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0669 - mean_absolute_error: 0.1801\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0710 - mean_absolute_error: 0.1801\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0657 - mean_absolute_error: 0.1801\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0690 - mean_absolute_error: 0.1800\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0767 - mean_absolute_error: 0.1800\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0659 - mean_absolute_error: 0.1800\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0567 - mean_absolute_error: 0.1799\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0531 - mean_absolute_error: 0.1798\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0626 - mean_absolute_error: 0.1798\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0507 - mean_absolute_error: 0.1797\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0378 - mean_absolute_error: 0.1796\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0481 - mean_absolute_error: 0.1795\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0534 - mean_absolute_error: 0.1795\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0474 - mean_absolute_error: 0.1794\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0430 - mean_absolute_error: 0.1793\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0341 - mean_absolute_error: 0.1792\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0499 - mean_absolute_error: 0.1791\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0588 - mean_absolute_error: 0.1790\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0454 - mean_absolute_error: 0.1790\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0394 - mean_absolute_error: 0.1789\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0399 - mean_absolute_error: 0.1788\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0411 - mean_absolute_error: 0.1787\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0347 - mean_absolute_error: 0.1786\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0575 - mean_absolute_error: 0.1785\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0681 - mean_absolute_error: 0.1785\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0437 - mean_absolute_error: 0.1784\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1791 - mean_absolute_error: 0.1784\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1491 - mean_absolute_error: 0.1785\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1330 - mean_absolute_error: 0.1785\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1217 - mean_absolute_error: 0.1786\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1083 - mean_absolute_error: 0.1786\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1333 - mean_absolute_error: 0.1786\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1283 - mean_absolute_error: 0.1787\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1142 - mean_absolute_error: 0.1787\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0901 - mean_absolute_error: 0.1787\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0824 - mean_absolute_error: 0.1787\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0734 - mean_absolute_error: 0.1787\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0582 - mean_absolute_error: 0.1787\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0525 - mean_absolute_error: 0.1786\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0565 - mean_absolute_error: 0.1785\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0547 - mean_absolute_error: 0.1785\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0412 - mean_absolute_error: 0.1784\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0352 - mean_absolute_error: 0.1784\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0787 - mean_absolute_error: 0.1783\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0499 - mean_absolute_error: 0.1782\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0491 - mean_absolute_error: 0.1782\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0431 - mean_absolute_error: 0.1781\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0357 - mean_absolute_error: 0.1780\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0392 - mean_absolute_error: 0.1779\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0344 - mean_absolute_error: 0.1779\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0322 - mean_absolute_error: 0.1778\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0268 - mean_absolute_error: 0.1777\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0249 - mean_absolute_error: 0.1776\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0243 - mean_absolute_error: 0.1775\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0261 - mean_absolute_error: 0.1774\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0225 - mean_absolute_error: 0.1773\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0204 - mean_absolute_error: 0.1771\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0191 - mean_absolute_error: 0.1770\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0199 - mean_absolute_error: 0.1769\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0225 - mean_absolute_error: 0.1768\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0216 - mean_absolute_error: 0.1766\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0223 - mean_absolute_error: 0.1765\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0186 - mean_absolute_error: 0.1764\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0173 - mean_absolute_error: 0.1763\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0217 - mean_absolute_error: 0.1762\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0224 - mean_absolute_error: 0.1760\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1843 - mean_absolute_error: 0.1760\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1417 - mean_absolute_error: 0.1761\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1224 - mean_absolute_error: 0.1761\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1066 - mean_absolute_error: 0.1762\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1001 - mean_absolute_error: 0.1762\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0899 - mean_absolute_error: 0.1762\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0866 - mean_absolute_error: 0.1762\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0860 - mean_absolute_error: 0.1762\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1030 - mean_absolute_error: 0.1762\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0737 - mean_absolute_error: 0.1762\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0786 - mean_absolute_error: 0.1761\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0682 - mean_absolute_error: 0.1761\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0563 - mean_absolute_error: 0.1761\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0567 - mean_absolute_error: 0.1760\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0567 - mean_absolute_error: 0.1760\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0916 - mean_absolute_error: 0.1760\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0663 - mean_absolute_error: 0.1759\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0573 - mean_absolute_error: 0.1759\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0716 - mean_absolute_error: 0.1759\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0561 - mean_absolute_error: 0.1758\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0420 - mean_absolute_error: 0.1758\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0500 - mean_absolute_error: 0.1757\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0544 - mean_absolute_error: 0.1757\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0353 - mean_absolute_error: 0.1756\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0357 - mean_absolute_error: 0.1755\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0277 - mean_absolute_error: 0.1754\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0357 - mean_absolute_error: 0.1753\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0315 - mean_absolute_error: 0.1753\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0390 - mean_absolute_error: 0.1752\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0392 - mean_absolute_error: 0.1751\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0277 - mean_absolute_error: 0.1750\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0243 - mean_absolute_error: 0.1749\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0304 - mean_absolute_error: 0.1748\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0285 - mean_absolute_error: 0.1747\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0365 - mean_absolute_error: 0.1746\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0288 - mean_absolute_error: 0.1745\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0312 - mean_absolute_error: 0.1744\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0215 - mean_absolute_error: 0.1743\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0233 - mean_absolute_error: 0.1742\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0191 - mean_absolute_error: 0.1741\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1723 - mean_absolute_error: 0.1741\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1285 - mean_absolute_error: 0.1741\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1310 - mean_absolute_error: 0.1742\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1103 - mean_absolute_error: 0.1742\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1052 - mean_absolute_error: 0.1742\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0920 - mean_absolute_error: 0.1742\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0727 - mean_absolute_error: 0.1742\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0871 - mean_absolute_error: 0.1742\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0957 - mean_absolute_error: 0.1742\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0847 - mean_absolute_error: 0.1742\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0907 - mean_absolute_error: 0.1742\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0852 - mean_absolute_error: 0.1742\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0778 - mean_absolute_error: 0.1742\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0627 - mean_absolute_error: 0.1742\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0521 - mean_absolute_error: 0.1741\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0561 - mean_absolute_error: 0.1741\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0512 - mean_absolute_error: 0.1741\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0538 - mean_absolute_error: 0.1740\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0445 - mean_absolute_error: 0.1740\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0390 - mean_absolute_error: 0.1739\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0360 - mean_absolute_error: 0.1738\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0342 - mean_absolute_error: 0.1738\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0363 - mean_absolute_error: 0.1737\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0288 - mean_absolute_error: 0.1736\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0338 - mean_absolute_error: 0.1735\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0296 - mean_absolute_error: 0.1734\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0252 - mean_absolute_error: 0.1733\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0342 - mean_absolute_error: 0.1732\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0333 - mean_absolute_error: 0.1732\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0240 - mean_absolute_error: 0.1731\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0237 - mean_absolute_error: 0.1730\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0336 - mean_absolute_error: 0.1729\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0299 - mean_absolute_error: 0.1728\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0437 - mean_absolute_error: 0.1727\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0295 - mean_absolute_error: 0.1727\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0257 - mean_absolute_error: 0.1726\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0244 - mean_absolute_error: 0.1725\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0205 - mean_absolute_error: 0.1724\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0221 - mean_absolute_error: 0.1723\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0231 - mean_absolute_error: 0.1722\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1851 - mean_absolute_error: 0.1722\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1489 - mean_absolute_error: 0.1723\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1289 - mean_absolute_error: 0.1723\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1138 - mean_absolute_error: 0.1724\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1158 - mean_absolute_error: 0.1724\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0910 - mean_absolute_error: 0.1724\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0903 - mean_absolute_error: 0.1724\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0869 - mean_absolute_error: 0.1724\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0727 - mean_absolute_error: 0.1724\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0614 - mean_absolute_error: 0.1724\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0531 - mean_absolute_error: 0.1724\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0567 - mean_absolute_error: 0.1724\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0625 - mean_absolute_error: 0.1723\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0539 - mean_absolute_error: 0.1723\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0558 - mean_absolute_error: 0.1723\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0712 - mean_absolute_error: 0.1723\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0572 - mean_absolute_error: 0.1722\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0448 - mean_absolute_error: 0.1722\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0477 - mean_absolute_error: 0.1722\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0350 - mean_absolute_error: 0.1721\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0394 - mean_absolute_error: 0.1720\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0498 - mean_absolute_error: 0.1720\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0359 - mean_absolute_error: 0.1719\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0290 - mean_absolute_error: 0.1719\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0378 - mean_absolute_error: 0.1718\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0321 - mean_absolute_error: 0.1717\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0422 - mean_absolute_error: 0.1716\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0620 - mean_absolute_error: 0.1716\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0405 - mean_absolute_error: 0.1716\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0508 - mean_absolute_error: 0.1715\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0344 - mean_absolute_error: 0.1715\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0264 - mean_absolute_error: 0.1714\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0299 - mean_absolute_error: 0.1713\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0299 - mean_absolute_error: 0.1712\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0307 - mean_absolute_error: 0.1712\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0632 - mean_absolute_error: 0.1711\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0408 - mean_absolute_error: 0.1711\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0442 - mean_absolute_error: 0.1710\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0342 - mean_absolute_error: 0.1710\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0315 - mean_absolute_error: 0.1709\n",
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1335 - mean_absolute_error: 0.1709\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1131 - mean_absolute_error: 0.1709\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0989 - mean_absolute_error: 0.1710\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0948 - mean_absolute_error: 0.1710\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0951 - mean_absolute_error: 0.1710\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0598 - mean_absolute_error: 0.1710\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0584 - mean_absolute_error: 0.1710\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0539 - mean_absolute_error: 0.1709\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0466 - mean_absolute_error: 0.1709\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0413 - mean_absolute_error: 0.1709\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0394 - mean_absolute_error: 0.1708\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0456 - mean_absolute_error: 0.1708\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0316 - mean_absolute_error: 0.1707\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0325 - mean_absolute_error: 0.1706\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0317 - mean_absolute_error: 0.1706\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0349 - mean_absolute_error: 0.1705\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0361 - mean_absolute_error: 0.1704\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0258 - mean_absolute_error: 0.1704\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0250 - mean_absolute_error: 0.1703\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0273 - mean_absolute_error: 0.1702\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0244 - mean_absolute_error: 0.1701\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0283 - mean_absolute_error: 0.1700\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0241 - mean_absolute_error: 0.1700\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0263 - mean_absolute_error: 0.1699\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0353 - mean_absolute_error: 0.1698\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0254 - mean_absolute_error: 0.1697\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0252 - mean_absolute_error: 0.1696\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0196 - mean_absolute_error: 0.1696\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0194 - mean_absolute_error: 0.1695\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0177 - mean_absolute_error: 0.1694\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0174 - mean_absolute_error: 0.1693\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0160 - mean_absolute_error: 0.1692\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0171 - mean_absolute_error: 0.1691\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0182 - mean_absolute_error: 0.1690\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0166 - mean_absolute_error: 0.1689\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0182 - mean_absolute_error: 0.1688\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0161 - mean_absolute_error: 0.1687\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0167 - mean_absolute_error: 0.1686\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0170 - mean_absolute_error: 0.1685\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0131 - mean_absolute_error: 0.1683\n"
     ]
    }
   ],
   "source": [
    "history_all = []\n",
    "for i in range(20):\n",
    "    index = np.array(random.sample(range(0,229120),1000))\n",
    "    index.sort()\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    #normalization through all images\n",
    "    #raw_image = hf[\"image\"][index]\n",
    "    #label = hf[\"specz\"][index]\n",
    "    #raw_image = np.transpose(raw_image,(0,2,3,1))\n",
    "    #log_image = np.log(raw_image+14.2354765) #the minimum of pixel value is -13.2354765.\n",
    "    #x = np.true_divide(log_image,6.331177841002785)\n",
    "    #y = label\n",
    "    \n",
    "    \n",
    "    #normalization per batch\n",
    "    #raw_image = hf[\"image\"][index]\n",
    "    #label = hf[\"specz\"][index]\n",
    "    #raw_image = np.transpose(raw_image,(0,2,3,1))\n",
    "    #image_min = np.min(raw_image)\n",
    "    #log_image = np.log(raw_image-image_min+1)\n",
    "    #x = np.true_divide(log_image,(np.max(log_image)))\n",
    "    #y = label\n",
    "    \n",
    "    #normalization per image \n",
    "    for j in index:\n",
    "        \n",
    "        raw_image = hf[\"image\"][j]\n",
    "        label = hf[\"specz\"][j]\n",
    "        raw_image = np.transpose(raw_image,(1,2,0))\n",
    "        image_min = np.min(raw_image)\n",
    "        rescale_image = raw_image+np.full((127,127,5),1-image_min)\n",
    "        log_image = np.log(rescale_image)\n",
    "        norm_image = np.true_divide(log_image,(np.max(log_image)))\n",
    "        x.append(norm_image)\n",
    "        y.append(label)\n",
    "    \n",
    "    x_train = np.array(x)\n",
    "    y_train = np.array(y)\n",
    "    \n",
    "    #image augmentation\n",
    "    \n",
    "    #datagen = ImageDataGenerator(rotation_range=180)\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    history = model.fit(x_train, y_train,epochs=40,shuffle = True,verbose=1)\n",
    "    history_all.append(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9180cbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_ = []\n",
    "for i in range(len(history_all)):\n",
    "    history_.append(history_all[i].history['loss'])\n",
    "\n",
    "history_ = np.array(history_)\n",
    "history_ = history_.reshape(800)\n",
    "plt.plot(history_, label='train')\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim([0,0.6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8617d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "#normalization through all images\n",
    "#index = np.arange(242000,244000)\n",
    "#raw_image_test = hf[\"image\"][index]\n",
    "#label_test = hf[\"specz\"][index]\n",
    "#raw_image_test = np.transpose(raw_image_test,(0,2,3,1))\n",
    "#log_image_test = np.log(raw_image_test+14.2354765) #the minimum of pixel value is -13.2354765.\n",
    "#x_test = np.true_divide(log_image_test,6.331177841002785)\n",
    "#y_test = label_test\n",
    "\n",
    "#normalization per batch\n",
    "\n",
    "\n",
    "for i in range (244000,247000):\n",
    "    raw_image = hf[\"image\"][i]\n",
    "    label = hf[\"specz\"][i]\n",
    "    raw_image = np.transpose(raw_image,(1,2,0))\n",
    "    image_min = np.min(raw_image)\n",
    "    log_image = np.log(raw_image-image_min+1)\n",
    "    norm_image = np.true_divide(log_image,(np.max(log_image)))\n",
    "    x_test.append(norm_image)\n",
    "    y_test.append(label)       \n",
    "    \n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70a2ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = model.predict(x_test)\n",
    "y_test_prediction = []\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    y_test_prediction.append(y_test_predict[i][0])\n",
    "\n",
    "y_test_prediction = np.asarray(y_test_prediction)\n",
    "\n",
    "y_test_ = []\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    y_test_.append(y_test[i][0])\n",
    "\n",
    "y_test_ = np.asarray(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c839a478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zspec_bin</th>\n",
       "      <th>count</th>\n",
       "      <th>L</th>\n",
       "      <th>bias_bw</th>\n",
       "      <th>bias_conv</th>\n",
       "      <th>scatter_bw</th>\n",
       "      <th>scatter_conv</th>\n",
       "      <th>outlier_bw</th>\n",
       "      <th>outlier_conv</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 4.0]</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.377607</td>\n",
       "      <td>0.089876</td>\n",
       "      <td>0.088113</td>\n",
       "      <td>0.124474</td>\n",
       "      <td>0.117144</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.182772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    zspec_bin  count         L   bias_bw  bias_conv  scatter_bw  scatter_conv  \\\n",
       "0  (0.0, 4.0]   3000  0.377607  0.089876   0.088113    0.124474      0.117144   \n",
       "\n",
       "   outlier_bw  outlier_conv       mse  \n",
       "0       0.065         0.369  0.182772  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from photoz_utils import *\n",
    "y_test_new = pd.Series(y_test_)\n",
    "y_test_predict_new = pd.Series(y_test_prediction)\n",
    "get_point_metrics(y_test_predict_new,y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd504a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "xy = np.vstack([y_test_,y_test_prediction])\n",
    "z = gaussian_kde(xy)(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c59788e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7dc46836d0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "fig, ax = plt.subplots()\n",
    "ax_ = ax.scatter(y_test, y_test_prediction, c=z,s = 1,edgecolor=None, norm=matplotlib.colors.LogNorm())\n",
    "plt.colorbar(ax_)\n",
    "plt.xlabel('spectroscopic redshift')\n",
    "plt.ylabel('photo z')\n",
    "plt.plot([.18,1.6*2.4],[0,1.2*2.4], color='black')\n",
    "plt.plot([0, 1.6 * 2.4], [.15, 2 * 2.4],color = 'black')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
